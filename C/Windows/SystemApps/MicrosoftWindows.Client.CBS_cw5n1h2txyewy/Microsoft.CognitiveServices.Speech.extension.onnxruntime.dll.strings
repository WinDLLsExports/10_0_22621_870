      
        
          
            
                
                    output = Div (X_Exp, X_ReduceSum)
                    output = Sub (X_Sub, X_Log)
                    X_Exp = Exp (X_Sub)
                    X_Log = Log (X_ReduceSum)
                    X_ReduceSum = ReduceSum <keepdims = 1> (X_Exp, axes)
                    X_Sub = Sub (input, X_ReduceMax)
                cond_out = Identity (cond)
                current = Add (prev, delta)
                CX = Mul (C, X)
                ERFCX = Erf (CX)
                ERFCXPlus1 = Add (ERFCX, One)
                PhiX = Mul (ERFCXPlus1, Half)
                range = Identity (prev)
                T1 = Mul (X_bias, X_bias)
                T2 = Mul (c, T1)
                T3 = Add (b, T2)
                T4 = Mul (X_bias, T3)
                T5 = Tanh (T4)
                T6 = Add (one, T5)
                T7 = Mul (X_bias, T6)
                Y = Mul (a, T7)
                Y = Mul (X, PhiX)
              }>
              <body = loop_body_attribute (int64 i, bool cond, prev) => (cond_out, current, range) {
            C = Or (O1, O2)
            ceil_result = Ceil (div_result)
            ceil_result_relu = Relu (ceil_result)
            ceil_result_relu_bool = Cast <to = 9> (ceil_result_relu)
            ceil_result_relu_int = Cast <to = 7> (ceil_result_relu)
            delta_casted = Cast <to = 1> (delta)
            div_result = Div (sub_result_casted, delta_casted)
            Elu_Result = Elu <alpha = 1.0>(X_alpha)
            HS_X = HardSigmoid<alpha = 0.16666667163372, beta = 0.5>(X) 
            loss = Div (loss_sum, weight_gather_sum)
            loss_sum = ReduceSum <keepdims = 0> (loss_Ndd)
            O1 = Greater (A, B)
            O1 = Less (A, B)
            O2 = Equal (A, B)
            sub_result = Sub (limit, start)
            sub_result_casted = Cast <to = 1> (sub_result)
            variadic_output, output = Loop (ceil_result_relu_int, ceil_result_relu_bool, start)
            weight_gather_sum = ReduceSum <keepdims = 0> (weight_gather)
            X_alpha = Div (X, alpha)
            Y = Mul (alpha, Elu_Result)
            Y = Mul (X, HS_X)
           Clipped_ZeroPoint_FP = Clip (Initial_ZeroPoint_FP, Q_Min, Q_Max)
           Initial_ZeroPoint_FP = Sub (Q_Min, Min_Scaled)
           Min_Scaled = Div (X_Min_Adjusted, Scale)
           Q_Max = Constant<value = float {255.0}>()
           Q_Min = Constant<value = float {0.0}>()
           Rounded_ZeroPoint_FP = Round (Clipped_ZeroPoint_FP)
           Scale = Div (X_Range, Q_Max)
           X_Max = ReduceMax <keepdims = 0> (x)
           X_Max_Adjusted = Max (X_Max, Q_Min)
           X_Min = ReduceMin <keepdims = 0> (x)
           X_Min_Adjusted = Min (X_Min, Q_Min)
           X_Range = Sub (X_Max_Adjusted, X_Min_Adjusted)
           y = QuantizeLinear (x, Scale, Zeropoint)
           y_scale = Identity (Scale)
           y_zero_point = Identity (Zeropoint)
           Zeropoint = Cast <to = 2> (Rounded_ZeroPoint_FP)
          {
          }
          E_Xsquared = ReduceMean <axes : ints = @axes> (X_squared)
          Epsilon = Constant <value = float {1e-9}>()
          EX_squared = Pow (X_RM, Exponent)
          Exponent = Constant <value = float {2.0}>()
          Processed_STD = Add (STD, Epsilon)
          STD = Sqrt (Variance)
          Variance = Sub (E_Xsquared, EX_squared)
          X_RM = ReduceMean <axes : ints = @axes> (X)
          X_squared = Pow (X, Exponent)
          X_variance = Sub (X, X_RM)
          Y = Div (X_variance, Processed_STD)
        {
        }
        X_Log = Reshape (X_LogSM_NCD, X_shape)
        X_LogSM = LogSoftmax <axis = 2> (X_NDC)
        X_LogSM_NCD = Transpose <perm = [0, 2, 1]> (X_LogSM)
        X_NCD = Reshape (scores, Shape3D)
        X_NDC = Transpose <perm = [0, 2, 1]> (X_NCD)
        X_shape = Shape (scores)
      const_zero_target_typed = Sub (expanded_target, expanded_target)
      expanded_target_int64 = Cast <to = 7> (expanded_target)
      input_gather_element = GatherElements <axis = 1> (input, expanded_target)
      loss_N1dd = Slice (loss_NCdd, const_zero, const_one, const_one)
      loss_NCdd = Neg (input_gather_element)
      mask = Equal (expanded_target_int64, const_ignore_index)
      transform_targets = Where (mask, const_zero_target_typed, expanded_target)
  - Ct = ft (.) Ct-1 + it (.) ct
  - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)
  - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)
  - Ht = (1 - zt) (.) ht + zt (.) Ht-1
  - Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)
  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0
  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0
  - Ht = ot (.) h(Ct)
  - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)
  - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)
  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)
  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)
  (NOTE: Below are optional)
  Affine(x)              - alpha*x + beta
  Chunk
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  Free 
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  Relu(x)                - max(0, x)
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0
  shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
  shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
  shape(A) = (2, 3, 4, 5), shape(B) = (5,)
  Sigmoid(x)             - 1/(1 + e^{-x})
  Size: 
  Softplus(x)            - log(1 + e^x)
  Softsign(x)            - x/(1 + |x|)
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  ThresholdedRelu(x)     - x if x >= alpha else 0
 !!"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$%&&&&&&&&&&&&'&&()))*f
 !"#$%&'()*+,-./0123
 != mat_h:
 "]AS
 (actual) rounded_bytes:
 (domain: 
 (node 
 (node_version: 
 (requested) num_bytes: 
 ) is different from what is supplied (
 , or optional typed entities
 , or sparse tensors
 . Got: 
 ."^&
 @forward
 | in_use: 
 | Requested Size: 
 <"n$
 = Constant()
 > dense_size: 
 0"^&
 6"* ]
 A\_[
 A^][
 A^^[
 A^^]
 A^_[
 A^_^
 A^_^][
 A^A\_
 A^A]A\_]
 A_^]
 A__]
 A__^
 A__^][
 A_A\_^]
 A_A]A\
 A_A]A\_^
 A_A]A\_^][
 A_A^]
 A_A^^
 A_A^^][
 A_A^_
 A_A^_][
 A_A^_^]
 A_A^A\
 A_A^A\^[
 A_A^A\_^
 A_A^A\_^][
 A_A^A]_^][
 A_A^A]A\^
 A_A^A]A\_
 A_A^A]A\_^]
 Actual:
 already exist.
 already exists.
 and 
 and are not expected to remain in the graph post partitioning. This is a bug in layout transformer.
 and Output 
 and type (
' appeared multiple times.
 appears in graph inputs and will not be treated as constant value/weight. 
 are '0' and '1'. 
 are '0' and '1'. The environment variable contained the value: 
 arena_extend_strategy: 
 as all the graph nodes have not been partitioned to the CUDA EP.
 as it still has output edges.
 as the model has control flow nodes which can't be supported by CUDA Graphs.
 at line 
 at NodeArg "
' attribute.
 Attribute:
 axis value 
 Axis=
 b"4$(&$(( l
 b"4*(,$(( d
 b.* 
 BackUp() can only be called after Next().
 because the CPU execution path is deemed faster than overhead involved with execution on other EPs 
 BFC Arena shrunk by 
 bins of max chunk size 
 broadcasting: (
 but different TensorProto.
 but expected 
 but input '
 but is of type: 
 but subgraphs produce 
 but the actually size is: 
 but the node in the model has the following type (
 but usage of initializer in graph expects 
 bytes for 
 bytes has max bytes of 
 bytes were able to be read.
 bytes.
 bytes. 
 can not be writen into Tensor type 
 cannot be safely updated to 
 Can't back up over more bytes than were returned by the last call to Next().
 capable of executing this node
 chunks of size 
 column: 
 combination in the memory arena shrink list: 
 combination is not an arena based allocator: 
 constraint was not found for 
 CUDA Graph for this model with tag: 
 data_type: 
 DeviceId:
 did not return correct number of compiled functions
 did not.
' dimension 
 Dimension=
 dimensions or more but input had shape of 
 dimensions.
 does not align with rank of input data: 
 does not contain a graph.
 does not match actual shape of 
 does not match existing output type of 
 does not match rank 
 does not match the actual size
 does not match the equation indices.
 does not match type of output: 
 does not match. 
 does not specify a valid type.
 does not.
 doesn't have an implementation that can cache computed pre-packed weights
 doesn't have an implementation that can consume provided pre-packed weights
' doesn't support memcpy 
 dst_size: 
 elements.
 else=
 Encountered following errors: (
 entries which doesn't match the number of fetches the frame was initialized with of 
 error message: 
 exceeded maximum protobuf size of 2GB: 
 Expected 
 expected size 
 expected to be of type: 
 expected to have map type
 expected to have optional type
 expected to have rank 
 expected to have rank >
 expected to have sequence type
 expected to have tensor or sparse tensor type
 expected to have tensor or sparse tensor type. Got: 
 expected to have tensor or sparse tensor type: 
 expected to have tensor or sparse type
 expected to have tensor type
 expected to have type but instead is null
 expected to have: 
 Expected: 
 ExplicitInputs:
 F".$
 fail, errcode = 
 fail: unexpected end
 failed
' failed
 failed.
 failed. Error:
 failed. File doesn't exist
 failed. Only 
 failed:
 failed: 
 for attribute 
 for operator 
 for output 
 for SizeFromDimension. Tensor has 
 for the following indices
 for transformer 
 got: 
 Got: 
 Graph may not conform to the ONNX spec and contain initializers that are not graph inputs.
 group: 
 H".$,
 H"@$
 H;|$@
 H;|$p
 H3E H3E
 has already been loaded.
 has already been registered.
' has been deprecated since version 
' has been used as graph input names multiple times.
' has been used as output names multiple times.
' has element type 
 has inconsistent type 
 has length of 
 has mismatched dimensions of 
 has rank 
 has unknown expected type
 has unsupported type 
 Hc*L
 Hc:H
 HcD$PI
 Hcl$PI
 However the types are incompatible.
 Implicit input name 
 ImplicitInputs:
 in 'Constant' node '
' in custom op '
 in function opset imports.
 in initializer but not in graph input
 in KernelRegistryManager
 in library, error code: 
 in node 
 in node (
 in one of the subgraphs.
 in the supported version range
 Index:
 index: 
 index=
 inferred=
 initial_growth_chunk_size_bytes: 
 initializer name is not unique
 Input shape=
 input with name 
 Input=
 inputs and requires 
 inputs but 
 inputs but Scan was only given 
 inputs but subgraph has 
 inputs. Either provide all subgraph inputs, or just the required inputs.
' instead of '
 into softmax(input + bias)
 is defined.
 is deprecated in domain_version of 
' is expected to have field 'floats'
' is expected to have field 'g'
' is expected to have field 'graphs'
' is expected to have field 'ints'
' is expected to have field 'sparse_tensor'
' is expected to have field 'strings'
' is expected to have field 't'
' is expected to have field 'tensors'
' is expected to have field 'type_proto'
' is expected to have field 'type_protos'
 is invalid for a tensor of rank 
 is invalid.
 is marked single but has an empty string in the graph
 is missing type info.
' is missing.
 is missing. Invalid ORT format model.
' is not a graph input, initializer, or output of a previous node.
 is not a registered function/op
 is not a valid date
 is not a valid day
 is not a valid year
 is not compatible with 
 is not currently registered or supported
 is not expected to be of type sparse tensor.
 is not expected to be of type tensor sequence.
 is not expected to be of type tensor.
 is not found
' is not found
 is not found or is not constant initializer.
 is not implemented
 is not in valid range [-
 is not output of any previous nodes.
 is not present.
 is not supported
 is not supported currently
 is not supported.
 is not the same as this node's index:
 is not used by any node.
 is null
 is null. Invalid ORT format model.
 is null. Type info is expected.
 is out of bounds.
 is outside range.
 is repeated.
 is required but missing.
 is required to be non-empty.
 is smaller than requested bytes of 
 is till opset 
 is undefined so it cannot be parsed.
 is under development and support for this is limited. The operator schemas and or other functionality could possibly change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
 is used by node 
 it.second=
 kernel channels: 
 kernel is not supported in 
 kernel start version: 
 kernel_end_version: 
 kernel_shape: 
 known by the checker.
 L"4$2
 line 
 Max:
 max_dead_bytes_per_chunk: 
 memory limit: 
 MemoryType:
 message of type "
 Microsoft Corporation. All rights reserved.
 Microsoft Operations Puerto Rico1
' Model is invalid.
 model may run depending upon legacy support of some older opset version operators.
 must be 1 instead of 
 must be either specified in graph inputs or graph initializers.
 must be equal to or twice the values size: 
 must be less than total buffer size: 
 must be within the inclusive range [
 must have shape {
 N"6$4,
 node '
 node. Name:'
 node_version: 
' not found
 not found.
 not in allowed input sizes.
 not in allowed output sizes.
 not in range [min=
 not specified
 Num entries in 'split' (must equal number of outputs) was 
 NumOutputs=
' of 
' of input parameter (
 of node 
' of node: 
 of size 
 Op Type: 
 Operating System
 optype 
' optype 
 optype:
' OpType:
 OpType: 
 or UNDEFINED. Got: 
 OrtAllocatorType:
 OrtMemType:
 out of bounds for shape 
 outputs but Scan expects 
 outputs which doesn't match the subgraph's 
 outputs.
 outputs. Expected 
 Parameter to BackUp() can't be negative.
 Please fix either the inputs or the model.
 provided for op: 
 Provider: [
 R"2  $
 referenced by function body node 
 Requested shape:
 returned nullptr
 rows: 
 should be of integer type and specify a type.
' should be stored in field '
 should specify a shape
 size: 
 size=
' source:
 source=
 sparse initializer name is not unique across initializers and sparse_initializers
' Status Message: 
 Sum of sizes in 'split' (must equal size of selected axis) was 
 sum of split values=
 t"n$B&I
 t]I;
 t1H;
 target:
 target=
 Target=
 Tensor=
 tgH;
' the model will use the latest encountered initializer
 the same as values size: 
 The total allocated bytes is now 
 then=
 This op has been implemented only for the following types (
 to be equal to values blocks: 
 to device type: 
 to have different number of elements
 type: 
 typestr: 
 unknown
 used in the node: 
 V"P$
 value of 'save' is only valid when saving an ORT format model.
 Value=
 values, but NNZ is 
- Version 16 adds bfloat16 to the types allowed (for the second and third parameter).
 Version mismatch.
 version: 
 was 
' was 
 was false.
 was not
 was not a tensor.
 were provided
 were provided.
 which is of op type: 
 Windows
 with domain: 
 with domain_version of 
 with following configs: initial_chunk_size_bytes: 
 X",$
 X$b&:(
!(it.GetName().empty())
!]_0t
!ba|H
!c->in_use() && (c->bin_num != kInvalidBinNum)
!c->in_use() && (c->bin_num == kInvalidBinNum)
!c1->in_use() && !c2->in_use()
!chunk->in_use()
!current_parallel_section
!found
!graph.GetInitializedTensor(new_initializer.name(), existing)
!has_axes || attr_axes_.size() == attr_starts_.size()
!helper.HaveTwoTensorInputs()
!input_tensor.IsDataType<std::string>()
!is_concrete_shape_
!IsNonTensor(*node_output)
!node_consumers.empty()
!op_type.empty()
!points_.empty()
!sum_input_moved
!This program cannot be run in DOS mode.
!TkjE
!using_counters_
!utils::HasExternalData(t_proto)
" : "
" because it is missing required fields: 
" when trying to load "
"""""""
"$$H2
"($t&*$q
", "block_size": [
", index: 
"^$,&
"^$,4
"^&^*^.00V4J
"args" : {
"bQ}X
"core": 
"dur" :
"H$,&&(**h
"J&j(:*
"L*("
"L<0"
"name" :"
"num_run": 
"p$v&,(
"ph" : "X",
"pid" :
"t$"&6(&&
"t$,&"($*
"thread_id": "
"thread_pool_name": "
"tid" :
"ts" :
"X$,&
#bAmX
#bQ}X
$$L;g8
$$L;T$`
$@ba~H
$@bA~H
$@ba~H
$]Y`H
$0bR~J
$0Z(\,^^`tbRdbf`hPjrvPr4p>n
$4&(($*(,*$|
$B&,$
$b&,(
$B&r(
$f(j*
$H9D$0
$Iba|H
$IbB}H
$L&.(,
$L&z()
$L;l$P
$L;t$8
$n&v$D(
$Nba|H
$qbB~J
$R&R(8*6"
$V&V((*
%hs!%p: 
%hs(%d) tid(%x) %08X %ws
%hs(%u)\%hs!%p: 
%Y-%m-%d_%H-%M-%S
&@((*$,
&\(,0
&|(N6
&8("*$,(.
&f>j@
&H(,*",*.
&H(,*",P.6,
&j#fi
&l(8*
&n(t*,,
&R(2& *
&S|9a
&T*n,\.42
&TpxAD
&V(4&t,0*
&X(R*l,X.R0
("*j"D
("2L4
($*("
(%A25
(%z]'
(.@.B
(@*(,$.(0"(
(\$@D
(\$`D
(\$PD
(\$PH
(_^][
(|$ D
(|$ H
(|$ I
(|$@f
(|$@H
(|$@I
(|$`D
(|$`E
(|$`H
(|$0D
(|$0f
(|$0H
(|$0I
(|$PD
(|$PH
(|$pH
(|$PH
(|$PI
(|$pL
(~*",
(~*x,
(=?~&
(=@N3
(=[15
(=Cu&
(=U05
(=v'3
(4b6E
(5.N3
(5'~&
(5+u&
(5305
(5J15
(5pP3
(5u]'
(A]_^[
(A^^][
(A^_][
(A^_^[
(A^A\_^][
(A^A]A\[
(A_^][
(A__^[
(A_A^
(A_A^][
(A_A^_^][
(A_A^A]A\_^][
(bQ}X
(caller: %p) 
(cannot determine missing fields for lite message)
(channels % 4) == 0
(D$ D
(D$ f
(D$ H
(D$ I
(D$ L
(D$ M
(D$ O
(D$@f
(D$@H
(d$`D
(D$`D
(d$`D
(D$`D
(d$`D
(D$`D
(d$`D
(D$`f
(d$`H
(D$0A
(d$0D
(D$0f
(D$0H
(D$0I
(D$0L
(d$PD
(D$PD
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pH
(D$PH
(float, default 0.5) the ratio of random dropout
(H*4,2F
(H;l$0
(HcA(
(inputs_.size() - 1) == i
(int, default 0) if nonzero, run dropout in test mode where the output is simply Y = X.
(L$ A
(l$ D
(L$ D
(l$ L
(l$@D
(L$@f
(L$@H
(L$`D
(L$`f
(L$0A
(L$0D
(L$0f
(L$0H
(L$pD
(l$pD
(L$Pf
(L$pf
(L$pH
(L*@,
(L;|$`L
(line: 
(local_source >= source) && (local_source < source + num_blocks * blocksize)
(local_source >= source) && (local_source < source + num_blocks * num_elts_in_block)
(local_source >= source) && (local_source < source + num_blocks)
(local_source >= source) && (local_source < source + sizeof(T) * num_blocks)
(null)
(op_type:
(Optional) A scalar or rank 1 tensor containing a single value to be filled if the mode chosen is `constant` (by default it is 0.0).
(Optional) A scalar value to be used if the mode chosen is `constant` (by default it is 0).
(Optional) A scalar value to be used if the mode chosen is `constant` (by default it is 0, empty string or False).
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor.
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor. Negative value means counting dimensions from the back. Accepted range is [-r-1, r] where r = rank(indices).
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected.
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
(Optional) By default, when any value in the 'shape' input is equal to zero the corresponding dimension value is copied from the input tensor dynamically. allowzero=1 indicates that if any value in the 'shape' input is set to zero, the zero value is honored, similar to NumPy.
(Optional) Ending axis for slicing the shape. Negative value means counting dimensions from the back. If omitted, sizes of all axes upto (including) the last one will be included.
(Optional) Index of the diagonal to be populated with ones. Default is 0. If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a lower diagonal.
(Optional) Seed to the random generator, if not specified we will auto generate one.
(Optional) Specify which axis is batch axis. Must be one of 1 (default), or 0.
(Optional) Specify which axis is time axis. Must be one of 0 (default), or 1.
(Optional) Starting axis for slicing the shape. Default value is 0.Negative value means counting dimensions from the back.
(Optional) The axis of the dequantizing dimension of the input tensor. Ignored for per-tensor quantization. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
(Optional) The axis of the quantization dimension of the input tensor. Ignored for per-tensor quantization. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
(Optional) The data type for the elements of the output tensor, if not specified, we will use int32.
(Optional) The data type for the elements of the output tensor, if not specified, we will use the data type of the input tensor.
(Optional) The data type for the elements of the output tensor. If not specified,the data type of the input tensor T1 is used. If input tensor T1 is also notspecified, then type defaults to 'float'.
(Optional) The data type of the tensors in the output sequence. The default type is 'float'.
(Optional) The dimension to apply unique. If not specified, the unique elements of the flattened input are returned. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
(Optional) The value of the output elements.Should be a one-element tensor. If not specified, it defaults to a tensor of value 0 and datatype float32
(Optional) Whether map negative infinity to true. Default to 1 so that negative infinity induces true. Set this attribute to 0 if negative infinity should be mapped to false.
(Optional) Whether map positive infinity to true. Default to 1 so that positive infinity induces true. Set this attribute to 0 if positive infinity should be mapped to false.
(Optional) Whether to sort the unique elements in ascending order before returning as output. Must be one of 0, or 1 (default).
(outputs_.size() - 1) == i
(p,v.,0
(-q15
(static_cast<size_t>(X_shape[1]) < nchwc_block_size) || ((X_shape[1] % nchwc_block_size) == 0)
(t$ f
(t$ H
(t$ L
(t$ u
(T$@D
(t$@H
(T$@H
(t$@H
(t$@I
(t$@L
(t$@M
(t$`f
(t$`H
(t$`I
(t$0D
(T$0f
(t$0H
(t$0L
(T$pD
(T$PD
(t$pf
(t$PH
(T$PH
(t$pH
(t$PH
(t$PI
(t$pI
(t$PL
(t$pL
(t$PL
(t*X,(.
(T,j.~0T4j6~8T<j>~@bDjF~HFLjN:P
(Tensor<T>) where the function `f(x) = quantize(Sigmoid(dequantize(x)))`, is applied to the data tensor elementwise.
(X_shape[1] % MlasNchwcGetBlockSize()) == 0
) != new size (
) : (
) + bottom_border (
) + right_border (
) + scale[0] (
) + scale[1] (
) -> (
) and node 
) and outputs (
) and the split dimension of the input (
) are not at boundary of span with size:
) attribute (
) because the ORT planned memory location device 
) bound to different types (
) dimensions are not positive.
) does not exist in the graph.
) does not have type information set by parent node.
) does not have type information.
) does not match expected type (
) does not match the data size(
) first dimension size does not equal NNZ.
) for attribute 'axis'
) for tensor of length:
) from file 
) has 
) has input size 
) has more inputs (
) has more outputs (
) has no index values.
) has output size 
) has zero input and zero output.
) in kernel registries for 
) in node (
) in op definition.
) in proto
) index value at position [
) input arg (
) is 0-element but contains data!
) is invalid.
) is not equal to number of scan inputs (
) is not equal to number of scan outputs (
) is not equal to the existing dim value (
) is not equal to the existing rank value (
) is not supported on this device
) is required but not specified.
) is stored externally and should not have data field.
) is stored externally but doesn't have a location.
) must have a dense-rank > 0
) must have INT64 type.
) must have rank 1 or 2.
) must have rank 1.
) needs to be greater than or equal to the left_border (
) needs to be greater than or equal to the top_border (
) node with name '
) of node (
) of operator (
) of Optype (
) of output arg (
) Op (
) output arg (
) second dimension size does not match rank of tensor.
) should be stored in 
) should contain one and only one value field.
) should not be stored in raw_data field
) should not contain more than one value field.
) should refer to attribute in parent node.
) than declared (
) to UNDEFINED is not allowed
) type inference failed
) vs (
)) , expected: (
), BIsSigned(
)\$@D
)\$`D
)\$PD
)\$PJ
)|$ D
)|$ I
)|$@H
)|$@r
)|$`D
)|$`E3
)|$`H
)|$`M
)|$0A
)|$0D
)|$0H
)|$PD
)|$pH
)|$PH
)|$PI
)|$PM
)<$Mc
)4$Mc
)bQ}X
)D$ 3
)D$ A
)D$ D
)D$ f
)D$ H
)D$ L
)D$@f
)D$@H
)D$@I
)D$@L
)d$`D
)D$`D
)d$`D
)D$`D
)d$`D
)D$`D
)d$`D
)D$`f
)D$`H
)d$`J
)D$`L
)D$0A
)d$0D
)D$0D
)D$0f
)D$0H
)D$0L
)D$pD
)d$PD
)d$pD
)D$pD
)D$PD
)d$PD
)D$PD
)D$pf
)D$Pf
)D$PH
)D$pH
)D$PH
)D$pH
)D$PH
)D$pL
)D$PM
)E@Ic
)E@LcF
)l$ D
)L$ D
)l$ D
)L$ D
)l$ D
)L$ f
)L$@D
)l$@D
)L$@D
)l$@D
)L$@f
)L$@H
)L$@L
)L$`D
)l$`D
)L$`D
)L$`H
)L$`L
)L$0A
)L$0D
)L$0f
)l$pD
)L$pD
)l$pD
)L$Pf
)L$PH
)L$pH
)L$PH
)L$pH
)L$PH
)L$PL
)Microsoft Root Certificate Authority 20100
)Microsoft Root Certificate Authority 20110
)'s input 
)'s output 
)t$ f
)t$ H
)t$ I
)t$ L
)t$ M
)T$@D
)t$@H
)T$@H
)t$@H
)t$@I
)t$@I+
)t$@L
)t$@L+
)t$`H
)t$`I
)t$`Ic
)t$`L
)t$`M
)t$0D
)T$0H
)t$0H
)T$0H
)t$0I
)t$0L
)T$pD
)T$PD
)T$PE
)t$pH
)t$PH
)t$pH
)t$PH
)t$PI
)t$pI
)t$PI
)t$pI
)t$PL
)t$pL
)t$pM
)t$PM
*",0.60X2
*$,x.*,
*(6(8
**History**
*?*kXIc
*\,`2
*^,,.
*^,,8
*8,".$0((
*B,**
*H;y 
*l$hb
*L,..,(
*n&H4
*R,R.Z044
*v&^"E
, &"&$&"
, .(*0
, block in memory pattern size is: 
, but it doesn't exist or is not accessible.
, but it is already registered from file 
, but it its domain is not
, but it its version is higher
, but its domain is not
, but its version is not 
, Chunk State: 
, column 
, data shape: 
, Error 
, error code: 
, external_data.length: 
, fall back to default allocation behavior
, Got 
, got 
, has unsupported type: 
, indices shape: 
, max supported IR version: 
, max=
, next: 
, node name: 
, prev: 
, requested shape:
, type: 
,.7uS
,|.:06.9
,2.$,
,4."0$2
,6.*0
,dL@a
,f0j2
,l6\8
,V0j2:4
,X.,0
,X<j>
.  Current allocation summary follows.
'. 0 == forward. 1 == reverse.
. bin_num:
. Bytes 
. Can't constant fold 
. Dimension 0 is 
. Do you have duplicated calls to SessionState::AddInitializedTensor function?
. Error message 
'. Error message 
. Execution Provider must generate unique names across the entire model.
. Execution will fail if ORT does not have a specialized kernel for this op
. Expected:
. Falling back to lenient merge.
. Ignoring allocator from 
. Index:
. Input tensor rank was 
. Invalid ORT format model.
'. It is no longer used by any node.
'. It is not used by any node and should be removed from the model.
'. Must be one of 'forward', 'reverse', or 'bidirectional'.
. No opset import for domain
. Output tensor rank was 
. Please, fix your model.
. Shape:
. shape=
. These are temporary nodes added during layout transformations 
. Total 
. Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.
.(00.p
.?AU?$Abs@_J@functors@onnxruntime@@
.?AU?$Abs@_K@functors@onnxruntime@@
.?AU?$Abs@C@functors@onnxruntime@@
.?AU?$Abs@E@functors@onnxruntime@@
.?AU?$Abs@F@functors@onnxruntime@@
.?AU?$Abs@G@functors@onnxruntime@@
.?AU?$Abs@H@functors@onnxruntime@@
.?AU?$Abs@I@functors@onnxruntime@@
.?AU?$Abs@M@functors@onnxruntime@@
.?AU?$Abs@N@functors@onnxruntime@@
.?AU?$Celu@M@functors@onnxruntime@@
.?AU?$default_delete@VBFCArena@onnxruntime@@@std@@
.?AU?$default_delete@VCPUExecutionProvider@onnxruntime@@@std@@
.?AU?$default_delete@VIAllocator@onnxruntime@@@std@@
.?AU?$default_delete@VIExecutionProvider@onnxruntime@@@std@@
.?AU?$default_delete@VModel@onnxruntime@@@std@@
.?AU?$ElementWiseRangedTransform@_J@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@_K@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@C@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@E@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@F@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@G@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@H@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@I@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@M@functors@onnxruntime@@
.?AU?$ElementWiseRangedTransform@N@functors@onnxruntime@@
.?AU?$Elu@M@functors@onnxruntime@@
.?AU?$Exp@M@functors@onnxruntime@@
.?AU?$Exp@N@functors@onnxruntime@@
.?AU?$Floor@M@functors@onnxruntime@@
.?AU?$HardSigmoid@M@functors@onnxruntime@@
.?AU?$LeakyRelu@M@functors@onnxruntime@@
.?AU?$MaxPool1DTask@C@onnxruntime@@
.?AU?$MaxPool1DTask@E@onnxruntime@@
.?AU?$MaxPool1DTask@M@onnxruntime@@
.?AU?$MaxPool1DTask@N@onnxruntime@@
.?AU?$MaxPool2DTask@C@onnxruntime@@
.?AU?$MaxPool2DTask@E@onnxruntime@@
.?AU?$MaxPool2DTask@M@onnxruntime@@
.?AU?$MaxPool2DTask@N@onnxruntime@@
.?AU?$MaxPool3DTask@C@onnxruntime@@
.?AU?$MaxPool3DTask@E@onnxruntime@@
.?AU?$MaxPool3DTask@M@onnxruntime@@
.?AU?$MaxPool3DTask@N@onnxruntime@@
.?AU?$ParametricSoftplus@M@functors@onnxruntime@@
.?AU?$Reciprocal@M@functors@onnxruntime@@
.?AU?$Reciprocal@N@functors@onnxruntime@@
.?AU?$Relu@M@functors@onnxruntime@@
.?AU?$Relu@N@functors@onnxruntime@@
.?AU?$ScaledTanh@M@functors@onnxruntime@@
.?AU?$Selu@M@functors@onnxruntime@@
.?AU?$Sigmoid@M@functors@onnxruntime@@
.?AU?$Sigmoid@N@functors@onnxruntime@@
.?AU?$Softplus@M@functors@onnxruntime@@
.?AU?$Softsign@M@functors@onnxruntime@@
.?AU?$Sqrt@M@functors@onnxruntime@@
.?AU?$Sqrt@N@functors@onnxruntime@@
.?AU?$Tanh@M@functors@onnxruntime@@
.?AU?$Tanh@N@functors@onnxruntime@@
.?AU?$ThresholdedRelu@M@functors@onnxruntime@@
.?AU_Crt_new_delete@std@@
.?AUAction@onnxruntime@@
.?AUBinaryReplaceWithQLinear@QDQ@onnxruntime@@
.?AUConvReplaceWithQLinear@QDQ@onnxruntime@@
.?AUCpuProviderFactory@onnxruntime@@
.?AUCustomOpKernel@onnxruntime@@
.?AUDataPropagationContext@onnx@@
.?AUDataPropagationContextImpl@shape_inference@onnx@@
.?AUException@Ort@@
.?AUFunctionBodyBuildContext@onnx@@
.?AUFunctionBodyBuildContextImpl@onnx@@
.?AUGemmReplaceWithQuant@QDQ@onnxruntime@@
.?AUIExecutionProviderFactory@onnxruntime@@
.?AUInferenceContext@onnx@@
.?AUInferenceContextImpl@shape_inference@onnx@@
.?AUMatMulReplaceWithQLinear@QDQ@onnxruntime@@
.?AUMergeIntoTarget@onnxruntime@@
.?AUNode__EdgeIterator@onnxruntime@@
.?AUNode__EdgeIterator_Impl@onnxruntime@@
.?AUNode__NodeIterator@onnxruntime@@
.?AUNode__NodeIterator_Impl@onnxruntime@@
.?AUNodeAttributes_Iterator@onnxruntime@@
.?AUNodeAttributes_Iterator_Impl@onnxruntime@@
.?AUNodeCompare@onnxruntime@@
.?AUNodeSelector@onnxruntime@@
.?AUOrtAllocator@@
.?AUOrtAllocatorImpl@onnxruntime@@
.?AUOrtAllocatorImplWrappingIAllocator@onnxruntime@@
.?AUOrtDefaultCpuAllocator@@
.?AUPriorityNodeCompare@onnxruntime@@
.?AUProviderHost@onnxruntime@@
.?AUProviderHostCPU@onnxruntime@@
.?AUProviderHostCPUImpl@onnxruntime@@
.?AUProviderHostImpl@onnxruntime@@
.?AUQDQReplaceWithNew@QDQ@onnxruntime@@
.?AURemoveNodes@onnxruntime@@
.?AUReplaceWithNew@onnxruntime@@
.?AUReplaceWithNewFixed@onnxruntime@@
.?AUReplaceWithQLinear@QDQ@onnxruntime@@
.?AUSequentialExecutionPlan@onnxruntime@@
.?AUSlice1@onnxruntime@@
.?AUSlice10@onnxruntime@@
.?AUTensorShapeProto_Dimension_Iterator@onnxruntime@@
.?AUTensorShapeProto_Dimension_Iterator_Impl@onnxruntime@@
.?AUTile@onnxruntime@@
.?AUUnaryReplaceWithQLinear@QDQ@onnxruntime@@
.?AUVariadicReplaceWithQLinear@QDQ@onnxruntime@@
.?AV?$_Func_base@_JPEB_J@std@@
.?AV?$_Func_base@_N$$V@std@@
.?AV?$_Func_base@_N_K@std@@
.?AV?$_Func_base@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@2@AEAVFunctionProto@2@@std@@
.?AV?$_Func_base@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_base@_NH@std@@
.?AV?$_Func_base@_NPEBVNode@onnxruntime@@PEBV12@@std@@
.?AV?$_Func_base@CPEBC@std@@
.?AV?$_Func_base@EPEBE@std@@
.?AV?$_Func_base@HPEAUComputeContext@onnxruntime@@PEAPEAX@std@@
.?AV?$_Func_base@HPEBH@std@@
.?AV?$_Func_base@I_K@std@@
.?AV?$_Func_base@MMMM@std@@
.?AV?$_Func_base@MPEBM@std@@
.?AV?$_Func_base@NPEBN@std@@
.?AV?$_Func_base@PEBVTensorProto@onnx@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_base@U?$Offset@UNodeIndexAndKernelDefHash@fbs@onnxruntime@@@flatbuffers@@_K@std@@
.?AV?$_Func_base@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV12@AEBV12@@std@@
.?AV?$_Func_base@V?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J_J@std@@
.?AV?$_Func_base@V?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J_J@std@@
.?AV?$_Func_base@V?$shared_ptr@VIAllocator@onnxruntime@@@std@@HW4OrtMemType@@@std@@
.?AV?$_Func_base@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAVFuncManager@3@AEBVOpKernelInfo@3@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAVGraph@3@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEAVGraph@3@AEA_NAEAVIExecutionProvider@3@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBV?$span@$$CB_K@gsl@@AEBVTensor@3@AEAV63@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVNode@3@AEAVGraph@3@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV67@AEBUResolveOptions@53@@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVNodeArg@3@_K@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@AEBVTensorShape@3@AEBUOrtMemoryInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@HAEBUOrtValue@@AEBUOrtCallback@3@_N_N@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@PEAX_K@std@@
.?AV?$_Func_base@VStatus@common@onnxruntime@@PEAXPEBUOrtApi@@PEAUOrtKernelContext@@@std@@
.?AV?$_Func_base@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_base@X$$V@std@@
.?AV?$_Func_base@X_J@std@@
.?AV?$_Func_base@X_J_J@std@@
.?AV?$_Func_base@X_K_K@std@@
.?AV?$_Func_base@XAEA_JPEB_J_J@std@@
.?AV?$_Func_base@XAEACPEBC_J@std@@
.?AV?$_Func_base@XAEAEPEBE_J@std@@
.?AV?$_Func_base@XAEAHPEBH_J@std@@
.?AV?$_Func_base@XAEAMPEBM_J@std@@
.?AV?$_Func_base@XAEANPEBN_J@std@@
.?AV?$_Func_base@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_base@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_base@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_base@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_base@XI@std@@
.?AV?$_Func_base@XPEA_K@std@@
.?AV?$_Func_base@XPEAD@std@@
.?AV?$_Func_base@XPEAE@std@@
.?AV?$_Func_base@XPEAH@std@@
.?AV?$_Func_base@XPEAM@std@@
.?AV?$_Func_base@XPEAPEAUOrtValue@@@std@@
.?AV?$_Func_base@XPEAX@std@@
.?AV?$_Func_base@XPEBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$_Func_base@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV12@0@ZV12@AEBV12@AEBV12@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J1@ZV12@AEBU3@_J_J@std@@
.?AV?$_Func_impl_no_alloc@P6A?AV?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J1@ZV12@AEAU3@_J_J@std@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@AEAVFuncManager@3@AEBVOpKernelInfo@3@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@ZV123@AEAV43@AEBV53@AEAV67@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@AEAVGraph@3@AEA_NAEBVIExecutionProvider@3@@ZV123@AEAV43@AEA_NAEAV53@@std@@
.?AV?$_Func_impl_no_alloc@P6A?AVStatus@common@onnxruntime@@AEBVNode@3@AEAVGraph@3@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV67@AEBUResolveOptions@53@@ZV123@AEBV43@AEAV53@AEBV67@AEAV67@AEBU853@@std@@
.?AV?$_Func_impl_no_alloc@P6A_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@2@AEAVFunctionProto@2@@Z_NAEBU12@AEBV32@AEAV42@@std@@
.?AV?$_Func_impl_no_alloc@P6AMMMM@ZMMMM@std@@
.?AV?$_Func_impl_no_alloc@P6AXAEAUDataPropagationContext@onnx@@@ZXAEAU12@@std@@
.?AV?$_Func_impl_no_alloc@P6AXAEAUInferenceContext@onnx@@@ZXAEAU12@@std@@
.?AV?$_Func_impl_no_alloc@P6AXAEAVOpSchema@onnx@@@ZXAEAV12@@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@_J@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@_K@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@C@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@E@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@F@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@G@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@H@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@I@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Abs@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Exp@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Exp@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Floor@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$LeakyRelu@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool1DTask@C@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool1DTask@E@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool1DTask@M@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool1DTask@N@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool2DTask@C@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool2DTask@E@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool2DTask@M@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool2DTask@N@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool3DTask@C@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool3DTask@E@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool3DTask@M@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$MaxPool3DTask@N@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Reciprocal@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Reciprocal@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Relu@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Relu@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sigmoid@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sigmoid@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sqrt@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Sqrt@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Tanh@M@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@U?$Tanh@N@functors@onnxruntime@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@UNodeCompare@onnxruntime@@_NPEBVNode@2@PEBV32@@std@@
.?AV?$_Func_impl_no_alloc@UPriorityNodeCompare@onnxruntime@@_NPEBVNode@2@PEBV32@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0031e1631721c75a1f7a0e71cb748ed7>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_006f042491572090b778a6887556c541>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_00b59445cb71ad9abff9006cdec65ab0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0127cc6c89895d74380b7c79a5b9fb82>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0251dfdaad61cfa5b2a46c99b78d27e8>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_02a8234b34a60137e169504412a1f413>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_02cf852cc5a543f808433f03632ba155>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_031e8dfd8d6a123502d9ec2194443e60>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_038eb253b7f4e93118566e43dda81530>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_03c53d5c540d06d25e58298bd3e2675f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_03e7406b29b220fa131a6585ce48dcd2>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0457fc55cb15f22bdcba75f54e0aa1c1>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_048b899a3305cb2c0c070dd18e5b4d17>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_055b4d24f8a1f4b549310d8384e8330c>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_06471b7954288b9dda9f9d99a72bb7c6>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_06e28cef24f38d1ecd4447df16780ad3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_06e5eb766e97cbbd1e9836fc044820b5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0847b334bbfd42737aafe7ba61663e74>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_08b89006bb2cd45177aec966a5a64a25>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_08db83bf9ac8665fc4de47cb08668b85>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0a0326aaa0c17e1dc10459d8b6c3398c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0a3d98e003a8310444f50c395f4ee870>@@_N_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0a786afdc494302a03a8347211af4f5e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0aa1cbb10b7e27c8eaa9e1c4d936a012>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0aeb3b3202e2e34a7d6b98b623e6a327>@@XPEAM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0af4c846dd5af6632beb77ffbd6469c9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0afff8b6c40408852605b1495798325e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0b0bbca98147f2b1d98b75bc68203f51>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0b4cc153b058489c05500d0b394c47a0>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0b84cd883df2cf8f5da7751da99be58c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0ba48c1f3299a5f4228b96a5876e6f39>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0c24edbe84bc491fb6a29a020f4d3aa5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0e4160f1c09428b722c89257b1bbabcb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0e85b1a3aa4aedfca1acdf52f931b8f2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f2ad18a551e793a8bddf1de1dc21689>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f569c3741dec4cbd25547f5cfa47a1f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0f619f3ff08e9e7659a763308b991cbe>@@VStatus@common@onnxruntime@@PEAX_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_0fb4e93f4014e9a9ed52287648f86c91>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_101e0d486e161cfbbc4332cd98f3239a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_11002e821957b929b79aa649ecf0a381>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1123ca3288c22333dcfbc6780e56f3b6>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_113fc5cdb3f9f5e45a498eccec03db60>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1147aa6d38b42c0a8559813b3004180f>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_115059020db09aa13bab825ad518034e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_11c15110a2869c43f5467753b7474409>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1221b4097effa32a8dd388b4455dd2c1>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_12237f9b9f786fa2f677523e51689677>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1249aa664b6dd8c7cf40d23fbaec080e>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_13046178b359e9c81742cfc406e97a28>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_13bf14abed62c4ddb7d24aa834c66cd3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_140ab31565a9f257f202ece6453c4bfd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_147527a66291af5e3f9c1e417e66fd9c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1476157c6a284e4f379191854345eea5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_14ab4d68c965e23bff80a9edfde3b16e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1642adc2d95a594ec2d1ca1c1679605d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_165747221b83b97edb1c8980b4a934c8>@@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_16aeacf7ad4b53ba550defbc9c03abde>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_18dbcf0a6112b471cd3435637c32f0f8>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_18e0b70d8d5a276d72055cc8661094dd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_18f6d57bac34239d650ddbef707551e4>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_191f334b7e6fbfb2860cdf729a487dba>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_194fafbac36b97ada7ff78b4fe337622>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_19653ee275cc0117099f6e46319415af>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_19a25a0e0bced01a01388502a5fb897a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1a286ef6a47f06b31852d582b51b4ff5>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1abf5a492f2ce98320288d0a19f9a732>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1c47a842a4ad24719aaf09edc25c7aef>@@PEBVTensorProto@onnx@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1c511d989171b0ae840c900d36af6cdf>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1cd5cfe6b76bb3ba1c53203d58a4eedd>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1cdda74d195f4dc7bbdbaed3ee174bf7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1d718ae1c6eee88a5015989ae3eac075>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1d7aed3977eb6b0e8500a44cbf6dc587>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1e6c58f2c47fbfdcb340ca8aa595e354>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1ea1e7671a1665ca234eb6cc181c60bb>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1efd3ecb51119ba3eba8bc9319f01386>@@XAEAMPEBM_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f3bf02585dcf20edf66f391042bccc5>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f77acb4e34034b00a5a2150384c9d77>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1f8675d15ee5efaa8f5579945c6d118a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_1fd04ff7ed408ca4ebed6e8107f19670>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_20a837f51a15ec806ec07fe236459bf3>@@MPEBM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_20ce3835ea17537cf13d089eb1a443c1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_217211e0b9216fbae93bbaf0026e78ee>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_218f765d5b26dc460cf68e4f7ef3c8f7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_21f2ebef859bbaf3ad57fb860d7bd5a6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_221457049dd6e599b1e592be3898266a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_22aeb0e20ec618f43aaa785665edaa1d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2369389c848e11c0cf2fa8c55ee9bc1b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_23a1bb0478ab7117c6dff4712434f02b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_23cd650266f5b996762e121f69bcde45>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_242966bc823a6ea57016299e4846b19a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_243c848b67147a62f5be9d25d42a217b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_24ac27632a899010d1e56f7da8454199>@@_JPEB_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_253a3836eec6c1ddbcb7d28211e21bd6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_265c7b3426b87aef377811f8829e6fd7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_27a06fd9b1f731a63767571c10bf29a4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_27a631d2450c357a52927c1dfbd2efda>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2830e7879c71bbb5a2447c8cce82dc3b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_28a69d198faef3db79470de4de6f53e9>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_28c42d729a2f53041e8b22b1ed6cdff0>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_28d76a4078a4a8dbd4ec44ed08d36b25>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a3f9f19c48a100998729328075237dc>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2a976ac88d60c988f6c82762c8669484>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2ac171e27e2ef21b455a8883502f09aa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2bed918e0092d38de095a3dfcc39bb6a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2bf767e58fd6076f82b597352ebe6a94>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2bf8017c8b0b3ab5a242f82899957cda>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2cdbc5f873c2ce32c36481fab53d6870>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2d779c3a3c8b726adf3efb1bfd3cbb40>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2dc16cf30de15202e0434934c8ec0571>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2e20e62e8d812957e92321838accac54>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2f3c8dfb82c3078faed3c459500f6cd5>@@VStatus@common@onnxruntime@@AEBVTensorShape@4@AEBUOrtMemoryInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_2f4103e1c4a1773101a6c1f055d56df4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3050f982855d87e103d3099ed68136e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_30e1101d7025e2d839d1daa9ac434cd1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_310ceee0e4c58a7a83d7d00319ed9410>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33215563a6aacb86deff746a6aa28a6c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3354f944db7877754471d985be3fe29b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3361a7c3c06ae8fda0091b29a15bc377>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_337593ad4f874bae98bb3aa9ea22758d>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33763db33c7430e0074fd25b65b4479f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_339ccdd8cf9a471a2525280227358fe6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33ab9233a6e2a6fe6c24d1963cbc3111>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_33c11271a908f4f215dd361ca0be165e>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3410038a349fbad62fb0cd42ca2fc595>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3435a69bc2a4a58cf25c9601fa916799>@@XPEA_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_348952d4e8cb4d6ca40b91f67d9fe4cc>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3525a67688acab3a16549c70f50b343d>@@_N$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_368acd23d928f0f5d2e3ced50c09e50c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_36945aef9b69b8bc246158e60ded74ff>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3723f23b8a34d9d98e7ee4d14fc03d1b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_37fc46271b5a9d577e78557058b76819>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3863377c4067e3a3117e9e245fcb11f1>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3a80fca790cdb0fce14ddaedefa20351>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3aac6f1c979a8b893423e58931ed2daa>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3acaf4e71a87bfb836a528474a23b2b9>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3ad3f00f380cbc79acdede7031c2b35c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3ae9af8a84288cef25a7cf83bd0834fa>@@XAEAEPEBE_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3b70c471f0d6c3603fdf76e6ccfb54a3>@@CPEBC@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3b79ba1930d9045b1d0a1c3e7b558aa7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3b97251de202434e86d007c33f9345a1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3bf9d7b5239a137326d2c5fa821fa737>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3ce4407e5879111e6c1a6435d36077e4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3cfedd26cd9ef5f4cd0322b54223b692>@@HPEBH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3d53fdafdcab72e11f157b0377fe813b>@@VStatus@common@onnxruntime@@AEAVFuncManager@4@AEBVOpKernelInfo@4@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3e2860b55958cf532cc6672e843fd5e5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3e5e22c83296c8f56ae7effebfec7009>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3e80eabb3a9d111992ebd5907a12e903>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3f0ef66d0b0de67b55e854d697da2fff>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_3fbfdfe39393a610cb9132779b271854>@@I_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_404d0fe71cc8d7867c9f1bc290b28bbd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4092000fa2c851eb2ddefc1b6efbf1fc>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_409a8ec0de4403e02d09bb9a4b937276>@@EPEBE@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_40d7d549b7296d37bd8a375a6a32735f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_40d9bd0925a189b8d1c995cd48d17d39>@@HPEBH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_40f74427ec28f20a5d59b70a3f7ba162>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_41bb79d9c7cc8f02e2f871c5095cf1ee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_42580b4f3e49f7dcfbf37d76233bd856>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_43d76a454d7e446551a32b163679964a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4404716c35945f1da6a07154c932397d>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_44094649bc82ecb2fc1ec6afdbc202d7>@@HPEBH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_458163864faccd230ccf1ce10d3e187d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_45e1f6e47762148b282b3bb16964d9a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_46087cac4b4384e4406cfa052cc4f414>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_464e1f80ac51d01e54b77145fd34c5bb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_46f2340c6974a9abf9bf427b63a5b9bc>@@V?$shared_ptr@VIAllocator@onnxruntime@@@std@@HW4OrtMemType@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_47f0845d7b66643be4c58515f34249ea>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_486023130535c54dc87259934f24df6e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4913db8c05460fd84e03b1ef7ec1a215>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4ae79009ffed4baaf3b13205e614d6ec>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4b94da34bdfcb505ddcef5cb50b95e3d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bcb1ddbded281b4b93a8d23384ad316>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bd02c7b372889e26c922fb97a0c9ac3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4bfaa77b47cc3b72c0199e4158dcfdd3>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4c0362c3e20008eb9ad4ca148d83f23f>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4c0d5472c0e9893aea307d804bd55070>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4c81a7b179f9e26e2d05ebefbb83c381>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4cd868df938477ea9946d2d55c43c695>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4de083bd9feef97ef116b9ac6f248cfc>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4e733be9ef1a8040b2cc0e98d09e233e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4e978ba75a8a0f3f4d2d1e75d74ac4de>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4f02b89eec40e1f508d9a8a5576d7ee8>@@XAEAMPEBM_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_4f04249e04d07d50d630e12dc9f30f23>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5032e4da5cc3197800498a50f18978ca>@@NPEBN@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5033badb7240167b30b90523bec68adf>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5061ec701805e08c70a11faeac892816>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_50ac1bbabd41636fda9e1bf36b1fc455>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_50bf1563c4f2a658d5a1f8997cf7d841>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_510b48fcc953c4af1dbcb4b8cf19756a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5151cdb5e2d0e967b0ff9b516f4dde5e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5169332acacd2cda6014329563a49097>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5178fbfdb12cb266aaef66d97a4a2fc5>@@NPEBN@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_51967558c7fd075e660195f4e6702ce2>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_519fe9cae569b1ad1c3f73288fa352d4>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_51f7b34ad2d14ff9bfb03559ccadc81f>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_522944c70ac483ca59ad2373ac030c86>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_52be072c62487a4543b8a1a3d2fbad23>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53001c91fe43da87bd732d9a4fb0e358>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5329cb936988b5974a3a2ce900136f33>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_534716bd90e3d628f36025c4e60922bb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_535c714f3912f6e19812f86aced1c234>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53687b87e8fc26669694bb154ed06213>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_538a9c85037de841067641f3e5d92fd5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53958a524045125d538038a834c170f9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_539862c5b8039ccfff5acf2ed512ba97>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_53e6651898ab41a7609d88940da1a1cb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_556d3d9e1da4d900ac4beace2594775f>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_56054d16adda54f2046f2f8778fd36d1>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_577697c65f7f30ab5c890fb5e643c3c6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_578472dc2e9e27345d825b47aca036a6>@@MPEBM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_57b4e734a8f319c201f732e76dc19318>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_581b6d14e5adbd13737160d24e40c605>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_581e172f6e6bf6d53a792d4f2adbb4c0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5820733bf712edf4856ad2454498e68c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5837c21ac5ed4b7ba5939ba692f3a2cd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5861f1c440cc9e376f7e9d4be12a7211>@@VStatus@common@onnxruntime@@PEAXPEBUOrtApi@@PEAUOrtKernelContext@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_58c18cbe2e241c86a9c2f0282cd3e9cd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_58e45bcf81f2eb4f6ae6b3f124defb13>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_58fbb8df4116cc5ed49a05a90528c0bc>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5933cfcb3215128b0a25c0614f75da87>@@XAEA_JPEB_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_598c6d249dbd14226af8e69fe738f910>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59a791f3e63b70edef38fb68dcebe7ec>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59d0c8449581e17e31aa5d36d4e1dfcc>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59d0f05394547c6e0e03de3b8b189e7d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59efc6d2c00331cc0701da5f7ba31f88>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59fa69d97a341ecc9726a25d2543c4ff>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_59fb7201bedc86d0ed85da074d1993f3>@@XAEAMPEBM_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5bd441e42294bfab33849ec1b22ce125>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5c5ac1f6c71d812ad45802a5c8ea5757>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5dddc316c01bb02791c37b03fa523bb0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5e0adb550519bb305a282a49bc052ff5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5e0f6565dc7aa7f6ebc79fe2fd37d8ea>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5fa3956cb796f4fb0ed4cc8ce896bcf4>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5fda51538eb73549320e6236b953b0c5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_5fe773ac1f878f81aadf16bc155901d0>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_601c95e3fba8a34ac8d24c850c4e911b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6105a132d5626ddb9b2ed4958c88e1e2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_61155733672bad5b1a1677020dbf30f2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_61a830e6f94472550f401a07bc054c29>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_61cda506a6bb2ddf6aa949685eb7c77c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_621fbd8d0cbcf0a8f4c51871d816bf2f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_62526b7eac31a4fea5091c2f348a5e23>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_62f1ce9bc208e37c7e5739c8f36388ed>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6367df6aa050372a33bd7465b9bffebf>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6434b01e914b4662f3f5703792865f82>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_64826d400df5e2683a863a4dbb954602>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_64e20fef6bc734aa72d77b8028e3b077>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_65379b8fe5c982ca5593c72a9026c7e8>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_655336b29940dd8dbdcd42ec2ee05996>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_65ea036252223d30a37862dfd4f7bc69>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6665c408830d0dff611752f43635ad2f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_66cabf3c04f8f57705ecc5d1dde38596>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6711c07c0f8ab9cb8e9a7125cbe3a01a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_673e4ce19ce5833538c9ec8e56f2275c>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6744a0008aca8ce8a0b29db8f1c01fa1>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_678560984ac7af19a5b63edeab48a227>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_67b6bf510365b722acc4b67b8d30f927>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_680b87823779380f32485d5ed8cbcf84>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_68d1128749cbe2edd5a4d05aa87c891c>@@XI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_68f8064281287c2a20e44f23c72be5d5>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6922b57be4edd39a89a7cea9e2ebb658>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6a3bd940152ae2677fd2b897f7b984e8>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6ae1de67e6e99002a693271defb4e48d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6aeba50936d3f6c7b11f3c24b58165e0>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6b0122b627329aed747a7281e017781a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6b9436f4089e82f5864d5365b56a5e02>@@XPEAD@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bb3fafba21860621ead2400f83d0ab0>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bbfc6268021e2bfd0f1bd3e4700889b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6bf7af48e7a4158e20b4f833c15de130>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6c857460828ce55880a8ee13df644424>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6c91c6f34bd8327dc22f6b7f8735fd5b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6cceb9a81b349eec63834bf776269859>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6cda9f0816757e5a4d291ef9c3329fae>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6d0547d7d9e564311a780ca9dc7db655>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6dd6cf995614bc7c2e490d548728e197>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6e2f42e69c3f77b25a074e65f1eca470>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6e3cb65d29853e95007cf81c805209f2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6f010deb824d03b6370449d6f782b9da>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_6f8420b50886667bda26b0e8f59183bf>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_70539968d61afd98aa9c406314f181bf>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_70b1e1dcbe48b81893d8f59a8144faf6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_70dd8648671da4762d31e7f5cb99db35>@@VStatus@common@onnxruntime@@AEAVFuncManager@4@AEBVOpKernelInfo@4@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_712a327d31152b694fd95674c69e7447>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_712b3a1726a5ab1ce39d1b3e7f50d979>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_716d92b2455b6dca0a3e195a50699167>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_727130accb380845b50f2c19a2b46d02>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_72aab4f7a75329bf9825db841274d3a3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_72e83488395612e0f6a2602b726a187c>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7331cae3c69c0d5b155ee357c1007837>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_739930acb5d4a4b1d92f387c9190b820>@@VStatus@common@onnxruntime@@$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_73cc642ed8afaa2889c4f09584fca345>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_747f5a5054cea5042105b3988bb8e54a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_761421d99b53ea1d25ac65996497fbea>@@_JPEB_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_76259788010337ce84c7523a6ac9ea2f>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_773e80e25f547e476dbfdd43767644cb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7807cde4d0ef8224ba8270c9901bf983>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_786b2ff03846fcfa21d00bf234deaff2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_78d2ff8fcf22c6166aa97abbb5fd0d75>@@XPEAPEAUOrtValue@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7965ceabe5f45db89655ad0a7fd04cd6>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_79f470cac7ca56067b4bc354acf028f6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7ab6b48869ceb01d1e728c1066baabd3>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7b13e0aa9183a7266252ed7dbdd54f99>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7c13e222993d6446f9d97d9b8d2341e0>@@VStatus@common@onnxruntime@@AEBV?$span@$$CB_K@gsl@@AEBVTensor@4@AEAV74@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7c393e0ced2515f63b0674de1e1229b1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7c61692eadeb4ccd34c8bb00529bfb83>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7ca26f875a5bd8018609c044fb5616a1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7db27467264314088f348a12ba91a5a9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_7ecdffb9bc3f419b33196d548224f0a4>@@XI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_80bd8f1476bc31a08ed6cb365cfefa4a>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_81de0b469ab0f1e7bc6d7cfef2665991>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8205a59784c4f81abae5636754370a87>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8288630972d659cd373e2f56e7530b06>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_82b38e81208f4cf45ccff9cab1f1ab56>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_845fb0d365668e61a65e09bae6280c09>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_84a2e50dc6af381ce5371c455f14a164>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_84e0d1c8300760043597f8486883bb16>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_85b8c9439e9295f048404909acdf29d3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_860b5cff89ff5f292872db2aaa19c52a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_86dd40270c718f299cd5113909653b31>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_874d535e153c7e2cc7bc8cf3f159ba49>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8811b8e0b984fa7408be2a8e645ea91e>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_885ce9bf676f456b6d4e77149ebef2ea>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_887dae5249605a4edc99e39f2a0adf15>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_888c8332848e83c225ef5f5587c3b38e>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88b1496ecc213c07fd24b30bb5c856e7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88cacdca8b660ada94d8f522e9f11bdd>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_88f211d79a091f6a481688e49635f453>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_89acb1907ff24a2b752ebe76d28b2b79>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_89d3c68acc787e643b03eef066fea4d2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a367ed868a5821659948b0a337825f5>@@XAEANPEBN_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8a900b8b41180a41f1571bb2c4cf6f8e>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8b7a180b7300a7362eece741d298bed3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8bbb4bb940b6248f0079a061cca5209e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8d1cbd61cf9e0403bbdc22c2b23b0de2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8dc767ccba8e089e41f89b04cb108c10>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8e2d345faf08aedb7570dd988fdca755>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8f0d91faf2fd476a9a61179d9b72837d>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8f5b5ae0f1d46d8c6eb147bbc6d3c96a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8f6bf12e356c17071a18123d1fef52d6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8fef7dbb6b3e81cda489ebe45ab449bb>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_8ffce33af8696a7a42fa073f6875aacb>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90811df5034c6b064f00ff028e410b34>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90a5aa05649581dcb39db34fc6f2962a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90e67d7cf9c8fca59bac4a84fc304da2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_90fa7e4386c5622637b0b1880f5ca8f3>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_913ebb992bc3e09bdf2737529cebbf5a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9148a73a32272a5a33edca914c11c2a4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_918223fcda849fef98116a4781c4f02e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9188795b2d63d4fadeae802c62453f68>@@VStatus@common@onnxruntime@@HAEBUOrtValue@@AEBUOrtCallback@4@_N_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_91a43e75998e3a49d1905d29f4a7bae4>@@VStatus@common@onnxruntime@@AEBVTensorShape@4@AEBUOrtMemoryInfo@@AEAUOrtValue@@AEA_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_91f296869b04eedc9f496835c423da26>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_91fdf8e96bd0363c4307fa79933bf9ee>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_922ea2af44b61076061b9738fd44abd8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9283763b81fbf1c4441399956127b6eb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9289ae269610356b68d5c3f46e89bf66>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_939f4702fdcc80c80258913a08838422>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9444b9c3df22cd88603cfb31f51cceb7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_94eb456bb6dd50ea434b460dd28415e2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_957302132dd7fea31b11af321304eee3>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95797973064e7dd662318da5d5424fd6>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95aae9bbb822c713ca9677b3a07b3381>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95ba9287d9318e63f29052645b806916>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95c74ffd32a4d994a62a191daf0fff27>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95cb1f26d899b1547c4804541e11a44a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95d4c31e5917c076b85b93f005fcb675>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95dd41682914710e4e8d31623057e7d3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_95e960d5e662fcb57840658a282318a0>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_965a3b769c39b0bedf189a3ea0545ea9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_96b6749a5bd8eb049fa653bd6c986087>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9800a6d45ddc69dc425addf83da8e9e3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_994ac64fe4673357a711f942252cee0c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a122db8c0c6f400c116ad5d2cdaf0bc>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a4c460641eeb4213d39e91aec522d90>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9a9b192dcae6874632669a18925ebf5e>@@XPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9ad4dd46fb7ebf522a3e85e715143745>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9b3108d194a09162f36c1b6ecbe4bd22>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9b63af4b3b6c6dd79d915ddcfe92473d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9bb5d71c29e163b6768bdebbeaa9ef83>@@VStatus@common@onnxruntime@@AEAVFuncManager@4@AEBVOpKernelInfo@4@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9bcf543f98218e465d42a5f7a449290e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c03d71b3e2a72420d0112f6f3840dd4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c23f807f5b88acf4c74334fd51de3b9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9c51e5beef5cfad81c8e2b8d3dd04a4a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9cc2379234b917d77614797746e75684>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9cf24a11d7a47ec83a2235f766fd2a5c>@@XPEAE@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9dc7af5c7bcff785bd9190f2cb464b36>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9dd547f200315c70f4064d52aef7ac6e>@@XI@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9de7ed3747c068fd694551112d802911>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9e35eefcb137cd146c958ca877000a5d>@@XAEACPEBC_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9e7e71f1a8889f6f7faa45e435ef1f25>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9f22cccb787c8b0be66f7b40706128ae>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_9f96fff69aa6e4d3c160f75385bed764>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a047e4fa7a019da5da5dcb5093bd2da9>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a0f363c6d35242db2945bd981d31d01b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a179296bb96622fe30c41b2986ab7695>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a191614639fd357df18cb9db7ec0bbb0>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a1b033c1238f74f04d136673bf3141a7>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a26d879b56b4c4dd33ee8f6ff5f1da50>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a2ae5f61cc20c1ab03a30ab181749eea>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a32f11f3f6edc3a900d9d34015d67705>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a345bf27d2a96610b3b006a123df813d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4015e490e3e9078f9108a810d677815>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a45f274125d5aab3ada44bd6d91ed7f6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4ad4e98f1a94b9237ebaa976e8eb831>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4fb1c1b5f905e04c31cbbe6c165878a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a51dc28255d67c31f47c2a37cec4d4e4>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a6025d7753fe49dfa6ce58be5196bf75>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a6353a4d545858b8902fbb038d252087>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a6d62ed7a3aadce21a3a08f0b111f7e9>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a7a0686f23e7f9337eaa10f069ee321b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a7f558f1dd0bc6dfbc34073d8010b2d2>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a8b00e76dfe980214923eafc43926fd4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a931912cfcdf336ec0429a60e07a6cf5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_a935037996bf9e3d7f1925320992d343>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa268cbc0b0d4966ec51ad17dda0ec82>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa638f082cd6e633ea8c394e1663fa60>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa831217bcc44892538d39aae8c330f6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aa88e462824a3ef64606c92b2b205d10>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ab076180da33c991061bdac15a41448d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ab7cc530eb49a3a15082dbc27eb613da>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ab7fd2a16f2ab36f5c7b628818e71578>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_abb9581c367ec240a8c0e5afd8181e99>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_acccfeb1e0041e26bf01c6097464f8c5>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_acdb2664af6229da1e4c43d330c314d8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ad8ca076531a0e62bdc4758313aec8ec>@@X$$V@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_adcf8be8a94343086b930752e64c0b0f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_adedb98ee19cb4d9a4a46a5fd17584b5>@@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ae0d8b5a2da4af67276477f8d17abe42>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aec81523952d967a50c07470b5814993>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_aecfda1830c0ee30e0e4a23c265062da>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af13a0a68d606e99765e2f7bd840b2f7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af2c39467b4484bc2a2f611cf533daa7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_af999ce2e03a2039dbf31c1ff13e0675>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b090b097d440a4b2445143675bf63aa8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b0ef8716b08a7c90da37b162fe225b7a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b0f9e3c706f87be7af57692823441e06>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b1c0cff63caf505f6536baee30943a62>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b24067cfb776b28c2465a46fad4c39cd>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b2b5b00a4ad3647a9a40b4f0dbb0745d>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b32e5f2bc2fafd58a4afcda5e8537c65>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b35f6304ab9b91e067de16d773b507fb>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b3e04491343c2b41488666814183e8a7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b3ffb2b19f45444139b13fc0568f9537>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b4d34ceb4628d068b1d974c038b79a44>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b547b93cbe3e16cfc4195284dfd5eaef>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b609acf5869a906202c2ec8d4f323bb0>@@XAEAHPEBH_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b62b9616dd6208ed1baf09034b8ca175>@@XAEAHPEBH_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b6c01241d8af757add895871e0bda6b2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b6c8ff4cf86b60687891fce83403bcfe>@@_JPEB_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b6dee4d13517d8cf66ef1e240c3ec6a4>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b765106161737954a77d8a171216f44e>@@XPEAH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b79d623619c8b488913a18719fb07ba7>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b83bed438099179cd13c5a6033b90f7d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b86aa8ef1de0593a5547f08d792c1565>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b881ee6a3336741e3e3697374c374936>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b88ca2272a912106e48e54848e61d223>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b92cd1be17f8632fbcc9dec212afe76b>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b9ad0ccbf56c00a46342640cba7cdc2c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_b9c72854712561eaa1748a5213a8f880>@@XAEAHPEBH_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ba9cfe2bb13e49d1f5f6d627965891ec>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_baa2815e04b51c513ad52e6ee2edd5e6>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb1f7ff97f0a93bd0d62291fdf3e87e2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb245b6c588ba3a259962707ee90e1f2>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb296edf374db63a1fb223cbff2a45aa>@@V?$unique_ptr@VIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@F@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bb618da91ef45dc5293c089a74c35488>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bbed65651851398ae9e91eb41072a5f9>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bc30b190ccdc11003b68eaf48bc55331>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bcef20d2b13b7b49fdebd823a7e734e1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_be82f0d3082d1770e6fe9b6560ab180a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_be9619b5fb1d1db7cf718b1fda3d5e82>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bea95f42caac40af3d5dbd854845ff13>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_bf3ede44b9863bac339552631fecea38>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c007df17e8115f08c5c6e2ce7e2201c0>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c21643d1fb44758b12325da46a2d32c5>@@_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c23a6e376db7c7388aa04e9eb8ee3aca>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c2634be0290355aa32c42903b822d942>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c277816ed3e96f001ac0003fb11da190>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c2abf8115bf6da52b8610764cf48ee0f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c2fef1cfbd08e9e21bcb74b985df87e6>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c39fd5c6fac165bf428d70a08e4c8f15>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c4dc4b2967ca7204e8ba49b0607e0250>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c646dd14edaacae64487e0b96ad575f5>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6728963f8bb91595df67d14c61fd8fa>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6a4c758ec4a05da2df0a96bda1f195f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c6cc7a538d9c817426d2f4671032805a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c7328f9d78ba121fe15792ce469c1b69>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c765ee4079d8132e5b64fd41ad2c9a7d>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c8779530b1b47f6b819a3c840cb70825>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c8957f10c145d7d78c010e1cb01ee7eb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c89e6783ea7ba65dd2bbca371d42018d>@@VStatus@common@onnxruntime@@AEAV?$shared_ptr@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9cc85b6189178098c01bbceb71ba127>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9e45910c6dad78e6e958bb0527b44e1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_c9fe283d46d2f293dcb8573f075d3809>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ca42e3f2ca4d6bbcd7bf706226d12a4c>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ca87e505bf8a7e1f26579083c3683d94>@@_NH@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cb7393b1270049ba922f1a24832dd162>@@NPEBN@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cba067a26cf21de5d0e68b8b6f37fe8f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc7060560dae87f5475ce357b0faca8e>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc71ada574b25d74a4c48413625b90d1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc810076352af54d8ab1334d58ef2ac8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cc9e076beb57119667e5b07bb3c48707>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cd453f5abbb4020fb3775475830cd8d1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cefaaa440fbc31a737d643cd7070b2a7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cf601ebc85517f1e503d9f32197b5b17>@@_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@3@AEAVFunctionProto@3@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cf886ef71e61e28cd5fd0d3055f9efbe>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cfafdf587dd99b527f40f2a9bbc4721a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_cfd05ce920f37ad131560f3f4ba5b162>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d05a56d909a989a3c2db176db7149e23>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d05c3c022071d814f376085832823fd8>@@XPEBVNode@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d085624eed89d70192230e9a1f62c5a7>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d08789fec1ddb2ea31a7e42b01821aaa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d0c5713ac46ee06d27e6324a463b7bee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d0fdf4211aa9516cbe57f435cdbb747f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d132db5c486427a93d54120da48d5ea6>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d1b650f23fa7659d3b2735ce4ed580e4>@@XAEA_JPEB_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2aedfced5017e33ef2fd58df23b739b>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2c19ae18917b59844dd4110518387dd>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2c978ff584bacbceac7be3bb080e51e>@@PEBVTensorProto@onnx@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d2d693a490e9887da5a024c703dc8e3e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d30ba908d7a4df45178218a83c8b90aa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d3857f49b3e4107314682ca90a39ea61>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d3c7976f3f38539a50838a16dd62ccb2>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d48cb9baeb37d51a45fff2e006fd2ed3>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d522df09ab9335db57f0cfc8c09d6630>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d5d46741b892946aacca2ea22e630eea>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d5d62f4b858abcded92348c54a906570>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d63de458c7355252fdf7dac6af546a6c>@@XPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d655da6f0498ff82874b3d8a213ddf66>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d6b1ae38293f8956d8614f7fd42d8be1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d6d6a472b26fc7f192d382e93bba1d57>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d70c00502c59385fd81a95257fd26b78>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d73f309e1e17ba4988eef7d15e33e2b5>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d77ac61f6238a68ec5589d982d5615ac>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d7872c9b42ef54f352452eac083f3a35>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d7a2681e4ada46acb33dd1adb547c252>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d7d65f11678621cb189879800cf53faf>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8059ce711ce14c36533947d64fa5a34>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d86f3bcde641b4c18df519c60bc10d09>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d88752c7e7055eb8ee4749bbd38c2e1a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@XPEBVDataTypeImpl@onnxruntime@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8b96520499b24df75ab37992af46b4d>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8e8fb9b3d14cba6be93e2f77767d47a>@@HPEAUComputeContext@onnxruntime@@PEAPEAX@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d8f306720719e22494f4df721d014f49>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_d9adada7822ba67bc618dd6220c7e11e>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_da7b70169c4d0c30b25c92beb94d63ae>@@XAEBVNodeArg@onnxruntime@@_N@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_da7c0e243075d823e83aad5424aee4f1>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_daa97a08fba16356a015278e0f3ca1ed>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dbdf3737eb2cb2871abd98870dad8484>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dcbbb46dcb2ccb38f1b7e3e89a0ca172>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dcbbb9aee7454d5a0feb975df66a7001>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dd92783c3b5068fe6d4b01b7a52eff87>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ddcedb921562b53aaf13cbc0af192f90>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ddff9a77cb22aafff303a88b4705bee2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_de00575298e9c7ead3b243890c596395>@@X$$QEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_de173f36c1a40fc38c17fd4d3151fc18>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dec8978adb68f88cd37c14b215792fcb>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_dfdd7885f2409b865180b051dead44b8>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e08a75ecff8a2a27b308be3f8dfddc66>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e128163c41b62dbd7415427042732d90>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e1a7abf114b955966097bd83c14de705>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e1a8783767138f2900763c385a76ace5>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e252e05424c33acac940c2f481ad24ee>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e318b9a1ac6011cec45976779008bc1d>@@VStatus@common@onnxruntime@@AEAVGraph@4@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e3ece229d743061e7008260e800aa786>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e41de5887194c6f47359224ea1f4265d>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e4fd1e1090be16100e1685f2f4877667>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e5264339f7df0674b92961d30b5a7ffa>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e65b3d84cc1ebbac94bfd47d08839322>@@XAEANPEBN_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e6687d53b2ff8a73e462a3df53da446b>@@XAEAUDataPropagationContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e69e76386d33ec96f42e27fde06de5c2>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e77a57374f1e055f8281ce5dd65e8ebd>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e79b149fca88b77c33b72523d605d32a>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_e7ad5c511f7f0ca88484948ab82410f1>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ea5f658f0d872dbd3ae3afb1f1fd1122>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eae84d9e160bdd32110c79960a898549>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eb887415aed41a3927a754246db16d35>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ec14091c8d829910b5be28a833d6a3dd>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ecc9b9120eb4793427a94169f5623a5b>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ed67f482bebf565f55f04daede9ac63d>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee8bcd2d07e1fd45b1c55d57b7556b9f>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee954de93bf759bd8b1f4b4c9716ded3>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ee988755aabf6d6b8cbe1162f42f9b60>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_eeeed7b40e814a0e70cf05a3907bbf81>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef1b5ee9690bf60d6d8ba03dec70f0fc>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef5c424a4193a85193eb7ea4c70aae69>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_ef9ce4d0dc32ab06ddd4426fedb787f1>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_efd47e41ca57d95ede53a33e8845ee3a>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f013722fb06ba87b6ded393d910c85c6>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f01e87ef597d7dc3f33e6877997ee749>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f05e941e43878b26850ba9c86261d871>@@VStatus@common@onnxruntime@@AEAVFuncManager@4@AEBVOpKernelInfo@4@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f0be09c6ec8e17e7ac33afa3db53ce78>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f0ea35f12b551ef953688db40e1f4b34>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f1490410ee527b42f3bd28e691dae2a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f20c684c9a749a148b4d30f212c71a01>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f273d4d4788dd6d522544c26d76a5ae4>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f2842527842316c8394eef731b560fea>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f2de741e38c166518c2010e724b68513>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f30a6117225d3cb8e4a11f826263726e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f418dafe297dbbe0e3ada3e20a715a40>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f4d85bd911255cc25b789888dd092506>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f55fed088cc6887bf534564a0809769f>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f563daf0e095e96808b0280be50284eb>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f59689bb1f16cb74228cd5fe68f4cabe>@@XAEA_JPEB_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f663e1cb5f92583d40a80c3711b532b4>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f77770976f2f1ea63d04f11ed8ae8858>@@MPEBM@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f7fefea6bfb8182e95c707a77e7f4a8f>@@X_K_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f88babf2ad8b675b7b86e082d193f4e3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f8ab3456636176a3e9c9876b6c4ed749>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f8dbfaed9d55440bb15cbf009ac934a6>@@X_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f8f4a9a0b8865f5f39e8ba472bf52edc>@@VStatus@common@onnxruntime@@AEBVNodeArg@4@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f92d41c84d566f3577a74275e60ee3bc>@@U?$Offset@UNodeIndexAndKernelDefHash@fbs@onnxruntime@@@flatbuffers@@_K@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f958ba65e401c00d0ddfa815d235fd3f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_f9b942c519c5abdf8c9e76770faf15a7>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fa46dd69454a850b787307a9d6678e80>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fbf4f22e77a262ac13623763b425fa95>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fc1c3f3352c8b4d29b9f843047cd4c91>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fc2c6db54ba2969b0c3aebde05d3921d>@@XAEANPEBN_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fcf7b72cb8688ac639f6066c6f9347c9>@@XAEAVOpSchema@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fd266a9166d0b10d35a0d8f14994daa2>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fd4f2bbf00caf507fea1cc6053ab984e>@@X_J_J@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fdb0134f4d01b5f723238dd45cc4059f>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@V<lambda_fe5b044a59055ca66e7af958ee5f5bc3>@@XAEAUInferenceContext@onnx@@@std@@
.?AV?$_Func_impl_no_alloc@VGraphConstantInitializerGetter@?A0x9d9d0a9c@onnxruntime@@PEBVTensorProto@onnx@@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@
.?AV?$_Iosb@H@std@@
.?AV?$_Ref_count_obj2@UCpuProviderFactory@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@V?$unordered_map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@U?$hash@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@U?$equal_to@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@UFuncInfo@FuncManager@onnxruntime@@@std@@@2@@std@@@std@@
.?AV?$_Ref_count_obj2@VAllocatorManager@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VCustomRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VIAllocatorImplWrappingOrtAllocator@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VKernelRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VModel@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VOnnxRuntimeOpSchemaRegistry@onnxruntime@@@std@@
.?AV?$_Ref_count_obj2@VSchemaRegistryManager@onnxruntime@@@std@@
.?AV?$_Ref_count_resource@PEAVBFCArena@onnxruntime@@U?$default_delete@VBFCArena@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVCPUExecutionProvider@onnxruntime@@U?$default_delete@VCPUExecutionProvider@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVIAllocator@onnxruntime@@U?$default_delete@VIAllocator@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVIExecutionProvider@onnxruntime@@U?$default_delete@VIExecutionProvider@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAVModel@onnxruntime@@U?$default_delete@VModel@onnxruntime@@@std@@@std@@
.?AV?$_Ref_count_resource@PEAXP6AXPEAX@Z@std@@
.?AV?$Add@_J@onnxruntime@@
.?AV?$Add@H@onnxruntime@@
.?AV?$Add@M@onnxruntime@@
.?AV?$Add@N@onnxruntime@@
.?AV?$ArgMax@C@onnxruntime@@
.?AV?$ArgMax@E@onnxruntime@@
.?AV?$ArgMax@H@onnxruntime@@
.?AV?$ArgMax@M@onnxruntime@@
.?AV?$ArgMax@N@onnxruntime@@
.?AV?$basic_filebuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ifstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ios@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ios@DU?$char_traits@D@std@@@std@@
.?AV?$basic_iostream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_iostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_istream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_istream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_istringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_ofstream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostream@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_ostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostringstream@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_ostringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@
.?AV?$basic_streambuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_stringbuf@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_stringbuf@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$basic_stringstream@_WU?$char_traits@_W@std@@V?$allocator@_W@2@@std@@
.?AV?$basic_stringstream@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@
.?AV?$BiasGelu@M$0A@@contrib@onnxruntime@@
.?AV?$Clip_6@M@onnxruntime@@
.?AV?$Clip_6Base@M@clip_internal@onnxruntime@@
.?AV?$ConstantOfShapeBase@U?$TypeList@_JUMLFloat16@onnxruntime@@MNCFHEGI_K_N@onnxruntime@@@onnxruntime@@
.?AV?$Conv@M@onnxruntime@@
.?AV?$CumSum@_J@onnxruntime@@
.?AV?$CumSum@H@onnxruntime@@
.?AV?$CumSum@M@onnxruntime@@
.?AV?$CumSum@N@onnxruntime@@
.?AV?$DequantizeLinear@C@onnxruntime@@
.?AV?$DequantizeLinear@E@onnxruntime@@
.?AV?$DequantizeLinear@H@onnxruntime@@
.?AV?$Div@_J@onnxruntime@@
.?AV?$Div@H@onnxruntime@@
.?AV?$Div@M@onnxruntime@@
.?AV?$Div@N@onnxruntime@@
.?AV?$DynamicQuantizeLinear@E@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@_J@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@_K@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@C@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@E@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@F@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@G@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@H@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@I@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Abs@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Exp@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Exp@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Floor@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$LeakyRelu@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Reciprocal@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Reciprocal@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Relu@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Relu@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sigmoid@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sigmoid@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sqrt@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Sqrt@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Tanh@M@functors@onnxruntime@@@onnxruntime@@
.?AV?$ElementWiseKernel@U?$Tanh@N@functors@onnxruntime@@@onnxruntime@@
.?AV?$Equal@_J@onnxruntime@@
.?AV?$Equal@_N@onnxruntime@@
.?AV?$Equal@H@onnxruntime@@
.?AV?$Equal@M@onnxruntime@@
.?AV?$Equal@N@onnxruntime@@
.?AV?$Erf@M@onnxruntime@@
.?AV?$Expand@_J@onnxruntime@@
.?AV?$Expand@_K@onnxruntime@@
.?AV?$Expand@_N@onnxruntime@@
.?AV?$Expand@C@onnxruntime@@
.?AV?$Expand@E@onnxruntime@@
.?AV?$Expand@F@onnxruntime@@
.?AV?$Expand@G@onnxruntime@@
.?AV?$Expand@H@onnxruntime@@
.?AV?$Expand@I@onnxruntime@@
.?AV?$Expand@M@onnxruntime@@
.?AV?$Expand@N@onnxruntime@@
.?AV?$Expand@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$Expand_8@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$FusedGemm@M@contrib@onnxruntime@@
.?AV?$Gelu@M@contrib@onnxruntime@@
.?AV?$Gemm@M@onnxruntime@@
.?AV?$Gemm@N@onnxruntime@@
.?AV?$Greater@_J@onnxruntime@@
.?AV?$Greater@H@onnxruntime@@
.?AV?$Greater@M@onnxruntime@@
.?AV?$Greater@N@onnxruntime@@
.?AV?$Hardmax@M@onnxruntime@@
.?AV?$IdentityOp@$00@onnxruntime@@
.?AV?$IdentityOp@$0A@@onnxruntime@@
.?AV?$LayerNorm@M$00@contrib@onnxruntime@@
.?AV?$LayerNorm@M$0A@@contrib@onnxruntime@@
.?AV?$LayerNorm@N$00@contrib@onnxruntime@@
.?AV?$LayerNorm@N$0A@@contrib@onnxruntime@@
.?AV?$Less@_J@onnxruntime@@
.?AV?$Less@H@onnxruntime@@
.?AV?$Less@M@onnxruntime@@
.?AV?$Less@N@onnxruntime@@
.?AV?$MapType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$MapType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$MatMul@_J@onnxruntime@@
.?AV?$MatMul@H@onnxruntime@@
.?AV?$MatMul@M@onnxruntime@@
.?AV?$MatMul@N@onnxruntime@@
.?AV?$Mul@_J@onnxruntime@@
.?AV?$Mul@H@onnxruntime@@
.?AV?$Mul@M@onnxruntime@@
.?AV?$Mul@N@onnxruntime@@
.?AV?$NonTensorType@V?$map@_J_JU?$less@_J@std@@V?$allocator@U?$pair@$$CB_J_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JNU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JN@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@_J@2@V?$allocator@U?$pair@$$CB_JV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_JU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@_J@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@NU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@N@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@U?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V12@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$NonTensorType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$numpunct@D@std@@
.?AV?$OptionalType@VTensor@onnxruntime@@_J@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@_K@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@_N@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@C@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@E@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@F@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@G@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@H@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@I@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@M@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@N@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@UBFloat16@2@@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@UMLFloat16@2@@onnxruntime@@
.?AV?$OptionalType@VTensor@onnxruntime@@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@_J@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@_K@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@_N@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@C@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@E@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@F@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@G@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@H@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@I@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@M@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@N@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@UBFloat16@2@@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@UMLFloat16@2@@onnxruntime@@
.?AV?$OptionalType@VTensorSeq@onnxruntime@@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$Pool@MVAveragePool@onnxruntime@@@onnxruntime@@
.?AV?$PRelu@M@onnxruntime@@
.?AV?$PrimitiveDataType@_J@onnxruntime@@
.?AV?$PrimitiveDataType@_K@onnxruntime@@
.?AV?$PrimitiveDataType@_N@onnxruntime@@
.?AV?$PrimitiveDataType@C@onnxruntime@@
.?AV?$PrimitiveDataType@E@onnxruntime@@
.?AV?$PrimitiveDataType@F@onnxruntime@@
.?AV?$PrimitiveDataType@G@onnxruntime@@
.?AV?$PrimitiveDataType@H@onnxruntime@@
.?AV?$PrimitiveDataType@I@onnxruntime@@
.?AV?$PrimitiveDataType@M@onnxruntime@@
.?AV?$PrimitiveDataType@N@onnxruntime@@
.?AV?$PrimitiveDataType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$PrimitiveDataType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$PrimitiveDataType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$ReduceKernel@$00@onnxruntime@@
.?AV?$ReduceKernel@$0A@@onnxruntime@@
.?AV?$ReduceKernelBase@$00@onnxruntime@@
.?AV?$ReduceKernelBase@$0A@@onnxruntime@@
.?AV?$ReduceLogSumExp@H@onnxruntime@@
.?AV?$ReduceLogSumExp@M@onnxruntime@@
.?AV?$ReduceLogSumExp@N@onnxruntime@@
.?AV?$ReduceMax@_J@onnxruntime@@
.?AV?$ReduceMax@C@onnxruntime@@
.?AV?$ReduceMax@E@onnxruntime@@
.?AV?$ReduceMax@H@onnxruntime@@
.?AV?$ReduceMax@M@onnxruntime@@
.?AV?$ReduceMax@N@onnxruntime@@
.?AV?$ReduceMean@H@onnxruntime@@
.?AV?$ReduceMean@M@onnxruntime@@
.?AV?$ReduceMean@N@onnxruntime@@
.?AV?$ReduceMin@_J@onnxruntime@@
.?AV?$ReduceMin@H@onnxruntime@@
.?AV?$ReduceMin@M@onnxruntime@@
.?AV?$ReduceMin@N@onnxruntime@@
.?AV?$ReduceSum@_J@onnxruntime@@
.?AV?$ReduceSum@H@onnxruntime@@
.?AV?$ReduceSum@M@onnxruntime@@
.?AV?$ReduceSum@N@onnxruntime@@
.?AV?$Round@M@onnxruntime@@
.?AV?$Round@N@onnxruntime@@
.?AV?$Round@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$Scan@$08@onnxruntime@@
.?AV?$SequenceTensorType@_J@onnxruntime@@
.?AV?$SequenceTensorType@_K@onnxruntime@@
.?AV?$SequenceTensorType@_N@onnxruntime@@
.?AV?$SequenceTensorType@C@onnxruntime@@
.?AV?$SequenceTensorType@E@onnxruntime@@
.?AV?$SequenceTensorType@F@onnxruntime@@
.?AV?$SequenceTensorType@G@onnxruntime@@
.?AV?$SequenceTensorType@H@onnxruntime@@
.?AV?$SequenceTensorType@I@onnxruntime@@
.?AV?$SequenceTensorType@M@onnxruntime@@
.?AV?$SequenceTensorType@N@onnxruntime@@
.?AV?$SequenceTensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SequenceTensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SequenceTensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@V?$allocator@V?$map@_JMU?$less@_J@std@@V?$allocator@U?$pair@$$CB_JM@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$SequenceType@V?$vector@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@V?$allocator@V?$map@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@MU?$less@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@2@V?$allocator@U?$pair@$$CBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@M@std@@@2@@std@@@2@@std@@@onnxruntime@@
.?AV?$SkipLayerNorm@M@contrib@onnxruntime@@
.?AV?$SkipLayerNorm@N@contrib@onnxruntime@@
.?AV?$Softmax@M@onnxruntime@@
.?AV?$Softmax@N@onnxruntime@@
.?AV?$SparseTensorType@_J@onnxruntime@@
.?AV?$SparseTensorType@_K@onnxruntime@@
.?AV?$SparseTensorType@_N@onnxruntime@@
.?AV?$SparseTensorType@C@onnxruntime@@
.?AV?$SparseTensorType@E@onnxruntime@@
.?AV?$SparseTensorType@F@onnxruntime@@
.?AV?$SparseTensorType@G@onnxruntime@@
.?AV?$SparseTensorType@H@onnxruntime@@
.?AV?$SparseTensorType@I@onnxruntime@@
.?AV?$SparseTensorType@M@onnxruntime@@
.?AV?$SparseTensorType@N@onnxruntime@@
.?AV?$SparseTensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SparseTensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$SparseTensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$Sub@_J@onnxruntime@@
.?AV?$Sub@H@onnxruntime@@
.?AV?$Sub@M@onnxruntime@@
.?AV?$Sub@N@onnxruntime@@
.?AV?$Sum_8@M@onnxruntime@@
.?AV?$Sum_8@N@onnxruntime@@
.?AV?$TensorType@_J@onnxruntime@@
.?AV?$TensorType@_K@onnxruntime@@
.?AV?$TensorType@_N@onnxruntime@@
.?AV?$TensorType@C@onnxruntime@@
.?AV?$TensorType@E@onnxruntime@@
.?AV?$TensorType@F@onnxruntime@@
.?AV?$TensorType@G@onnxruntime@@
.?AV?$TensorType@H@onnxruntime@@
.?AV?$TensorType@I@onnxruntime@@
.?AV?$TensorType@M@onnxruntime@@
.?AV?$TensorType@N@onnxruntime@@
.?AV?$TensorType@UBFloat16@onnxruntime@@@onnxruntime@@
.?AV?$TensorType@UMLFloat16@onnxruntime@@@onnxruntime@@
.?AV?$TensorType@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV?$ThreadPoolTempl@VEnv@onnxruntime@@@concurrency@onnxruntime@@
.?AV?$TopK@$0L@_J@onnxruntime@@
.?AV?$TopK@$0L@H@onnxruntime@@
.?AV?$TopK@$0L@M@onnxruntime@@
.?AV?$TopK@$0L@N@onnxruntime@@
.?AV?$Where@_J@onnxruntime@@
.?AV?$Where@E@onnxruntime@@
.?AV?$Where@H@onnxruntime@@
.?AV?$Where@M@onnxruntime@@
.?AV?$Where@N@onnxruntime@@
.?AV?$Where@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@onnxruntime@@
.?AV_Facet_base@std@@
.?AV_Generic_error_category@std@@
.?AV_Ref_count_base@std@@
.?AV_System_error_category@std@@
.?AV<lambda_0031e1631721c75a1f7a0e71cb748ed7>@@
.?AV<lambda_006f042491572090b778a6887556c541>@@
.?AV<lambda_00b59445cb71ad9abff9006cdec65ab0>@@
.?AV<lambda_0127cc6c89895d74380b7c79a5b9fb82>@@
.?AV<lambda_0251dfdaad61cfa5b2a46c99b78d27e8>@@
.?AV<lambda_02a8234b34a60137e169504412a1f413>@@
.?AV<lambda_02cf852cc5a543f808433f03632ba155>@@
.?AV<lambda_031e8dfd8d6a123502d9ec2194443e60>@@
.?AV<lambda_038eb253b7f4e93118566e43dda81530>@@
.?AV<lambda_03c53d5c540d06d25e58298bd3e2675f>@@
.?AV<lambda_03e7406b29b220fa131a6585ce48dcd2>@@
.?AV<lambda_0457fc55cb15f22bdcba75f54e0aa1c1>@@
.?AV<lambda_048b899a3305cb2c0c070dd18e5b4d17>@@
.?AV<lambda_055b4d24f8a1f4b549310d8384e8330c>@@
.?AV<lambda_06471b7954288b9dda9f9d99a72bb7c6>@@
.?AV<lambda_06e28cef24f38d1ecd4447df16780ad3>@@
.?AV<lambda_06e5eb766e97cbbd1e9836fc044820b5>@@
.?AV<lambda_0847b334bbfd42737aafe7ba61663e74>@@
.?AV<lambda_08b89006bb2cd45177aec966a5a64a25>@@
.?AV<lambda_08db83bf9ac8665fc4de47cb08668b85>@@
.?AV<lambda_0a0326aaa0c17e1dc10459d8b6c3398c>@@
.?AV<lambda_0a3d98e003a8310444f50c395f4ee870>@@
.?AV<lambda_0a786afdc494302a03a8347211af4f5e>@@
.?AV<lambda_0aa1cbb10b7e27c8eaa9e1c4d936a012>@@
.?AV<lambda_0aeb3b3202e2e34a7d6b98b623e6a327>@@
.?AV<lambda_0af4c846dd5af6632beb77ffbd6469c9>@@
.?AV<lambda_0afff8b6c40408852605b1495798325e>@@
.?AV<lambda_0b0bbca98147f2b1d98b75bc68203f51>@@
.?AV<lambda_0b4cc153b058489c05500d0b394c47a0>@@
.?AV<lambda_0b84cd883df2cf8f5da7751da99be58c>@@
.?AV<lambda_0ba48c1f3299a5f4228b96a5876e6f39>@@
.?AV<lambda_0c24edbe84bc491fb6a29a020f4d3aa5>@@
.?AV<lambda_0e4160f1c09428b722c89257b1bbabcb>@@
.?AV<lambda_0e85b1a3aa4aedfca1acdf52f931b8f2>@@
.?AV<lambda_0f2ad18a551e793a8bddf1de1dc21689>@@
.?AV<lambda_0f569c3741dec4cbd25547f5cfa47a1f>@@
.?AV<lambda_0f619f3ff08e9e7659a763308b991cbe>@@
.?AV<lambda_0fb4e93f4014e9a9ed52287648f86c91>@@
.?AV<lambda_101e0d486e161cfbbc4332cd98f3239a>@@
.?AV<lambda_11002e821957b929b79aa649ecf0a381>@@
.?AV<lambda_1123ca3288c22333dcfbc6780e56f3b6>@@
.?AV<lambda_113fc5cdb3f9f5e45a498eccec03db60>@@
.?AV<lambda_1147aa6d38b42c0a8559813b3004180f>@@
.?AV<lambda_115059020db09aa13bab825ad518034e>@@
.?AV<lambda_11c15110a2869c43f5467753b7474409>@@
.?AV<lambda_1221b4097effa32a8dd388b4455dd2c1>@@
.?AV<lambda_12237f9b9f786fa2f677523e51689677>@@
.?AV<lambda_1249aa664b6dd8c7cf40d23fbaec080e>@@
.?AV<lambda_13046178b359e9c81742cfc406e97a28>@@
.?AV<lambda_13bf14abed62c4ddb7d24aa834c66cd3>@@
.?AV<lambda_140ab31565a9f257f202ece6453c4bfd>@@
.?AV<lambda_147527a66291af5e3f9c1e417e66fd9c>@@
.?AV<lambda_1476157c6a284e4f379191854345eea5>@@
.?AV<lambda_14ab4d68c965e23bff80a9edfde3b16e>@@
.?AV<lambda_1642adc2d95a594ec2d1ca1c1679605d>@@
.?AV<lambda_165747221b83b97edb1c8980b4a934c8>@@
.?AV<lambda_16aeacf7ad4b53ba550defbc9c03abde>@@
.?AV<lambda_18dbcf0a6112b471cd3435637c32f0f8>@@
.?AV<lambda_18e0b70d8d5a276d72055cc8661094dd>@@
.?AV<lambda_18f6d57bac34239d650ddbef707551e4>@@
.?AV<lambda_191f334b7e6fbfb2860cdf729a487dba>@@
.?AV<lambda_194fafbac36b97ada7ff78b4fe337622>@@
.?AV<lambda_19653ee275cc0117099f6e46319415af>@@
.?AV<lambda_19a25a0e0bced01a01388502a5fb897a>@@
.?AV<lambda_1a286ef6a47f06b31852d582b51b4ff5>@@
.?AV<lambda_1abf5a492f2ce98320288d0a19f9a732>@@
.?AV<lambda_1c47a842a4ad24719aaf09edc25c7aef>@@
.?AV<lambda_1c511d989171b0ae840c900d36af6cdf>@@
.?AV<lambda_1cd5cfe6b76bb3ba1c53203d58a4eedd>@@
.?AV<lambda_1cdda74d195f4dc7bbdbaed3ee174bf7>@@
.?AV<lambda_1d718ae1c6eee88a5015989ae3eac075>@@
.?AV<lambda_1d7aed3977eb6b0e8500a44cbf6dc587>@@
.?AV<lambda_1e6c58f2c47fbfdcb340ca8aa595e354>@@
.?AV<lambda_1ea1e7671a1665ca234eb6cc181c60bb>@@
.?AV<lambda_1efd3ecb51119ba3eba8bc9319f01386>@@
.?AV<lambda_1f3bf02585dcf20edf66f391042bccc5>@@
.?AV<lambda_1f77acb4e34034b00a5a2150384c9d77>@@
.?AV<lambda_1f8675d15ee5efaa8f5579945c6d118a>@@
.?AV<lambda_1fd04ff7ed408ca4ebed6e8107f19670>@@
.?AV<lambda_20a837f51a15ec806ec07fe236459bf3>@@
.?AV<lambda_20ce3835ea17537cf13d089eb1a443c1>@@
.?AV<lambda_217211e0b9216fbae93bbaf0026e78ee>@@
.?AV<lambda_218f765d5b26dc460cf68e4f7ef3c8f7>@@
.?AV<lambda_21f2ebef859bbaf3ad57fb860d7bd5a6>@@
.?AV<lambda_221457049dd6e599b1e592be3898266a>@@
.?AV<lambda_22aeb0e20ec618f43aaa785665edaa1d>@@
.?AV<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>@@
.?AV<lambda_2369389c848e11c0cf2fa8c55ee9bc1b>@@
.?AV<lambda_23a1bb0478ab7117c6dff4712434f02b>@@
.?AV<lambda_23cd650266f5b996762e121f69bcde45>@@
.?AV<lambda_242966bc823a6ea57016299e4846b19a>@@
.?AV<lambda_243c848b67147a62f5be9d25d42a217b>@@
.?AV<lambda_24ac27632a899010d1e56f7da8454199>@@
.?AV<lambda_253a3836eec6c1ddbcb7d28211e21bd6>@@
.?AV<lambda_265c7b3426b87aef377811f8829e6fd7>@@
.?AV<lambda_27a06fd9b1f731a63767571c10bf29a4>@@
.?AV<lambda_27a631d2450c357a52927c1dfbd2efda>@@
.?AV<lambda_2830e7879c71bbb5a2447c8cce82dc3b>@@
.?AV<lambda_28a69d198faef3db79470de4de6f53e9>@@
.?AV<lambda_28c42d729a2f53041e8b22b1ed6cdff0>@@
.?AV<lambda_28d76a4078a4a8dbd4ec44ed08d36b25>@@
.?AV<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@
.?AV<lambda_2a3f9f19c48a100998729328075237dc>@@
.?AV<lambda_2a976ac88d60c988f6c82762c8669484>@@
.?AV<lambda_2ac171e27e2ef21b455a8883502f09aa>@@
.?AV<lambda_2bed918e0092d38de095a3dfcc39bb6a>@@
.?AV<lambda_2bf767e58fd6076f82b597352ebe6a94>@@
.?AV<lambda_2bf8017c8b0b3ab5a242f82899957cda>@@
.?AV<lambda_2cdbc5f873c2ce32c36481fab53d6870>@@
.?AV<lambda_2d779c3a3c8b726adf3efb1bfd3cbb40>@@
.?AV<lambda_2dc16cf30de15202e0434934c8ec0571>@@
.?AV<lambda_2e20e62e8d812957e92321838accac54>@@
.?AV<lambda_2f3c8dfb82c3078faed3c459500f6cd5>@@
.?AV<lambda_2f4103e1c4a1773101a6c1f055d56df4>@@
.?AV<lambda_3050f982855d87e103d3099ed68136e7>@@
.?AV<lambda_30e1101d7025e2d839d1daa9ac434cd1>@@
.?AV<lambda_310ceee0e4c58a7a83d7d00319ed9410>@@
.?AV<lambda_33215563a6aacb86deff746a6aa28a6c>@@
.?AV<lambda_3354f944db7877754471d985be3fe29b>@@
.?AV<lambda_3361a7c3c06ae8fda0091b29a15bc377>@@
.?AV<lambda_337593ad4f874bae98bb3aa9ea22758d>@@
.?AV<lambda_33763db33c7430e0074fd25b65b4479f>@@
.?AV<lambda_339ccdd8cf9a471a2525280227358fe6>@@
.?AV<lambda_33ab9233a6e2a6fe6c24d1963cbc3111>@@
.?AV<lambda_33c11271a908f4f215dd361ca0be165e>@@
.?AV<lambda_3410038a349fbad62fb0cd42ca2fc595>@@
.?AV<lambda_3435a69bc2a4a58cf25c9601fa916799>@@
.?AV<lambda_348952d4e8cb4d6ca40b91f67d9fe4cc>@@
.?AV<lambda_3525a67688acab3a16549c70f50b343d>@@
.?AV<lambda_368acd23d928f0f5d2e3ced50c09e50c>@@
.?AV<lambda_36945aef9b69b8bc246158e60ded74ff>@@
.?AV<lambda_3723f23b8a34d9d98e7ee4d14fc03d1b>@@
.?AV<lambda_37fc46271b5a9d577e78557058b76819>@@
.?AV<lambda_3863377c4067e3a3117e9e245fcb11f1>@@
.?AV<lambda_3a80fca790cdb0fce14ddaedefa20351>@@
.?AV<lambda_3aac6f1c979a8b893423e58931ed2daa>@@
.?AV<lambda_3acaf4e71a87bfb836a528474a23b2b9>@@
.?AV<lambda_3ad3f00f380cbc79acdede7031c2b35c>@@
.?AV<lambda_3ae9af8a84288cef25a7cf83bd0834fa>@@
.?AV<lambda_3b70c471f0d6c3603fdf76e6ccfb54a3>@@
.?AV<lambda_3b79ba1930d9045b1d0a1c3e7b558aa7>@@
.?AV<lambda_3b97251de202434e86d007c33f9345a1>@@
.?AV<lambda_3bf9d7b5239a137326d2c5fa821fa737>@@
.?AV<lambda_3ce4407e5879111e6c1a6435d36077e4>@@
.?AV<lambda_3cfedd26cd9ef5f4cd0322b54223b692>@@
.?AV<lambda_3d53fdafdcab72e11f157b0377fe813b>@@
.?AV<lambda_3e2860b55958cf532cc6672e843fd5e5>@@
.?AV<lambda_3e5e22c83296c8f56ae7effebfec7009>@@
.?AV<lambda_3e80eabb3a9d111992ebd5907a12e903>@@
.?AV<lambda_3f0ef66d0b0de67b55e854d697da2fff>@@
.?AV<lambda_3fbfdfe39393a610cb9132779b271854>@@
.?AV<lambda_404d0fe71cc8d7867c9f1bc290b28bbd>@@
.?AV<lambda_4092000fa2c851eb2ddefc1b6efbf1fc>@@
.?AV<lambda_409a8ec0de4403e02d09bb9a4b937276>@@
.?AV<lambda_40d7d549b7296d37bd8a375a6a32735f>@@
.?AV<lambda_40d9bd0925a189b8d1c995cd48d17d39>@@
.?AV<lambda_40f74427ec28f20a5d59b70a3f7ba162>@@
.?AV<lambda_41bb79d9c7cc8f02e2f871c5095cf1ee>@@
.?AV<lambda_42580b4f3e49f7dcfbf37d76233bd856>@@
.?AV<lambda_43d76a454d7e446551a32b163679964a>@@
.?AV<lambda_4404716c35945f1da6a07154c932397d>@@
.?AV<lambda_44094649bc82ecb2fc1ec6afdbc202d7>@@
.?AV<lambda_458163864faccd230ccf1ce10d3e187d>@@
.?AV<lambda_45e1f6e47762148b282b3bb16964d9a7>@@
.?AV<lambda_46087cac4b4384e4406cfa052cc4f414>@@
.?AV<lambda_464e1f80ac51d01e54b77145fd34c5bb>@@
.?AV<lambda_46f2340c6974a9abf9bf427b63a5b9bc>@@
.?AV<lambda_47f0845d7b66643be4c58515f34249ea>@@
.?AV<lambda_486023130535c54dc87259934f24df6e>@@
.?AV<lambda_4913db8c05460fd84e03b1ef7ec1a215>@@
.?AV<lambda_4ae79009ffed4baaf3b13205e614d6ec>@@
.?AV<lambda_4b94da34bdfcb505ddcef5cb50b95e3d>@@
.?AV<lambda_4bcb1ddbded281b4b93a8d23384ad316>@@
.?AV<lambda_4bd02c7b372889e26c922fb97a0c9ac3>@@
.?AV<lambda_4bfaa77b47cc3b72c0199e4158dcfdd3>@@
.?AV<lambda_4c0362c3e20008eb9ad4ca148d83f23f>@@
.?AV<lambda_4c0d5472c0e9893aea307d804bd55070>@@
.?AV<lambda_4c81a7b179f9e26e2d05ebefbb83c381>@@
.?AV<lambda_4cd868df938477ea9946d2d55c43c695>@@
.?AV<lambda_4de083bd9feef97ef116b9ac6f248cfc>@@
.?AV<lambda_4e733be9ef1a8040b2cc0e98d09e233e>@@
.?AV<lambda_4e978ba75a8a0f3f4d2d1e75d74ac4de>@@
.?AV<lambda_4f02b89eec40e1f508d9a8a5576d7ee8>@@
.?AV<lambda_4f04249e04d07d50d630e12dc9f30f23>@@
.?AV<lambda_5032e4da5cc3197800498a50f18978ca>@@
.?AV<lambda_5033badb7240167b30b90523bec68adf>@@
.?AV<lambda_5061ec701805e08c70a11faeac892816>@@
.?AV<lambda_50ac1bbabd41636fda9e1bf36b1fc455>@@
.?AV<lambda_50bf1563c4f2a658d5a1f8997cf7d841>@@
.?AV<lambda_510b48fcc953c4af1dbcb4b8cf19756a>@@
.?AV<lambda_5151cdb5e2d0e967b0ff9b516f4dde5e>@@
.?AV<lambda_5169332acacd2cda6014329563a49097>@@
.?AV<lambda_5178fbfdb12cb266aaef66d97a4a2fc5>@@
.?AV<lambda_51967558c7fd075e660195f4e6702ce2>@@
.?AV<lambda_519fe9cae569b1ad1c3f73288fa352d4>@@
.?AV<lambda_51f7b34ad2d14ff9bfb03559ccadc81f>@@
.?AV<lambda_522944c70ac483ca59ad2373ac030c86>@@
.?AV<lambda_52be072c62487a4543b8a1a3d2fbad23>@@
.?AV<lambda_53001c91fe43da87bd732d9a4fb0e358>@@
.?AV<lambda_5329cb936988b5974a3a2ce900136f33>@@
.?AV<lambda_534716bd90e3d628f36025c4e60922bb>@@
.?AV<lambda_535c714f3912f6e19812f86aced1c234>@@
.?AV<lambda_53687b87e8fc26669694bb154ed06213>@@
.?AV<lambda_538a9c85037de841067641f3e5d92fd5>@@
.?AV<lambda_53958a524045125d538038a834c170f9>@@
.?AV<lambda_539862c5b8039ccfff5acf2ed512ba97>@@
.?AV<lambda_53e6651898ab41a7609d88940da1a1cb>@@
.?AV<lambda_556d3d9e1da4d900ac4beace2594775f>@@
.?AV<lambda_56054d16adda54f2046f2f8778fd36d1>@@
.?AV<lambda_577697c65f7f30ab5c890fb5e643c3c6>@@
.?AV<lambda_578472dc2e9e27345d825b47aca036a6>@@
.?AV<lambda_57b4e734a8f319c201f732e76dc19318>@@
.?AV<lambda_581b6d14e5adbd13737160d24e40c605>@@
.?AV<lambda_581e172f6e6bf6d53a792d4f2adbb4c0>@@
.?AV<lambda_5820733bf712edf4856ad2454498e68c>@@
.?AV<lambda_5837c21ac5ed4b7ba5939ba692f3a2cd>@@
.?AV<lambda_5861f1c440cc9e376f7e9d4be12a7211>@@
.?AV<lambda_58c18cbe2e241c86a9c2f0282cd3e9cd>@@
.?AV<lambda_58e45bcf81f2eb4f6ae6b3f124defb13>@@
.?AV<lambda_58fbb8df4116cc5ed49a05a90528c0bc>@@
.?AV<lambda_5933cfcb3215128b0a25c0614f75da87>@@
.?AV<lambda_598c6d249dbd14226af8e69fe738f910>@@
.?AV<lambda_59a791f3e63b70edef38fb68dcebe7ec>@@
.?AV<lambda_59d0c8449581e17e31aa5d36d4e1dfcc>@@
.?AV<lambda_59d0f05394547c6e0e03de3b8b189e7d>@@
.?AV<lambda_59efc6d2c00331cc0701da5f7ba31f88>@@
.?AV<lambda_59fa69d97a341ecc9726a25d2543c4ff>@@
.?AV<lambda_59fb7201bedc86d0ed85da074d1993f3>@@
.?AV<lambda_5bd441e42294bfab33849ec1b22ce125>@@
.?AV<lambda_5c5ac1f6c71d812ad45802a5c8ea5757>@@
.?AV<lambda_5dddc316c01bb02791c37b03fa523bb0>@@
.?AV<lambda_5e0adb550519bb305a282a49bc052ff5>@@
.?AV<lambda_5e0f6565dc7aa7f6ebc79fe2fd37d8ea>@@
.?AV<lambda_5fa3956cb796f4fb0ed4cc8ce896bcf4>@@
.?AV<lambda_5fda51538eb73549320e6236b953b0c5>@@
.?AV<lambda_5fe773ac1f878f81aadf16bc155901d0>@@
.?AV<lambda_601c95e3fba8a34ac8d24c850c4e911b>@@
.?AV<lambda_6105a132d5626ddb9b2ed4958c88e1e2>@@
.?AV<lambda_61155733672bad5b1a1677020dbf30f2>@@
.?AV<lambda_61a830e6f94472550f401a07bc054c29>@@
.?AV<lambda_61cda506a6bb2ddf6aa949685eb7c77c>@@
.?AV<lambda_621fbd8d0cbcf0a8f4c51871d816bf2f>@@
.?AV<lambda_62526b7eac31a4fea5091c2f348a5e23>@@
.?AV<lambda_62f1ce9bc208e37c7e5739c8f36388ed>@@
.?AV<lambda_6367df6aa050372a33bd7465b9bffebf>@@
.?AV<lambda_6434b01e914b4662f3f5703792865f82>@@
.?AV<lambda_64826d400df5e2683a863a4dbb954602>@@
.?AV<lambda_64e20fef6bc734aa72d77b8028e3b077>@@
.?AV<lambda_65379b8fe5c982ca5593c72a9026c7e8>@@
.?AV<lambda_655336b29940dd8dbdcd42ec2ee05996>@@
.?AV<lambda_65ea036252223d30a37862dfd4f7bc69>@@
.?AV<lambda_6665c408830d0dff611752f43635ad2f>@@
.?AV<lambda_66cabf3c04f8f57705ecc5d1dde38596>@@
.?AV<lambda_6711c07c0f8ab9cb8e9a7125cbe3a01a>@@
.?AV<lambda_673e4ce19ce5833538c9ec8e56f2275c>@@
.?AV<lambda_6744a0008aca8ce8a0b29db8f1c01fa1>@@
.?AV<lambda_678560984ac7af19a5b63edeab48a227>@@
.?AV<lambda_67b6bf510365b722acc4b67b8d30f927>@@
.?AV<lambda_680b87823779380f32485d5ed8cbcf84>@@
.?AV<lambda_68d1128749cbe2edd5a4d05aa87c891c>@@
.?AV<lambda_68f8064281287c2a20e44f23c72be5d5>@@
.?AV<lambda_6922b57be4edd39a89a7cea9e2ebb658>@@
.?AV<lambda_6a3bd940152ae2677fd2b897f7b984e8>@@
.?AV<lambda_6ae1de67e6e99002a693271defb4e48d>@@
.?AV<lambda_6aeba50936d3f6c7b11f3c24b58165e0>@@
.?AV<lambda_6b0122b627329aed747a7281e017781a>@@
.?AV<lambda_6b9436f4089e82f5864d5365b56a5e02>@@
.?AV<lambda_6bb3fafba21860621ead2400f83d0ab0>@@
.?AV<lambda_6bbfc6268021e2bfd0f1bd3e4700889b>@@
.?AV<lambda_6bf7af48e7a4158e20b4f833c15de130>@@
.?AV<lambda_6c857460828ce55880a8ee13df644424>@@
.?AV<lambda_6c91c6f34bd8327dc22f6b7f8735fd5b>@@
.?AV<lambda_6cceb9a81b349eec63834bf776269859>@@
.?AV<lambda_6cda9f0816757e5a4d291ef9c3329fae>@@
.?AV<lambda_6d0547d7d9e564311a780ca9dc7db655>@@
.?AV<lambda_6dd6cf995614bc7c2e490d548728e197>@@
.?AV<lambda_6e2f42e69c3f77b25a074e65f1eca470>@@
.?AV<lambda_6e3cb65d29853e95007cf81c805209f2>@@
.?AV<lambda_6f010deb824d03b6370449d6f782b9da>@@
.?AV<lambda_6f8420b50886667bda26b0e8f59183bf>@@
.?AV<lambda_70539968d61afd98aa9c406314f181bf>@@
.?AV<lambda_70b1e1dcbe48b81893d8f59a8144faf6>@@
.?AV<lambda_70dd8648671da4762d31e7f5cb99db35>@@
.?AV<lambda_712a327d31152b694fd95674c69e7447>@@
.?AV<lambda_712b3a1726a5ab1ce39d1b3e7f50d979>@@
.?AV<lambda_716d92b2455b6dca0a3e195a50699167>@@
.?AV<lambda_727130accb380845b50f2c19a2b46d02>@@
.?AV<lambda_72aab4f7a75329bf9825db841274d3a3>@@
.?AV<lambda_72e83488395612e0f6a2602b726a187c>@@
.?AV<lambda_7331cae3c69c0d5b155ee357c1007837>@@
.?AV<lambda_739930acb5d4a4b1d92f387c9190b820>@@
.?AV<lambda_73cc642ed8afaa2889c4f09584fca345>@@
.?AV<lambda_747f5a5054cea5042105b3988bb8e54a>@@
.?AV<lambda_761421d99b53ea1d25ac65996497fbea>@@
.?AV<lambda_76259788010337ce84c7523a6ac9ea2f>@@
.?AV<lambda_773e80e25f547e476dbfdd43767644cb>@@
.?AV<lambda_7807cde4d0ef8224ba8270c9901bf983>@@
.?AV<lambda_786b2ff03846fcfa21d00bf234deaff2>@@
.?AV<lambda_78d2ff8fcf22c6166aa97abbb5fd0d75>@@
.?AV<lambda_7965ceabe5f45db89655ad0a7fd04cd6>@@
.?AV<lambda_79f470cac7ca56067b4bc354acf028f6>@@
.?AV<lambda_7ab6b48869ceb01d1e728c1066baabd3>@@
.?AV<lambda_7b13e0aa9183a7266252ed7dbdd54f99>@@
.?AV<lambda_7c13e222993d6446f9d97d9b8d2341e0>@@
.?AV<lambda_7c393e0ced2515f63b0674de1e1229b1>@@
.?AV<lambda_7c61692eadeb4ccd34c8bb00529bfb83>@@
.?AV<lambda_7ca26f875a5bd8018609c044fb5616a1>@@
.?AV<lambda_7db27467264314088f348a12ba91a5a9>@@
.?AV<lambda_7ecdffb9bc3f419b33196d548224f0a4>@@
.?AV<lambda_80bd8f1476bc31a08ed6cb365cfefa4a>@@
.?AV<lambda_81de0b469ab0f1e7bc6d7cfef2665991>@@
.?AV<lambda_8205a59784c4f81abae5636754370a87>@@
.?AV<lambda_8288630972d659cd373e2f56e7530b06>@@
.?AV<lambda_82b38e81208f4cf45ccff9cab1f1ab56>@@
.?AV<lambda_845fb0d365668e61a65e09bae6280c09>@@
.?AV<lambda_84a2e50dc6af381ce5371c455f14a164>@@
.?AV<lambda_84e0d1c8300760043597f8486883bb16>@@
.?AV<lambda_85b8c9439e9295f048404909acdf29d3>@@
.?AV<lambda_860b5cff89ff5f292872db2aaa19c52a>@@
.?AV<lambda_86dd40270c718f299cd5113909653b31>@@
.?AV<lambda_874d535e153c7e2cc7bc8cf3f159ba49>@@
.?AV<lambda_8811b8e0b984fa7408be2a8e645ea91e>@@
.?AV<lambda_885ce9bf676f456b6d4e77149ebef2ea>@@
.?AV<lambda_887dae5249605a4edc99e39f2a0adf15>@@
.?AV<lambda_888c8332848e83c225ef5f5587c3b38e>@@
.?AV<lambda_88b1496ecc213c07fd24b30bb5c856e7>@@
.?AV<lambda_88cacdca8b660ada94d8f522e9f11bdd>@@
.?AV<lambda_88f211d79a091f6a481688e49635f453>@@
.?AV<lambda_89acb1907ff24a2b752ebe76d28b2b79>@@
.?AV<lambda_89d3c68acc787e643b03eef066fea4d2>@@
.?AV<lambda_8a367ed868a5821659948b0a337825f5>@@
.?AV<lambda_8a900b8b41180a41f1571bb2c4cf6f8e>@@
.?AV<lambda_8b7a180b7300a7362eece741d298bed3>@@
.?AV<lambda_8bbb4bb940b6248f0079a061cca5209e>@@
.?AV<lambda_8d1cbd61cf9e0403bbdc22c2b23b0de2>@@
.?AV<lambda_8dc767ccba8e089e41f89b04cb108c10>@@
.?AV<lambda_8e2d345faf08aedb7570dd988fdca755>@@
.?AV<lambda_8f0d91faf2fd476a9a61179d9b72837d>@@
.?AV<lambda_8f5b5ae0f1d46d8c6eb147bbc6d3c96a>@@
.?AV<lambda_8f6bf12e356c17071a18123d1fef52d6>@@
.?AV<lambda_8fef7dbb6b3e81cda489ebe45ab449bb>@@
.?AV<lambda_8ffce33af8696a7a42fa073f6875aacb>@@
.?AV<lambda_90811df5034c6b064f00ff028e410b34>@@
.?AV<lambda_90a5aa05649581dcb39db34fc6f2962a>@@
.?AV<lambda_90e67d7cf9c8fca59bac4a84fc304da2>@@
.?AV<lambda_90fa7e4386c5622637b0b1880f5ca8f3>@@
.?AV<lambda_913ebb992bc3e09bdf2737529cebbf5a>@@
.?AV<lambda_9148a73a32272a5a33edca914c11c2a4>@@
.?AV<lambda_918223fcda849fef98116a4781c4f02e>@@
.?AV<lambda_9188795b2d63d4fadeae802c62453f68>@@
.?AV<lambda_91a43e75998e3a49d1905d29f4a7bae4>@@
.?AV<lambda_91f296869b04eedc9f496835c423da26>@@
.?AV<lambda_91fdf8e96bd0363c4307fa79933bf9ee>@@
.?AV<lambda_922ea2af44b61076061b9738fd44abd8>@@
.?AV<lambda_9283763b81fbf1c4441399956127b6eb>@@
.?AV<lambda_9289ae269610356b68d5c3f46e89bf66>@@
.?AV<lambda_939f4702fdcc80c80258913a08838422>@@
.?AV<lambda_9444b9c3df22cd88603cfb31f51cceb7>@@
.?AV<lambda_94eb456bb6dd50ea434b460dd28415e2>@@
.?AV<lambda_957302132dd7fea31b11af321304eee3>@@
.?AV<lambda_95797973064e7dd662318da5d5424fd6>@@
.?AV<lambda_95aae9bbb822c713ca9677b3a07b3381>@@
.?AV<lambda_95ba9287d9318e63f29052645b806916>@@
.?AV<lambda_95c74ffd32a4d994a62a191daf0fff27>@@
.?AV<lambda_95cb1f26d899b1547c4804541e11a44a>@@
.?AV<lambda_95d4c31e5917c076b85b93f005fcb675>@@
.?AV<lambda_95dd41682914710e4e8d31623057e7d3>@@
.?AV<lambda_95e960d5e662fcb57840658a282318a0>@@
.?AV<lambda_965a3b769c39b0bedf189a3ea0545ea9>@@
.?AV<lambda_96b6749a5bd8eb049fa653bd6c986087>@@
.?AV<lambda_9800a6d45ddc69dc425addf83da8e9e3>@@
.?AV<lambda_994ac64fe4673357a711f942252cee0c>@@
.?AV<lambda_9a122db8c0c6f400c116ad5d2cdaf0bc>@@
.?AV<lambda_9a4c460641eeb4213d39e91aec522d90>@@
.?AV<lambda_9a9b192dcae6874632669a18925ebf5e>@@
.?AV<lambda_9ad4dd46fb7ebf522a3e85e715143745>@@
.?AV<lambda_9b3108d194a09162f36c1b6ecbe4bd22>@@
.?AV<lambda_9b63af4b3b6c6dd79d915ddcfe92473d>@@
.?AV<lambda_9bb5d71c29e163b6768bdebbeaa9ef83>@@
.?AV<lambda_9bcf543f98218e465d42a5f7a449290e>@@
.?AV<lambda_9c03d71b3e2a72420d0112f6f3840dd4>@@
.?AV<lambda_9c23f807f5b88acf4c74334fd51de3b9>@@
.?AV<lambda_9c51e5beef5cfad81c8e2b8d3dd04a4a>@@
.?AV<lambda_9cc2379234b917d77614797746e75684>@@
.?AV<lambda_9cf24a11d7a47ec83a2235f766fd2a5c>@@
.?AV<lambda_9dc7af5c7bcff785bd9190f2cb464b36>@@
.?AV<lambda_9dd547f200315c70f4064d52aef7ac6e>@@
.?AV<lambda_9de7ed3747c068fd694551112d802911>@@
.?AV<lambda_9e35eefcb137cd146c958ca877000a5d>@@
.?AV<lambda_9e7e71f1a8889f6f7faa45e435ef1f25>@@
.?AV<lambda_9f22cccb787c8b0be66f7b40706128ae>@@
.?AV<lambda_9f96fff69aa6e4d3c160f75385bed764>@@
.?AV<lambda_a047e4fa7a019da5da5dcb5093bd2da9>@@
.?AV<lambda_a0f363c6d35242db2945bd981d31d01b>@@
.?AV<lambda_a179296bb96622fe30c41b2986ab7695>@@
.?AV<lambda_a191614639fd357df18cb9db7ec0bbb0>@@
.?AV<lambda_a1b033c1238f74f04d136673bf3141a7>@@
.?AV<lambda_a26d879b56b4c4dd33ee8f6ff5f1da50>@@
.?AV<lambda_a2ae5f61cc20c1ab03a30ab181749eea>@@
.?AV<lambda_a32f11f3f6edc3a900d9d34015d67705>@@
.?AV<lambda_a345bf27d2a96610b3b006a123df813d>@@
.?AV<lambda_a4015e490e3e9078f9108a810d677815>@@
.?AV<lambda_a45f274125d5aab3ada44bd6d91ed7f6>@@
.?AV<lambda_a4ad4e98f1a94b9237ebaa976e8eb831>@@
.?AV<lambda_a4fb1c1b5f905e04c31cbbe6c165878a>@@
.?AV<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@
.?AV<lambda_a51dc28255d67c31f47c2a37cec4d4e4>@@
.?AV<lambda_a6025d7753fe49dfa6ce58be5196bf75>@@
.?AV<lambda_a6353a4d545858b8902fbb038d252087>@@
.?AV<lambda_a6d62ed7a3aadce21a3a08f0b111f7e9>@@
.?AV<lambda_a7a0686f23e7f9337eaa10f069ee321b>@@
.?AV<lambda_a7f558f1dd0bc6dfbc34073d8010b2d2>@@
.?AV<lambda_a8b00e76dfe980214923eafc43926fd4>@@
.?AV<lambda_a931912cfcdf336ec0429a60e07a6cf5>@@
.?AV<lambda_a935037996bf9e3d7f1925320992d343>@@
.?AV<lambda_aa268cbc0b0d4966ec51ad17dda0ec82>@@
.?AV<lambda_aa638f082cd6e633ea8c394e1663fa60>@@
.?AV<lambda_aa831217bcc44892538d39aae8c330f6>@@
.?AV<lambda_aa88e462824a3ef64606c92b2b205d10>@@
.?AV<lambda_ab076180da33c991061bdac15a41448d>@@
.?AV<lambda_ab7cc530eb49a3a15082dbc27eb613da>@@
.?AV<lambda_ab7fd2a16f2ab36f5c7b628818e71578>@@
.?AV<lambda_abb9581c367ec240a8c0e5afd8181e99>@@
.?AV<lambda_acccfeb1e0041e26bf01c6097464f8c5>@@
.?AV<lambda_acdb2664af6229da1e4c43d330c314d8>@@
.?AV<lambda_ad8ca076531a0e62bdc4758313aec8ec>@@
.?AV<lambda_adcf8be8a94343086b930752e64c0b0f>@@
.?AV<lambda_adedb98ee19cb4d9a4a46a5fd17584b5>@@
.?AV<lambda_ae0d8b5a2da4af67276477f8d17abe42>@@
.?AV<lambda_aec81523952d967a50c07470b5814993>@@
.?AV<lambda_aecfda1830c0ee30e0e4a23c265062da>@@
.?AV<lambda_af13a0a68d606e99765e2f7bd840b2f7>@@
.?AV<lambda_af2c39467b4484bc2a2f611cf533daa7>@@
.?AV<lambda_af999ce2e03a2039dbf31c1ff13e0675>@@
.?AV<lambda_b090b097d440a4b2445143675bf63aa8>@@
.?AV<lambda_b0ef8716b08a7c90da37b162fe225b7a>@@
.?AV<lambda_b0f9e3c706f87be7af57692823441e06>@@
.?AV<lambda_b1c0cff63caf505f6536baee30943a62>@@
.?AV<lambda_b24067cfb776b28c2465a46fad4c39cd>@@
.?AV<lambda_b2b5b00a4ad3647a9a40b4f0dbb0745d>@@
.?AV<lambda_b32e5f2bc2fafd58a4afcda5e8537c65>@@
.?AV<lambda_b35f6304ab9b91e067de16d773b507fb>@@
.?AV<lambda_b3e04491343c2b41488666814183e8a7>@@
.?AV<lambda_b3ffb2b19f45444139b13fc0568f9537>@@
.?AV<lambda_b4d34ceb4628d068b1d974c038b79a44>@@
.?AV<lambda_b547b93cbe3e16cfc4195284dfd5eaef>@@
.?AV<lambda_b609acf5869a906202c2ec8d4f323bb0>@@
.?AV<lambda_b62b9616dd6208ed1baf09034b8ca175>@@
.?AV<lambda_b6c01241d8af757add895871e0bda6b2>@@
.?AV<lambda_b6c8ff4cf86b60687891fce83403bcfe>@@
.?AV<lambda_b6dee4d13517d8cf66ef1e240c3ec6a4>@@
.?AV<lambda_b765106161737954a77d8a171216f44e>@@
.?AV<lambda_b79d623619c8b488913a18719fb07ba7>@@
.?AV<lambda_b83bed438099179cd13c5a6033b90f7d>@@
.?AV<lambda_b86aa8ef1de0593a5547f08d792c1565>@@
.?AV<lambda_b881ee6a3336741e3e3697374c374936>@@
.?AV<lambda_b88ca2272a912106e48e54848e61d223>@@
.?AV<lambda_b92cd1be17f8632fbcc9dec212afe76b>@@
.?AV<lambda_b9ad0ccbf56c00a46342640cba7cdc2c>@@
.?AV<lambda_b9c72854712561eaa1748a5213a8f880>@@
.?AV<lambda_ba9cfe2bb13e49d1f5f6d627965891ec>@@
.?AV<lambda_baa2815e04b51c513ad52e6ee2edd5e6>@@
.?AV<lambda_bb1f7ff97f0a93bd0d62291fdf3e87e2>@@
.?AV<lambda_bb245b6c588ba3a259962707ee90e1f2>@@
.?AV<lambda_bb296edf374db63a1fb223cbff2a45aa>@@
.?AV<lambda_bb618da91ef45dc5293c089a74c35488>@@
.?AV<lambda_bbed65651851398ae9e91eb41072a5f9>@@
.?AV<lambda_bc30b190ccdc11003b68eaf48bc55331>@@
.?AV<lambda_bcef20d2b13b7b49fdebd823a7e734e1>@@
.?AV<lambda_be82f0d3082d1770e6fe9b6560ab180a>@@
.?AV<lambda_be9619b5fb1d1db7cf718b1fda3d5e82>@@
.?AV<lambda_bea95f42caac40af3d5dbd854845ff13>@@
.?AV<lambda_bf3ede44b9863bac339552631fecea38>@@
.?AV<lambda_c007df17e8115f08c5c6e2ce7e2201c0>@@
.?AV<lambda_c21643d1fb44758b12325da46a2d32c5>@@
.?AV<lambda_c23a6e376db7c7388aa04e9eb8ee3aca>@@
.?AV<lambda_c2634be0290355aa32c42903b822d942>@@
.?AV<lambda_c277816ed3e96f001ac0003fb11da190>@@
.?AV<lambda_c2abf8115bf6da52b8610764cf48ee0f>@@
.?AV<lambda_c2fef1cfbd08e9e21bcb74b985df87e6>@@
.?AV<lambda_c39fd5c6fac165bf428d70a08e4c8f15>@@
.?AV<lambda_c4dc4b2967ca7204e8ba49b0607e0250>@@
.?AV<lambda_c646dd14edaacae64487e0b96ad575f5>@@
.?AV<lambda_c6728963f8bb91595df67d14c61fd8fa>@@
.?AV<lambda_c6a4c758ec4a05da2df0a96bda1f195f>@@
.?AV<lambda_c6cc7a538d9c817426d2f4671032805a>@@
.?AV<lambda_c7328f9d78ba121fe15792ce469c1b69>@@
.?AV<lambda_c765ee4079d8132e5b64fd41ad2c9a7d>@@
.?AV<lambda_c8779530b1b47f6b819a3c840cb70825>@@
.?AV<lambda_c8957f10c145d7d78c010e1cb01ee7eb>@@
.?AV<lambda_c89e6783ea7ba65dd2bbca371d42018d>@@
.?AV<lambda_c9cc85b6189178098c01bbceb71ba127>@@
.?AV<lambda_c9e45910c6dad78e6e958bb0527b44e1>@@
.?AV<lambda_c9fe283d46d2f293dcb8573f075d3809>@@
.?AV<lambda_ca42e3f2ca4d6bbcd7bf706226d12a4c>@@
.?AV<lambda_ca87e505bf8a7e1f26579083c3683d94>@@
.?AV<lambda_cb7393b1270049ba922f1a24832dd162>@@
.?AV<lambda_cba067a26cf21de5d0e68b8b6f37fe8f>@@
.?AV<lambda_cc7060560dae87f5475ce357b0faca8e>@@
.?AV<lambda_cc71ada574b25d74a4c48413625b90d1>@@
.?AV<lambda_cc810076352af54d8ab1334d58ef2ac8>@@
.?AV<lambda_cc9e076beb57119667e5b07bb3c48707>@@
.?AV<lambda_cd453f5abbb4020fb3775475830cd8d1>@@
.?AV<lambda_cefaaa440fbc31a737d643cd7070b2a7>@@
.?AV<lambda_cf601ebc85517f1e503d9f32197b5b17>@@
.?AV<lambda_cf886ef71e61e28cd5fd0d3055f9efbe>@@
.?AV<lambda_cfafdf587dd99b527f40f2a9bbc4721a>@@
.?AV<lambda_cfd05ce920f37ad131560f3f4ba5b162>@@
.?AV<lambda_d05a56d909a989a3c2db176db7149e23>@@
.?AV<lambda_d05c3c022071d814f376085832823fd8>@@
.?AV<lambda_d085624eed89d70192230e9a1f62c5a7>@@
.?AV<lambda_d08789fec1ddb2ea31a7e42b01821aaa>@@
.?AV<lambda_d0c5713ac46ee06d27e6324a463b7bee>@@
.?AV<lambda_d0fdf4211aa9516cbe57f435cdbb747f>@@
.?AV<lambda_d132db5c486427a93d54120da48d5ea6>@@
.?AV<lambda_d1b650f23fa7659d3b2735ce4ed580e4>@@
.?AV<lambda_d2aedfced5017e33ef2fd58df23b739b>@@
.?AV<lambda_d2c19ae18917b59844dd4110518387dd>@@
.?AV<lambda_d2c978ff584bacbceac7be3bb080e51e>@@
.?AV<lambda_d2d693a490e9887da5a024c703dc8e3e>@@
.?AV<lambda_d30ba908d7a4df45178218a83c8b90aa>@@
.?AV<lambda_d3857f49b3e4107314682ca90a39ea61>@@
.?AV<lambda_d3c7976f3f38539a50838a16dd62ccb2>@@
.?AV<lambda_d48cb9baeb37d51a45fff2e006fd2ed3>@@
.?AV<lambda_d522df09ab9335db57f0cfc8c09d6630>@@
.?AV<lambda_d5d46741b892946aacca2ea22e630eea>@@
.?AV<lambda_d5d62f4b858abcded92348c54a906570>@@
.?AV<lambda_d63de458c7355252fdf7dac6af546a6c>@@
.?AV<lambda_d655da6f0498ff82874b3d8a213ddf66>@@
.?AV<lambda_d6b1ae38293f8956d8614f7fd42d8be1>@@
.?AV<lambda_d6d6a472b26fc7f192d382e93bba1d57>@@
.?AV<lambda_d70c00502c59385fd81a95257fd26b78>@@
.?AV<lambda_d73f309e1e17ba4988eef7d15e33e2b5>@@
.?AV<lambda_d77ac61f6238a68ec5589d982d5615ac>@@
.?AV<lambda_d7872c9b42ef54f352452eac083f3a35>@@
.?AV<lambda_d7a2681e4ada46acb33dd1adb547c252>@@
.?AV<lambda_d7d65f11678621cb189879800cf53faf>@@
.?AV<lambda_d8059ce711ce14c36533947d64fa5a34>@@
.?AV<lambda_d86f3bcde641b4c18df519c60bc10d09>@@
.?AV<lambda_d88752c7e7055eb8ee4749bbd38c2e1a>@@
.?AV<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@
.?AV<lambda_d8b96520499b24df75ab37992af46b4d>@@
.?AV<lambda_d8e8fb9b3d14cba6be93e2f77767d47a>@@
.?AV<lambda_d8f306720719e22494f4df721d014f49>@@
.?AV<lambda_d9adada7822ba67bc618dd6220c7e11e>@@
.?AV<lambda_da7b70169c4d0c30b25c92beb94d63ae>@@
.?AV<lambda_da7c0e243075d823e83aad5424aee4f1>@@
.?AV<lambda_daa97a08fba16356a015278e0f3ca1ed>@@
.?AV<lambda_dbdf3737eb2cb2871abd98870dad8484>@@
.?AV<lambda_dcbbb46dcb2ccb38f1b7e3e89a0ca172>@@
.?AV<lambda_dcbbb9aee7454d5a0feb975df66a7001>@@
.?AV<lambda_dd92783c3b5068fe6d4b01b7a52eff87>@@
.?AV<lambda_ddcedb921562b53aaf13cbc0af192f90>@@
.?AV<lambda_ddff9a77cb22aafff303a88b4705bee2>@@
.?AV<lambda_de00575298e9c7ead3b243890c596395>@@
.?AV<lambda_de173f36c1a40fc38c17fd4d3151fc18>@@
.?AV<lambda_dec8978adb68f88cd37c14b215792fcb>@@
.?AV<lambda_dfdd7885f2409b865180b051dead44b8>@@
.?AV<lambda_e08a75ecff8a2a27b308be3f8dfddc66>@@
.?AV<lambda_e128163c41b62dbd7415427042732d90>@@
.?AV<lambda_e1a7abf114b955966097bd83c14de705>@@
.?AV<lambda_e1a8783767138f2900763c385a76ace5>@@
.?AV<lambda_e252e05424c33acac940c2f481ad24ee>@@
.?AV<lambda_e318b9a1ac6011cec45976779008bc1d>@@
.?AV<lambda_e3ece229d743061e7008260e800aa786>@@
.?AV<lambda_e41de5887194c6f47359224ea1f4265d>@@
.?AV<lambda_e4fd1e1090be16100e1685f2f4877667>@@
.?AV<lambda_e5264339f7df0674b92961d30b5a7ffa>@@
.?AV<lambda_e65b3d84cc1ebbac94bfd47d08839322>@@
.?AV<lambda_e6687d53b2ff8a73e462a3df53da446b>@@
.?AV<lambda_e69e76386d33ec96f42e27fde06de5c2>@@
.?AV<lambda_e77a57374f1e055f8281ce5dd65e8ebd>@@
.?AV<lambda_e79b149fca88b77c33b72523d605d32a>@@
.?AV<lambda_e7ad5c511f7f0ca88484948ab82410f1>@@
.?AV<lambda_ea5f658f0d872dbd3ae3afb1f1fd1122>@@
.?AV<lambda_eae84d9e160bdd32110c79960a898549>@@
.?AV<lambda_eb887415aed41a3927a754246db16d35>@@
.?AV<lambda_ec14091c8d829910b5be28a833d6a3dd>@@
.?AV<lambda_ecc9b9120eb4793427a94169f5623a5b>@@
.?AV<lambda_ed67f482bebf565f55f04daede9ac63d>@@
.?AV<lambda_ee8bcd2d07e1fd45b1c55d57b7556b9f>@@
.?AV<lambda_ee954de93bf759bd8b1f4b4c9716ded3>@@
.?AV<lambda_ee988755aabf6d6b8cbe1162f42f9b60>@@
.?AV<lambda_eeeed7b40e814a0e70cf05a3907bbf81>@@
.?AV<lambda_ef1b5ee9690bf60d6d8ba03dec70f0fc>@@
.?AV<lambda_ef5c424a4193a85193eb7ea4c70aae69>@@
.?AV<lambda_ef9ce4d0dc32ab06ddd4426fedb787f1>@@
.?AV<lambda_efd47e41ca57d95ede53a33e8845ee3a>@@
.?AV<lambda_f013722fb06ba87b6ded393d910c85c6>@@
.?AV<lambda_f01e87ef597d7dc3f33e6877997ee749>@@
.?AV<lambda_f05e941e43878b26850ba9c86261d871>@@
.?AV<lambda_f0be09c6ec8e17e7ac33afa3db53ce78>@@
.?AV<lambda_f0ea35f12b551ef953688db40e1f4b34>@@
.?AV<lambda_f1490410ee527b42f3bd28e691dae2a7>@@
.?AV<lambda_f20c684c9a749a148b4d30f212c71a01>@@
.?AV<lambda_f273d4d4788dd6d522544c26d76a5ae4>@@
.?AV<lambda_f2842527842316c8394eef731b560fea>@@
.?AV<lambda_f2de741e38c166518c2010e724b68513>@@
.?AV<lambda_f30a6117225d3cb8e4a11f826263726e>@@
.?AV<lambda_f418dafe297dbbe0e3ada3e20a715a40>@@
.?AV<lambda_f4d85bd911255cc25b789888dd092506>@@
.?AV<lambda_f55fed088cc6887bf534564a0809769f>@@
.?AV<lambda_f563daf0e095e96808b0280be50284eb>@@
.?AV<lambda_f59689bb1f16cb74228cd5fe68f4cabe>@@
.?AV<lambda_f663e1cb5f92583d40a80c3711b532b4>@@
.?AV<lambda_f77770976f2f1ea63d04f11ed8ae8858>@@
.?AV<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@
.?AV<lambda_f7fefea6bfb8182e95c707a77e7f4a8f>@@
.?AV<lambda_f88babf2ad8b675b7b86e082d193f4e3>@@
.?AV<lambda_f8ab3456636176a3e9c9876b6c4ed749>@@
.?AV<lambda_f8dbfaed9d55440bb15cbf009ac934a6>@@
.?AV<lambda_f8f4a9a0b8865f5f39e8ba472bf52edc>@@
.?AV<lambda_f92d41c84d566f3577a74275e60ee3bc>@@
.?AV<lambda_f958ba65e401c00d0ddfa815d235fd3f>@@
.?AV<lambda_f9b942c519c5abdf8c9e76770faf15a7>@@
.?AV<lambda_fa46dd69454a850b787307a9d6678e80>@@
.?AV<lambda_fbf4f22e77a262ac13623763b425fa95>@@
.?AV<lambda_fc1c3f3352c8b4d29b9f843047cd4c91>@@
.?AV<lambda_fc2c6db54ba2969b0c3aebde05d3921d>@@
.?AV<lambda_fcf7b72cb8688ac639f6066c6f9347c9>@@
.?AV<lambda_fd266a9166d0b10d35a0d8f14994daa2>@@
.?AV<lambda_fd4f2bbf00caf507fea1cc6053ab984e>@@
.?AV<lambda_fdb0134f4d01b5f723238dd45cc4059f>@@
.?AV<lambda_fe5b044a59055ca66e7af958ee5f5bc3>@@
.?AVAllocator@flatbuffers@@
.?AVApiGraph@onnxruntime@@
.?AVApiNode@onnxruntime@@
.?AVApiTensor@onnxruntime@@
.?AVApiValueInfo@onnxruntime@@
.?AVAttentionFusion@onnxruntime@@
.?AVAttributeProto@onnx@@
.?AVbad_alloc@std@@
.?AVbad_array_new_length@std@@
.?AVbad_cast@std@@
.?AVbad_optional_access@std@@
.?AVBaseSelector@QDQ@onnxruntime@@
.?AVBFCArena@onnxruntime@@
.?AVBiasDropoutFusion@onnxruntime@@
.?AVBiasGeluFusion@onnxruntime@@
.?AVBiasSoftmaxFusion@onnxruntime@@
.?AVBinaryNodeGroupSelector@QDQ@onnxruntime@@
.?AVBinarySelector@QDQ@onnxruntime@@
.?AVCast@?A0xf3e57488@onnxruntime@@
.?AVCastElimination@onnxruntime@@
.?AVClip@onnxruntime@@
.?AVClipQuantFusion@onnxruntime@@
.?AVCLogSink@logging@onnxruntime@@
.?AVCommonSubexpressionElimination@onnxruntime@@
.?AVConcat@onnxruntime@@
.?AVConcatBase@onnxruntime@@
.?AVConstantFolding@onnxruntime@@
.?AVConstantOfShape@?A0x34ff6731@onnxruntime@@
.?AVConvActivation@selectors@?A0xe2853e69@onnxruntime@@
.?AVConvActivationFusion@onnxruntime@@
.?AVConvAddFusion@onnxruntime@@
.?AVConvAddRelu@selectors@?A0xe2853e69@onnxruntime@@
.?AVConvBNFusion@onnxruntime@@
.?AVConvInteger@onnxruntime@@
.?AVConvMulFusion@onnxruntime@@
.?AVConvNodeGroupSelector@QDQ@onnxruntime@@
.?AVConvSelector@QDQ@onnxruntime@@
.?AVCopyingFileInputStream@FileInputStream@io@protobuf@google@@
.?AVCopyingFileOutputStream@FileOutputStream@io@protobuf@google@@
.?AVCopyingInputStream@io@protobuf@google@@
.?AVCopyingInputStreamAdaptor@io@protobuf@google@@
.?AVCopyingOstreamOutputStream@OstreamOutputStream@io@protobuf@google@@
.?AVCopyingOutputStream@io@protobuf@google@@
.?AVCopyingOutputStreamAdaptor@io@protobuf@google@@
.?AVCPUAllocator@onnxruntime@@
.?AVCPUDataTransfer@onnxruntime@@
.?AVCPUExecutionProvider@onnxruntime@@
.?AVDataTypeImpl@onnxruntime@@
.?AVDeepCpuGruOp@onnxruntime@@
.?AVDeepCpuLstmOp@onnxruntime@@
.?AVDefaultAllocator@flatbuffers@@
.?AVDivMulFusion@onnxruntime@@
.?AVDropDQNodeGroupSelector@QDQ@onnxruntime@@
.?AVDropDQNodesSelector@QDQ@onnxruntime@@
.?AVDropQDQNodeGroupSelector@QDQ@onnxruntime@@
.?AVDropQDQNodesSelector@QDQ@onnxruntime@@
.?AVDynamicQuantizeLSTM@contrib@onnxruntime@@
.?AVDynamicQuantizeMatMul@contrib@onnxruntime@@
.?AVDynamicQuantizeMatMulFusion@onnxruntime@@
.?AVEliminateDropout@onnxruntime@@
.?AVEliminateIdentity@onnxruntime@@
.?AVEliminateSlice@onnxruntime@@
.?AVEmbedLayerNormFusion@onnxruntime@@
.?AVEnv@onnxruntime@@
.?AVEnvThread@onnxruntime@@
.?AVEnvTime@onnxruntime@@
.?AVerror_category@std@@
.?AVexception@detail@nlohmann@@
.?AVexception@std@@
.?AVExecutionFrame@onnxruntime@@
.?AVExecutionPlanBase@onnxruntime@@
.?AVExLibLoader@onnxruntime@@
.?AVExpandElimination@onnxruntime@@
.?AVExtendedThreadPoolInterface@concurrency@onnxruntime@@
.?AVfacet@locale@std@@
.?AVFastGeluFusion@onnxruntime@@
.?AVFatalException@protobuf@google@@
.?AVFileInputStream@io@protobuf@google@@
.?AVFileOutputStream@io@protobuf@google@@
.?AVFreeDimensionOverrideTransformer@onnxruntime@@
.?AVFunction@onnxruntime@@
.?AVFunctionImpl@onnxruntime@@
.?AVFunctionKernel@onnxruntime@@
.?AVFunctionProto@onnx@@
.?AVFuseConvActivation@actions@?A0xe2853e69@onnxruntime@@
.?AVFuseConvAddRelu@actions@?A0xe2853e69@onnxruntime@@
.?AVFusedConvFloat@contrib@onnxruntime@@
.?AVFuseReluClip@onnxruntime@@
.?AVGather@onnxruntime@@
.?AVGatherBase@onnxruntime@@
.?AVGatherElements@onnxruntime@@
.?AVGeluApproximation@onnxruntime@@
.?AVGeluFusion@onnxruntime@@
.?AVGemmActivationFusion@onnxruntime@@
.?AVGemmBase@onnxruntime@@
.?AVGemmNodeGroupSelector@QDQ@onnxruntime@@
.?AVGemmSelector@QDQ@onnxruntime@@
.?AVGemmSumFusion@onnxruntime@@
.?AVGemmTransposeFusion@onnxruntime@@
.?AVGraph@onnxruntime@@
.?AVGraphConstantInitializerGetter@?A0x9d9d0a9c@onnxruntime@@
.?AVGraphInferencer@onnx@@
.?AVGraphInferencerImpl@onnxruntime@@
.?AVGraphInferencerImpl@shape_inference@onnx@@
.?AVGraphProto@onnx@@
.?AVGraphRef@api@onnx_layout_transformation@@
.?AVGraphTransformer@onnxruntime@@
.?AVIAllocator@onnxruntime@@
.?AVIAllocatorImplWrappingOrtAllocator@onnxruntime@@
.?AVIControlFlowKernel@controlflow@onnxruntime@@
.?AVIDataTransfer@onnxruntime@@
.?AVIExecutionFrame@onnxruntime@@
.?AVIExecutionProvider@onnxruntime@@
.?AVIExecutor@onnxruntime@@
.?AVIf@onnxruntime@@
.?AVInferenceContextImpl@onnxruntime@@
.?AVInferenceError@onnx@@
.?AVInferenceSession@onnxruntime@@
.?AVInsertCastTransformer@onnxruntime@@
.?AVinvalid_argument@std@@
.?AVinvalid_iterator@detail@nlohmann@@
.?AVIOnnxRuntimeOpSchemaCollection@onnxruntime@@
.?AVios_base@std@@
.?AVISchemaRegistry@onnx@@
.?AVISequentialPlannerContext@onnxruntime@@
.?AVISink@logging@onnxruntime@@
.?AVITensorAllocator@onnxruntime@@
.?AVIterator@?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@
.?AVIterator@?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@
.?AVLayerNormFusion@onnxruntime@@
.?AVLoggingWrapper@@
.?AVlogic_error@std@@
.?AVLSTMBase@onnxruntime@@
.?AVMapProto@onnx@@
.?AVMatMulAddFusion@onnxruntime@@
.?AVMatMulInteger@onnxruntime@@
.?AVMatMulIntegerBase@onnxruntime@@
.?AVMatMulIntegerToFloat@contrib@onnxruntime@@
.?AVMatMulIntegerToFloatBase@contrib@onnxruntime@@
.?AVMatMulIntegerToFloatFusion@onnxruntime@@
.?AVMatMulNodeGroupSelector@QDQ@onnxruntime@@
.?AVMatMulScaleFusion@onnxruntime@@
.?AVMatMulSelector@QDQ@onnxruntime@@
.?AVMatmulTransposeFusion@onnxruntime@@
.?AVMaxPoolV8@onnxruntime@@
.?AVMemcpyTransformer@onnxruntime@@
.?AVMessageLite@protobuf@google@@
.?AVMLAS_QGEMM_OUTPUT_PROCESSOR@@
.?AVMLAS_QGEMM_SCALE_BIAS_OUTPUT_PROCESSOR@@
.?AVModelProto@onnx@@
.?AVNchwcAveragePool@contrib@onnxruntime@@
.?AVNchwcConv@contrib@onnxruntime@@
.?AVNchwcMaxPool@contrib@onnxruntime@@
.?AVNchwcPoolBase@contrib@onnxruntime@@
.?AVNchwcTransformer@onnxruntime@@
.?AVNhwcInferenceContext@contrib@onnxruntime@@
.?AVNhwcTransformer@onnxruntime@@
.?AVNodeGroupSelector@QDQ@onnxruntime@@
.?AVNodeProto@onnx@@
.?AVNodeRef@api@onnx_layout_transformation@@
.?AVNonTensorTypeBase@onnxruntime@@
.?AVNoopElimination@onnxruntime@@
.?AVNotImplementedException@onnxruntime@@
.?AVNotWhereFusion@onnxruntime@@
.?AVOnnxRuntimeException@onnxruntime@@
.?AVOnnxRuntimeOpSchemaRegistry@onnxruntime@@
.?AVOperatorSetIdProto@onnx@@
.?AVOpKernel@onnxruntime@@
.?AVOpKernelContext@onnxruntime@@
.?AVOpKernelContextInternal@onnxruntime@@
.?AVOpSchemaRegistry@onnx@@
.?AVOptimizerExecutionFrame@onnxruntime@@
.?AVOptionalProto@onnx@@
.?AVOptionalTypeBase@onnxruntime@@
.?AVOstreamOutputStream@io@protobuf@google@@
.?AVother_error@detail@nlohmann@@
.?AVout_of_range@detail@nlohmann@@
.?AVout_of_range@std@@
.?AVParallelExecutor@onnxruntime@@
.?AVparse_error@detail@nlohmann@@
.?AVPoolBase@onnxruntime@@
.?AVPow@onnxruntime@@
.?AVPrimitiveDataTypeBase@onnxruntime@@
.?AVQDQFinalCleanupTransformer@onnxruntime@@
.?AVQDQPropagationTransformer@onnxruntime@@
.?AVQDQS8ToU8Transformer@onnxruntime@@
.?AVQDQSelectorActionTransformer@onnxruntime@@
.?AVRange@onnxruntime@@
.?AVReluQuantFusion@onnxruntime@@
.?AVRemoveDuplicateCastTransformer@onnxruntime@@
.?AVReorderInput@contrib@onnxruntime@@
.?AVReorderOutput@contrib@onnxruntime@@
.?AVReshape@onnxruntime@@
.?AVReshapeFusion@onnxruntime@@
.?AVResultException@wil@@
.?AVRewriteRule@onnxruntime@@
.?AVRuleBasedGraphTransformer@onnxruntime@@
.?AVruntime_error@std@@
.?AVScatterND@onnxruntime@@
.?AVSchemaError@onnx@@
.?AVSchemaRegistryManager@onnxruntime@@
.?AVSelectorActionTransformer@onnxruntime@@
.?AVSequenceProto@onnx@@
.?AVSequenceTensorTypeBase@onnxruntime@@
.?AVSequentialExecutor@onnxruntime@@
.?AVSequentialPlannerContext@onnxruntime@@
.?AVShape@onnxruntime@@
.?AVSimpleTensorAllocator@onnxruntime@@
.?AVSimplifiedLayerNormFusion@onnxruntime@@
.?AVSkipLayerNormFusion@onnxruntime@@
.?AVSliceBase@onnxruntime@@
.?AVSparseTensorProto@onnx@@
.?AVSparseTensorTypeBase@onnxruntime@@
.?AVSplit@onnxruntime@@
.?AVSplitBase@onnxruntime@@
.?AVSqueeze@onnxruntime@@
.?AVSqueezeBase@onnxruntime@@
.?AVStringStringEntryProto@onnx@@
.?AVTelemetry@onnxruntime@@
.?AVTensorAllocatorWithMemPattern@onnxruntime@@
.?AVTensorAnnotation@onnx@@
.?AVTensorProto@onnx@@
.?AVTensorProto_Segment@onnx@@
.?AVTensorRef@api@onnx_layout_transformation@@
.?AVTensorShapeProto@onnx@@
.?AVTensorShapeProto_Dimension@onnx@@
.?AVTensorTypeBase@onnxruntime@@
.?AVThreadPoolInterface@Eigen@@
.?AVTrainingInfoProto@onnx@@
.?AVTranspose@onnxruntime@@
.?AVTransposeBase@onnxruntime@@
.?AVTransposeOptimizer@onnxruntime@@
.?AVtype_error@detail@nlohmann@@
.?AVtype_info@@
.?AVTypeProto@onnx@@
.?AVTypeProto_Map@onnx@@
.?AVTypeProto_Opaque@onnx@@
.?AVTypeProto_Optional@onnx@@
.?AVTypeProto_Sequence@onnx@@
.?AVTypeProto_SparseTensor@onnx@@
.?AVTypeProto_Tensor@onnx@@
.?AVUnaryNodeGroupSelector@QDQ@onnxruntime@@
.?AVUnarySelector@QDQ@onnxruntime@@
.?AVUnsqueeze@onnxruntime@@
.?AVUnsqueezeBase@onnxruntime@@
.?AVUnsqueezeElimination@onnxruntime@@
.?AVValidationError@checker@onnx@@
.?AVValueInfoProto@onnx@@
.?AVValueInfoRef@api@onnx_layout_transformation@@
.?AVVariadicNodeGroupSelector@QDQ@onnxruntime@@
.?AVVariadicSelector@QDQ@onnxruntime@@
.?AVViewerFunctionImpl@onnxruntime@@
.?AVWindowsEnv@?A0x6f1db497@onnxruntime@@
.?AVWindowsEnvTime@?A0x936fa4c5@onnxruntime@@
.?AVWindowsTelemetry@onnxruntime@@
.?AVWindowsThread@?A0x6f1db497@onnxruntime@@
.?AVWOStreamSink@logging@onnxruntime@@
.?AVZeroCopyInputStream@io@protobuf@google@@
.?AVZeroCopyOutputStream@io@protobuf@google@@
.00cfg
.5?53
.B0x.
.b2^4
.CRT$XCA
.CRT$XCL
.CRT$XCU
.CRT$XCZ
.CRT$XDA
.CRT$XDZ
.CRT$XIA
.CRT$XIZ
.CRT$XLA
.CRT$XLC
.CRT$XLD
.CRT$XLZ
.CRT$XPA
.CRT$XPZ
.CRT$XTA
.CRT$XTZ
.D0".-
.data
.data$r
.data$rs
.edata
.F0422
.gfids
.giats
.idata$2
.idata$3
.idata$4
.idata$5
.idata$6
.Input initial_c must have shape {
.json
.L0j2
.L0Z&6(
.N*>(M
.P6A?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV01@0@Z
.P6A?AV?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J1@Z
.P6A?AV?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J1@Z
.P6A?AVStatus@common@onnxruntime@@AEAVFuncManager@2@AEBVOpKernelInfo@2@AEAV?$unique_ptr@VOpKernel@onnxruntime@@U?$default_delete@VOpKernel@onnxruntime@@@std@@@std@@@Z
.P6A?AVStatus@common@onnxruntime@@AEAVGraph@2@AEA_NAEBVIExecutionProvider@2@@Z
.P6A?AVStatus@common@onnxruntime@@AEBVNode@2@AEAVGraph@2@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV56@AEBUResolveOptions@42@@Z
.P6A_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@1@AEAVFunctionProto@1@@Z
.P6AMMMM@Z
.P6AXAEAUDataPropagationContext@onnx@@@Z
.P6AXAEAUInferenceContext@onnx@@@Z
.P6AXAEAVOpSchema@onnx@@@Z
.P6AXPEAX@Z
.pdata
.rdata
.rdata$r
.rdata$T
.rdata$voltmd
.rdata$zETW0
.rdata$zETW1
.rdata$zETW2
.rdata$zETW9
.rdata$zzzdbg
.rsrc$01
.rsrc$02
.text
.text$di
.text$mn
.text$mn$00
.text$x
.text$yd
.tls$
.tls$ZZZ
.V04.t402
.xdata
.xdata$x
: Chunks 
: Conflict with existing kernel def hash.
: Conflicting with a registered kernel with op versions.
: failed validating the check: 
:$<T>
:*<HR
:0<~>p:F(
:b>vBpD
:F<.>
:F<N6(8
:L<.>,6T:
:Loopt
:n<^>
; expected 
; last read: '
;ai.ou{f
;ba~H
;ba=@
;h u=H
;H9D3(
;J }wH
;p uN
;w,~PA
;Y(|0
? but has rank 
??0?$basic_ios@_WU?$char_traits@_W@std@@@std@@IEAA@XZ
??0?$basic_ios@DU?$char_traits@D@std@@@std@@IEAA@XZ
??0?$basic_iostream@_WU?$char_traits@_W@std@@@std@@QEAA@PEAV?$basic_streambuf@_WU?$char_traits@_W@std@@@1@@Z
??0?$basic_iostream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@@Z
??0?$basic_istream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@_N@Z
??0?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAA@PEAV?$basic_streambuf@_WU?$char_traits@_W@std@@@1@_N@Z
??0?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAA@PEAV?$basic_streambuf@DU?$char_traits@D@std@@@1@_N@Z
??0?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@IEAA@XZ
??0?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAA@XZ
??0_Locinfo@std@@QEAA@PEBD@Z
??0_Lockit@std@@QEAA@H@Z
??0facet@locale@std@@IEAA@_K@Z
??1?$basic_ios@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
??1?$basic_ios@DU?$char_traits@D@std@@@std@@UEAA@XZ
??1?$basic_iostream@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
??1?$basic_iostream@DU?$char_traits@D@std@@@std@@UEAA@XZ
??1?$basic_istream@DU?$char_traits@D@std@@@std@@UEAA@XZ
??1?$basic_ostream@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
??1?$basic_ostream@DU?$char_traits@D@std@@@std@@UEAA@XZ
??1?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAA@XZ
??1?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAA@XZ
??1_Locinfo@std@@QEAA@XZ
??1_Lockit@std@@QEAA@XZ
??1facet@locale@std@@MEAA@XZ
??5?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@AEAF@Z
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@_J@Z
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@H@Z
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@I@Z
??6?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV01@K@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_J@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_K@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@_N@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@F@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@H@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@I@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@K@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@P6AAEAV01@AEAV01@@Z@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@P6AAEAVios_base@1@AEAV21@@Z@Z
??6?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV01@PEBX@Z
??Bid@locale@std@@QEAA_KXZ
?_Decref@facet@locale@std@@UEAAPEAV_Facet_base@3@XZ
?_Fiopen@std@@YAPEAU_iobuf@@PEB_WHH@Z
?_Getcat@?$codecvt@DDU_Mbstatet@@@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?_Getcat@?$ctype@_W@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?_Getcat@?$ctype@D@std@@SA_KPEAPEBVfacet@locale@2@PEBV42@@Z
?_Getcvt@_Locinfo@std@@QEBA?AU_Cvtvec@@XZ
?_Getfalse@_Locinfo@std@@QEBAPEBDXZ
?_Getgloballocale@locale@std@@CAPEAV_Locimp@12@XZ
?_Gettrue@_Locinfo@std@@QEBAPEBDXZ
?_Incref@facet@locale@std@@UEAAXXZ
?_Init@?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAAXXZ
?_Ipfx@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAA_N_N@Z
?_Lock@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAAXXZ
?_Lock@?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAAXXZ
?_Osfx@?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAXXZ
?_Osfx@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAXXZ
?_Pninc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@IEAAPEA_WXZ
?_Pninc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@IEAAPEADXZ
?_Syserror_map@std@@YAPEBDH@Z
?_Throw_C_error@std@@YAXH@Z
?_Unlock@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@UEAAXXZ
?_Unlock@?$basic_streambuf@DU?$char_traits@D@std@@@std@@UEAAXXZ
?_Winerror_map@std@@YAHH@Z
?_Xbad_alloc@std@@YAXXZ
?_Xbad_function_call@std@@YAXXZ
?_Xinvalid_argument@std@@YAXPEBD@Z
?_Xlength_error@std@@YAXPEBD@Z
?_Xout_of_range@std@@YAXPEBD@Z
?33{@
?456789:;<=
?always_noconv@codecvt_base@std@@QEBA_NXZ
?c_str@?$_Yarn@D@std@@QEBAPEBDXZ
?cerr@std@@3V?$basic_ostream@DU?$char_traits@D@std@@@1@A
?classic@locale@std@@SAAEBV12@XZ
?clear@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAAXH_N@Z
?flush@?$basic_ostream@_WU?$char_traits@_W@std@@@std@@QEAAAEAV12@XZ
?flush@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@XZ
?get@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAHXZ
?getloc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEBA?AVlocale@2@XZ
?getloc@ios_base@std@@QEBA?AVlocale@2@XZ
?id@?$codecvt@DDU_Mbstatet@@@std@@2V0locale@2@A
?id@?$ctype@_W@std@@2V0locale@2@A
?id@?$ctype@D@std@@2V0locale@2@A
?id@?$numpunct@D@std@@2V0locale@2@A
?imbue@?$basic_ios@_WU?$char_traits@_W@std@@@std@@QEAA?AVlocale@2@AEBV32@@Z
?imbue@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAA?AVlocale@2@AEBV32@@Z
?imbue@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAXAEBVlocale@2@@Z
?imbue@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAXAEBVlocale@2@@Z
?in@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEBD1AEAPEBDPEAD3AEAPEAD@Z
?out@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEBD1AEAPEBDPEAD3AEAPEAD@Z
?put@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@D@Z
?read@?$basic_istream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@PEAD_J@Z
?sbumpc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?setbuf@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAPEAV12@PEA_W_J@Z
?setbuf@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAPEAV12@PEAD_J@Z
?setstate@?$basic_ios@_WU?$char_traits@_W@std@@@std@@QEAAXH_N@Z
?setstate@?$basic_ios@DU?$char_traits@D@std@@@std@@QEAAXH_N@Z
?sgetc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?showmanyc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JXZ
?showmanyc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JXZ
?snextc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHXZ
?sputc@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@QEAAG_W@Z
?sputc@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAAHD@Z
?sputn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@QEAA_JPEB_W_J@Z
?sputn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@QEAA_JPEBD_J@Z
?sync@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAHXZ
?sync@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAHXZ
?uflow@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAAGXZ
?uflow@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAAHXZ
?uncaught_exception@std@@YA_NXZ
?unshift@?$codecvt@DDU_Mbstatet@@@std@@QEBAHAEAU_Mbstatet@@PEAD1AEAPEAD@Z
?wclog@std@@3V?$basic_ostream@_WU?$char_traits@_W@std@@@1@A
?widen@?$basic_ios@DU?$char_traits@D@std@@@std@@QEBADD@Z
?widen@?$ctype@_W@std@@QEBA_WD@Z
?write@?$basic_ostream@DU?$char_traits@D@std@@@std@@QEAAAEAV12@PEBD_J@Z
?xsgetn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JPEA_W_J@Z
?xsgetn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JPEAD_J@Z
?xsputn@?$basic_streambuf@_WU?$char_traits@_W@std@@@std@@MEAA_JPEB_W_J@Z
?xsputn@?$basic_streambuf@DU?$char_traits@D@std@@@std@@MEAA_JPEBD_J@Z
@ 9A 
@ 9A uxH
@ 9p 
@ A9A 
@ H;}
@ H+A
@ Hc@ H
@ HcX H
@$L(J
@(A;B
@,9E,
@,A;B
@.data
@.reloc
@.rsrc
@:`x$
@\B,D"F$H(@
@_RDATA
@~DjF
@08~F
@20Z#
@60[D
@60CD
@6P(E
@6pGD
@6PnE
@6PRE
@8,:|
@8{Ptt
@8|$ t
@8|$P
@8|$Pt
@83tdH
@8kPt
@8kPt_3
@8kPto3
@8oPtt
@8wPt
@A\_^][
@A]A\_^]
@A^][
@A^^[
@A^_]
@A^_^
@A^_^][
@A^A]A\
@A^A]A\_^
@A_][
@A__^
@A_A]A\^[
@A_A]A\_^
@A_A^]
@A_A^^
@A_A^_
@A_A^_^[
@A_A^_^]
@A_A^A\
@A_A^A\^]
@A_A^A\_^
@A_A^A\_^][
@A_A^A]][
@A_A^A]A\_
@A_A^A]A\_^[
@A_A^A]A\_^]
@bq|H
@bq|I
@bQ~I
@f`"E
@fDjF
@HB,D&F,>
@hJ(@
@hJ@@.4~>
@hJNN
@HPX`
@SATAUAVH
@SATAVAWH
@SAUAVH
@SAUH
@SAVH
@SLcT$pLc\$XHc\$HL
@SUATAUAWH
@SUAUAVAWH
@SUAVAWH
@SUAVH
@SUVATAUAVAWH
@SUVATAVH
@SUVAVAWH
@SUVAVH
@SUVAWH
@SUVH
@SUVWATAUAVAWH
@SUVWATAUAVH
@SUVWATAUAWH
@SUVWATAVAWH
@SUVWATAVH
@SUVWATH
@SUVWAUAVAWH
@SUVWAUAVH
@SUVWAUAWH
@SUVWAVAWH
@SUVWAVH
@SUVWAWH
@SUVWH
@SUWATAUAVAWH
@SUWATAVAWH
@SUWATAVH
@SUWAUAVAWH
@SUWAVAWH
@SUWAVH
@SUWAWH
@SUWH
@SVATAUAWH
@SVATAVAWH
@SVATH
@SVAVAWH
@SVAVH
@SVWATAUAVAWH
@SVWATAVAWH
@SVWATH
@SVWAUH
@SVWAVAWH
@SVWAVH
@SVWAWH
@SVWH
@SWATAUAVAWH
@SWATAUH
@SWATAVH
@SWATH
@SWAUAVAWH
@SWAUAVH
@SWAUH
@SWAVAWH
@SWAVH
@SWAWH
@t_H;
@t`H;
@t1H;
@UATH
@UAUAVAWH
@UAUH
@UAVAWH
@UAVH
@USVATAUAVAWH
@USVWATAUAVAW
@USVWATAUAVAWH
@USVWATAVAWH
@USVWATAWH
@USVWAUAVAWH
@USVWAUH
@USVWAVAWH
@USVWAVH
@USVWAWH
@USVWH
@USWH
@UVATAVAWH
@UVATAWH
@UVAUH
@UVAVH
@UVWATAUAVAWH
@UVWAVAWH
@UVWH
@UWAVAWH
@UWAVH
@VATAVH
@VATAVL
@VAVAWH
@VAVH
@VAWH
@VWAVAWH
@VWAVH
@VWAWH
@WATAUAVAWH
@WATAVAWH
@WAWH
@zBX\
[ UVWATAUAVAWH
[ UVWH
[%hs(%hs)]
[%hs]
'[', '{', or a literal
[json.exception.
[libprotobuf %s %s:%d] %s
[Memory] SessionStateInitializer statically allocates 
[numpy.where](https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html)
[ONNXRuntimeError]
[oz:h<g
[ParseError at position 
[ShapeInferenceError] 
[TypeInferenceError] 
\ z"n$X.
\$ 9B(uNH
\$ A^A\^
\$ ATAVAWH
\$ AVH
\$ D8|$(
\$ D8t$(
\$ E3
\$ H;
\$ H;U
\$ H+
\$ I;
\$ I+\$
\$ Ii
\$ L;
\$ L+
\$ M;
\$ Mi
\$ Mk
\$ UH
\$ UVL
\$ UVWATAUAVAWH
\$ UVWATAUH
\$ UVWATAWH
\$ UVWAVAWH
\$ UVWH
\$ VH
\$ VWATAVAWH
\$ VWAVH
\$ WAVAWH
\$ WH
\$$@2
\$(D8t$0
\$(E3
\$(H;
\$(H;U
\$(H+\$ H
\$(L;
\$@@2
\$@D;
\$@E3
\$@ff
\$@H;
\$@H;]
\$@H+
\$@Hc
\$@u!
\$`H;
\$`u'
\$0^]
\$0A+
\$0E3
\$0E9`
\$0ff
\$0fff
\$0H#
\$0H;
\$0H+
\$0Hc
\$0HcV
\$0Hk
\$0M;
\$4D9
\$8A_A]A\_]
\$8A_A^A]A\_
\$8E3
\$8H;
\$8L;
\$8t'H
\$D8YPtuH
\$HA_A^_^]
\$HE3
\$Hff
\$Hfff
\$HH;
\$HI;
\$hI;
\$hL;
\$hL;\$p
\$p+]
\$p9Y0u
\$pE3
\$PE3
\$pE3
\$pI;
\$PI;
\$PL+
\$X8P
\$XE3
\$xE3
\$xH;
\$XHc\$pH
\$XI;
\$XLcD$TH
\@^.\
\~^,`~b,d.f
\3JCy7
\4^"f"h(d
\4^"n"p(d
\D$ fH
\L$ f
\t^n`4b"d f(^
] (usually, this means you 
] already exists with value [
] because it's the graph's output.
] for now
] is not supported this build 
] not in lexicographic sorted order.
] not in sorted order.
] op_type [
] out of range [0, 
] out of range.
] should not be greater than specified axis dim value [
](A+]0A
], "core": 
], could not find NodeArg 
], Value=
]. Actual value is 
]. It will be overwritten
]. Its actual value is: 
]X@#bBUX@
]X@#bQ}H
^ +^0
^ H+^
^(+^0
^4`"b"d(\
^4j"l"d(\ZXe
^6h:<<\@
^fbjdBf:V%
^Xbjd
_(+_0
__acrt_iob_func
__C_specific_handler
__current_exception
__current_exception_context
__CxxFrameHandler4
__RTtypeid
__std_exception_copy
__std_exception_destroy
__std_terminate
__std_type_info_compare
__std_type_info_destroy_list
__std_type_info_name
__stdio_common_vfprintf
__stdio_common_vsnprintf_s
__stdio_common_vsprintf
__stdio_common_vswprintf
_aligned_free
_aligned_malloc
_beginthreadex
_bn_nchwc
_callnewh
_Cast
_cexit
_close
_configure_narrow_argv
_crt_atexit
_CxxThrowException
_dclass
_difftime64
_dummy
_errno
_execute_onexit_table
_fdclass
_fdsign
_fence_after
_fence_before
_fseeki64
_fstat64i32
_FusedMatMulAndScale
_get_stream_buffer_pointers
_gmtime64_s
_initialize_narrow_environment
_initialize_onexit_table
_initterm
_initterm_e
_invalid_parameter_noinfo
_invalid_parameter_noinfo_noreturn
_kernel_time
_localtime64_s
_lock_file
_min_zero_constant
_mktime64
_Mtx_destroy_in_situ
_Mtx_init_in_situ
_Mtx_lock
_Mtx_unlock
_nchwc
_post_dq
_pre_q
_purecall
_q_to_dqJ
_Query_perf_counter
_Query_perf_frequency
_RDATA
_read
_register_onexit_function
_RuleBasedTransformer
_seh_filter_dll
_sopen_s
_stat64i32
_strtoi64
_sum_transformed
_Thrd_hardware_concurrency
_Thrd_id
_token_
_transformed
_unlock_file
_Unused
_write
_wsopen_s
_Xtime_get_ticks
`.rdata
`::Jf
`@Per-column quantization parameter of batched matrix should have same dimension as the matrix,and its size by K should be equal to the matrix's size.
`0^0\
`08~F
`0M+`(I
`60kD
`6P{E
`A]_[
`A^^]
`A^_[
`A^_^
`A^_^[]
`A^_^][
`A^A\_][
`A^A][
`A^A]]
`A__]
`A_A^_^[
`A_A^_^]
`A_A^A\_^
`A_A^A\_^[]
`A_A^A\_^][
`A_A^A]_^][
`A_A^A]A\_][
`A_A^A]A\_^[
`A_A^A]A\_^]
`anonymous-namespace'::GetDataTransfer
`anonymous-namespace'::GetExternalDataInfo
`anonymous-namespace'::GetIndicesTensor
`anonymous-namespace'::ReadExternalDataForTensor
`anonymous-namespace'::ValidateFillInputArgs
`c` - cell gate
`f(x) = quantize(dequantize(x)) for dequantize(x) >= 0`, is applied to the data tensor elementwise.
`f` - forget gate
`Fb.`
`fdjf
`h` - hidden gate
`H` - Hidden state
`i` - input gate
`InlinedVector::at(size_type)` failed bounds check
`num_directions` - 2 if direction == bidirectional else 1
`o` - output gate
`P[iof]`  - P peephole weight vector for input, output, and forget gates
`PB[iof]`  - P peephole weight vector for backward input, output, and forget gates
`R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates
`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates
`r` - reset gate
`Rb[iofc]` - R bias vectors for input, output, forget, and cell gates
`RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates
`Rb[zrh]` - R bias vectors for update, reset, and hidden gates
`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates
`RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates
`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates
`RBbi` - RR bias vectors for backward input gate
`Rbi` - R parameter bias vector for input gate
`RBi` - R recurrence weight matrix for backward input gate
`Ri` - R recurrence weight matrix for input gate
`t` - time step (t-1 means previous time step)
`W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates
`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates
`Wb[iofc]` - W bias vectors for input, output, forget, and cell gates
`WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates
`Wb[zrh]` - W bias vectors for update, reset, and hidden gates
`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates
`WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates
`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates
`WBbi` - WR bias vectors for backward input gate
`Wbi` - W parameter bias vector for input gate
`WBi` - W parameter weight matrix for backward input gate
`Wi` - W parameter weight matrix for input gate
`X` - input tensor
`z` - update gate
{ AVH
{"cat" : "
{"main_thread": {
{additionalDocumentation}
{bQ}X
{name}
|$ A;
|$ A^
|$ ATAVAWH
|$ AV
|$ AVH
|$ AVM
|$ AWH
|$ D8t$(
|$ E3
|$ ff
|$ H;
|$ H9A
|$ Hc
|$ I;
|$ Ik
|$ L;
|$ M;
|$ M;zH
|$ Mco
|$ Mi
|$ UATAUAVAWH
|$ UAVAWH
|$ UH
|$$9y0tAA
|$(A^
|$(D8|$0
|$(H;
|$(H;S
|$(Hc
|$(I;
|$(I+
|$(Ik
|$(L;
|$(M;zH
|$(Mc
|$@E3
|$@ff
|$@fff
|$@H#A0H
|$@H;|$x
|$@H;t$X
|$@Hc
|$@I;
|$@L;
|$@M;
|$`E3
|$`H;
|$`H+
|$0E3
|$0ff
|$0fff
|$0H;
|$0H+|$(H
|$0H9
|$0I;
|$0L;
|$0Lc
|$0Mc
|$0u5H
|$4D;|$8
|$4E9y(
|$8D8{
|$8E3
|$8ff
|$8H;
|$8H+
|$8I;
|$8I+|$0H
|$8L;
|$8M;
|$AD2
|$H9S(u
|$HA;
|$HE3
|$hE3
|$HE3
|$hE3
|$HE3
|$hff
|$Hfff
|$HH;
|$HH+
|$hH+
|$HH+
|$HI;
|$hI9>tyH
|$hL;
|$HL;
|$hL;
|$hL;|$p
|$HM;
|$HMco
|$P;G
|$P@2
|$p+}
|$PD;
|$PE2
|$pE3
|$PE3
|$pE3
|$PE3
|$PH;
|$pH;
|$PH;
|$pH;}
|$pH+
|$PH+
|$PI;
|$pI;
|$PI;
|$pI;
|$PI;
|$pI;
|$pI;~
|$PL+
|$PLi
|$PM;
|$poH
|$PtXH
|$PtZI
|$x@8y
|$xE3
|$XE3
|$Xff
|$xfff
|$XfI
|$XH;
|$xH;
|$XH;
|$xH;
|$xH;_
|$XHc\$pH
|$XI;
|$xI;
|$xL;
|$xL+
|$XLcD$TH
|$XM;
|`zL2z~
|H(L"
} fff
} for per-channel quantization. Actual:
} for per-tensor/layer quantization or shape {
}(D9eP~n
}(E+}0E
}, "sub_threads": {
}, input shape = {
}. Actual:
}:fff
}0|$0J
}0M+}(I
}0t$ 
}7fff
}'fff
}HX"b
}HX"br]HQ
}HX$"b
}HX$*b
}HX$:b
}HX$:bb]HQ
}HX$2b
}HX$2bb]HQ
}HX\I
}HX\K
}offf
~ |\H
~ +~0
~ b$j&
~ H+~
~ I+~
~(+~0
~(D+~0D
~(E+~0E
~,fff
~,HcK,H+
~~~~~~~~~~~~~~~~
~3a*~3a*~3a*~3a*A
~5fff
~Dfff
~HFJDL
~HoD$
~HoL$
~HoL2
~HoT2
~HoTr
~L$ H
~LH;H t#
~o] I
~oL$ I
~T$ f
~T$ H
~Ufff
+_Int32
++index < c.size()
++Q5@.{
++Q5@.Q5@.Q5@.Q5@.{
+ba~H
+bA~H
+ba~H
+Error parsing node:
< ,"&
<"DZ:
<0>46
<2?~>
<bQ}X
<CbA~H
<F>.@
<h>n@,B"J L(H
<HZj\~^bbjd:f
<Nba|H
<p_fd> is less than 0.
<p_fd> less than 0.
<p>V@
<parse error>
<U+%.4X>
<uninitialized>
<V@jB
<X@jB:D
==> Context: 
=2?~>2?~>2?~>2?~>4?~?4?~?4?~?4?~?
=2?~>4?~?
=4?~?
> @(B
>"t%H
>"t(H
>"t2H
>^@*>
>^@pF=
>~@XB,P"R H(@P<
>~@XB,T"V H(@
>0O'H
>2@*>
>703HB
>bA|I
>f@rB
>HiL$8
>HkL$@XH
>HkL$0
>HkL$88H
>http://www.microsoft.com/pki/certs/MicRooCerAut_2010-06-23.crt0
>NGdx
>TDjN
>X@RBtLNH>F
0 <= p && p_int < shape_proto->dim_size()
0 == memory_size % kMinAllocationSize
0"P$"&}
0$2(*
0{4vh
00010203040506070809101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899
040904E4
0A\_^][
0A]^[
0A^][
0A^^]
0A^^]H
0A^_^
0A^_^][
0A^A\^][
0A^A]A\
0A^A]A\_^[]
0A__[
0A__^][
0A_A]A\
0A_A]A\_]
0A_A^^
0A_A^_
0A_A^_^[
0A_A^_^]
0A_A^A\
0A_A^A\_^
0A_A^A\_^[]
0A_A^A\_^][
0A_A^A]_[
0A_A^A]_^
0A_A^A]A\_
0A_A^A]A\_^[
0A_A^A]A\_^]
0bQ~I
0D$CI
0F2442
0H2*0P,
0L+4$L+
0t2n4
0vFVH
1 == capability.nodes.size()
1 for the first maximum value, and 0 for all others
1(0&0
1.11.1
1/0-0
110708205909Z
1bB~J
1D beta tensor for layer normalization  with shape (hidden_size)
1D bias tensor with shape (hidden_size
1D gamma tensor for layer normalization with shape (hidden_size)
1D input tensor
1-D input tensor
1D input tensor with shape (3 * hidden_size)
1D input tensor with shape (hidden_size)
1D input tensor, whose dimension is same as B's last dimension
1D int64 tensor of the same length as input's dimension number, includes numbers of repeated copies along input's dimensions.
1D mask_index tensor with shape (batch_size)
1D output tensor
1D skip tensor with shape (hidden_size
1-D tensor given as [start1, ..., startN, end1, ..., endN], where N is the rank of X. The RoIs' coordinates are normalized in the coordinate system of the input image. It only takes effect when coordinate_transformation_mode is "tf_crop_and_resize"
1-D tensor of 2 elements: [crop_height, crop_width]. All cropped image patches are resized to this size. Both crop_height and crop_width need to be positive.
1-D tensor of axes that `starts` and `ends` apply to.
1-D tensor of axes that `starts` and `ends` apply to. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
1-D tensor of ending indices (exclusive) of corresponding axis in `axes`
1-D tensor of ending indices (exclusive) of corresponding axis in axes
1-D tensor of floats
1-D tensor of shape (num_rois,) with each element denoting the index of the corresponding image in the batch.
1-D tensor of slice step of corresponding axis in `axes`. Default to 1. 
1-D tensor of slice step of corresponding axis in `axes`. Negative value means slicing backward. 'steps' cannot be 0. Defaults to 1.
1-D tensor of starting indices of corresponding axis in `axes`
1-D Tensor of the range.
1D tensor. The shape of the expected output tensor. If empty tensor is given, the output would be a scalar. All values must be >= 0.
1Lcx,D
1M+0I
2)tRL
2}>E7
2~4H6x8
20220726085702.174Z0
20220726112033Z
20220727112033Z0w0=
210902183259Z
210930182225Z
211202190524Z
220901183259Z0t1
224$2m
230012+4675970
230228190524Z0
260708210909Z0~1
284"6$8(0]
2bb}H
2D attention mask with shape (batch_size, sequence_length)
2D input tensor to copy shape, and optionally, type information from.
2D input tensor with shape (batch_size, sequence_length)
2D input tensor with shape (batch_size, total_sequence_length)
2D input tensor with shape (batch_size, vocab_size)
2D input tensor with shape (hidden_size, 2 * hidden_size)
2D input tensor with shape (hidden_size, 3 * hidden_size)
2D input tensor with shape (hidden_size, hidden_size)
2D input tensor with shape (input_hidden_size, 3 * hidden_size), hidden_size = num_heads * head_size
2D input tensor with shape (input_hidden_size, 3 * hidden_size), where hidden_size = num_heads * head_size
2D matrix with shape (K,N)
2D matrix with shape (M,N)
2D output tensor with shape (batch_size, vocab_size)
2D position ids with shape (batch_size, sequence_length)
2D segment IDs with shape (batch_size, sequence_length)
2D with shape (, hidden_size)
2D with shape (,hidden_size)
2D words IDs with shape (batch_size, sequence_length)
2-dimensional sparse matrix A. Either COO or CSR format
2f4f6(@
2H;q 
2H;y 
2j4f6(@62
2L4.6,&
2L4@6$"
2L4462*"
2L4j6
2l4n6,8":$<(>r2
2V4$6
2z4$6\8Y
2z4r648":$<(4
3^RichA
300930183225Z0|1
32-bit hash value.
333333
3333333
3bb}H
3bQ}X
3D input tensor with shape (batch_size, sequence_length, hidden_size)
3D input tensor with shape (batch_size, sequence_length, hidden_size), hidden_size = num_heads * head_size
3D input tensor with shape (batch_size, sequence_length, input_hidden_size)
3D input tensor with shape (sequence_length, batch_size, hidden_size), hidden_size = num_heads * head_size
3D input tensor with shape (total_sequence_length, batch_size, hidden_size)
3D output tensor with shape (batch_size, sequence_length, hidden_size)
3D output tensor with shape (sequence_length, batch_size, hidden_size)
3D skip tensor with shape (batch_size, sequence_length, hidden_size)
3http://www.microsoft.com/pkiops/docs/primarycps.htm0@
3http://www.microsoft.com/pkiops/Docs/Repository.htm0
4 ""$$(&B
4)t(L
4|688":$<(4-
4|68B"D$<(480
4|6P@(6
4|6P@(6:2
4|6P@(6X2
40Z2(4(6:8X:
456789:;<=
486">$@(<
486"F$H(<
4-D tensor after resizing, [N,C,H,W]
4-D tensor of shape (N, C, H, W), where N is the batch size, C is the numbers of channels, H and W are the height and width of the input data.
4-D tensor of shape (N, C, H_out, W_out).
4-D tensor, [N,C,H,W]
4F6482>tFFT4V2D$F$H
4f8j:
4n6^8
4n6t8
4p6t8,:
4X8j:
5JCy7
5JCy7JCy7JCy7JCy7
6$*("J
6)t|L
6_outB
6bA|H
6bQ}X
6ddlf(h
6n:~<
6N826 :
6P@(6
6P@(6*2*B
6P@(6\2
'7=*BL?
7HiL$@
8 :H<9
8$:(*
8$:|0
8(u!H
8(u%H
8)u:H
8,$.$0R2
8,u%H
8@HPX`,
8@HPX`hv
8@HR@JB
8@J l
8^,t3HcN
8_^][
8_u2I
8_u3I
8_u4I
8{u1H
8}tU3
8<u%H
8>u:H
8A^_][
8A^_^[
8A^A\_[
8A^A]_[
8A_A^
8A_A^^[
8A_A^_^][
8A_A^A\_
8A_A^A]A\_[
8A_A^A]A\_^][
8b:@<
8E?ubH
8F:.<,6
8F:.<,6D8
8F:@<
8f<j>
8giP9giP9giP9giP9
8KPtk
8KPtwL
8L$@L
8L:@<
8L:@<"@
8MPtk
8MPtm
8NPtk
8NPtm
8OPti
8OPtk
8OPtm
8OPtz
8Scanu
8striu
8T$`I
8t:n<
8V:.<0> @bBxDZF^HXJRVi
8v6H+U
9{ ~h
9{(t%H
961c151d2e87f2686a955a9be24d316f1362bf21 3.9.1
9B(uzH
9H9t$xu
9P(uUI
9w(t%H
9Yielu
9zv0H
A + (M * K) <= A_end
A + (M * lda - (lda - K)) <= A_end
A 0-D bool tensor. If given, this will scale gradients by the inverse of frequency of the indices (words) in the mini-batch. Default  is ``False``
A 0-D scalar tensor. If specified, the entries at `padding_idx` do not contribute to the gradient; therefore, the embedding vector at `padding_idx` is not updated during training, i.e. it remains as a fixed pad.
A 0-D tensor containing a single value corresponding to the number diagonals above or below the main diagonal to exclude or include. Default value is 0 if it's not specified.
A 0-D tensor containing a single value corresponding to the number diagonals above or the main diagonal to exclude or include.Default value is 0 if it's not specified.
A 0-D tensor. Must be in the range [-rank(x), rank(x)-1]. Negative value means counting dimensions from the back.
A 1-D input tensor that is to be processed.
A 1-D INT64 tensor containing indices of 'Y' elements' first occurance in 'X'. When 'axis' is provided, it contains indices to subtensors in input 'X' on the 'axis'. When 'axis' is not provided, it contains indices to values in the flattened input tensor. 
A 1-D INT64 tensor containing the count of each element of 'Y' in input 'X'
A 1-D INT64 tensor containing the the count of each element of 'uniques' in the input 'x'
A 1-D INT64 tensor containing, for elements of 'X', its corresponding indices in 'Y'. When 'axis' is provided, it contains indices to subtensors in output 'Y' on the 'axis'. When 'axis' is not provided, it contains indices to values in output 'Y'. 
A 1-D INT64 tensor of the same size as 'x' containing the indices for each value in 'x' in the output 'uniques'
A 1-D tensor containing a single positive value corresponding to the number of top elements to retrieve
A 1-D tensor holding values from the input dictionary.
A 1-D tensor indicates the shape you want to expand to, following the broadcast rule
A 1-D tensor of the same type as 'x' containing all the unique values in 'x' sorted in the same order that they occur in the input 'x'
A 1-D tensor with same type as the inputs containing generated range of values.
A 1-D values of (height, width).
A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder).
A 2D Matrix that represents the distance between each pair of the two collections of inputs.
A 2D tensor with the contents of the input tensor, with input dimensions up to axis flattened to the outer dimension of the output and remaining input dimensions flattened into the inner dimension of the output.
A 9B 
A boolean termination condition. Optional. Pass empty string to skip.
A collection of intercepts.
A collection of weights of the model(s).
A Conv/ConvTranspose node has both 'auto_pad' and 'pads' attributes
A dictionary.
A dimension cannot be less than -1, got 
A dso with name 
a filter
A float.
A H;B up
A H+A
A H9A
A list of 2 (or 4 if bidirectional) activation functions for update, reset, and hidden gates. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
A list of floats.
A list of integers, along which to reduce. The default is to caculate along axes [0,2,3] for calculating mean and variance along each channel. Two variables with the same C-coordinate are associated with the same mean and variance.
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor. Accepted range is [-r, r-1] where r = rank(data).
A list of integers. By default, reverse the dimensions, otherwise permute the axes according to the values given.
A list of ints.
A list of labels.
A list of strings. One and only one of 'keys_*'s should be set.
A list of strings. One and only one of 'value_*'s should be set.
A manual rescaling weight given to each class. If given, it has to be a 1D Tensor assigning weight to each of the classes. Otherwise, it is treated as if having all ones.
A maximum trip-count for the loop specified at runtime. Optional. Pass empty string to skip.
A N-D input tensor that is to be processed.
A node with a function body within a subgraph within another function body is currently not supported in ORT
A scalar boolean tensor. If true, it indicates that optional-type input contains an element. Otherwise, it is empty.
A shape tensor must be a vector tensor.
A string indicating the desired element type of the output tensor, one of 'TO_FLOAT', 'TO_STRING', 'TO_INT64'.
A string to use when an input integer value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
A string vocabulary array.<br>One and only one of the vocabularies must be defined.
A string.
A target node must be set.
A tensor of rank >= axis.
A tensor of the same type as 'X' containing all the unique values or subtensors sliced along a provided 'axis' in 'X', either sorted or maintained in the same order they occur in input 'X'
A tensor representing the same data as the input map, ordered by their keys
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. 
A tensor that concats all the intermediate output values of the hidden. It has shape `[seq_length, num_directions, batch_size, hidden_size]`. It is optional if `output_sequence` is 0.
A u^H9A
A value that needs replacing.
A(A;@
A(A;B
A(tzA
A,A;@
A,A;B
A,A9@
A;@(t
A;@(u
A;@,t
A;@0t
A;A(t
A;A(u
A;A,t
A;A0t
A;B(t
A;B,t
A;B0t
A;C(t
A;C,t
A;C0t
A;F(t
A;F,t
A\A]A^_^[]
A\A]A^A__^[]
A\A^_^[]
A]_^[]
A]A\_[
A]A\_^[]
A^_^[
A^_^[]
A^_^][
A^A\_][
A^A]_][
A^A]A\_]
A^A]A\_^
A^A]A\_^][
A__][
A__^[]
A_A\[
A_A\^]
A_A\_^[]
A_A]_^][
A_A]A\[
A_A]A\^
A_A^]
A_A^^[
A_A^^]
A_A^_
A_A^_]
A_A^_^[
A_A^_^[]
A_A^_^]
A_A^_^][
A_A^A\
A_A^A\_]
A_A^A\_^
A_A^A\_^[
A_A^A\_^[]
A_A^A\_^][
A_A^A]
A_A^A]]
A_A^A]_]
A_A^A]_^
A_A^A]_^[]
A_A^A]A\]
A_A^A]A\^
A_A^A]A\^[]
A_A^A]A\^][
A_A^A]A\_
A_A^A]A\_][
A_A^A]A\_^[
A_A^A]A\_^[]
A_A^A]A\_^]
A_A^A]A\_^][
a_scale
A_scale
a_zero_point
A_zero_point
A|U@ 
A<X@@
A0H;L$(
A0H9A(u
A0t>H
A4XH 
A5XH 
A8EPt
A8Ftu
A8Fuu
A8NPtk
A9F(t.I
A9X,t
A9X0t
A9Y0t
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_
ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/
abort
ACLExecuH9
ACLExecutionProvider
Acosh
AcquireSRWLockExclusive
across_channels
activation
Activation function to apply to the scores input.
Activation functions:
activation_
activation_alpha
activation_beta
activation_func_names.size() == static_cast<size_t>(num_directions_) * 2
activation_func_names.size() == static_cast<size_t>(num_directions_) * 3
activation_gamma
activation_params
activation_params count mismatch
activation_size
activations
adapterLuidHighPart
adapterLuidLowPart
add_B_tensor_proto
Added in transpose optimizer
Adding default CPU execution provider.
AddInitializedTensor already has tensor with name 
addition
additional add to QxK' with shape (batch_size, num_heads, sequence_length, sequence_length).
Additional elements added to the side with higher coordinate indices in the output. Each padding value in "output_padding" must be less than the corresponding stride/dilation dimension. By default, this attribute is a zero vector. Note that this attribute doesn't directly affect the computed output values. It only controls the selection of the computed values, so changing this attribute only adds or removes output elements. If "output_shape" is explicitly provided, "output_padding" does not contribute additional size to "output_shape" but participates in the computation of the needed padding amount. This is also called adjs or adjustment in some frameworks.
Affine
affine
aggregate_function
ai.onnx
ai.onnx.ml
ai.onnx.preview.training
ai.onnx.training
align_corners
All implicit inputs should have OrtValue instances by now. 
All inputs to Concat must have same rank
All inputs to Concat must have same rank. Input 
All inputs to 'Range' op must be of the same type
All nodes have been placed on [
All Tensor and Sequence types
All Tensor types
All Tensor, Sequence(Tensor), Optional(Tensor), and Optional(Sequence(Tensor)) types
all types
All values in input have to be in the range:[0, 1].
Allocated memory at 
Allocation of memory pattern buffer for 
Allocation of tensor types requires a shape.
allocator
allocator != nullptr
Allocator already registered for 
Allocator:
allocator_ != nullptr
allocator_for_caching.get() != nullptr
allocator_ptr_
AllocPlan(ml_value_idx).program_counter.Ends().back() == program_counter
ALLOW_RELEASED_ONNX_OPSET_ONLY
Allowed values are 'half_pixel' and 'output_half_pixel'. Use the value 'half_pixel' to pixel shift the input coordinates by -0.5 (the recommended behavior). Use the value 'output_half_pixel' to omit the pixel shift for the input (use this for a backward-compatible behavior).
allowzero
alpha
alpha == 1.0f && (beta == 0.0f || beta == 1.0f)
AMDiuE
An allocator for this device has already been registered for sharing.
An attribute specifying the number of scan_inputs M. 
An axes tensor must be a scalar or a 1-D tensor.
An axes tensor must be a vector tensor.
An entry for this node should be added in onnx_ops_available_versions and static_kernel_hashes map.
An input tensor that is to be processed.
An input tensor to hash.
An input tensor with shape [num_batches, num_classes, spatial_dimension]
An input tensor with shape [num_batches, spatial_dimension, 4]. The single box data format is indicated by center_point_box.
An input tensor.
An integer to use when an input string value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
An integer vocabulary array.<br>One and only one of the vocabularies must be defined.
An integer.
An optional list of K flags, one for each scan_output. The i-th element of the list specifies whether the i-th scan_output should be constructed by appending or prepending a new value in each iteration: 0 indicates appending and 1 indicates prepending. If omitted, all scan_output tensors will be produced by appending a value in each iteration.
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output.
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1].
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input.
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
An optional list of M flags. The i-th element of the list specifies the direction to be scanned for the i-th scan_input tensor: 0 indicates forward direction and 1 indicates reverse direction. If omitted, all scan_input tensors will be scanned in the forward direction.
an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.
An optional string. Token's regular expression in basic POSIX format (pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.
An ordered collection of tensors, all with the same element type.
An OrtValue for this name has already been added.
An split tensor must be a vector tensor.
anchors
and produces one output data (Tensor<T>) where the function `f(x) = quantize(alpha * dequantize(x)) for dequantize(x) < 0`,
and the running statistics in training mode (training_mode=True).
APH9AH
APH9AHt~
API VERSION 
api-ms-win-core-debug-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-2.dll
api-ms-win-core-file-l1-1-0.dll
api-ms-win-core-file-l1-2-0.dll
api-ms-win-core-handle-l1-1-0.dll
api-ms-win-core-heap-l1-1-0.dll
api-ms-win-core-heap-l2-1-0.dll
api-ms-win-core-interlocked-l1-1-0.dll
api-ms-win-core-libraryloader-l1-2-0.dll
api-ms-win-core-libraryloader-l2-1-0.dll
api-ms-win-core-localization-l1-2-0.dll
api-ms-win-core-path-l1-1-0.dll
api-ms-win-core-processenvironment-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-1.dll
api-ms-win-core-processthreads-l1-1-3.dll
api-ms-win-core-processtopology-obsolete-l1-1-0.dll
api-ms-win-core-profile-l1-1-0.dll
api-ms-win-core-string-l1-1-0.dll
api-ms-win-core-synch-l1-1-0.dll
api-ms-win-core-synch-l1-2-0.dll
api-ms-win-core-sysinfo-l1-1-0.dll
api-ms-win-core-sysinfo-l1-2-0.dll
api-ms-win-crt-convert-l1-1-0.dll
api-ms-win-crt-filesystem-l1-1-0.dll
api-ms-win-crt-heap-l1-1-0.dll
api-ms-win-crt-locale-l1-1-0.dll
api-ms-win-crt-math-l1-1-0.dll
api-ms-win-crt-runtime-l1-1-0.dll
api-ms-win-crt-stdio-l1-1-0.dll
api-ms-win-crt-string-l1-1-0.dll
api-ms-win-crt-time-l1-1-0.dll
api-ms-win-crt-utility-l1-1-0.dll
api-ms-win-eventing-provider-l1-1-0.dll
apply
apply softmax to elements for dimensions softmax_axis or higher
Applying runtime optimization action 
AQ5@.
arena_extend_strategy
ArgMax
ArgMin
Argument is not a tensor
Argument mismatch when removing edge.
Argument type mismatch when adding edge.
ArmNNExecutionProvider
array
Array of sequence lengths.  len(seq_lengths) should equal batch size N.
ArrayFeatureExtractor
as.,k{n?,
Asinh
asymmetric
At least one element in the sequence is of a type different from others.
At least one graph node must be specified in the propagation edge.
At least one output should be requested.
At most one dimension can be -1.
Atanh
ATAUAVH
ATAUAWH
ATAVAWH
ATAVH
Attempt to retrieve final output before it was set.
Attempt to use DefaultLogger but none has been registered.
Attempting to broadcast an axis by a dimension other than 1. 
Attempting to get an input that does not exist.
Attempting to get an output that does not exist.
Attempting to get index by a name which does not exist:
Attempting to load runtime optimization records for a previously loaded optimizer: 
Attention
Attention mask index with shape (batch_size)
Attention mask with shape (batch_size, 1, max_sequence_length, max_sequence_length), (batch_size, past_sequence_length + sequence_length)or (batch_size, sequence_length, past_sequence_length + sequence_length), or index with shape (batch_size) or (2 * batch_size).
Attention mask with shape (batch_size, sequence_length)
AttentionFusion
Attibute name and type don't match
AttnLSTM
Attribute 
Attribute '
Attribute (name: 
Attribute `broadcast=1` needs to be passed to enable broadcasting.
Attribute axes has incorrect length
Attribute dilations has incorrect size
Attribute dtype should be of integer type and specify a type.
Attribute expected to have a one-dim sparse tensor
Attribute expected to have a one-dim tensor
Attribute expected to have tensor or sparse tensor type
Attribute kernel_shape has incorrect size
Attribute kernel_shape has incorrect size.
Attribute kernel_shape must be specified
Attribute kernel_shape must be specified.
Attribute 'max_output_boxes' must be >= 1.
Attribute name and type don't match for '
Attribute pads has incorrect length
Attribute pads has incorrect size
Attribute pads has incorrect size.
Attribute perm for Transpose has repeated value: 
Attribute perm of Transpose has an invalid value. Value 
Attribute pooled_shape has incorrect length
Attribute pooled_shape must be specified
Attribute 'pooled_size' must be >= 1.
Attribute 'scales' is required.
Attribute 'scales' must have floats type.
Attribute specification type mismatch.
Attribute strides has incorrect size
Attribute strides has incorrect size.
Attribute to is not set.
Attribute 'type' should be a TypeProto and it should specify a type.
Attribute value for pads is required
Attribute 'value' of Constant node must exist with 'Tensor' data.
Attribute 'value_float' expect a float.
Attribute 'value_floats' expect a list of floats.
Attribute 'value_int' expect an integer.
Attribute 'value_ints' expect a list of integers.
Attribute 'value_string' expect a string.
Attribute 'value_strings' expect a list of strings.
Attribute: 
AUAVAWH
AUAVH
AUAWH
Authu
auto_pad
auto_pad == AutoPadType::NOTSET
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = input_shape[i] * strides[i]` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output spatial size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
Available memory of 
AVAWH
average
AveragePool
axes as an input and attribute cannot be specified at the same time.
'axes' attribute must not contain any duplicates
'axes' has a duplicate axis
'axes' has an axis outside of the tensor dimension count
'axes' has an out of range axis
'axes' has duplicates
Axes input is null
Axes that `starts` and `ends` apply to. It's optional. If not present, will be treated as [0, 1, ..., len(`starts`) - 1].
axes_tensor != nullptr
axes_tensor->Shape().NumDimensions() == 0 || axes_tensor->Shape().NumDimensions() == 1
axes_tensor->Shape().NumDimensions() == 1
AXHc8H
axis 
axis == 1 || axis == largest
axis >= -tensor_rank && axis <= tensor_rank - 1
Axis along which to repeat.
Axis has less than the requested k elements.
'axis' must be in [
axis must be in [-r, r-1]
'axis' must be in [-rank(indices), rank(indices)-1]
'axis' must be in [-rank(indices)-1, rank(indices)]
axis must be in [-rank, rank)
axis must be in [-rank, rank-1].
axis must be in [-rank, rank-1]. input rank was 
axis tensor can be int32 or int64 only
Axis tensor must be provided to the CumSum op
Axis tensor should be 0D or 1D
Axis tensor should be of type `int32_t` or `int64_t`
Axis1D = Constant()
B + (N * ldb - (ldb - K)) <= B_end
b 4""$
B 9A 
B H+B
B H9A
B L+B
B taL
b"-@,
b"ZJV
b"ZLV
B(A;G
B,A;G
b_scale
B_scale
b_zero_point
B_zero_point
b},4C
b}.<C
b}/<C
b}-4C
b->free_chunks.size() == bin_info.total_chunks_in_bin - bin_info.total_chunks_in_use
b0d,f0h(j0l.n
B2D = Flatten <axis=0> (B)
b2t(v
B3utO
B5}oN/
ba$@]
ba$@_
ba$@Y
ba,@]
ba,@_
ba,@Y
ba|H(
ba<@]
ba<@_
ba<@Y
ba4@]
ba4@_
ba4@Y
BA99u
Background class ID.
background_class
bad allocation
bad array new length
bad cast
bad dimensions
Bad node spec for node. Name: 
Bad optional access
BAhL+
Base values for classification, added to final class score; the size must be the same as the classes or can be left unassigned (assumed 0)
base_values
base_values_as_tensor
batch_axis
batch_dims
batch_indices
batch_indices shape input tensor has wrong dimension
BatchNormalization
Batchwise recurrent operations (layout == 1) are not supported. If you need support create a github issue with justification.
bb]HQ
bB]X@C
bB]X@K
bb}H{
bb}HQ
bb}HX
bb}HX'H
bbeHQ
bbuHQ
bBUX@[
bBUX@{
bBUX@c
bBUX@k
bBUX@s
BE L+
BE@L+
BE`L+
BeamSearch
Begin execution
BEpL+
Bernoulli
beta is expected to have 1 dimension, got 
Beta should be of shape (hidden_size). 
beta should have 1 dimension, dimension size known, and same hidden size as word_embedding.
beta_quant
beta_scale
beta_zero_point
BFC Arena ran out of memory trying to allocate 
BFD4F2
BfFjH
bfloat16
BFLOAT16BOOLCOMPLEX128COMPLEX64DOUBLEFLOATFLOAT16INT16INT32INT64INT8STRINGUINT16UINT32UINT64UINT8UNDEFINED
BHD,F&H*JH>
Bhttp://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt0
Bias applied to each channel, same size as C.
bias is expected to have 1 dimension, got 
bias tensor
Bias tensor of shape (C).
Bias tensor.
BiasDropout
BiasDropoutFusion
Biased = Add (Scaled, B2D)
Biased = Identity (Scaled)
BiasGelu
BiasGeluFusion
BiasSoftmax
BiasSoftmaxFusion
bidirectional
BifurcationDetector
bilinear
Bin for 
Bin size: Chunks in_use/total (if not zero). Allocated bytes in_use/total. Requested bytes.
bin->free_chunks.count(h) == 1
Binarized output data
Binarizer
binary
BinForSize(bin_size * 2 - 1) == BinFromIndex(b)
BinForSize(bin_size * 2) != BinFromIndex(b)
BinForSize(bin_size + 255) == BinFromIndex(b)
BinForSize(bin_size) == BinFromIndex(b)
BinFromIndex(c->bin_num)->free_chunks.erase(h) > 0
BitShift
BLD@F
BLD@F"4
BlDpF,H
Blocks of [blocksize, blocksize] are moved.
blocksize
Blocksize must be positive
bn_B_tensor_proto
bn_mean_tensor_proto
bn_scale
bn_scale_tensor_proto
bn_var_tensor_proto
Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length.
boolean
Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).
Boolean. Indicates whether upper or lower part of matrix is retained. Default is true.
Boolean. Whether the identification of stop words in X is case-sensitive. Default is false
border
'Border' attribute must be present and must contain exactly 4 values - (left_border, top_border, right_border, bottom_border)
Both `data` and `indices` input tensors in GatherND op need to have rank larger than 0.
Both attributes isinf_only and isnan_only cannot be set. Unset both to check for both conditions.
both data and indices tensor need to have rank larger than zero.
Box IOU threshold value.
box_coding
boxes
boxes and scores should have same num_batches.
boxes and scores should have same spatial_dimension.
boxes must be a 3D tensor.
boxes_tensor
BPfff
bq$H]
bq$H_
bq$HX\
bq$HY
bq,H]
bq,H_
bq,HXS
bq,HY
bQ|H[
bQ}H[
'bQ}X
bQ<@_
bq<H]
bq<H_
bQ<HX@
bq<HY
bq4H]
bq4H_
bQ4HXL
bq4HY
br]HQ
br}H{
bR}H|
br}HQ
breHQ
bReX@{
bReX@3b
bReX@3bQ}H
broadcast
broadcast bias across input for dimensions broadcast_axis to softmax_axis-1
Broadcast Output range [
broadcast_axis
BroadcastLooper requires two tensors as input.
bruHQ
bsearch
Buffer containing the initializer must be owned by the user.
Buffer overflow
buffer size is too small for string element
buffers_.find(location) == buffers_.end()
buffers_.size() == buffer_sizes_.size()
bumped the operator version but 
by either re-generating the model with latest exporter/converter 
C + (M * ldc - (ldc - N)) <= C_end
C = ((A - A_zero_point) * (B - B_zero_point)) * (A_scale * B_scale)/C_scale + C_zero_point
C = (A_scale * (A - A_zero_point) + B_scale * (B - B_zero_point))/C_scale + C_zero_point
C 9A 
C A;A0t
C D+C0
C(@8{
C(+C,H
C(+C0
C(A9E
C(D;8
C(D+C0D
C(D8{
C(D8s
C(D98
C(H+C H
C(H9C@u,H
C@f99H
C@H;}
C@H;CHt
C@H;U
C@H+C8H
C\$@H
C\$`H
C\$0D
C\$0H
C\$8H
C\$hH
C\$PH
C\$pH
C\$PH
C\$pH
C\$PH
C\$pH
C\$PH
C\$XH
C\$XL
C_scale
c_shape != nullptr
c_shape is required if c_data is provided
C_zero_point
c->bin_num == bin_num
c->in_use() && (c->bin_num == kInvalidBinNum)
C0H;U
C0H9C(u
c2->prev == h1
C8H;C@t
Cached EP instance for graph replay is not set yet before calling ReplayGraph()
CallContext:[%hs] 
called_ == 1
calloc
cAMDt
Can broadcast 0 by 0 or 1. 
Can not find the execution provider 
Can not find the node 
Can not get shape initializer data!
Can not use strings in pre-allocated memory. Use CreateSparseTensorAsOrtValue() to allocate memory inside and copy
Can only add a new input at the end of the current ones.
Candidate for fallback CPU execution: 
Cannot apply CumSum operator on a scalar
cannot compare iterators of different containers
Cannot concatenate scalars
cannot find allocator
Cannot find missing input: 
Cannot find NodeArgs for [
cannot get value
Cannot infer type and shape for function
Cannot infer type and shape for node name 
Cannot parse data from external tensors. Please 
Cannot replace concat node with initializer:
Cannot reshape initializer 
Cannot slice scalars
Cannot split using values in 'split' attribute. Axis=
cannot use at() with 
cannot use erase() with 
cannot use key() for non-object iterators
Cannot use the same name as both a subgraph initializer and subgraph input: 
Cannot use user supplied initializer with name: (
Can't 
can't constant fold 
Can't happen
Can't merge shape info. Both source and target dimension have values but they differ. Source=
Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:
Can't remove node 
Can't slice a non-tensor OrtValue. Type was 
Can't use func with null ptr
Carries out batch normalization as described in the paper
case_change_action
cast != nullptr
Cast Input from int64 to int32
Cast mask from int64 to int32
cast node to cast from float16 to float32 on cpu
cast output of layer norm
cast scale of layer norm
Cast_Scale
cast_to
CastElimination
CastFloat16Transformer
CastLike
CastMap
CategoryMapper
cats_int64s
cats_strings
Caught exception while destructing CustomOpsLoader with message: 
Caught exception while loading custom ops with message: 
CbQ~I
CD$`f
CD$8f
CD$8H
CD$Hf
CD$pE3
CD$Pf
CD$pf
CDist
ceil_mode
ceilf
Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.
center_point_box
channels
channels_ <= X_shape[1]
channels_ > 0
channels_last
char_embedding_size
CHECK failed: !is_closed_: 
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_used_) == (buffer_size_): 
CHECK failed: (count) <= (buffer_used_): 
CHECK failed: (count) >= (0): 
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - SerialArena::kBlockHeaderSize): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
CheckNodesInPathK returns false
CheckNodesInPathQ returns false
CheckNodesInPathV return false
CheckSliceParameters return false
CheckSliceParameters return false for slice2
CheckSliceParameters returns false for last_slice
CheckSliceParameters returns false for mask_slice
CheckSliceParameters returns false for slice1
checksum
Child node if expression is false
Child node if expression is false.
Child node if expression is true
Child node if expression is true.
Chosen support vectors
Chttp://www.microsoft.com/pkiops/crl/MicCodSigPCA2011_2011-07-08.crl0a
CL$(3
CL$@H
CL$pH
CL$pL
Class labels if using integer labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels if using string labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels when using integer labels. One and only one 'classlabels' attribute must be defined.
Class labels when using string labels. One and only one 'classlabels' attribute must be defined.
Class scores (one per class per example), if prob_a and prob_b are provided they are probabilities for each class, otherwise they are raw scores.
class_ids
class_nodeids
class_treeids
class_weights
class_weights_as_tensor
classes_strings
Classification outputs (one class per example).
Classification scores ([N,E] - one score for each class and example
classlabels_int64s
classlabels_ints
classlabels_strings
clip_ > 0.f
ClipQuantRewrite
close() failed: 
CloseHandle
CMust have valid 'axis' attribute
code != static_cast<int>(common::OK)
Coefficient of ELU default to 1.0.
Coefficient of ELU.
Coefficient of leakage default to 0.01.
Coefficient of leakage.
Coefficient of SELU default to 1.0507.
Coefficient of SELU default to 1.05070102214813232421875 (i.e., float32 approximation of 1.0507009873554804934193349852946).
Coefficient of SELU default to 1.6732.
Coefficient of SELU default to 1.67326319217681884765625 (i.e., float32 approximation of 1.6732632423543772848170429916717).
coefficients
com.micrH9
com.microsoft
com.microsoft.
com.microsoft.experimental
com.microsoft.nchwc
com.microsoft.QLinearAdd
com.microsoft.QLinearAveragePool
com.microsoft.QLinearConcat
com.microsoft.QLinearGlobalAveragePool
com.microsoft.QLinearLeakyRelu
com.microsoft.QLinearMul
com.microsoft.QLinearReduceMean
com.microsoft.QLinearSigmoid
com.ms.internal.nhwc
CommonSubexpressionElimination
CompanyName
Compiled kernel hashes must be provided
compiled_kernel_hashes != nullptr
complex128
complex64
ComplexMul
ComplexMulConj
Compress
Compute_
Computed size: 
ComputePad: pad type not supported.
Computes an one-layer GRU. This operator is usually supported via some custom
Computes an one-layer LSTM. This operator is usually supported via some
Computes an one-layer simple RNN. This operator is usually supported
Computes the indices of the {name} elements of the input tensor's element along the
Concat
concat first input value is not -1
concat_after_gather does not have expected number of inputs or output edges
concat_after_gather input 2 does not have expected value
concat_result
Concatenated tensor
ConcatFromSequence
condition
Condition for the if
Config key is empty or longer than maximum length 128
Config value is longer than maximum length 1024
Config with key [
Conflicting free dimension overrides.
const_ignore_index
const_one
const_one_casted
const_one_casted = Cast (const_one_float)
const_one_float
const_transpose_optimizer
const_zero
const_zero_casted
const_zero_casted = Cast (const_zero_float)
const_zero_float
const_zero_target_typed
constant
Constant
Constant initializer NodeArg shape should not be null. NodeArg: 
constant_value
ConstantFill
ConstantFolding
ConstantOfShape
Constrain bias type to 32-bit integer tensor.
Constrain filter type to 8-bit integer tensor.
Constrain index tensor to int64
Constrain indice type to int32 or int64
Constrain indices to integer types
Constrain input a and its zero point data type to 8-bit integer tensor.
Constrain input A and its zero point types to 8 bit tensors.
Constrain input A data type to 8-bit integer tensor.
Constrain input A data types as 16-bit integer tensor
Constrain input A, b_scale and output Y data type as float tensor.
Constrain input a_scale, b_scale and output Y data type as float tensor.
Constrain input and output  types to float tensors.
Constrain input and output float tensors types.
Constrain input and output integer tensors types
Constrain input and output to all tensor types.
Constrain input and output types (except mean and inv_std_var) to float tensors.
Constrain input and output types to 8 bit signed and unsigned tensors.
Constrain input and output types to 8 bit tensors.
Constrain input and output types to all numeric tensors and bool tensors.
Constrain input and output types to all numeric tensors.
Constrain input and output types to all numerical tensor types.
Constrain input and output types to all tensor and sequence types.
Constrain input and output types to all tensor types (including bfloat).
Constrain input and output types to all tensor types.
Constrain input and output types to all tensor, sequence, and optional types.
Constrain input and output types to all tensors.
Constrain input and output types to any tensor type.
Constrain input and output types to float and 8 bit tensors.
Constrain input and output types to float and float16 tensors.
Constrain input and output types to float or half tensors.
Constrain input and output types to float tensors
Constrain input and output types to float tensors.
Constrain input and output types to float/int tensors.
Constrain input and output types to float32 tensors.
Constrain input and output types to floating-point tensors.
Constrain input and output types to high-precision and 8 bit numeric tensors.
Constrain input and output types to high-precision numeric tensors.
Constrain input and output types to int8 tensors.
Constrain input and output types to integer tensors.
Constrain input and output types to numeric tensors.
Constrain input and output types to signed numeric tensors.
Constrain input and output types to singed/unsigned int8 tensors.
Constrain input and output types.
Constrain input b and its zero point data type to 8-bit integer tensor.
Constrain input B and its zero point types to 8 bit tensors.
Constrain input B data type to 8-bit integer tensor.
Constrain input B data types as 16-bit integer tensor
Constrain input C to 32 bit integer tensors.
Constrain input 'ratio' types to float tensors.
Constrain input type to 8-bit integer tensor.
Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.
Constrain input types and output Y type to float tensors.
Constrain input types to 8 bit signed and unsigned tensors.
Constrain input types to all tensor types.
Constrain input types to any tensor type.
Constrain input types to common numeric type tensors.
Constrain input types to float tensors.
Constrain input types.
Constrain input types. Casting from complex is not supported.
Constrain input types. Casting from strings and complex are not supported.
Constrain input types. Strings and complex are not supported.
Constrain input w and its zero point data type to 8-bit integer tensor.
Constrain input x and its zero point data type to 8-bit integer tensor.
Constrain input X and output types to float/int tensors.
Constrain input 'X' and output 'Y' to all tensor types.
Constrain input Y types to float/int tensors.
Constrain input, weight, and output types to floating-point tensors.
Constrain input0 and output types to float tensors
Constrain key_padding_mask to bool tensors.
Constrain mask index to integer types
Constrain mask to integer types
Constrain mean and inv_std_var to be float tensors.
Constrain mean and inv_std_var to float tensors.
Constrain mean and variance types to float tensors.
Constrain mean and variance types to float tensors. It allows all float type for U.
Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).
Constrain output mask types to boolean tensors.
Constrain output 'mask' types to boolean tensors.
Constrain output to 32 bit tensor
Constrain output to int64 tensor, which should be a scalar though.
Constrain output to int64 tensor.
Constrain output to integral tensor. It must be a scalar(tensor of empty shape).
Constrain output type to 8-bit integer tensor.
Constrain output type to all tensor or sequence types.
Constrain output type to float32 or 8 bit tensors.
Constrain output type to unsigned and signed 32-bit integer tensor.
Constrain output types to 32 bit tensors.
Constrain output types to all numeric tensors and bool tensors.
Constrain output types to all tensor types.
Constrain output types to any tensor type.
Constrain output types to be numerics.
Constrain output types to bool, int32, int64, float16, float, double tensors.
Constrain output types to boolean tensors.
Constrain output types to float tensors.
Constrain output types to integral tensors.
Constrain output types. Casting to complex is not supported.
Constrain output types. Casting to strings and complex are not supported.
Constrain output types. Strings and complex are not supported.
Constrain output y and its zero point data type to 8-bit integer tensor.
Constrain output Y data type as 32-bit integer tensor.
Constrain output y data type to 32-bit integer tensor.
Constrain output Y data types as 32-bit integer tensor.T3 must be tensor(uint32) when both T1 and T2 are tensor(uint16),or must be tensor(int32) when either T1 or T2 is tensor(int16).
Constrain output zero point types to 8 bit tensors.
Constrain position to integral tensor. It must be a scalar(tensor of empty shape).
Constrain repeat's type to int64 tensors.
Constrain roi type to float or double.
Constrain scale and bias types to float tensors.
Constrain scale types to any float tensor type.
Constrain scale types to float tensors.
Constrain scores input and output types to float tensors.
Constrain seq_lens to integer tensor.
Constrain seq_lens to integral tensors.
Constrain split size to integral tensor.
Constrain target to integer types
Constrain the output to a boolean tensor.
Constrain tiles and axis's type to int64 tensors.
Constrain to all fixed size tensor and sequence types. If the dtype attribute is not provided this must be a valid output type.
Constrain to all tensor types.
Constrain to any tensor type.
Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.
Constrain to boolean tensors.
Constrain to integer types
Constrain to integer types.
Constrain to tensor(float).
Constrain to tensor(int32).
Constrain types to float tensors.
Constrain types to int tensors.
Constrain weights types to 8 bit tensors.
Constrain 'x' and 'x_zero_point' to 8-bit integer tensors.
Constrain 'x' to float or int32 tensor.
Constrain 'x' to float tensor.
Constrain 'x', 'y_scale' to float tensors.
Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
Constrain 'y', 'x_scale' to float tensors.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensors.
Constrain 'y_zero_point' and 'y' to 8-bit unsigned integer tensor.
Constrains input and output to only numeric types.
Constrains input to boolean tensor.
Constrains input to float tensors.
Constrains input to integral tensors.
Constrains input to only numeric types.
Constrains input type to all tensor and sequence types.
Constrains input type to optional tensor and optional sequence types.
Constrains input types to all numeric tensors.
Constrains input/output to boolean tensors.
Constrains output to a boolean tensor.
Constrains output to boolean tensor.
Constrains output type to all optional tensor or optional sequence types.
Constrains to boolean tensors.
consumed_inputs
Container for generated shape data cannot be nullptr when enable_data_propagation option is set.
conv.GetOutputEdgesCount() == 1 && conv.OutputNodesBegin()->OpType() == "Add"
conv_B_tensor_proto
conv_W_tensor_proto
conv_window_size
ConvAct
ConvActivationFusion
ConvAddFusion
ConvAddFusion_Add_B_
ConvAddFusion_B_
ConvAddRelu
ConvBNFusion
ConvBnFusion_BN_B_
ConvBnFusion_W_
ConvInteger
ConvMulFusion
ConvMulFusion_Mul_B_
ConvMulFusion_W_
ConvTranspose
ConvTransposeWithDynamicPads
coordinate_transformation_mode
Copy from/to host memory
copy_info.size() == num_feeds
CoreMLExecutionProvider
corrupted protobuf data: tensor shape size(
Could not finalize session options while constructing the inference session. Error Message: 
Could not find a CPU kernel and hence 
Could not find an implementation for 
Could not find chunk in bin
Could not find OrtValue with idx '
Could not find OrtValue with name '
Could not find Region for 
Could not find Region for: 
Could not parse model successfully while constructing the inference session
Could not write a profile because no model was loaded.
count == 1
count_include_pad
counter.current_offset == last
counts
Couple the input and forget gates if 1, default 0.
Couple the input and forget gates if 1.
CPH+H
CPU allocator not found
CPU execution provider: BFloat16 data type is not supported with ScatterND opset 16 when reduction is 'add'.
CPU execution provider: BFloat16 data type is not supported with ScatterND opset 16 when reduction is 'mul'.
CPU execution provider: MLFloat16 data type is not supported with ScatterND opset 16 when reduction is 'add'.
CPU execution provider: MLFloat16 data type is not supported with ScatterND opset 16 when reduction is 'mul'.
CPU execution provider: string data type is not supported with ScatterND opset 16 when reduction is 'mul'.
CPUExecuH9
CPUExecutionProvider
Create state function failed. Return value:
Create_State_
Created a new Cast node to interchange Cast and Transpose nodes
Created a new Transpose node to interchange Cast and Transpose nodes
CreateDirectoryA
CreateDirectoryW
CreateFeedsFetchesManager must be called prior to execution of graph.
CreateFile2
Creating 
Creating and using per session threadpools since use_per_session_threads_ is true
Creating BFCArena for 
crop_size
crop_size shape input tensor has wrong dimension
CropAndResize
Ct$ H
CT$ H
Ct$ H
CT$ L
CT$(A
Ct$@H
CT$@L
Ct$`H
CT$`H
CT$`L
CT$8H
CT$8L
CT$hH
CT$pH
Ct$pH
CT$pH
CT$PL
Ct$XH
CT$xL
cubic_coeff_a
CUDA and/or ROCM execution provider is either not enabled or not available.
CUDA execution provider is not enabled in this build.
CUDAExecutionProvider
cudaMalloc
CudaPinned
CumSum
cur + size <= end
cur_index == &*indices_data.cend()
cur_iteration_ < num_iterations_
cur_tokens
current <= buffer_size_
current_mean = ReduceMean(X, axis=all_except_channel_index)
current_var =  ReduceVar(X, axis=all_except_channel_index)
Currently do not support dims higher than 2 dimensions: 
custom implementation such as CuDNN.
custom join thread function not set
custom join thread function not set for inter op thread pool
custom join thread function not set for intra op thread pool
custom op registered at runtime
custom_create_thread_fn returned invalid handle.
CX9{Pu(
D$ D;
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ ff
D$ fff
D$ fH
D$ H)x
d$ H;
D$ H;
d$ H;
D$ H;
D$ H;]
D$ H;D$(t H
D$ H;D$(u
D$ H;QHt
D$ H;S
D$ H;V
D$ H;W
D$ H+
D$ H9
D$ H9P s
D$ H9X s
D$ Hc
D$ HcH
D$ I;
D$ I+
D$ J+4 x
D$ L#
D$ L)`
d$ L;
D$ L;
d$ L;
D$ L;
d$ L;
D$ L;
d$ L;
D$ L;
D$ L;T$8
D$ L+
D$ M+
D$ tp
D$$A;
D$$falsH
D$$nullA
D$$trueA
D$(E3
d$(E3
D$(E3
D$(eH
D$(H;
D$(H;}
D$(H;S
D$(H;U
D$(H;V
D$(H;W
D$(H+
D$(H+p
D$(Hc
D$(HcA
D$(I;
d$(I;Q
D$(I+
D$(L;
D$(L+
D$(Liq`@!
D$(M;
D$(N9, 
D$@D;
D$@D9
D$@E3
d$@E3
D$@E3
d$@E3
D$@E3
d$@E3
D$@E3
D$@fH
d$@H;
D$@H;
d$@H;
D$@H;
d$@H;
D$@H;
D$@H;H
D$@H+
D$@H9
D$@H9x }
d$@Hc
D$@Hc
D$@HcH
D$@I;
D$@L;
D$@L+
D$@Lc
D$@M;
D$@Mc
D$@Mc@
D$`E3
D$`H;
d$`H;\$h
D$`H+
d$`H+
D$`H+
d$`H+
D$`H+
d$`H+
D$`H+
d$`H+
D$`H+
D$`HcH
D$`I;
d$`I;
D$`I;
D$`I;D$
D$`I+
d$`L;
D$`L;
d$`L+
D$`L+D$XI
D$`Lc
d$`Mc
d$>&6(4*
D$0{H
D$09H }
D$0A9
D$0D;
D$0D9p }
D$0D9x }
D$0E2
D$0E3
d$0E3
D$0E3
D$0fH
D$0H;
D$0H;D$@t
D$0H;S
D$0H;U
D$0H;W
D$0H;WXt
D$0H+
D$0H+<
D$0H9H s
D$0H9p }
D$0H9P }
D$0H9X }
D$0Hc
D$0HcH
D$0HcK,
D$0I;
d$0I;
D$0I;
d$0I;Q
D$0I;V
D$0I+
D$0Ic
D$0L;
D$0L;I
D$0L+
D$0L9@ s
D$0Lc
D$0Li
D$0M+
D$0xVH;
D$1H+
D$4E3
D$4fD
D$8[H
D$8]H
D$8=H
d$8E3
D$8E3
d$8E3
D$8E3
d$8E3
D$8E3
d$8E3
D$8E3
d$8E3
D$8E3
d$8E3
D$8H;
D$8H;H
D$8H;S
D$8H;SHt
D$8H;x
D$8H+
D$8H9D$0
D$8HcK(
D$8I;
D$8I+D$0H
D$8Ic@
D$8Ik
d$8L;
D$8L;
d$8L;
D$8L;
D$8L+
D$8Lc
D$AE2
D$dfff
D$EE3
D$hE3
D$HE3
D$hE3
D$HE3
D$hE3
d$HE3
D$HE3
D$hE3
D$HE3
D$hff
D$hfff
D$HH#
D$HH;
D$hH;
D$HH;
d$hH;
D$HH;
d$HH;
D$HH;
D$hH;0tK
D$HH;D$Ht
D$HH;D$Ht&
D$hH;D$p
D$hH;D$pt
D$hH;D$pu}
D$hH;D$puL
D$hH;D$pum
D$HH;E
D$hH;E
D$HH;L$Ht
d$HH;U8t
D$hH+
D$HH+
D$hH+
D$HH+
D$hH+
D$HH+
D$hH+
D$hHc
D$HI;
d$HI;
D$HI;
d$HI;
D$HI+
D$hL;
D$HL;
D$hL;
D$HL;
D$HL+
D$HM;
d$hM;l$
D$HuC
D$IL+
D$p(L
D$p+E
D$PA8
D$pD+E
D$PE3
d$PE3
D$PE3
d$PE3
D$pE3
D$PE3
D$pE3
D$PE3
d$PE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
d$PE3
D$pE3
D$PE3
D$pE3
D$PE3
d$PE3
D$pE3
d$PE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$pE3
D$PE3
D$PfD
D$pfD
D$PfD
D$PfE
D$Pff
d$pH;
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$PH;D$Xt
D$PH;W
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH9D$@uf
D$PH9D$H
D$pHcH
D$PHcH
D$pHcH
D$PHcH
D$pHcH
D$PHcH
D$pHcH
D$PHcH
D$pHcH
D$PHcH
D$pHcH
D$PHcH
D$PHcP
D$PI;
D$pI+
d$PI+
D$PL;
d$PL;
D$PL;
D$pL+
D$PLc
D$pLc
d$pM;
d$pM+
d$PtPH
D$XD;
D$XD+
D$xE3
D$XE3
D$xE3
D$XE3
D$xE3
D$xH;
d$XH;
D$xH;
D$XH;
D$xH;
D$XH;
D$xH;
D$xH;XX
D$xH+
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+
D$xI;
D$xI+
D$xL;
d$XL+
D$xL+
d$XL+
D$XL+
D$XL+t$8L
d$xL9
D$xLc
D$xM;
D$xt=
D$XtCH
D,h0y
D:\a\_work\1\s\onnxruntime\build\Windows\RelWithDebInfo\op_reduction.generated\onnxruntime\contrib_ops\cpu\cpu_contrib_kernels.cc
D:\a\_work\1\s\onnxruntime\build\Windows\RelWithDebInfo\op_reduction.generated\onnxruntime\core\providers\cpu\cpu_execution_provider.cc
D:\a\_work\1\s\onnxruntime\build\Windows\RelWithDebInfo\RelWithDebInfo\Microsoft.CognitiveServices.Speech.extension.onnxruntime.pdb
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\controlflow\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\controlflow\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\generator\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\generator\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\logical\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\logical\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\math\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\math\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\nn\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\nn\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\object_detection\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\object_detection\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\optional\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\quantization\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\quantization\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\reduction\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\reduction\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\rnn\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\rnn\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\sequence\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\tensor\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\tensor\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\traditionalml\defs.cc
D:\a\_work\1\s\onnxruntime\cmake\external\onnx\onnx\defs\traditionalml\old.cc
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google/protobuf/parse_context.h
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\arena.cc
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream.cc
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl.cc
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl_lite.cc
D:\a\_work\1\s\onnxruntime\cmake\external\protobuf\src\google\protobuf\message_lite.cc
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/common/const_pointer_container.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/common/logging/logging.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/data_types.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/data_types_internal.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/op_kernel_context.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/ort_value.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/framework/tensor.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/graph/graph.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/optimizer/graph_transformer.h
D:\a\_work\1\s\onnxruntime\include\onnxruntime\core/platform/EigenNonBlockingThreadPool.h
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops/cpu/activations.h
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\bert\bias_gelu.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\fused_conv.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\fused_gemm.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\layer_norm.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\nchwc_ops.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\nchwc_ops.h
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\quantization\dynamic_quantize_lstm.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\quantization\dynamic_quantize_matmul.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\contrib_ops\cpu\skip_layer_norm.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core/common/safeint.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/bfc_arena.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/copy.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/execution_frame.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/execution_providers.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/feeds_fetches_manager.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/func_kernel.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/mem_pattern_planner.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/mldata_type_utils.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/node_index_info.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/op_kernel_context_internal.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/ort_value_tensor_slicer.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/sequential_execution_plan.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/tensorprotoutils.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/framework/TensorSeq.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/graph/extended_graph_edge.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/graph/function_impl.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/graph/model_load_utils.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/attention_fusion_helper.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/initializer.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/optimizer/selectors_actions/helpers.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/platform/path_lib.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/common.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/activation/activations.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/controlflow/scan_utils.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/element_wise_ranged_transform.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/generator/constant_of_shape_base.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/clip.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/element_wise_ops.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/math/matmul_helper.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/nn/conv_attributes.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/nn/pool_attributes.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/nn/pool_base.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/reduction/reduction_ops.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/rnn/deep_cpu_gru.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/rnn/rnn_helpers.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/identity_op.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/reshape.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/slice.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/split.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/squeeze.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/transpose.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/unsqueeze.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/providers/cpu/tensor/utils.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core/session/inference_session.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\helper.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\logging\logging.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\path.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\profiler.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\status.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\common\threadpool.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\flatbuffers\flatbuffers_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocation_planner.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocator.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\allocatormgr.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\bfc_arena.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\config_options.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_transfer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_transfer_manager.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\data_types.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\endian_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\ex_lib_loader.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\execution_frame.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\execution_provider.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\fallback_cpu_capability.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\feeds_fetches_manager.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\fuse_nodes_funcs.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\graph_partitioner.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\kernel_def_builder.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\kernel_registry.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\mldata_type_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\node_index_info.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\op_kernel.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\op_kernel_info.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\ort_value_tensor_slicer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\parallel_executor.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\prepacked_weights.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\prepacked_weights_container.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sequential_executor.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\session_state.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\session_state_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sparse_tensor.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\sparse_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_allocator_with_mem_pattern.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_shape.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensor_type_and_shape.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\tensorprotoutils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\framework\utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\bert_defs.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\contrib_defs.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\nchwc_schema_defs.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\nhwc_schema_defs.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\onnx_deprecated_operators.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\contrib_ops\quantization_defs.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\function.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_flatbuffers_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\graph_viewer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\model.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\runtime_optimization_record_container.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\graph\schema_registry.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\attention_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_dropout_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_gelu_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\bias_softmax_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\common_subexpression_elimination.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\constant_folding.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_activation_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_add_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_bn_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\conv_mul_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\dynamic_quantize_matmul_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\embed_layer_norm_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\fast_gelu_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\free_dim_override_transformer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gelu_approximation.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gelu_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gemm_activation_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\gemm_sum_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer_mgr.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\graph_transformer_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\initializer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\insert_cast_transformer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\layer_norm_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_add_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_integer_to_float.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_scale_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\matmul_transpose_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\nchwc_transformer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\nhwc_transformer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\optimizer_execution_frame.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\clip_quantizelinear.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_final_cleanup.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_propagation.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_s8_to_u8.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\qdq_transformer\qdq_util.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\relu_clip_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\reshape_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\rule_based_graph_transformer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\actions.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\helpers.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\selectors_actions\selector_action_transformer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\skip_layer_norm_fusion.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\transformer_memcpy.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\transpose_optimizer\optimizer_api_impl.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\transpose_optimizer\ort_transpose_optimizer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\unsqueeze_elimination.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\optimizer\utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\platform\windows\env.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\activation\activations.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\controlflow\if.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\controlflow\scan_9.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\controlflow\scan_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\generator\constant_of_shape.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\clip.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\cumsum.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\element_wise_ops.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\gemm_base.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\gemm_helper.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\hardmax.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\matmul.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\softmax.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\math\top_k.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\nn\conv.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\nn\pool.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\quantization\conv_integer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\quantization\dynamicquantizelinear.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\quantization\matmul_integer.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\quantization\quantize_linear.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\reduction\reduction_ops.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\deep_cpu_gru.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\deep_cpu_lstm.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\lstm_base.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\lstm_base.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\rnn\rnn_helpers.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\cast_op.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\concat.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\concatbase.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gather.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gather_elements.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gather_elements.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\gatherbase.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\reshape_helper.h
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\scatter_nd.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\slice.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\split.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\tile.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\transpose.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\providers\cpu\tensor\unsqueeze.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\custom_ops.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\environment.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\inference_session.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\inference_session_utils.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\IOBinding.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\onnxruntime_c_api.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\ort_env.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\session\provider_bridge_ort.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\util\math_cpu.cc
D:\a\_work\1\s\onnxruntime\onnxruntime\core\util\thread_utils.cc
D;|$0ujH
D;<)|dH
D;8|tH
D;B(|
D;J0t
D;y }mH
d@f.d
D`HrJ
D+3L9c0u
D+b0L
D+k0E
D+s0D
D+z0A
D=xz#
D3d$(
D3d$(I
D6F:>
D8$:u
D8@4tqH
D8{8u;H
D84:u
D8d$@H
D8D$@t
D8d$0
D8I1A
D8n t
D8n,tEH
D8oPt
D8P5u
D8R1u
D8t$@t:A9l$
D8t$0
D8t$At$A9m
D8wPt
D8Z1u
D9`(t
D9`,I
D9{(t&H
D9|$h~
D9}H~f
D9~(u
D9G vu
D9h(t
D9H,tcH
D9h0t
D9J0t
D9K vr
D9K vs
D9O(u
D9p }
Data for input  
Data of TensorProto ( tensor name: 
data overflow
Data size mismatch. Tensor: 
data tensor must have rank >= 1
Data to be binarized
Data to be classified.
Data to be encoded, a tensor of shape [N,C] or [C]
Data to be encoded.
Data to be processed.
Data to be regressed.
Data to be scaled.
Data to be selected
data type 
Data type for starts and ends inputs' is not supported in this build. Got 
data type is not supported
Data type mismatch
data_0
data_scale
data_transfer registered is nullptr.
data_type
data_zero_point
DataTypeUtils::FromDataTypeString - Received invalid data type string 
DbQ}X
DCR (default) for depth-column-row order re-arrangement. Use CRD for column-row-depth order.
decoder
Decoder input ids after merging predicted tokens
Decoder input ids.
Decoder subgraph to execute in a loop.
DecoderAttention
default 1; Pooled output Y's height.
default 1; Pooled output Y's width.
Default logger already set. 
default_float
default_int64
default_logger_id must be provided if instance_type is InstanceType::Default
default_string
DEFAULTEXTERNAL
Defines behaviour if 'axes' is empty. Default behaviour with 'false' is to reduce all axes. When axes is empty and this attribute is set to true, input tensor will not be reduced,and the output tensor would be equivalent to input tensor.
Defines how to aggregate leaf values within a target. <br>One of 'AVERAGE,' 'SUM,' 'MIN,' 'MAX.'
DeleteFile() failed - path: 
DeleteFileW
delta
delta in Range operator can not be zero!
delta in Range operator should be scalar like tensor, yet got shape:
Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", scale = length_resized / length_original, <br/>
DENSE
dense shape must 2-D. Got: 
depth
DepthToSpace
DequantizeLinear
DequantizeLinear with type int32 should have no zero point or all zero points should be 0
deque<T> too long
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Deserialize tensor 
DeserializeTensorProto() takes either pre-allocated buffer or an allocator!
Destination must have a CPU allocator set
Destination should be empty
detect_negative
detect_positive
detection_boxes
detection_classes
detection_scores
Deviation = Sub (XU, Mean2D)
Device:[
DeviceType:
DictVectorizer
Did not find an arena based allocator registered for device-id 
Did not find session options in the model file to be used while running the model
Diff between in-use and requested bytes is 
Dilation not supported for AutoPadType::SAME_UPPER or AutoPadType::SAME_LOWER.
Dilation value along each spatial axis of filter.
Dilation value along each spatial axis of filter. If not present, the dilation defaults to 1 along each spatial axis.
dilation value along each spatial axis of the filter.
dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis.
dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each axis.
dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each spatial axis.
dilations
Dilations dimensions should match kernel shape
dilations.size() == kernel_shape.size()
dim_param value with no name. Invalid ORT format model.
dim0_offset < dim0_size
dimension <= num_dims
Dimension could not be inferred: incompatible shapes
Dimension mismatch in unification between 
Dimension of input 
Dimension on which to do the sort.
Dimension on which to do the sort. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Dimension value inferred (
dims.size() == extents.size() && dims.size() >= steps.size()
dims.size() == extents_.size()
dims.size() == starts.size()
dims.size() == starts.size() && dims.size() == extents_.size() && dims.size() >= steps.size()
dims.size() == steps.size()
dims.size()=
dims[d_i] < d_max
dimstart <= dimend && dimend <= values_.size()
direction
Direction of moving bits. It can be either "RIGHT" (for right shift) or "LEFT" (for left shift).
directions
directions.size() == num_entries
discarded
Distribution
DistributionEnqueue
Div and Shape does not have edge
Div and Shape1 does not have edge
div_inputs.size() == 2
Divide by zero
Dividend tensor
division
Divisor tensor
DivMulFusion
DmlExecutionProvider
DnnlExecutionProvider
dNnP(R)
does not have the graph for key 
domain == kOnnxDomain
Domain already set in registry
domain_version != -1
domainToVersionMap
Done saving initialized tensors
Done saving OrtValue mappings.
double
double_data
drop_states
dropDQ
Dropout
dst.DataType() == src.DataType()
dst_implicit_input_idx < (int)node->ImplicitInputDefs().size()
dst_node != nullptr
dst_strides.size() == src_strides.size() && src_strides.size() == copy_shape.size() && !copy_shape.empty()
dst_type->value_case() == src_type->value_case() && (!dst_data_element_type_present || dst_data_element_type == src_data_element_type)
Dt$PH
dtype
dtype_ != nullptr
dtype_attribute->second.has_i()
dup_replacements.find(&arg) == dup_replacements.end()
Duplicate constant node sparse initializer name: '
Duplicate initializer (dense or ConstantNode): '
Duplicate initializer (dense, sparse or ConstantNode): '
Duplicate sparse_tensor_initializer: '
Duplicate type constraint name
duplicated allocator
duplicated allocator: 
duplicated location
duplicated ort_value index:
DXHjJ:L
Dynamic block base set to 
DynamicQuantizeLinear
DynamicQuantizeLSTM
DynamicQuantizeLSTM : 
DynamicQuantizeMatMul
DynamicQuantizeMatMulFusion
DynamicSlice
E D+E0D
E HcH
E I+E
E(A;@(u
E(A+E0A
E(D+E0D
e(D+e0D
E(H+E H
e)tTL
E/H;E7
E;X$|
E@H+E0H
E@HcH
E\$pH
e_.,>
E_Xsquared
e`A^_]
E0C1)0'
E0H#D$0H
E0H9E
E0HcH
E84(u
E8H;E@t
E9}(u
Each element of the sequence should be either tensor or map.
early stop or not
early_stopping
EfficientNMS_TRT
EgH;QHt
E'H;E/tBH
EHfff
EHH+E@H
Ehttp://crl.microsoft.com/pki/crl/products/MicRooCerAut_2010-06-23.crl0Z
Ehttp://www.microsoft.com/pkiops/certs/MicCodSigPCA2011_2011-07-08.crt0
Einsum
Einsum expression string.
Either the key tensor or the value tensor has NumDimensions > 1
elem_proto != nullptr
elem_type
elem_type_ != nullptr
element index is out of bounds
Element type of input 
Element type of inputs are expected to be the same.
Element type of optional input 
Element type of optional input was unknown
Element type of sequence input 
Element type of sequence input was unknown
Element type of tensor or sparse tensor input was unknown
Element_size of: 
elements, but feeds has 
EliminateDropout
EliminateIdentity
EliminateSlice
Ellipsis represents incompatible dimensions.
else_branch
embedding_size
embedding_sum
EmbedLayerNormalization
EmbedLayerNormFusion
Empty graph proto from deserialization of ORT format model
Empty sequence.
Enable broadcasting
enable_profiling
enable_profiling option in the model file must be an integer
enabled_
EnableOrtCustomOps: Custom operators in onnxruntime-extensions are not enabled
Encoded output data
Encoded output data, having one more dimension than X.
Encoder input ids.
encoder_decoder_init
Encoding type for the boxes or anchors inputs.
Encountered unknown exception in Initialize()
Encountered unknown exception in Load()
Encountered unknown exception in Run()
end >= starts_.back()
end of input
Ending indices (exclusive) of corresponding axis in axes`
Ends must be a 1-D array
ENGINE_ERROR
entiu
entry != initialized_tensors_to_allocate.end() && entry->second->data_type() != ONNX_NAMESPACE::TensorProto_DataType_STRING
entry != kernel_create_info_map.cend()
entry != kernel_create_info_map_.cend()
entry != node_to_subgraph_ss.second.cend()
entry != nullptr
entry != regions_.end()
Entry exists in node 
entry.program_counter.HasValidEntries()
Env is null
env_ptr == p_instance_.get()
Environment dependent string that denotes the locale according to which output strings needs to be upper/lowercased.Default en_US or platform specific equivalent as decided by the implementation.
eos_token_id
EP_FAIL
EpH;Ex
Epsilon
epsilon
epsilon_ >= 0
Equal
equal
equal const not matched.
equation
Equations (Default: f=Sigmoid, g=Tanh):
Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):
Equations (Default: f=Tanh):
ERROR
Error context: 
Error during EndProfiling(): 
Error mapping feeds: 
Error mapping output names: 
Error merging shape info for output. '
Error parsing function body:
Error parsing TensorProto (expected a tensor shape).
Error parsing TensorProto (expected a tensor type).
Error parsing TensorProto shape (expected numeric dimension).
Error unexpected extra input in node:
Error: Duplicate definition-site for (
errorCategory
errorCode
errorMessage
ERt)H
Et$PH
EvaluationStart
EvaluationStop
EventRegister
EventSetInformation
EventUnregister
EventWriteTransfer
EX_squared
Exception
Exception caught: 
Exception during initialization: 
Exception during loading: 
Exception running nodes starting at 
excessive array size: 
excessive object size: 
exclude_outside
exclusive
exec_plan_index
exec_plan_ptr
Execution frame was null
Execution providers must be registered before the session is initialized.
Execution providers must be registered before the session is initialized. 
Execution type '
execution_mode
execution_mode is not valid
execution_mode option in the model file must be an integer
ExecutionProviderEvent
executionProviderIds
EXH;E`t
Existing destination type is not compatible with source type.
Existing entry in compiled kernel hashes for 
Existing registration with name 
existing_entries.find(attribute_name) == existing_entries.cend()
existing->second == &tensor
Exiting due to terminate flag being set to true.
EXM#upM
Expand
ExpandBroadcastLooper should only have a shape for the second input.
ExpandDims
expanded
expanded_target
expanded_target = Unsqueeze (target, axes)
expanded_target_int64
ExpandElimination
Expect mask data type is uint8 or float
expected a registered ONNX type
Expected AllocateFinalOutput to have been called to before we increment the iterator
Expected AllocateFinalOutput to have been called to before we read the OrtValue from the iterator.
Expected character 
Expected Conv then Add.
Expected shape from model of 
Expected value:
Expecting activation to be one of Affine, Relu, LeakyRelu, ThresholdedRelu, Tanh, ScaledTanh, Sigmoid, HardSigmoid, Elu, Softsign, Softplus. Got 
Expecting all elements to be tensors. Got: 
Expecting data type to be set as string
Expecting fully sparse tensors to have indices shape {0}
Expecting fully sparse tensors to have value shape {0}
Expecting index blocks: 
Expecting indices to be equal the number of values or be twice as many
Expecting indices to have 2-D shape . Got: 
Expecting inner index size: 
Expecting inner indices to be same as nnz. Got: 
Expecting one index. Got: 
Expecting to contain one index, got: 
Expecting to have at lest 3-D shape. Got:
Expecting two indices. Got: 
EXPERIMENTALSTABLE
Exponent
Exponential penalty to the length. Default value 1.0 means no penalty.Value > 1.0 encourages longer sequences, while values < 1.0 produces shorter sequences.Shape is (1,)
Extended allocation by 
Extending BFCArena for 
extents.size()=
External data type cannot be UNDEFINED or STRING.
External data type must not be UNDEFINED or STRING.
Extra unparsed input unexpected.
extra_add
extra_shape
extrapolation_value
EyeLike
F .",
F D+F0D
F L+F
f M+f
F$H:J
F&b(M
F(+F0
F(9_(
F(D+F0D
F(E+F0E
F(fff
F(I+F H
f^jjl:n
F0H#D$0H
F0H;Q
F0H9F(t
F0I;F8t
F8I+F(H
f9Gvu$
f9Pvu$
fA9Fvu
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum), default is 0.9f.
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).
Faild to find path to qkv_matmul
Faild to find path v
Faild to find path v to Split
Faild to match concat node for Gather paths
Faild to match gemm gather path
Faild to match gemm path
Faild to match path 1 for unidirectional mask
Faild to match path 2 for unidirectional mask
Faild to match path 3 for unidirectional mask
Faild to match path 4 for unidirectional mask
Faild to match the path (Div-->Where-->Add) for unidirectional mask
Failed in match input mask subgraph
Failed in match Transpose attribute perm. Expected: 0, 2, 1, 3
Failed in match v_matmul and v_add input shape
Failed in match v_transpose attribute perm. Expected: 0, 2, 1, 3
Failed memory size calculation
Failed since multiple edges matched:
Failed to add kernel for 
Failed to allocate memory for requested buffer of size 
Failed to convert dense initializer to sparse
Failed to convert mask to int32
Failed to copy tensor to 
Failed to create output tensor for 
Failed to create output tensor for If output 
Failed to create output tensor for output #
Failed to create the inter-op thread pool for the parallel executor, setting ExecutionMode to SEQUENTIAL
Failed to find a free memory block despite calling Extend. rounded_bytes=
Failed to find allocator for device 
Failed to find initializer for name: 
Failed to find initializer to reshape with name 
Failed to find input name in the mapping: 
Failed to find kernel def hash (
Failed to find kernel for 
Failed to find mask path
Failed to find path 1 of position shape.
Failed to find path 2 of position shape.
Failed to find path for k
Failed to find path for mask
Failed to find path for past_k
Failed to find path for present_k
Failed to find path for present_v and past_v
Failed to find path for q
Failed to find reshape shape path 1
Failed to find reshape shape path 2
Failed to find shape path
Failed to find Softmax node
Failed to find symbol 
Failed to get allocator for location: 
Failed to get allocator for optimizer
Failed to get Clip min/max constants.
Failed to get initializer tensor.
Failed to get position embedding weights.
Failed to get size of TensorProto
Failed to load model because protobuf parsing failed.
Failed to load model with error: 
Failed to load Q, K and V bias tensors, or data type is not float or float16.
Failed to load Q, K and V weights, or data type is not float or float16.
Failed to match position embedding subgraph.
Failed to match position subgraph.
Failed to match Shape node. 
Failed to match v_concat
Failed to parse max_length or it is not positive integer scalar
Failed to parse num_beams or it is not positive integer scalar
Failed to parse num_return_sequences or it is not positive integer scalar
Failed to parse path root: 
Failed to remove node.
Failed to set node op schema.
Failed to set op schema for added DQ node.
Failed to set op schema for added Q node.
Failed to unload DSO: 
Failed to write value with snprintf().
FailFast
false
false literal
fast_gelu_output
fast_shape.size() == 2
fast_shape.size() == 3
fast_shape[0] * fast_shape[2] == output.Shape().Size()
fast_shape[0] == output.Shape().Size()
fast_shape[1] == output.Shape().Size()
FastGelu
FastGeluFusion
FATAL
Fatal error: 
Fatal error: 0 count processors from GetLogicalProcessorInformation
Fatal error: 0 count processors from GetSystemInfo
fbQ}X
fbs_attr cannot be null
fbs_node_arg_names cannot be null
fC9tE
fclose
fD9dB
fD9dj
fD9H6u
fD9Iv
Feature id for each node.
feature_map_0
feature_map_1
feature_map_2
feature_map_3
FeatureVectorizer
feed_locations.size() == copy_info.size()
feeds.size() == feed_mlvalue_idxs.size()
feeds_fetches_manager_ && info_
fetch_alloc_info.size() == copy_info.size()
Fetches vector passed to GetOutputs contains 
fetches.empty() || fetches.size() == fetch_mlvalue_idxs_.size()
fetches.size() == node->OutputDefs().size()
fff?@
fffff
ffffff
fffffff
FFH4J2L<N
fflush
fg:SM
fgetc
fgetpos
FHI;FPt
Field '
file_path == nullptr
FileDescription
FileVersion
filter_info_ == nullptr
Final beam score of the generated sequences. Shape is (batch_size, num_return_sequences)
Final N loop carried dependency values then K scan_outputs
Final N loop carried dependency values then K scan_outputs. Scan outputs must be Tensors.
Final values of the loop's N state variables followed by K scan_outputs
final_output_mlvalue_
final_state_and_scan_outputs
FindClose
FindFirstFileW
FindNextFileW
First input does not have rank 2
First input operand for the logical operator.
first input tensor has wrong dimension
First input tensor must have rank 3
First operand, base of the exponent.
First operand, input to be shifted.
First operand, should share the type with the second operand.
First operand.
First set of probability coefficients.
First, offset by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.
Flag indicating whether the regression is a one-class SVM or not.
Flatten
float
FLOAT
Float representing the threshold for deciding when to remove boxes based on score. It is a scalar.
Float representing the threshold for deciding whether boxes overlap too much with respect to IOU. It is scalar. Value range [0, 1]. Default to 0.
float_data
float16
float16)M9H
FLOATFLOATSGRAPHGRAPHSINTINTSSPARSE_TENSORSPARSE_TENSORSSTRINGSTRINGSTENSORTENSORSTYPE_PROTOTYPE_PROTOSUNDEFINED
FLOATS
floats
floor
Floor
floorf
Flush-to-zero and denormal-as-zero are 
For each node, define what to do in the presence of a missing value: if a value is missing (NaN), use the 'true' or 'false' branch based on the value in this array.<br>This attribute may be left undefined, and the defalt value is false (0) for all nodes.
For each node, define what to do in the presence of a NaN: use the 'true' (if the attribute value is 1) or 'false' (if the attribute value is 0) branch based on the value in this array.<br>This attribute may be left undefined and the defalt value is false (0) for all nodes.
For example, the following tensor shapes are supported (with broadcast=1):
For map type num_values MUST be 2
for node: 
For ort_value with index: 
For previous (depreciated) non-spatial cases, implementors are suggested
forgot to update the version range in DomainToVersionRange 
Format() == SparseFormat::kBlockSparse
Format() == SparseFormat::kCoo
Format() == SparseFormat::kCsrc
Format() == SparseFormat::kUndefined
format_data_.size() == 1U
format_data_.size() == 2U
FormatMessageA
FormatMessageW
found duplicated provider 
Found kernel for Op with name (
Found session/run/environment configuration in the model file to be used while running the model
found_in_outer_scope_location_map
Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get "nearest" pixel in input tensor from x_original, so this attribute is valid only if "mode" is "nearest".
foward
Fp;Gpt
FPI+F@H
FPI9FHtIH
fputc
frame != nullptr
fread
FreeDimensionOverrideTransformer
FreeLibrary
FreeLibrary failed with error 
fsetpos
Ft8At
Fu8Au
func info for node: 
function
Function body initialization failed for Function '
Function body initialization failed for node '
fused 
fused Add and Gelu
fused Add-Dropout-(Add) for 
Fused an attention node for GPT.
Fused an attention node.
Fused Attention subgraphs 
fused EmbedLayerNorm subgraphs 
fused Gelu subgraphs 
fused Gemm 
Fused Gemm with Sum
Fused Gemm with Transpose
fused GPT2Gelu subgraphs 
fused LayerNorm subgraphs 
fused Matmul and Add 
Fused MatMul and Scale
fused MatMul and Transpose 
Fused reshape node: 
fused SkipLayerNorm subgraphs 
fused_function_subgraph
FusedConv
FusedGemm
FusedMatMul
FuseReluClip
FuseReluClip_
fusion_style == IExecutionProvider::FusionStyle::Function
FVH$Ja
FVHtJ2L
fwrite
FXH,J
FxH;FxtJH
FxI;Fxu
FXI+FHH
FXL+FPI
G +G0
G 9A 
G D+G0D
G H;G(t
G I;G(t
G I+G
G(+G0
G(9G,tPA
G(A9F(
G(D+G0D
g(D+g0D
G(D+G0D
G8<4u
gamma
gamma is expected to have 1 dimension, got 
Gamma should be of shape (hidden_size). 
gamma should have 2 dimension, dimension size known, and same hidden size as word_embedding.
gamma_quant
gamma_scale
gamma_zero_point
gates
Gather
gather axis value not expected
gather indices not matched.
gather input 1 value is not expected
Gather node in path 2 is not linked to another subgraph.
Gather Tind type not supported in this build.
Gather_1
Gather_11
Gather_13
GatherElements
GatherElements op: Cannot operate on scalar input
GatherElements op: Data type of input 'data' should match the data type of the output
GatherElements op: 'indices' shape should have values within bounds of 'data' shape. Invalid value in indices shape is: 
GatherElements op: Rank of input 'data' needs to be equal to rank of input 'indices'
GatherElements op: Value in indices must be within bounds [
GatherND
gCY&mB
Gelu approximation
GeluApproximation
GeluFusion
Gemm bias is not constant
Gemm bias is not constant initializer
Gemm bias shape is not expected
Gemm bias shape not expected
Gemm does not have 3 inputs
Gemm weight is not constant initializer
Gemm weight shape is not expected
GEMM: Dimension mismatch, W: 
Gemm: Invalid bias shape for broadcast
gemm_input_edge.src_arg_index < 2
GemmActivationFusion
GemmSumFusion
GemmTransposeFusion
Gemv found an unexpected CBLAS_TRANSPOSE input of
GENERAL ERROR
generated at runtime
generic
GenuD
Get preallocated buffer for initializer '
GetCurrentProcessId
GetCurrentProcessorNumber
GetCurrentThread
GetCurrentThreadId
GetEnvironmentVariableA
GetFileAttributesA
GetFileAttributesW
GetFileSizeEx
GetFileSizeEx 
GetFinalPathNameByHandle() failed: 
GetFinalPathNameByHandleW
GetFusedActivationAttr(info, activation_).IsOK()
GetLastError
GetLogicalProcessorInformation
GetModuleFileNameA
GetProcAddress
GetProcessHeap
GetProvider
GetSystemInfo
GetSystemTimeAsFileTime
GetSystemTimePreciseAsFileTime
gfffffff
gfffffffH
gfffffffH+
gfffffffI
Given model could not be parsed while creating inference session. Error message: 
GivenTensorFill
global
Global attention flags with shape (batch_size, sequence_length)
global_bias
global_weight
GlobalAveragePool
GlobalLpPool
GlobalMaxPool
Got invalid dimensions for input: 
Got nullptr from GetKernel for node: 
GPH9GHthH
GPT2Gelu
GRAPH
Graph
graph
Graph attribute inferencing failed: 
Graph attribute inferencing returned type information for 
Graph attribute value was null. Invalid ORT format model.
Graph contains an invalid node: 
Graph ctor should have created NodeArg for initializer. Missing:
Graph has 
Graph initializer names must appear after the actual inputs: 
Graph is null. Invalid ORT format model.
Graph must be in single static assignment (SSA) form, however '
Graph state to be loaded into must be empty.
Graph to run if condition is false. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the then_branch.
Graph to run if condition is true. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the else_branch.
graph.RemoveNode(gemm_node.Index())
graph.RemoveNode(sum_node.Index())
graph_->GetNode(idx) != nullptr
graph_index
graph_inputs_excluding_initializers_.empty() && graph_inputs_including_initializers_.empty() && value_info_.empty() && graph_outputs_.empty()
graph_optimization_level
graph_optimization_level is not valid
graph_optimization_level option in the model file must be an integer
graph_proto != nullptr
graph_proto cannot be null
graph_proto_ is not in sync with name_to_initial_tensor_.
graph_transformation_mgr_.SetSteps(session_options_.max_num_graph_transformation_steps).IsOK()
GraphProto attribute inferencing is not enabled in this InferenceContextImpl instance.
graphs
GRAPHS
Greater
greater
greater_equal
GreaterOrEqual
GridSample
group
GRU operator does not support double yet
GRUUnit
gsl::narrow_cast<int64_t>(input_axes_.size()) == num_scan_inputs_
gsl::narrow_cast<int64_t>(input_shape.Size()) == size
gsl::narrow_cast<int64_t>(output_axes_.size()) == num_scan_outputs
gsl::narrow_cast<int64_t>(tensor_shape.NumDimensions()) >= slice_dimension
Gt8At
Gu8Au
Gvf9Av
GXH;GXu
h != kInvalidChunkHandle
H ,"&
h < chunks_.size()
H H+H
h t",$
h VWATAVAWH
H"L0N0P"RJT
H#}0H
H#A0H
H#C@H
H#C0E3
H#C0H
H#CXH
H#D$HH
H#D$xHk
H#E@H
H#E0H
H#E0L
H#EpH
H#F0H
H#F0L
H#G0H
H#K0H
H#L$xH
H#U0H
H#V`L
H#W`L
H&.(,
H(;M(u
H(A;I
H,A;I
H;\$ tk
H;\$0
H;\$0t
H;{ |
H;{8u
H;{HtdH
H;{Hv
H;|$ 
H;|$(t
H;|$`
H;|$0t
H;|$0tHH;
H;|$8t
H;|$p
H;|$p|
H;|$pL
H;|$Pr
H;|$Pu
H;|$x
H;|$X
H;}HtBM
H;=U;7
H;0uoA
H;8uiH
H;A(s
H;APuS
H;D$(
H;D$`
H;D$0
H;D$0L
H;D$hM
H;D$P
H;D$X
H;D$x
H;D$Xu
H;EpuOL
H;EpuSL
H;ExuLL
H;G@|
H;H s
H;H@s
H;HHs`H
H;K r
H;L$ht*
H;L$xt
H;Mxt.I
H;Q }kM9N
H;Q }kM9O
H;Q r
H;q r
H;Q r
H;r }cH
H;s`r
H;s8uuH
H;S8v
H;t$ 
H;T$@uzM
H;T$`|
H;t$0t
H;t$8
H;t$H
H;t$HH
H;t$ht
H;t$HtYH
H;t$p
H;t$x
H;t$xs
H;u r
H;U t
H;U't
H;W8v
H;Y |
H;Y r
H;y suH
H;z r
H_^][
h~jzlJn(lBh
H~LjN
H+\$ H
H+A8H;
H+AxH
H+C8H
H+C8H;
H+CxH
H+CxH+
H+D$8
H+D$HL
H+D$PH
H+E8H
H+F8H
H+F8H;
H+G8H
H+K8H
H+K8H;
H+kxH
H+L$ A
H+L$ f
H+L$@H
H+L$0H
H+N8H;
H+SxH;
H+T$`H
H+T$HH
H+T$xH
h> bNd6f4
h0VN*P(R:TXV|XRZl\`^R`znNj4h>f
H8H+H0H
H9\$@
H9\$`
H9\$p
H9_@~
H9|$p
H98t=H
H9A s
H9A u
H9C`u
H9Chu
H9D$0t
H9D$8
H9D$H
H9D$Ht
H9E`t6L
H9F0u)M
H9FDtzI
H9l$(u
H9l$@}
H9L$0
H9L$pt
H9P s
H9p s
H9P s
H9q }
H9q0vb
H9Qhs
H9r s/H
H9t$8}
H9t$X
H9t$xu>M
H9w u@
H9wht
H9x s
H9y }
H9y s
H9Y uRA
H9Y0t
HA]^][
hA^^][
HA^_^[
hA^_^[
hA^A]
HA^A]_^][
HA__][
HA_A]
hA_A^
HA_A^][
HA_A^_[
hA_A^_[
hA_A^_^
HA_A^_^][
hA_A^_^][
HA_A^_^][
HA_A^A\[
HA_A^A\_][
HA_A^A]_^[
hA_A^A]A\_^[]
hA_A^A]A\_^][
HA_A^A]A\_^][
hA_A^A]A\_^][
HA_A^A]A\_^][
hA_A^A]A\_^][
half_pixel
hardmax
Hardmax
Hardmax inputs N, D and N * D must be < 
Hardmax(element in input, axis) = 1 if the element is the first maximum value along the specified axis, 0 otherwise
HardSigmoid
hardsigmoid
HardSwish
has output size 
has_key_padding_mask
has_key_padding_mask or not
has_layer_state
has_starts && has_ends && attr_starts_.size() == attr_ends_.size()
HasDataType(dense_proto)
Having memory pattern enabled is not supported while using the DML Execution Provider. 
hBj.h
Hc@hH
Hc@PH
Hc\$D
Hc_$H
Hc|$ L
HcA I
HcA,H
HcA8H
HcAhH
HcAPH
HcB H
HcB8H
HcBPH
HcC(H
HcC(H;
HcC,H
HcD$ H
HcD$\
HcD$8H
HcEHH
HcF H
HcF0H
HcFHH
HcFPH
HcFpH
HcFXH
HcG H
HcGPH
HcGXH
HcH0H
HcK(I
HcK,I
Hcl$ H
HcL$ L
HcL$0M
HcL$hH;
HcO$H
HcO$L
HcP,H
HcPhH
HcPPH
HcQ0H
HcS(H
HcT$0H
HcT$HI
Hct$P
HcT$xL
HcU0H
HcUhH
HcW$C
Hcx,H
HeapAlloc
HeapFree
height_scale
helper.HaveTwoTensorInputs()
HfLjN:P
hFrGh
hidden
Hidden layer sizes of Q, K, V paths in Attention
hidden_prev
hidden_size
hidden_size != num_heads * head_size
hipMalloc
hJljn:p
HL$`L;
hnj^l
HnJ^L
hResult
http://www.microsoft.com0
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
HUSVH
HUSVWATAUAVAWH
HUSVWATAUAVH
HUSVWATAUH
HUSVWAVATH
HUSVWAVAUATH
HUSVWAWAVAUATH
HUSVWAWH
HUSVWH
HXH9NX
HXI9HX
hXljn:p
HzJXL(J`
i < input_shape.NumDimensions()
i < tensors_.size()
I#~0H
I#D$0H
I#E0H
I#E0M
I#EpH
I#F0H
I#F0L
I#F0M
I#G0H
I#M0H
I#O0H
I#O0M
I#V0H
I#w0H
I#W0H
I#w0H
I#W0H
I#w0H
I#W0H
I#w0H
I#W0H
I#w0H
I#W0H
I#w0H
I#W0H
I#w0H
I#W0H
I#w0H
I#W0H
I#w0H
I#W0H
I#w0H
I#W0H
I;\$xu
I;]xt
I;]xtbL
I;6ugD;j
I;p |
I;p rdH
I;Q@t
I;Q8|
I;QXt
I;T$(
I;U8v
I;Y8|
I+4$H
I+AHH
I+E8H
I+F8H
I+F8H;
I+N H
I+V`H
I+VHH
I94$I
I9Jhs
I9Khs
I9Q8~{
I9upt
Iba|H
IbbeHQ
IbR=@
IbR=P
Ic(H;
Ic@(H
Ic@8H
Ic@PH
Ic8H;
IcD$8H
IcD$hH
IcE H
IcE L
IcE8H
IcEhH
IcEhL
IcEPH
IcFhL
IcG L
IcG8H
IcGhH
IcGhL
IcGPH
IcM0H
IcP Ic@
IcP(H
id >= 0 && static_cast<size_t>(id) < ort_value_info_.size()
Identifier expected but not found.
Identity
Identity_1
Identity_13
Identity_14
Identity_16
ideru
IExecutionProvider constructor must be called with true for use_metadef_id_creator
IExecutionProvider::Compile with fused Node and dll path is not implemented by 
IExecutionProvider::Compile with fused Node is not implemented by 
IExecutionProvider::Compile with FusedNodeAndGraph is not implemented by 
If 0, normalize the mean only.  Default is 1.
If 1, mean and variance are computed across channels. Default is 0.
If align_corners=1, the extrema (-1 and 1) are considered as referring to the center points of the input's corner pixels. If align_corners=0, they are instead considered as referring to the corner points of the input's corner pixels, making the sampling more resolution agnostic.
if coordinate_transformation_mode is "align_corners", <br/>
if coordinate_transformation_mode is "asymmetric", <br/>
if coordinate_transformation_mode is "half_pixel", <br/>
if coordinate_transformation_mode is "pytorch_half_pixel", <br/>
if coordinate_transformation_mode is "tf_crop_and_resize", <br/>
if coordinate_transformation_mode is "tf_half_pixel_for_nn", <br/>
If has_layer_state = true, layer_state = {} or [a,b]; else layer_state = None
If keepdims equal 0, then the resulting tensor have the reduced dimension pruned.
If necessary the right-hand-side argument will be broadcasted to match the
If node has 
'If' node has 
If set to 1 will perform the sums in reverse direction.
If set to 1 will return exclusive sum in which the top element is not included. In other terms, if set to 1, the j-th output element would be the sum of the first (j-1) elements. Otherwise, it would be the sum of the first j elements.
If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0.
If set to nonzero, run spatial batch normalization in test mode, default is 0.
If set to true then it indicates dropout is being used for training. It is an optional value hence unless specified explicitly, it is false. If it is false, ratio is ignored and the operation mimics inference mode where nothing will be dropped from the input data and if mask is requested as output it will contain all ones.
If set to true, it indicates BatchNormalization is being used for training, and outputs 1, 2, 3, and 4 would be populated.
If set, defines the broadcast dimensions.
If set, defines the broadcast dimensions. See doc for details.
If shape was concrete we shouldn't be using a custom allocator
If spatial is true, the dimension of bias is (C). If spatial is false, the dimensions of bias are (C x D1 x ... x Dn)
If spatial is true, the dimension of scale is (C). If spatial is false, the dimensions of scale are (C x D1 x ... x Dn)
If spatial is true, the dimension of the running mean (training) or the estimated mean (testing) is (C). If spatial is false, the dimensions of the running mean (training) or the estimated mean (testing) are (C x D1 x ... x Dn).
If spatial is true, the dimension of the running variance(training) or the estimated variance (testing) is (C). If spatial is false, the dimensions of the running variance(training) or the estimated variance (testing) are (C x D1 x ... x Dn).
If static_kv = true, cross-attention; else self-attention
If the value of map_form is 'SPARSE,' this attribute indicates the total length of the output tensor.
If true and category is not present, will return all zeros; if false and a category if not found, the operator will fail.
If true, check only for Inf, -Inf.
If true, check only for NaN.
If true, compute the mean and variance across all spatial elements If false, compute the mean and variance across per feature.Default is 1.
If true, compute the mean and variance across per activation. If false, compute the mean and variance across per feature over each mini-batch.
If use_past = true, use cache; else no cache
If value is 1, output type is uint32_t, else int32_t. Default value is 1.
ignore_index
Ignoring unsupported session option in ORT config: 
IHL;IPu
Ihttp://crl.microsoft.com/pki/crl/products/MicRooCerAut2011_2011_03_22.crl0^
illegal input path:
Image size.
image_size
ImageScaler
implementation such as CuDNN.
Imputed output data
imputed_value_floats
imputed_value_int64s
Imputer
in initializers. 
in onnx/defs/schema.h).
in the inclusive range [
in[idx]->IsTensor()
Incompatible dimensions
Incompatible dimensions for matrix multiplication
Incorrect arena extend strategy.
Incorrect or missing attribute value for starts and ends
Incorrect or missing input value for starts and ends
index < data_.size()
index < nodes_.size() && ((node = nodes_[index]) != nullptr || !required)
index >= 0 && static_cast<size_t>(index) < inputs.size()
index >= 0 && static_cast<size_t>(index) < outputs.size()
index is out of bounds
index out of range
Index out of range
Index size: 
IndexedSubGraph contains values not present in the Graph
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [0, R], where R is the rank of the input tensor. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [-r, r], where r is the rank of the input tensor. Negative value means counting dimensions from the back. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
Indicates the transform to apply to the regression output vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates the transform to apply to the score. <br> One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Indicates the transform to apply to the scores vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates whether to do OvR or multinomial (0=OvR is the default).
Indicates whether to only output as many values as are in the input (dense), or position the input based on using the key of the map as the index of the output (sparse).<br>One of 'DENSE', 'SPARSE'.
indices
Indices
indices element out of data bounds, idx=
Indices shape must have dim[0] == 2
Indices tensor from max pooling across the input tensor. The dimensions of indices are the same as output tensor. The values in indices of are the indices of the selected values during pooling. The indices are computed as flatten 1-D tensor, and the indices do not consider padding. So the values in indices are in [0, N x C x D1 x ... x Dn).
Indices tensor must have rank >= 1
indices_shape[1] > 0 && static_cast<size_t>(indices_shape[1]) == dims.size()
InferenceSession is null. Invalid ORT format model.
Inferred elem type differs from existing elem type: (
Inferred shape and existing shape differ in dimension 
Inferred shape and existing shape differ in rank: (
info == nullptr
info.GetAttr("direction", &direction).IsOK()
info.GetAttr("hidden_size", &int64_value).IsOK() && int64_value > 0
info.GetAttr("keepdims", &keepdims).IsOK()
info.GetAttr("linear_before_reset", &int64_value).IsOK()
info.GetAttr("storage_order", &storage_order).IsOK()
info.GetAttr<float>("alpha", &alpha_).IsOK()
info.GetAttr<int64_t>("axis", &axis_).IsOK()
info.GetAttr<int64_t>("channels", &channels_).IsOK()
info.GetAttr<int64_t>("channels_last", &channels_last_).IsOK()
info.GetAttr<int64_t>("count_include_pad", &temp).IsOK()
info.GetAttr<int64_t>("num_scan_inputs", &num_scan_inputs_).IsOK()
info.GetAttr<int64_t>("p", &p_).IsOK()
info.GetAttr<int64_t>("transA", &temp).IsOK()
info.GetAttr<int64_t>("transB", &temp).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("body", &proto).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("else_branch", &proto).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("then_branch", &proto).IsOK()
info.GetAttr<std::string>("auto_pad", &auto_padding).IsOK()
info.GetAttrs("axes", axes_).IsOK()
info.GetAttrs("kernel_shape", kernel_shape).IsOK()
info_ == nullptr
init_optional_zero_point_int8_b33fd0fa-cd7b-4b10-ae5a-df64cabfe1f8
init_optional_zero_point_uint8_b33f88f7-c464-43e3-8692-97ac832bb14a
Initial values of the loop's N state variables followed by M scan_inputs
initial_c
initial_chunk_size_bytes
initial_growth_chunk_size_bytes
initial_h
initial_state_and_scan_inputs
Initialized tensor with unexpected type: 
Initializer 
initializer != nullptr
Initializer tensor is missing. Invalid ORT format model.
Initializer with same name exists. Name:
initializer_node_arg != nullptr
InitializeSListHead
Initializing session.
InitOnceBeginInitialize
InitOnceComplete
Inner and Outer indices must either be both zero or non-zero
inner_num == src.Values().Shape().Size()
Input
input
Input 
input != nullptr
Input 0 is expected to have 1 or more dimensions, got 
Input 1 dimension 0 should have same length as the last dimension of input 0
Input 1 is expected to have 1 dimensions, got 
Input A zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Input and output types can be of any tensor type.
Input and target dimension value mismatch.
input and zero_point pair is expected to have be same type.
input and zero_point pair is expected to have same type.
input array doesn't equal tensor size
input array is too short
Input A's scale. It's a scalar, which means a per-tensor/layer quantization.
Input axes has incorrect length
Input axes has invalid data
Input axis is invalid: 
Input B must have shape {
Input B zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Input B's scale. It's a scalar, which means a per-tensor/layer quantization.
Input can be of any tensor type.
Input cannot be split evenly on selected axis. Input shape=
Input channels C is not equal to kernel channels * group.
input count mismatch
input count mismatch, expected 2 inputs - the tensor to be processed and a tensor containing k value
Input count of Tile OP mismatch, the first one is empty
Input count of Tile OP mismatch, the second one is empty
Input data
Input data tensor containing the indices corresponding to elements in the first input tensor X.This tensor is typically the second output of the MaxPool op.Dimensions must be the same as input tensor X. The indices are linear, i.e. computed considering the tensor as flattened 1-D tensor, assuming row-major storage. Also, the linear indices should not consider padding. So the values in indices are in the range [0, N x C x D1 x ... x Dn).
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn)
Input data tensor from previous layer; has size (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and width. Note that this is for the 2D image. Otherwise the size is (N x C x D1 x D2 ... x Dn). Optionally, if dimension denotation is in effect, the operation expects input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data tensor from the previous layer.
Input data tensor from the previous operator; 4-D feature map of shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
Input data tensor from the previous operator; According to channels_last, dimensions for image case are (N x C x H x W), or (N x H x W x C) where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), or (N x D1 X D2 ... Dn x C) where N is the batch size.
Input data tensor from the previous operator; dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size, C is the number of channels. Statistics are computed for every channel of C over N and D1 to Dn dimensions. For image data, input dimensions become (N x C x H x W). The op also accepts single dimension input of size N in which case C is assumed to be 1
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimension are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size.
Input data tensor from the previous operator; dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data tensor that has to be unpooled. This tensor is typically the first output of the MaxPool op.Dimensions for image case are (N x C x H x W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data. For non-image case, the dimensions are in the form of (N x C x D1 x D2 ... Dn), where N is the batch size. Optionally, if dimension denotation is in effect, the operation expects the input data tensor to arrive with the dimension denotation of [DATA_BATCH, DATA_CHANNEL, DATA_FEATURE, DATA_FEATURE ...].
Input data to be scaled
Input data type does not match the expected data type
Input data type does not match the expected data type. Current data type is 
Input data type is not int32 or int64
Input data.
Input data. It can be either tensor or scalar.
Input 'depth' must be a scalar or rank 1 tensor.
Input 'depth' must have exactly one element.
Input dimension cannot be less than 3.
Input dimensions are either [C] or [N][C] allowed
input edges
Input element type of 
Input for n-gram extraction
Input id is not valid. 
input index: 
Input initial_h must have shape {
Input is ether string UTF-8 or int32/int64
input is expected to have 3 dimensions, got 
Input is expected to have dim value in all dimensions.
Input is not of one of the supported map types.
Input is not of one of the supported sequence types.
Input is not of type sequence or map.
Input matrix
Input must be an optional-type value containing an element with type information.
Input must be of COO format
Input must be of CSR format
'input' must have rank >= 2
input name cannot be empty
Input of reshape_before_gemm is not the input of subgraph
Input of shape [N,F]
Input offset, 4-D tensor of shape (N, H_out, W_out, 2), where H_out and W_out are the height and width of grid and output, Grid specifies the sampling pixel locations normalized by the input spatial dimensions. Therefore, it should have most values in the range of [-1, 1]. If grid has values outside the range of [-1, 1], the corresponding outputs will be handled as defined by padding_mode.
Input P must have shape {
Input R must have shape {
Input rank for starts and ends should be the same: (
Input rank must be >= 2.
Input scale. It's a scalar, which means a per-tensor/layer quantization.
Input 'scales' must have float element type.
Input Sequence and Tensor are expected to have the same elem type. Sequence=
Input Sequence and Tensor are expected to have type info. Current type is null.
Input sequence.
Input sequence_lens must have shape {
Input shape is unknown or not 2D, or data type unknown
Input shape must have either [C] or [1,C] dimensions where C > 0
input shape: 
Input 'sizes' must have int64 element type.
Input 'split' can not be empty.
Input steps has incorrect length
input tensor
Input tensor
Input tensor A
Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.
input tensor and indices tensor must has rank larger than 0. 
Input tensor B
Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.
Input tensor C
Input tensor C, can be inplace.
Input tensor C. The shape of C should be unidirectional broadcastable to (M, N).
Input tensor can be of arbitrary type.
Input tensor containing indices. Any entries in the 'indices' input tensor with values outside the range [-depth, depth-1] will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
Input tensor containing indices. The values must be non-negative integers. Any entries in the 'indices' input tensor with values outside the range [0, depth) will result in one-hot representation with all 'off_value' values in the output tensor.In case 'indices' is of non-integer type, the values will be casted to int64 before use.
Input tensor must be 2-dimensional
Input tensor must be 4-dimensional
Input tensor must have at least 2 dimensions
Input tensor must have atleast 2 dimensions
Input tensor must have rank 1 or 2
Input tensor must have rank 2
Input tensor of [N,C,H,W], where N is the batch axis, C is the channel or depth, H is the height and W is the width.
Input tensor of any shape broadcastable to X shape, the exponent component.
Input tensor of any shape, base of the exponent.
Input tensor of any shape.
Input tensor of rank 2 or higher.
Input tensor of shape (N, C) or (N, C, d1, d2, ..., dk).
Input tensor of shape [N,C,H,W]
Input tensor to be cast.
Input tensor to be inserted into the input sequence.
Input tensor to copy shape and optionally type information from.
Input tensor whose elements to be clipped
input tensor with shape (batch_size, num_heads, sequence_length or total_sequence_length, head_size)
Input tensor with shape [batch_size, class_size], where class_size is the number of all possible outcomes. Each value along the axis zero represents the unnormalized log-probability of each corresponding outcome in a batch.
Input tensor X must have atleast 2 dimensions.
Input tensor.
Input tensor. Every matrix in the batch must be invertible.
Input tensors of wrong rank (0).
Input tensors to check.
Input to 'Range' op should be scalars (Tensor with only one element and shape empty)
Input to set must exist.
Input type for input at index 
Input type for input at index 0 is null. Type info is expected.
Input type is not float tensor but keys_floats is set
Input type is not int64 tensor but keys_int64s is set
Input type is not string tensor but key_strings is set
Input type is null. Input must have Type information.
Input type is null. Type information is expected for the input.
Input type was null
Input 'values' must be rank 1 tensor.
Input 'values' must have exactly two elements.
Input W must have shape {
Input was expected to have either tensor, sequence, optional or map type. Got 
Input was expected to have map type. Got 
Input was expected to have optional type. Got 
Input was expected to have sequence type. Got 
Input was expected to have tensor or sparse tensor type. Got 
Input with name: 
Input X must have 3 dimensions only. Actual:
Input X's scale. It's a scalar, which means a per-tensor/layer quantization.
Input X's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Input zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Input/Output is a string tensor
Input: 
input_0
input_1
input_arg->Type() != nullptr
input_as_shape
input_copy_needed != DeviceCopyCheck::Unknown && output_copy_needed != DeviceCopyCheck::Unknown
input_dims.size() >= 2
input_forget
input_gather_element
input_gather_element = GatherElements <axis = 1> (input, transform_targets)
input_gather_element_transform
input_gather_element_transform = Where (mask, const_zero_casted, input_gather_element)
input_gather_element_transform = Where (mask, const_zero_float, input_gather_element)
input_ids
Input_ids and segment id should have the same shape. 
input_ids shall be 2 dimensions
input_indices.size() == expected_values.size() && input_indices.size() > 0
input_mean
input_node.InputDefs().size() == 2 && scale_and_index->second < 2
input_offset >= 0 && output_offset >= 0
input_ptr
input_rank == reference_rank
input_scale
input_sequence
input_shape.Size() > 0 || input_shape[0] == 0
input_shape[i] == 1
input_size < std::numeric_limits<std::ptrdiff_t>::max()
input_tensor_ptr != nullptr
input_type_shape
input_var
'input_var'.
input_zero_point
input->Exists()
InputBroadcaster can only start at span boundary!
inputdimensions
Inputs
inputs
Inputs 0 shall be 2 dimensions
Inputs 0 shall be 3 dimensions
Inputs 4 shall be 5 dimensions
inputs are expected to have tensor type and output type should not be null.
inputs are expected to have tensor type.
Input's height (
Input's shape must be 4-D
Input's shape should be 1D or 2D
Input's width (
Insert and concatenate on a new axis or not, default 0 means do not insert new axis.
InsertCastTransformer works on the assumption that `dtype` attribute holds an integer.
Inserted by QDQPropagationTransformer
inserted_in_name_to_entry
InsertedCast_
Inserting Q/DQ pair between 
InstanceNormalization
Insufficient dimensions to slice on 
int16
int1u
int32
int32_data
int3u
int64
Int64 tensor
int64_data
int64_vocabulary
int6u
int8u
Integer indicate the format of the box data. The default is 0. 0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Mostly used for TF models. 1 - the box data is supplied as [x_center, y_center, width, height]. Mostly used for Pytorch models.
Integer overflow
Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.
Integer representing the embedding vector size for each word.If not provide, use the fileter size of conv weight
Integer representing the maximum number of boxes to be selected per batch per class. It is a scalar. Default to 0, which means no output.
Integer value expected, but not found.
inter_op_num_threads
inter_op_num_threads option in the model file must be an integer
intercepts
Internal Build
internal error
Internal error.
Internal error. The preallocated buffer is too small. Requires 
InternalName
InternalTestingExecutionProvider
inter-op
-inter-op
intra_op_num_threads
intra_op_num_threads option in the model file must be an integer
intra-op
-intra-op
InUse:                    
inv_std_var
Invalid activation function of 
Invalid allocation kind: 
invalid allocator.
Invalid attribute perm {
Invalid axes attribute, axes attribute (if present) should have the same size as starts/ends attributes
Invalid bias shape
invalid BOM; must be 0xEF 0xBB 0xBF if given
invalid channel count
invalid comment; expecting '/' or '*' after '/'
invalid comment; missing closing '*/'
Invalid data type 
Invalid data type for GRU operator of 
Invalid data type for LSTM operator of 
Invalid DataTypeImpl TypeProto definition
Invalid destination node arg slot specified when adding edge.
Invalid destination node arg slot specified when removing edge.
Invalid dim0_offset of 
Invalid dimension of 
Invalid dimension value: 
Invalid 'direction' argument of '
Invalid 'end'. Value is larger than 'start'.
Invalid ExecutionOrder
invalid expand shape
Invalid fd was supplied: 
Invalid Feed Input Name:
Invalid free dimension override.
Invalid GRU hidden gate activation function: 
Invalid GRU reset gate activation function: 
invalid hash bucket count
invalid index 
Invalid index requested for map type.
Invalid index: 
invalid indice found, indice = 
Invalid input index for node 
Invalid input shape. Only N can be zero. Got:
Invalid input shape: 
Invalid key found: 
invalid literal
invalid location range
Invalid LSTM merge activation function of 
invalid map<K, T> key
Invalid model. Node input '
Invalid node index 
Invalid node indexes specified when adding edge.
Invalid node indexes specified when removing edge.
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected digit after exponent sign
Invalid ORT format model.
Invalid Output Name:
Invalid position of 0
Invalid position of 0.
Invalid program_counter entries at index 
Invalid rank for 
Invalid rank for input: 
Invalid run log severity level. Not a valid onnxruntime::logging::Severity value: 
invalid scales dimension
invalid scales value
Invalid scan input:
Invalid session log severity level. Not a valid onnxruntime::logging::Severity value: 
Invalid shape value: 
Invalid source node arg slot specified when adding edge.
Invalid source node arg slot specified when removing edge.
Invalid SparseTensor indices. INT16 indices must be in the raw data of indices tensor
Invalid SparseTensor indices. INT8 indices must be in the raw data of indices tensor
Invalid SparseTensor indices. Should be rank 0 or 1. Got:
Invalid SparseTensor indices. Should one of the following types: int8, int16, int32 or int64
Invalid 'start'. Value is smaller than previous 'end'.
Invalid start/ending offset [
invalid stod argument
invalid stof argument
invalid stoi argument
invalid stol argument
invalid stoll argument
invalid stoull argument
invalid string position
invalid string: '\u' must be followed by 4 hex digits
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: forbidden character after backslash
invalid string: ill-formed UTF-8 byte
invalid string: missing closing quote
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
Invalid Target shape product of 0
Invalid Target shape product of 0. Product cannot be 0 in combination with -1
Invalid tensor data type 
Invalid tensor shape slice argument.
Invalid TensorProto
invalid unordered_map<K, T> key
Invalid usage. Input 1 is a shape with no data.
Invalid value for 
Invalid value for attribute axis
Invalid value for attribute k
Invalid value in scan_input_axes for input 
Invalid value in scan_output_axes for output 
Invalid value in 'split' attribute. All values must be > 0
Invalid value of attribute 'axis'. Accepted range=[
Invalid value of attribute 'axis'. Rank=
Invalid value(
Invalid value/s in sequence_lens. All values must be > 0 and < seq_length. seq_length=
Invalid values in '
invalid vector subscript
INVALID_ARGUMENT
INVALID_GRAPH
invalid_iterator
INVALID_PROTOBUF
Inverse
inverse_indices
InvStdDev
InvStdDev = Reshape (InvStdDev2D, ReducedShape)
InvStdDev2D = Reciprocal (StdDev)
iou_threshold
iou_threshold must be in range [0, 1].
IR_VERSIONIR_VERSION_2017_10_10IR_VERSION_2017_10_30IR_VERSION_2017_11_3IR_VERSION_2019_1_22IR_VERSION_2019_3_18IR_VERSION_2019_9_19IR_VERSION_2020_5_8_START_VERSION
Irfft
irVersion
is applied to the data tensor elementwise.
'is defined.
is not supported.
is_case_sensitive
is_concrete_shape_
is_model_proto_parsed
is_test
IsAllFinite
isalnum
isalpha
IsBQuantParamSupported(b_zero_point->Shape(), b ? b->Shape() : b_shape_)
IsBQuantParamSupported(b_zp_tensor->Shape(), b_tensor ? b_tensor->Shape() : b_shape_)
IsDebuggerPresent
isdigit
IsGraphCaptured()
IsInf
isinf_only
ISink must be provided.
IsNaN
isnan_only
IsOptionalSeqTensor(type)
IsOptionalTensor(type)
isRedist
IsSameDataType(tensor)
IsScalarOr1ElementVector(a_zero_point)
IsScalarOr1ElementVector(a_zero_point_tensor)
IsScalarOr1ElementVector(W_Zero_Point)
IsScalarOr1ElementVector(X_Zero_Point)
isspace
IsSparseTensor()
IsTensor()
IsTensorSequence()
iter != onnx_ops_available_versions.end()
iteration_num_ < sequence_len_
iterator does not fit current value
iterator out of range
itr != node_args.end()
j ~"Z&j(~*Z.j0~2J6j8~:b>j@~BzFjH~JTNjP`R4V
j d"6
j j"f$:(
j j"j$j&j(j*j,j.j0j2j4j6j8j:j<d>6
j j"j$j&j(j*j,j.j0j2j4j6j8j:j<j>j@dB4
j t",$
J![^Jb
j?$Dsp
J^NjPfR:V%
J>f;O
J0;K0
J0;K4
J0L9rPH
JFLZhljFr4t2h$j$l
JLLjN
JNZj\
JPH+h
Json stored in the `ort_config` key cannot be parsed. Error message: 
JtL$N\J
jxlJn(l
jzlJn(l
k and v are not from same Split node
k argument [
k fff
K H91t
K input must be a one-dimensional tensor of size 1.
K input must be of type int64.
k root is not layer norm
k tensor should be a 1D tensor of size 1
k VWATAVAWH
k VWAVH
K(+K0
k(+k0
K(+K0
k_matmul and k_add shape not matched
k_reshape const not matched
k_transpose has not perm attribute
k_transpose perm attribute not matched
k0L9{
K0L9L$PuYH
K8H9CHt
KbbeHQ
Keep the reduced dimension or not, default 1 mean keep reduced dimension.
Keep the split dimension or not. Default 1, which means we keep split dimension. If input 'split' is specified, this attribute is ignored.
keepdims
Kernel
kernel != nullptr
Kernel create info hashes are null. Invalid ORT format model.
Kernel create info is null. Invalid ORT format model.
Kernel create info node indices are null. Invalid ORT format model.
kernel def can't be NULL
Kernel not found
kernel_info != nullptr
kernel_params
kernel_shape
kernel_shape is not compatible with W shape.
kernel_shape num_dims is not compatible with W num_dims.
kernel_shape num_dims is not compatible with X num_dims.
kernel_shape[dim] > 0
kernel_type
key '
key and value cache shall be 4 dimensions
Key and value tensors have unequal number of elements.
Key type is not supported yet.
key type mismatch from MapProto. existing=
Key type of map input 
Key type of map input was unknown
key_cache
key_padding_mask
key_type
keys_floats
keys_int64s
keys_strings
KH;|$@t
KhH91t
known by the checker.
KpH91t
kv_weight
kXH9+t
KxH91t
l t",$
L"H$.&,.L"H$.&,8
L"n$\448e
L#o0M
L$ 9L$$u H
L$ A;
l$ ATAUAVAWL
l$ AVAWH
l$ AVL
L$ E3
l$ E3
L$ E3
l$ E3
L$ fA
l$ ff
l$ fff
L$ fI
L$ H;
L$ H;SHt
L$ H;V
L$ H+
L$ H3
L$ Hc
L$ HcQ
L$ Hk
L$ L;
l$ L;
l$ L9|$0u
L$ Lci
l$ M;
L$ M+
L$ SH
L$ SUVWH
L$ SVWH
L$ SWH
L$ UVWATAUAVAWH
l$ VAVAWH
l$ VH
l$ VWATAVAWH
l$ VWAUAVAWH
l$ VWAVH
L$ VWAVH
l$ VWAVH
l$ VWAWH
l$ WATAUAVAWH
l$ WATAVH
l$ WAVAWH
l$ WH
L$ WH
l$ WH
L$!I;
L$$D3
l$(@8t$0t
L$(8H
L$(9J(
l$(A^
L$(E3
l$(E3
L$(fH
L$(H;
L$(H;L$0
l$(H;S
L$(H;V
L$(H;W
l$(H+
L$(H+L$ H
L$(H3
L$(HcB
l$(I;
L$(I;
L$(I+
L$(L;
L$(L+
l$(M;
L$,HcJ
L$@ H
L$@@L
l$@A_A^A]_^
l$@A_A^A]A\
L$@E3
l$@ff
L$@H;
L$@H;SHt
l$@H+
L$@H+
L$@H3
L$@HcQ
L$@I+
L$@L;
L$\HcJ
l$`A;
L$`E3
l$`H;
L$`H;
l$`H;
L$`H+
L$`H3
l$`Hc
L$`L;
L$`L+
L$<HcJ
L$=H;
l$0A_A^
L$0E2
l$0E3
L$0E3
l$0fff
l$0H;
L$0H;
L$0H;S
L$0H;SHt
L$0H;W
L$0H+
l$0H+
L$0H+
L$0H3
l$0Hc
L$0HcQ
L$0I;
l$0I;
L$0I;
L$0I+
l$0I+
L$0I+
L$0IcY
L$0L;
l$0L;t$h
L$0L;v
l$0M;
L$0M;
l$0M;
L$0M;
l$0M;
L$0M+
l$0t^H
L$1B8
l$8@8h
l$8@8k
l$8D8h
l$8D8k
L$8E2
l$8E3
L$8E3
l$8E3
l$8H;
L$8H;
l$8H;
L$8H;S
L$8H;SHt
L$8H+
l$8H+
L$8H+
l$8H+
L$8H3
l$8Hc)L
L$8HcB
l$8I;
L$8I;
L$8I;P
L$8I+
l$8L;
L$8L;
L$8L;d$P
l$8M9L$
L$AE3
L$DD;
l$DE3
L$DH;
L$h@"
L$h@8}
L$HD;
L$HE3
l$hE3
L$HE3
L$hE3
L$HE3
l$HE3
L$hE3
L$HE3
l$hff
L$HH;
l$HH;
l$hH;
L$HH;
L$hH;
L$HH;
L$hH;
L$HH;
L$hH;L$x
L$HH+
l$HH+
l$hH+
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
l$hHc
L$HHcB
L$hI+
l$HIc
l$HIcE
L$hL;
L$HL;
L$hL;
L$hL;L$p
l$HL;l$X
l$hL+
L$hM;
l$huNI
L$LH+
L$LHcJ
L$N.P
L$pE3
l$PE3
L$pE3
l$PE3
L$pE3
L$PH#
L$pH#
L$pH;
L$PH;
L$pH;L$x
L$PH;SHt
L$pH+
l$PH+
L$pH+
l$PH+
L$pH+
l$PH+
L$PH+
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
l$PHc
L$PHcQ
L$pHcQ
L$PHcQ
L$pI+
L$PI+
L$pL;
L$PL;
L$PLc
l$pM;
L$PMc
l$PtRI
L$xE3
L$XE3
L$Xf;
l$Xff
L$xH;
L$XH;
L$xH;
L$XH;
L$xH;M
l$XH+
L$xH+
L$XH+
l$XH+
L$xH+
L$XH+
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$xHc
L$XHcB
l$xI;
L$XI+
L$xL;
L$XL;
L$xL;
l$xL;|$@t
l$XL;t$`
l$xt|H
L)|$(M
l,wtm
L;\$@
L;\$`
L;\$h
L;\$P
L;\$p
L;\$x
L;|$@
L;|$8t
L;|$H
L;|$P
L;|$p
L;|$P
L;|$X
L;A }Gf
L;A }If
L;a r
L;A r
L;AhL
L;B r
L;B s
L;d$ u
L;d$`
L;d$0
L;d$H
L;d$P
L;D$pH
L;D$PuGH
L;d$x
L;E L
L;E@L
L;E`L
L;EpL
L;FPuS
L;I }PL+
L;I r
L;J s
L;l$`
L;l$0
L;l$8
L;l$H
L;l$P
L;l$PtNH
L;Q r
L;R r
L;s rwH;
L;t$@H
L;t$`
L;t$0t
L;T$h
L;t$h
L;t$p
L;T$X
L;uhH
L;Y }Hf
L;y r
L;y spH
l?33{@33{@33{@33{@
l{RsD
L+,$L+
L+\$ I
L+|$8
L+|$PI
L+4$H
L+d$ M
L+d$0
L+d$HI
L+IHL
L+KxM
L+l$0L
L+l$8I
L+l$8t
L+l$HI
L1 norm
L2 norm
l8n"p$r(j
L9 u+H;
L9@ s
L9` s
L9{0u
L9|$(
L9|$(|
L9|$(u
L9|$0u
L9A s
L9H s
L9I s
L9l$(
L9l$(u
L9L$0
L9P s
L9p s
L9P s
L9Qhs
L9qXt
L9s }
L9s`v=A
L9t$ uzI
L9t$H
L9t$Hu
L9t$x
L9x s
L9x8t4H
L9yxA
L9yXuNA
Label encoder has only one input.
Label encoder has only one output.
LabelEncoder
labels
lambd
largest
largest <= 1
last >= first
Last dimension of `indices` input tensor in GatherND op must not be larger than the rank of `data` tensor
Last dimension of beta and input does not match
Last dimension of bias and input does not match
Last dimension of gamma and input does not match
last dimension of indices must not be larger and rank of data tensor
last dimension of indices must not be larger than rank of input tensor
last_loop_red_size > 0
last_loop_size > 0
layer_norm_out
LayerNorm Output
layernorm_out
LayerNormalization
LayerNormFusion
layout
layout_ == 0
Lc\$@E3
Lc2E3
LcA$H
LcD$TL
Lcd$XM
LcG$A
LcG$H
LcI$L
Lcl$Pf
Lcq H
Lct$h3
lda >= K && ldb >= K && ldc >= N
ldexp
LeakyRelu
leakyrelu
Left input tensor for the logical operator.
left operand cannot broadcast on dim 
left.NumDimensions() == 2 || left.NumDimensions() == 1
left_num_dims > 2 && left_num_dims == right_num_dims
left_num_dims and right_num_dims must be >= 1
legacy optimization attribute.
Legal_policy_statement
LegalCopyright
len <= op_schema.inputs().size()
len >= 0 && static_cast<uint64_t>(len) < std::numeric_limits<size_t>::max()
length
length > buffer.size()
length of each output
Length of each output. It can be either a scalar(tensor of empty shape), or a 1-D tensor. All values must be >= 0. 
length of each output. Values should be >= 0.
Length of input sequence. It must be a scalar(tensor of empty shape).
length_penalty
lengths allocation failed
less_equal
LessOrEqual
Level
limit
limit in Range operator should be scalar like tensor, yet got shape:
Limit:                    
LINEAR
linear
linear_before_reset
LinearClassifier
LinearRegressor
List of 3 elements containing gamma, coef0, and degree, in that order. Zero if unused for the kernel.
List of categories, ints.<br>One and only one of the 'cats_*' attributes must be defined.
List of categories, strings.<br>One and only one of the 'cats_*' attributes must be defined.
list of floats. This attribute stores the weight of each n-gram in pool. The i-th element in weights is the weight of the i-th n-gram in pool. Its length equals to the size of ngram_indexes. By default, weights is an all-one tensor.This attribute is used when mode is "IDF" or "TFIDF" to scale the associated word counts.
List of int64 n-grams learned from the training set. Either this or pool_strings attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
list of int64s (type: AttributeProto::INTS). This list is parallel to the specified 'pool_*' attribute. The i-th element in ngram_indexes indicate the coordinate of the i-th n-gram in the output tensor.
List of integers indicate the padding element count at the beginning and end of each axis, for 2D it is the number of pixel. `paddings` rank should be double of the input's rank. `paddings` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded).
List of integers indicating the dimensions to squeeze. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
List of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D it is the number of pixels. `pads` rank should be double of the input's rank. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
List of non-negative integers, indicate the dimensions to be inserted
List of non-negative integers, indicate the dimensions to squeeze.
List of stop words. If not set, no word would be removed from X.
List of strings n-grams learned from the training set. Either this or pool_int64s attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
List of tensors for 
List of tensors for concatenation
List of tensors for Max.
List of tensors for Mean.
List of tensors for Min
List of tensors for Sum.
List of tensors/scale/zero_point for concatenation
list too long
llroundl
LnPrRBT
load external data into raw data for tensor: 
Load model 
Load model from 
loadedFrom
loading_ort_format && serialized_session_state != nullptr
LoadLibrary failed with error 
LoadNodeArgsFromOrtFormat: Node [
LoadPackagedLibrary
loatu
locale
localeconv
LocalFree
localtime_s(&local_tm, &in_time_t) == 0
location
location dimensions do not match shape size
log of softmax
Log probability tensor. If the output of softmax is prob, its value is log(prob).
log sum
log sum exponent
log_prob
log_prob = Identity (X_Log)
log1pf
LogHr
logsoftmax
LogSoftmax
LogSoftmax(input, axis) = Log(Softmax(input, axis=axis))
LogStart must pair with LogEnd
Long tensor containing the indices to extract from embedding matrix.
LongformerAttention
Loop 'body' subgraph outputs should all be tensors but output 
Loop 'body' subgraph outputs should all be tensors or sequences but output 
Loop 'body' subgraph outputs should all be tensors or sequences or optionals, but output 
Loop 'body' subgraph scan outputs should all be tensors but output 
loss = Mul (loss_unweighted, weight_gather)
loss = ReduceMean <keepdims = 0> (loss_Ndd)
loss = ReduceSum <keepdims = 0> (loss_Ndd)
loss = Squeeze (loss_N1dd, axes)
loss_N1dd
loss_N1dd = Slice (loss_NCdd, const_zero, const_one, const_one)
loss_NCdd
loss_NCdd = Neg (input_gather_element_transform)
loss_Ndd
loss_Ndd = Mul (loss_unweighted, weight_gather)
loss_Ndd = Squeeze (loss_N1dd, axes)
loss_sum
loss_unweighted
loss_unweighted = Squeeze (loss_N1dd, axes)
Lower boundary of the output values.
lp pool
LpNormalization
LpPool
LSTM operator does not support double yet
Lt@T-
lzvhx|zz~h
M +M0
m fff
M H1E
M(+M0
M(A+M0A
M,9H,
M;A |
M;A M
M;A8|
M;EHu
M;F u
M;J |
M;Y |
M@HcQ
M_ == 1 && N_ == 1 was false
M_ >= 0 && K_ > 0 && N_ >= 0
M+,$I
M+<$I
M0I+M(H
M0K0I
m8fff
M90u7
M9A8~yff
Main Graph instance should have populated all subgraphs when being resolved.
malloc
Map is missing type entry for its value
map(int64, double)
map(int64, float)
map(int64, string)
map(string, double)
map(string, float)
map(string, int64)
map/set too long
map_form
map_type
MapFileIntoMemory is not implemented on Windows.
MAPOPTIONALSEQUENCESPARSE_TENSORTENSORUNDEFINED
mapped_feed_names_.size() == feed_names_.size()
mapped_output_names_.size() == output_names_.size()
Mask data type is not int32 or int64 or float32
Mask Index Output
Mask is neither unidirectional nor all ones
Mask of vocabulary for first step. Words that masked with 0 are not allowed to be generated, and 1 is allowed. Shape is (batch_size, vocab_size)
Mask of vocabulary. Words that masked with 0 are not allowed to be generated, and 1 is allowed. Shape is (vacab_size)
Mask shape is unknown or not 2D, or data type unknown
mask_index
mask_index_out
Mask_Int32
mask_mul const input not matched
mask_sub const input not matched
mask_unsqueeze_1 axes not matched. Expect: 1
mask_unsqueeze_2 axes not matched. Expect: 2
MaskCast
Matched 
MatchInputMaskSubgraph returns false
MatchPastSubgraph returns false
MatchUnidirMaskSubgraph returns NULL
MatMul
MatMul dimension mismatch
MatMul_With_Transpose
MatMulAddFusion
MatMulInteger
MatmulInteger : B zero point is not valid
MatmulInteger : b zero point is not valid
MatmulInteger : input1 zero point must be a scalar or 1D tensor of size 1
MatMulInteger16
MatMulIntegerToFloat
MatMulIntegerToFloat : input a zero point must be a scalar or 1D tensor of size 1. Per-Channel is not supported yet.
MatMulIntegerToFloatFusion
MatMulScaleFusion
MatmulTransposeFusion
Matrix after normalization
Matrix multiply results
Matrix multiply results from A * B
Max detections to output.
max should be a scalar.
max_dead_bytes_per_chunk
max_gram_length
max_length
max_map
max_mem
max_ngram_size
max_output_boxes
max_output_boxes_per_class
max_skip_count
max->Shape().IsScalar()
MaxAllocSize:             
Maximum n-gram length. If this value is 3, 3-grams will be used to generate the output.
Maximum number of events reached, could not record profile event.
Maximum number of items (integers/strings) to be skipped when constructing an n-gram from X. If max_skip_count=1, min_gram_length=2, max_gram_length=3, this operator may generate 2-grams with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and skip_count=1
Maximum value, above which element is replaced by max
Maximum value, above which element is replaced by max. It must be a scalar(tensor of empty shape).
MaxInUse:                 
MaxPool
MaxpoolWithMask
MaxRoiPool
MaxUnpool
MaxUnpool op must have either two or three inputs.
Mc0I;
McEhM
McH,H
Mean = Reshape (Mean2D, ReducedShape)
Mean2D = ReduceMean <axes = [1]> (XU)
MeanOfSquare = ReduceMean <axes = [1]> (Square)
MeanVarianceNormalization
Mem pattern for initializer 
memchr
memcmp
memcpy
Memcpy
MemcpyFromHost
MemcpyToHost
MemcpyTransformer
memmove
Memory pattern planner is not enabled on this execution framework.
memory.enable_memory_arena_shrinkage
memory_seq_lens
memset
metadef_id_generator_
Method IncrementIndexAndComputeOffset assumes this value is strictly positive.
metric
M'H+M
MHH;Mh
Microsof
Microsoft
Microsoft America Operations1&0$
Microsoft Code Signing PCA 2011
Microsoft Code Signing PCA 20110
Microsoft Corporation
Microsoft Corporation0
Microsoft Corporation1
Microsoft Corporation1%0#
Microsoft Corporation1&0$
Microsoft Corporation1(0&
Microsoft Corporation1200
Microsoft Time-Stamp PCA 2010
Microsoft Time-Stamp PCA 20100
Microsoft Time-Stamp Service
Microsoft Time-Stamp Service0
Microsoft.CognitiveServices.Speech.extension.onnxruntime.dll
Microsoft.ML.ONNXRuntime
MIGraphXExecutionProvider
min should be a scalar.
min_ <= max_
min_gram_length
min_length
min_ngram_size
min->Shape().IsScalar()
mincharnum
Minimum n-gram length. If this value is 2 and max_gram_length is 3, output may contain counts of 2-grams and 3-grams.
Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored
Minimum value, under which element is replaced by min
Minimum value, under which element is replaced by min. It must be a scalar(tensor of empty shape).
Mismatch between expected shape and shape from first output
Mismatch between Graph and IndexedSubGraph. Input not found:
Mismatch between Graph and IndexedSubGraph. Node not found: 
Mismatch between Graph and IndexedSubGraph. Output not found:
Mismatch between number of source and target dimensions. Source=
Mismatch between number of splits (
Mismatch between source and target type. Source=
Mismatch between the sum of 'split' (
Mismatched attribute type in '
Mismatched data types between input and output Tensors. 
Mismatched map tensor key type:
Mismatched sparse tensor element type:
Mismatched tensor element type for output 
Mismatched tensor element type:
Mismatched type for output 
Mismatched type:
Missing action 
Missing dimensions for initializer. Invalid ORT format model.
Missing dims for sparse initializer: 
Missing indicies for sparse initializer: 
Missing Input: 
Missing model IR version.
Missing Model. Invalid ORT format model.
Missing name for SparseTensor initializer. Invalid ORT format model.
Missing opset in the model. All ModelProtos MUST have at least one entry that specifies which version of the ONNX OperatorSet is being imported.
Missing or invalid starts and ends attribute
Missing raw data for initializer. Invalid ORT format model.
Missing session state for subgraph. Node:'
Missing string data for initializer. Invalid ORT format model.
Missing values for sparse initializer. Invalid ORT format model.
Missing/Invalid 'axes' attribute value
Missing/Invalid 'axis' attribute value
Misuse of LoopStateVariable. Attempt to move beyond end of sequence
ml_type != nullptr
MLDataType for: 
mlvalue.Fence() == nullptr
model format error!
model format error! Missing 'location'
model format error! Need a key for the external data info
model format error! Need a value for the external data info
Model must have opset imports. Invalid ORT format model.
model type: 0 for GPT-2; 1 for encoder decoder like T5
Model was not loaded
Model was not loaded.
MODEL_LOADED
model_loading_array
model_loading_from_saved_proto
model_loading_uri
model_path must not be empty. Ensure that a path is provided when the model is created or loaded.
model_run
model_type
modelDomain
modelGraphName
modelMetaData
modelProducerName
modelProducerVersion
ModelProto corresponding to the model to be loaded has already been parsed. Invoke Load().
ModelProto corresponding to the model to be loaded has not been parsed yet. This API should be called in conjunction with a ctor that takes a model abstraction.
ModelProto does not have a graph.
ModelProto needs to be parsed to check for ORT config within it
momentum
More work items than threads
Move it out of graph inputs if there is no need to override it, 
Msg:[%ws] 
MSVCP140_APP.dll
mul_B_tensor_proto
mul_inputs.size() == 2
MulInteger
multi_class
MultiByteToWideChar
MultilevelCropAndResize_TRT
Multinomial
Multiple errors were found.
multiplication
Multiplicative spatial scale factor to translate ROI coordinates from their input scale to the scale used when pooling.
Multiplicative spatial scale factor to translate ROI coordinates from their input spatial scale to the scale used when pooling, i.e., spatial scale of the input feature map X relative to the input image. E.g.; default is 1.0f. 
MurmurHash3
Must be a scalar or 1D tensor or size 1.
must be overloaded.
Must contain BlockSparse format. Got: 
Must contain Coo format. Got: 
Must contain Csr format. Contains: 
Must have 1 or more inputs
Must have a single dimension
Must have a single dimension of 1
Must have a valid data type
Must have a valid input shape.
Must have the same shape
Must have the same size. Got src_size: 
Must use Function based fusion when exporting compiled nodes to dll.
mutually equal shape is specified by the argument "axis", and if it is not set,
MXH;MX
MXH9MXt
N +N0
n <= num_threads_+1
n >= 0
n >= 0 && static_cast<size_t>(n) < ort_value_info_.size()
n >= 0 && static_cast<size_t>(n) < plan_.allocation_plan.size()
N 9H u\
N classes
n fff
N H;H 
N H;H u
N H+N
N L+N
n p",$
N$P$R*T
N(+N0
N(A+N0A
N, Top class for each point
N@length overflow
n_supports
n_targets
n~pPr(p
N0fff
N0L0J
name:
name: 
naxes > 0
NbP4R(T$V(Ne
NchwcTransformer
N-D full precision Input tensor to be quantized.
N-D full precision output tensor. It has same shape as input 'x'.
N-D quantized input tensor to be de-quantized.
N-D quantized Input tensor to be de-quantized.
N-D quantized output tensor. It has same shape as input 'x'.
N-D tensor
N-D tensor after resizing
N-dimensional dense matrix B
N-dimensional matrix A
N-dimensional matrix B
N-dimensional quantized matrix a
N-dimensional quantized matrix b
nearest
nearest_mode
Negative values are not allowed in a shape specification
NegativeLogLikelihoodLoss
Nested parallelism not supported
New shape
new suffix match index
new_axis
new_axis must be either 0 or 1
new_gemm_input_defs.size() == 3
new_gemm_output_defs.size() == 1
new_key_cache
new_num_elts == old_num_elts
new_value_cache
nFpZ>(B
Ngram results
ngram_counts
ngram_indexes
ngram_indexes must be non-empty with no negative values
ngram_size
NGramRepeatBlock
NHP,R&T*V$N
Nhttp://www.microsoft.com/pkiops/crl/Microsoft%20Time-Stamp%20PCA%202010(1).crl0l
NhwcConv
NhwcMaxPH9
NhwcMaxPool
NhwcTransformer
NLP4R2
NnapiExecutionProvider
NnP^R
No allocator for this device has been registered for sharing.
No attribute with name:'
No attribute with name: 
No attribute with this name is defined.
No Graph instance was found for attribute 
No graph was found in the protobuf.
No kernel shape is set.
No matching 'start' entry.
No NodeArg found for name 
No Op registered for 
No opset import for domain '
No opset registered for domain 
No provider specified.
no repeat ngrams size
No requested allocator available
NO_MODEL
no_repeat_ngram_size
NO_SUCHFILE
Node 
node != nullptr
Node (
node ("
Node [
Node id for each node. Ids may restart at zero for each tree, but it not required to.
Node id for each node. Node ids must restart at zero for each tree and increase sequentially.
node id that this weight is for.
Node index is out of range
Node index value is too large to save to ORT format model: 
Node is missing. Invalid ORT format model.
Node must only have one used output
Node placements
node.GetAttributeNameToMutableSubgraphMap().empty()
Node:
Node::LoadEdgesFromOrtFormat, edge is missing for 
Node::LoadFromOrtFormat, input_arg_counts is missing
node_arg
node_arg_ != nullptr
node_arg_name cannot be null
node_idx <= NodesToOptimizeIndices::kEmptyNodeIndex
node_in_parent_graph->InputDefs().size() == function_body_graph.GetInputsIncludingInitializers().size()
node_in_parent_graph->OutputDefs().size() == function_body_graph.GetOutputs().size()
node_index < nodes_.size()
node_index_info and ort_value_idx_map are out of sync and cannot be used
node_index_info_
node_index_info_.GetMaxMLValueIdx() == ort_value_idx_map.MaxIdx()
node_input_def_idx >= 0 && static_cast<size_t>(node_input_def_idx) < node_inputs.size()
node_offsets_index < node_offsets_size_
node_output_def_idx >= 0 && static_cast<size_t>(node_output_def_idx) < node_outputs.size()
node->GetOutputEdgesCount() == 0
nodearg
NodeArg is missing. Invalid ORT format model.
NodeArg Name is missing. Invalid ORT format model.
NodeEdge is missing. Invalid ORT format model.
NodeProto (name: 
Nodes in a graph must be topologically sorted, however input '
Nodes to optimize are not valid, skipping action.
nodes_.size() < static_cast<unsigned int>(std::numeric_limits<int>::max())
nodes_falsenodeids
nodes_featureids
nodes_hitrates
nodes_hitrates_as_tensor
nodes_missing_value_tracks_true
nodes_modes
nodes_nodeids
nodes_treeids
nodes_truenodeids
nodes_values
nodes_values_as_tensor
Non concat axis dimensions must match: Axis 
Non per-tensor quantization is not supported now.
non_tensor_base != nullptr
NonMaxSuppression
NonZero
Non-zero status code returned while running 
noop_with_empty_axes
NoopElimination
normalize_variance
normalized
Normalized = Div (Deviation, StdDev)
normalized exponential
NormalizedT = Cast (Normalized)
Normalizer
Not able to find appropriate IDataTransfer to copy sparse data
Not eliminating output 
Not enough elements in dilations. Expected: 
Not enough elements in kernel shape. Expected: 
Not enough elements in pads. Expected: 
Not enough elements in strides. Expected: 
Not enough produced nodes in the runtime optimization record.
not enough space: expected 
Not expecting an allocator set
not implemented
Not implemented
Not supported
Not supported with filtered graph.
NOT_IMPLEMENTED
NOT_SET
Notations:
Note that 'input_mean' and 'input_var' are expected to be the estimated
Notice that ReduceVar refers to the population variance, and it equals to
NOTSET
NotWhereFusion
nPM;nXtQ3
nt16u
nt32u
nt64u
ntelA
Null entry in dimensions. Invalid ORT format model.
Null entry in metadata_props. Invalid ORT format model.
Null floats attribute. Invalid ORT format model.
Null graph attribute. Invalid ORT format model.
Null ints attribute. Invalid ORT format model.
null literal
Null map type info. Invalid ORT format model.
Null sequence type info. Invalid ORT format model.
Null string attribute. Invalid ORT format model.
Null string in strings attribute. Invalid ORT format model.
Null strings attribute. Invalid ORT format model.
Null tensor attribute. Invalid ORT format model.
Null tensor in tensors attribute. Invalid ORT format model.
Null tensor type info. Invalid ORT format model.
Null tensors attribute. Invalid ORT format model.
Null type info for 
Null value type info in fbs::MapType. Invalid ORT format model.
Null value type info in fbs::SequenceType. Invalid ORT format model.
nullptr != func_meta_def
nullptr != p.output_tensor
nullptr != tensor_type_base
nullptr != type_proto
nullptr == p_data
num_axes > 0
num_beams
num_detections
num_dims_with_pad - 1 != num_output_dims
num_dims_with_pad - 2 != num_output_dims
num_dims_with_pad != num_output_dims
num_explicit_inputs == static_cast<size_t>(target_input_idx)
num_heads
num_return_sequences
num_scan_inputs
num_subgraph_outputs == static_cast<size_t>(num_outputs)
num_variadic_inputs == num_subgraph_inputs
NumAllocs:                
NumArenaExtensions:       
NumArenaShrinkages:       
number
number literal
Number of attention heads
Number of beams for beam search. 1 means no beam search. Shape is (1)
Number of elements of attribute 'scales' must be same as rank of input 'X'
Number of elements of input 'scales' must be same as rank of input 'X'
Number of elements of input 'sizes' must be same as rank of input 'X'
Number of entries in '
Number of entries in 'scan_input_axes' was 
Number of entries in 'scan_output_axes' was 
number of groups input channels and output channels are divided into.
number of groups input channels and output channels are divided into. default is 1.
Number of input tensors does not match the operands in the equation.
Number of neurons in the hidden layer
Number of neurons in the hidden layer.
Number of repeated copies to make of the input tensor.
Number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. If > 0, then exactly sampling_ratio x sampling_ratio grid points are used. If == 0, then an adaptive number of grid points are used (computed as ceil(roi_width / output_width), and likewise for height). Default is 0.
Number of scan input axes specified (
Number of scan output axes specified (
Number of times to sample.
Number of top elements to retrieve
Number of values should be at least 1.
number overflow parsing '
NumReducedAxes = Neg (Axis1D)
NumReducedAxes = Sub (Rank, Axis1D)
NumReserves:              
NupharExecutionProvider
O +O0
O H;H tj2
O H;O 
O H+O
O H91t
O L+O
O M+O
o"bq=H
O(+O0
o(+o0
O(+O0
o|$0J
O0M0K
object
object key
object separator
oD$0L
oD$8f
offset
offset % span_size_ == 0
offset + size <= size_t(span.size())
offset < 0
offset >= 0 && static_cast<size_t>(offset) < node_values_size_
offsets buffer is not equal to tensor size
One (or two if bidirectional) activation function for input gate. The activation function must be one of the activation functions specified above. Optional: Default `Tanh` if not specified.
One and only one of the attributes 'value', 'value_*' or 'sparse_value' must be specified for a Constant node.
One float, indicates the value to be filled, default is 0
One float, indicates the value to be filled.
One of 'MAX,' 'L1,' 'L2'
One of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
One or more outputs forming a sequence of tensors after splitting
One or more outputs forming list of tensors after splitting
One sided attention windows length W, or half of total window length
one_class
OneHot
OneHot node must have three inputs.
OneHotEncoder
onesided
Only bool
Only CPU allocators can be shared between multiple sessions for now.
Only CPU devices are supported for now.
Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time.
Only one node should produce an output. Existing entry for 
Only one of keys_*'s can be set in label encoder.
Only one of the attributes 'base_values', 'base_values_as_tensor' should be specified.
Only one of the attributes 'class_weights', 'class_weights_as_tensor' should be specified.
Only one of the attributes 'nodes_hitrates', 'nodes_hitrates_as_tensor' should be specified.
Only one of the attributes 'nodes_values', 'nodes_values_as_tensor' should be specified.
Only one of the attributes 'target_weights', 'target_weights_as_tensor' should be specified.
Only one of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
Only one of values_*'s can be set in label encoder.
Only one thread was configured for parallel execution. Hence will use sequential execution.
Only ONNX MLDataType can be registered
Only supports `int32_t` or `int64_t` inputs for split
Only supports `int32_t` or `int64_t` inputs for starts/ends/axes/steps
Only tensors are supported for external outputs for now.
Only tensors, tensor sequence, optional tensor, and optional tensor sequence types are supported
Only works on matrices with three dimensions.
Only works on matrices with two dimensions.
Onnx domain not found in opset imports.
ONNX Runtime
ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 
ONNX Runtime only *guarantees* support for models stamped with opset version 7 or above for opset domain 'ai.onnx'. Please upgrade your model to opset 7 or higher. For now, this opset 
ONNX Schema 
onnx.AttributeProto
onnx.FunctionProto
onnx.GraphProto
onnx.MapProto
onnx.ModelProto
onnx.NodeProto
onnx.OperatorSetIdProto
onnx.OptionalProto
onnx.SequenceProto
onnx.SparseTensorProto
onnx.StringStringEntryProto
onnx.TensorAnnotation
onnx.TensorProto
onnx.TensorProto.Segment
onnx.TensorShapeProto
onnx.TensorShapeProto.Dimension
onnx.TrainingInfoProto
onnx.TypeProto
onnx.TypeProto.Map
onnx.TypeProto.Opaque
onnx.TypeProto.Optional
onnx.TypeProto.Sequence
onnx.TypeProto.SparseTensor
onnx.TypeProto.Tensor
onnx.ValueInfoProto
ONNX_NAMESPACE::TensorProto::DataType_IsValid(t_proto.data_type())
onnxruntime
onnxruntime.dll
onnxruntime::`anonymous-namespace'::actions::FuseConvActivation::ExtraAttributes
onnxruntime::`anonymous-namespace'::actions::FuseConvAddRelu::ValueMoves
onnxruntime::`anonymous-namespace'::ApplyOrtFormatModelRuntimeOptimizations
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashes
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashesImpl
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashesImpl::<lambda_6d5d79dc9c3bbca8e0221531cea74284>::operator ()
onnxruntime::`anonymous-namespace'::Cast::Cast
onnxruntime::`anonymous-namespace'::CastToString
onnxruntime::`anonymous-namespace'::ConstantOfShape::Compute
onnxruntime::`anonymous-namespace'::CopyData
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<__int64>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<double>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<float>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<int>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<struct onnxruntime::BFloat16>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<struct onnxruntime::MLFloat16>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<unsigned __int64>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<unsigned int>::operator ()
onnxruntime::`anonymous-namespace'::GetCurrentTimeString
onnxruntime::`anonymous-namespace'::GetInputNodeMerges
onnxruntime::`anonymous-namespace'::GetIntermediateMLFloat16ToFloatTensor
onnxruntime::`anonymous-namespace'::GetNextPropagationEdge
onnxruntime::`anonymous-namespace'::GetOutputNodeMerges
onnxruntime::`anonymous-namespace'::GetPreviousPropagationEdge
onnxruntime::`anonymous-namespace'::GetScalarConstantInitializer
onnxruntime::`anonymous-namespace'::GetScaleFromNode
onnxruntime::`anonymous-namespace'::InsertQDQPair
onnxruntime::`anonymous-namespace'::MoveInputOutputImpl
onnxruntime::`anonymous-namespace'::ParsePathRoot
onnxruntime::`anonymous-namespace'::PartitionOrtFormatModel
onnxruntime::`anonymous-namespace'::PropagateDQForward
onnxruntime::`anonymous-namespace'::PropagateQBackward
onnxruntime::`anonymous-namespace'::TraverseFormalParametersWithTypeProto
onnxruntime::`anonymous-namespace'::TypeBindingResolver::Resolve
onnxruntime::`anonymous-namespace'::VerifyEachNodeIsAssignedToAnEp
onnxruntime::`anonymous-namespace'::VerifyEachNodeIsAssignedToAnEpImpl
onnxruntime::`anonymous-namespace'::WindowsEnv::DeleteFolder
onnxruntime::`anonymous-namespace'::WindowsEnv::FormatLibraryFileName
onnxruntime::`anonymous-namespace'::WindowsEnv::GetCanonicalPath
onnxruntime::`anonymous-namespace'::WindowsEnv::GetNumCpuCores
onnxruntime::`anonymous-namespace'::WindowsEnv::ReadFileIntoBuffer
onnxruntime::`anonymous-namespace'::WindowsThread::WindowsThread
onnxruntime::AccumulateAllNestedSubgraphsInfo
onnxruntime::AllocateSparseTensor
onnxruntime::AllocatorManager::InsertAllocator
onnxruntime::AllocPlanPerValue::ProgramCounter::AddEnd
onnxruntime::AllocPlanPerValue::ProgramCounter::AddStart
onnxruntime::ApiGraph::CopyValueInfo
onnxruntime::ApiGraph::GetValueInfo
onnxruntime::ApiGraph::ReshapeInitializer
onnxruntime::ApiGraph::TransposeInitializer
onnxruntime::ApiTensor::Data
onnxruntime::ApiTensor::NumElements
onnxruntime::ApiValueInfo::PermuteDims
onnxruntime::AttentionFusion::ApplyImpl
onnxruntime::AttentionFusion::FuseSubGraph
onnxruntime::AttentionFusionHelper::CheckDistilBertReshapeShape
onnxruntime::AttentionFusionHelper::CheckNodesInPathK
onnxruntime::AttentionFusionHelper::CheckNodesInPathQ
onnxruntime::AttentionFusionHelper::CheckNodesInPathV
onnxruntime::AttentionFusionHelper::CheckSliceParameters
onnxruntime::AttentionFusionHelper::FuseGptAttention
onnxruntime::AttentionFusionHelper::MatchGemmSubgraph
onnxruntime::AttentionFusionHelper::MatchInputMaskSubgraph
onnxruntime::AttentionFusionHelper::MatchPastSubgraph
onnxruntime::AttentionFusionHelper::MatchUnidirMaskSubgraph
onnxruntime::AttentionFusionHelper::ValidateGemmInitializer
onnxruntime::AttentionFusionHelper::ValidateUnidirMask
onnxruntime::BFCArena::AllocateRawInternal
onnxruntime::BFCArena::AllocationRegion::AllocationRegion
onnxruntime::BFCArena::AllocationRegion::IndexFor
onnxruntime::BFCArena::BFCArena
onnxruntime::BFCArena::ChunkFromHandle
onnxruntime::BFCArena::DeallocateRawInternal
onnxruntime::BFCArena::DumpMemoryLog
onnxruntime::BFCArena::Extend
onnxruntime::BFCArena::Extend::<lambda_6bf74fe8c2f6f409bb5a2a70c054cf56>::operator ()
onnxruntime::BFCArena::FindChunkPtr
onnxruntime::BFCArena::FreeAndMaybeCoalesce
onnxruntime::BFCArena::get_bin_debug_info
onnxruntime::BFCArena::InsertFreeChunkIntoBin
onnxruntime::BFCArena::Merge
onnxruntime::BFCArena::RegionManager::RegionFor
onnxruntime::BFCArena::RegionManager::RemoveAllocationRegion
onnxruntime::BFCArena::RemoveFreeChunkFromBin
onnxruntime::BFCArena::RemoveFreeChunkIterFromBin
onnxruntime::BFCArena::Reserve
onnxruntime::BFCArena::Shrink
onnxruntime::BFCArena::SplitChunk
onnxruntime::BiasDropoutFusion::ApplyImpl
onnxruntime::BiasGeluFusion::ApplyImpl
onnxruntime::BiasSoftmaxFusion::ApplyImpl
onnxruntime::Broadcaster::Broadcaster
onnxruntime::BroadcastIterator::Append
onnxruntime::BroadcastIterator::Init
onnxruntime::BroadcastLooper
onnxruntime::CheckInput
onnxruntime::Clip::ComputeImpl<__int64>::operator ()
onnxruntime::Clip::ComputeImpl<double>::operator ()
onnxruntime::Clip::ComputeImpl<float>::operator ()
onnxruntime::Clip::ComputeImpl<signed char>::operator ()
onnxruntime::Clip::ComputeImpl<unsigned __int64>::operator ()
onnxruntime::Clip::ComputeImpl<unsigned char>::operator ()
onnxruntime::clip_internal::Clip_6Base<float>::Clip_6Base
onnxruntime::common::Status::Status
onnxruntime::CommonSubexpressionElimination::ApplyImpl
onnxruntime::ComputePadAndOutputShape
onnxruntime::ConcatBase::ComputeImpl
onnxruntime::ConcatBase::ConcatBase
onnxruntime::ConcatBase::PrepareForCompute
onnxruntime::concurrency::CreateThreadPoolHelper
onnxruntime::concurrency::ThreadPool::ParallelFor
onnxruntime::concurrency::ThreadPool::ParallelSection::ParallelSection
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEnd
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEndAndStart
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::Reset
onnxruntime::concurrency::ThreadPoolProfiler::Stop
onnxruntime::concurrency::ThreadPoolTempl<class onnxruntime::Env>::RunInParallel
onnxruntime::concurrency::ThreadPoolTempl<class onnxruntime::Env>::RunInParallelSection
onnxruntime::ConfigOptions::AddConfigEntry
onnxruntime::ConstantFolding::ApplyImpl
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::ConstantOfShapeBase
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::PrepareCompute
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::SetValue
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::SetValueFromTensorProto
onnxruntime::ConstPointerContainer<class std::vector<class onnxruntime::NodeArg *,class std::allocator<class onnxruntime::NodeArg *> > >::at
onnxruntime::contrib::BiasGelu<float,0>::Compute
onnxruntime::contrib::DynamicQuantizeLSTM::PrePack
onnxruntime::contrib::DynamicQuantizeMatMul::Compute
onnxruntime::contrib::FusedConvFloat::FusedConvFloat
onnxruntime::contrib::FusedGemm<float>::FusedGemm
onnxruntime::contrib::LayerNorm<double,0>::Compute
onnxruntime::contrib::LayerNorm<double,0>::LayerNorm
onnxruntime::contrib::LayerNorm<double,1>::Compute
onnxruntime::contrib::LayerNorm<double,1>::LayerNorm
onnxruntime::contrib::LayerNorm<float,0>::Compute
onnxruntime::contrib::LayerNorm<float,0>::LayerNorm
onnxruntime::contrib::LayerNorm<float,1>::Compute
onnxruntime::contrib::LayerNorm<float,1>::LayerNorm
onnxruntime::contrib::MatMulIntegerToFloat::Compute
onnxruntime::contrib::MatMulIntegerToFloatBase::ComputeCommon
onnxruntime::contrib::NchwcConv::Compute
onnxruntime::contrib::NchwcConv::NchwcConv
onnxruntime::contrib::NchwcPoolBase::NchwcPool
onnxruntime::contrib::NchwcPoolBase::NchwcPoolBase
onnxruntime::contrib::RegisterCpuContribKernels
onnxruntime::contrib::RegisterNchwcKernels
onnxruntime::contrib::RegisterQuantizationKernels
onnxruntime::contrib::ReorderInput::Compute
onnxruntime::contrib::ReorderInput::ReorderInput
onnxruntime::contrib::ReorderOutput::Compute
onnxruntime::contrib::ReorderOutput::ReorderOutput
onnxruntime::contrib::SkipLayerNorm<double>::SkipLayerNorm
onnxruntime::contrib::SkipLayerNorm<float>::SkipLayerNorm
onnxruntime::Conv<float>::Compute
onnxruntime::ConvAddFusion::Apply
onnxruntime::ConvAttributes::ConvAttributes
onnxruntime::ConvAttributes::InferOutputShape
onnxruntime::ConvBNFusion::Apply
onnxruntime::ConvertMaskToInt32
onnxruntime::ConvInteger::Compute
onnxruntime::ConvMulFusion::Apply
onnxruntime::core_impl::<lambda_536a6e9cd022d0c1fa0cbf0549e74cf6>::operator ()
onnxruntime::core_impl::<lambda_69537c8792caaade49ceebada4159678>::operator ()
onnxruntime::core_impl::<lambda_c278e4ec57a99b58d713632b35dd4157>::operator ()
onnxruntime::core_impl::<lambda_d8aa0ac057a171b3efa96a44f9d49b91>::operator ()
onnxruntime::CPUDataTransfer::CopyTensor
onnxruntime::CPUExecutionProvider::GetKernelRegistry
onnxruntime::CreateAllocator
onnxruntime::CreateCustomRegistry
onnxruntime::CreateReplacementNode
onnxruntime::CreateSchema
onnxruntime::CumSum<__int64>::Compute
onnxruntime::CumSum<double>::Compute
onnxruntime::CumSum<float>::Compute
onnxruntime::CumSum<int>::Compute
onnxruntime::CustomOpKernel::CustomOpKernel
onnxruntime::data_types_internal::DataTypeRegistry::RegisterDataType
onnxruntime::data_types_internal::IsCompatible
onnxruntime::data_types_internal::MapTypeHelper::Set
onnxruntime::data_types_internal::OptionalTypeHelper::Set
onnxruntime::data_types_internal::SequenceTypeHelper::Set
onnxruntime::DataTransferManager::CopySparseTensors
onnxruntime::DataTransferManager::CopyTensors
onnxruntime::DataTypeImpl::GetType<T>() == type_
onnxruntime::DeepCpuGruOp::Compute
onnxruntime::DeepCpuGruOp::ComputeImpl
onnxruntime::DeepCpuGruOp::DeepCpuGruOp
onnxruntime::DeepCpuLstmOp::Compute
onnxruntime::DeepCpuLstmOp::PrePack
onnxruntime::DequantizeLinear<int>::Compute
onnxruntime::DispatchStridedCopy
onnxruntime::DoTransposeEltWise
onnxruntime::DoTransposeImpl
onnxruntime::DynamicQuantizeLinear<unsigned char>::Compute
onnxruntime::DynamicQuantizeMatMulFusion::ApplyImpl
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<__int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<__int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<short> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<short> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<signed char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<signed char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned __int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned __int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned short> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned short> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Floor<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Floor<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::LeakyRelu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::LeakyRelu<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<float> >::ElementWiseKernel
onnxruntime::EmbedLayerNormFusion::ApplyImpl
onnxruntime::ExecutionFrame::{ctor}::<lambda_7d7605caeb4f06ba6e5ae22b6401d8c8>::operator ()
onnxruntime::ExecutionFrame::AllocateAsPerAllocationPlan
onnxruntime::ExecutionFrame::AllocateMLValueTensorPreAllocateBuffer
onnxruntime::ExecutionFrame::AllocateMLValueTensorSelfOwnBufferHelper
onnxruntime::ExecutionFrame::AllocateReusedOrtValueIfNotAllocatedHelper
onnxruntime::ExecutionFrame::ExecutionFrame
onnxruntime::ExecutionFrame::GetAllocationPlan
onnxruntime::ExecutionFrame::ReleaseMLValueImpl
onnxruntime::ExecutionFrame::TraceAllocate
onnxruntime::ExecutionFrame::TraceFree
onnxruntime::ExecutionFrame::VerifyOutputSizes
onnxruntime::ExecutionProviders::Add
onnxruntime::ExLibLoader::{dtor}::<lambda_3229e3f829fe3a5ff7c7841155b8b8df>::operator ()
onnxruntime::ExLibLoader::~ExLibLoader
onnxruntime::ExLibLoader::LoadExternalLib
onnxruntime::Expand_8<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute::<lambda_2288f63c5e7894f75698468e4f3eb00c>::operator ()
onnxruntime::ExpandBroadcastLooper
onnxruntime::FastGeluFusion::ApplyImpl
onnxruntime::fbs::utils::LoadAttributeOrtFormat
onnxruntime::fbs::utils::LoadInitializerOrtFormat
onnxruntime::fbs::utils::LoadMapTypeOrtFormat
onnxruntime::fbs::utils::LoadOpsetImportOrtFormat
onnxruntime::fbs::utils::LoadSequenceTypeOrtFormat
onnxruntime::fbs::utils::LoadSparseInitializerOrtFormat
onnxruntime::fbs::utils::LoadTensorDimensionOrtFormat
onnxruntime::fbs::utils::LoadTensorShapeOrtFormat
onnxruntime::fbs::utils::LoadTensorTypeAndShapeOrtFormat
onnxruntime::fbs::utils::LoadTypeInfoOrtFormat
onnxruntime::fbs::utils::LoadValueInfoOrtFormat
onnxruntime::fbs::utils::SaveAttributeOrtFormat
onnxruntime::fbs::utils::SaveInitializerOrtFormat
onnxruntime::fbs::utils::SaveMapTypeOrtFormat
onnxruntime::fbs::utils::SaveSequenceTypeOrtFormat
onnxruntime::fbs::utils::SaveSparseInitializerOrtFormat
onnxruntime::fbs::utils::SaveTensorTypeAndShapeOrtFormat
onnxruntime::fbs::utils::SaveTypeInfoOrtFormat
onnxruntime::fbs::utils::SaveValueInfoOrtFormat
onnxruntime::FeedsFetchesInfo::FeedsFetchesInfo
onnxruntime::FeedsFetchesInfo::MapNamesToMLValueIdxs
onnxruntime::FeedsFetchesManager::SetDeviceCopyChecks
onnxruntime::FinalizeSessionOptions
onnxruntime::FreeDimensionOverrideTransformer::ApplyImpl
onnxruntime::FreeDimensionOverrideTransformer::FreeDimensionOverrideTransformer
onnxruntime::FuncManager::GetFuncs
onnxruntime::FunctionImpl::FunctionImpl
onnxruntime::FunctionKernel::Create
onnxruntime::functors::ElementWiseRangedTransform<float>::Create
onnxruntime::functors::HardSigmoid<float>::Init
onnxruntime::functors::ParametricSoftplus<float>::Init
onnxruntime::functors::ScaledTanh<float>::Init
onnxruntime::functors::Selu<float>::Init
onnxruntime::FuseReluClip::Apply
onnxruntime::FuseSubGraph
onnxruntime::FuseSubGraphDistilBert
onnxruntime::FuseSubGraphQK
onnxruntime::FuseSubGraphQKDistilBert
onnxruntime::FuseSubGraphQKImpl
onnxruntime::Gather::Compute
onnxruntime::GatherBase::GatherBase
onnxruntime::GatherElements::GatherElements
onnxruntime::GeluApproximation::ApplyImpl
onnxruntime::GeluFusion::ApplyImpl
onnxruntime::GemmActivationFusion::ApplyImpl
onnxruntime::GemmBase::GemmBase
onnxruntime::GemmBroadcastBias
onnxruntime::GemmHelper::GemmHelper
onnxruntime::GemmSumFusion::Apply
onnxruntime::GemmSumFusion::SatisfyCondition
onnxruntime::GetCapabilityForEP
onnxruntime::GetCpuPreferredNodes
onnxruntime::GetCpuPreferredNodes::<lambda_8811b8e0b984fa7408be2a8e645ea91e>::operator ()
onnxruntime::GetKernelCreateInfo
onnxruntime::GetNodesToOptimizeIndices::<lambda_069fd95563047ae0c4e53fb8dd3a0690>::operator ()
onnxruntime::GetQConstantLowerUpper
onnxruntime::GetSinceVersionForNewOp
onnxruntime::GetSubGraphSessionStatesOrtFormat
onnxruntime::GetTransposePerms
onnxruntime::Graph::AddEdge
onnxruntime::Graph::AddInitializedTensor
onnxruntime::Graph::AllocateNode
onnxruntime::Graph::BuildConnections
onnxruntime::Graph::CleanUnusedInitializersAndNodeArgs
onnxruntime::Graph::CreateFusedSubGraphNode
onnxruntime::Graph::FinalizeFuseSubGraph
onnxruntime::Graph::ForThisAndAllSubgraphs
onnxruntime::Graph::Graph
onnxruntime::Graph::InferAndVerifySubgraphTypes
onnxruntime::Graph::InferAndVerifyTypeMatch
onnxruntime::Graph::InitFunctionBodyForNode
onnxruntime::Graph::InitializeStateFromModelFileGraphProto
onnxruntime::Graph::InitInputsInitializersOutputs
onnxruntime::Graph::InlineFunction
onnxruntime::Graph::KahnsTopologicalSort
onnxruntime::Graph::LoadFromOrtFormat
onnxruntime::Graph::LoadFromOrtFormat::<lambda_24d691d3e5f81c7bd3c40ac3ff7d1f76>::operator ()
onnxruntime::Graph::NodeAtIndexImpl
onnxruntime::Graph::PerformTypeAndShapeInferencing
onnxruntime::Graph::RemoveEdge
onnxruntime::Graph::RemoveInitializedTensor
onnxruntime::Graph::RemoveNode
onnxruntime::Graph::Resolve
onnxruntime::Graph::SaveToOrtFormat
onnxruntime::Graph::SetInputs
onnxruntime::Graph::SetOuterScopeNodeArgs
onnxruntime::Graph::ToGraphProto
onnxruntime::Graph::ToGraphProtoInternal
onnxruntime::Graph::UpdateShapeInference
onnxruntime::Graph::VerifyNodeAndOpMatch
onnxruntime::graph_utils::AddInitializer
onnxruntime::graph_utils::AddNodeInput
onnxruntime::graph_utils::CanUpdateImplicitInputNameInSubgraphs
onnxruntime::graph_utils::ExtendedGraphEdge::GetMutableNodeAtEnd
onnxruntime::graph_utils::ExtendedGraphEdge::GetNodeAtEnd
onnxruntime::graph_utils::ExtendedGraphEdge::TryCreateFromInputOrInitializerToNode
onnxruntime::graph_utils::ExtendedGraphEdge::TryCreateFromNodeToOutput
onnxruntime::graph_utils::FindPath
onnxruntime::graph_utils::GetIndexFromName
onnxruntime::graph_utils::GetNodeInputName
onnxruntime::graph_utils::GetNodeOutputName
onnxruntime::graph_utils::RemoveNode
onnxruntime::graph_utils::RemoveNodeWithSingleNodeInSingleUsedOutput
onnxruntime::graph_utils::ReplaceNodeInput
onnxruntime::graph_utils::UpdateImplicitInputNameInSubgraph
onnxruntime::GraphPartitioner::Partition
onnxruntime::GraphPartitioner::PartitionOnnxFormatModel
onnxruntime::GraphPartitioner::PartitionOrtFormatModel
onnxruntime::GraphTransformer::Apply
onnxruntime::GraphTransformer::Recurse
onnxruntime::GraphTransformerManager::ApplyTransformers
onnxruntime::GraphViewer::GetNodesInTopologicalOrder
onnxruntime::GraphViewer::GetRootNodes
onnxruntime::GraphViewer::GraphViewer
onnxruntime::HandleNegativeAxis
onnxruntime::Hardmax<float>::Compute
onnxruntime::IAllocator::CalcMemSizeForArrayWithAlignment::<lambda_1dd79544acf23ae3afd11302d7a0d9a2>::operator ()
onnxruntime::IDataTransfer::CopySparseTensors
onnxruntime::IDataTransfer::CopyTensors
onnxruntime::IdentityOp<0>::Compute
onnxruntime::IdentityOp<1>::Compute
onnxruntime::IExecutionFrame::GetMLValue
onnxruntime::IExecutionFrame::GetOrCreateNodeOutputMLValue
onnxruntime::IExecutionFrame::IExecutionFrame
onnxruntime::IExecutionFrame::Init
onnxruntime::IExecutionProvider::GenerateMetaDefId
onnxruntime::IExecutionProvider::InsertAllocator
onnxruntime::IExecutionProvider::TryInsertAllocator
onnxruntime::If::Compute
onnxruntime::If::Info::Info
onnxruntime::If::Init
onnxruntime::If::SetupSubgraphExecutionInfo
onnxruntime::IfImpl::Execute
onnxruntime::IfImpl::Initialize
onnxruntime::IncrementIndexAndComputeOffsetSetup
onnxruntime::inference_session_utils::JsonConfigParser::ParseOrtConfigJsonInModelProto
onnxruntime::inference_session_utils::JsonConfigParser::ParseOrtConfigJsonInModelProto::<lambda_98c68a30f5b1cb5acbbe1d8255ff290f>::operator ()
onnxruntime::inference_session_utils::JsonConfigParser::ParseSessionOptionsFromModelProto
onnxruntime::InferenceSession::{dtor}::<lambda_2d91af5d8f3e88a3721667de76a73c43>::operator ()
onnxruntime::InferenceSession::~InferenceSession
onnxruntime::InferenceSession::AddCustomOpDomains
onnxruntime::InferenceSession::AddPredefinedTransformers
onnxruntime::InferenceSession::CachedExecutionProviderForGraphReplay::ReplayGraph
onnxruntime::InferenceSession::ConstructorCommon
onnxruntime::InferenceSession::ConstructorCommon::<lambda_7c14b5b3ba89015b9f6468edc3832bfe>::operator ()
onnxruntime::InferenceSession::CreateLoggerForRun
onnxruntime::InferenceSession::EndProfiling
onnxruntime::InferenceSession::GetModelInputs
onnxruntime::InferenceSession::GetModelMetadata
onnxruntime::InferenceSession::GetModelOutputs
onnxruntime::InferenceSession::GetOverridableInitializers
onnxruntime::InferenceSession::InferenceSession
onnxruntime::InferenceSession::Initialize
onnxruntime::InferenceSession::Initialize::<lambda_4dd40fbfce8b243a9fb43e8983477352>::operator ()
onnxruntime::InferenceSession::Initialize::<lambda_c6bff5ff6892027db42ce3633458d3ed>::operator ()
onnxruntime::InferenceSession::InitLogger
onnxruntime::InferenceSession::Load
onnxruntime::InferenceSession::LoadOrtModel
onnxruntime::InferenceSession::LoadOrtModel::<lambda_165747221b83b97edb1c8980b4a934c8>::operator ()
onnxruntime::InferenceSession::NewIOBinding
onnxruntime::InferenceSession::RegisterExecutionProvider
onnxruntime::InferenceSession::Run
onnxruntime::InferenceSession::SaveToOrtFormat
onnxruntime::InferenceSession::ShrinkMemoryArenas
onnxruntime::InferenceSession::TransformGraph
onnxruntime::InferenceSession::ValidateInputs
onnxruntime::Initializer::Initializer
onnxruntime::Initializer::ReadExternalRawData
onnxruntime::Initializer::ToProto
onnxruntime::InitNestedModelLocalFunction
onnxruntime::InlineNodes
onnxruntime::InputBroadcaster::AdvanceBy
onnxruntime::InsertCastTransformer::ApplyImpl
onnxruntime::IOBinding::BindInput
onnxruntime::IOBinding::BindOutputImpl
onnxruntime::IOBinding::SynchronizeInputs
onnxruntime::IOBinding::SynchronizeOutputs
onnxruntime::IOTypeConstraintHelper
onnxruntime::KernelDefBuilder::VariadicAlias
onnxruntime::KernelRegistry::Register
onnxruntime::KernelRegistry::TryCreateKernel
onnxruntime::KernelUseSharedPrePackedBuffers
onnxruntime::LayerNormFusion::ApplyImpl
onnxruntime::LoadOrtModelBytes
onnxruntime::logging::LoggingManager::CreateDefaultLogger
onnxruntime::logging::LoggingManager::DefaultLogger
onnxruntime::logging::LoggingManager::LoggingManager
onnxruntime::LoopDir
onnxruntime::LSTMBase::ComputeImpl
onnxruntime::LSTMBase::LSTMBase
onnxruntime::MatchAndProcess
onnxruntime::MatchInputToConcatSubgraph
onnxruntime::MatchPositionEmbeddingSubgraphsFromGather
onnxruntime::math::Gemv
onnxruntime::math::NextPosition
onnxruntime::MatMul<__int64>::Compute
onnxruntime::MatMul<double>::Compute
onnxruntime::MatMul<float>::Compute
onnxruntime::MatMul<int>::Compute
onnxruntime::MatMulAddFusion::ApplyImpl
onnxruntime::MatMulComputeHelper::Compute
onnxruntime::MatMulComputeHelper::Compute::<lambda_0b24200fa934277fc2b30a9b53636fed>::operator ()
onnxruntime::MatMulInteger::Compute
onnxruntime::MatMulIntegerToFloatFusion::ApplyImpl
onnxruntime::MatMulScaleFusion::ApplyImpl
onnxruntime::MatmulTransposeFusion::ApplyImpl
onnxruntime::MaxPoolV8::ComputeImpl
onnxruntime::MemcpyTransformer::ApplyImpl
onnxruntime::MemPatternPlanner::TraceAllocation
onnxruntime::MergeIntoTarget::Run
onnxruntime::MergeShapeInfo
onnxruntime::ml::RegisterOnnxMLOperatorKernels
onnxruntime::Model::Load
onnxruntime::Model::LoadFromOrtFormat
onnxruntime::Model::Model
onnxruntime::Model::Save
onnxruntime::Model::SaveToOrtFormat
onnxruntime::model_load_utils::IsAllowReleasedONNXOpsetsOnlySet
onnxruntime::model_load_utils::ValidateOpsetForDomain
onnxruntime::MoveInputOutput
onnxruntime::NchwcTransformer::ApplyImpl
onnxruntime::NchwcTransformerImpl::TransformConv
onnxruntime::NhwcTransformer::ApplyImpl
onnxruntime::Node::ForEachWithIndex
onnxruntime::Node::LoadEdgesFromOrtFormat
onnxruntime::Node::LoadEdgesFromOrtFormat::<lambda_801af3d4b18b804a1ada0ca03a24b550>::operator ()
onnxruntime::Node::LoadFromOrtFormat
onnxruntime::Node::LoadFromOrtFormat::<lambda_6f09c8359fd46aaa68c171497d71a319>::operator ()
onnxruntime::Node::SaveToOrtFormat
onnxruntime::NodeArg::UpdateTypeAndShape
onnxruntime::NodeIndexInfo::GetMLValueIndex
onnxruntime::NodeIndexInfo::GetNodeOffset
onnxruntime::NodeIndexInfo::Init::<lambda_1123ca3288c22333dcfbc6780e56f3b6>::operator ()
onnxruntime::NodeIndexInfo::Init::<lambda_4404716c35945f1da6a07154c932397d>::operator ()
onnxruntime::NodesToOptimize::GetNode
onnxruntime::NodesToOptimizeIndicesBuilder::Build
onnxruntime::NonMaxSuppressionBase::GetThresholdsFromInputs
onnxruntime::NonMaxSuppressionBase::PrepareCompute
onnxruntime::NonTensorTypeBase::FromDataContainer
onnxruntime::NonTensorTypeBase::IsMapCompatible
onnxruntime::NonTensorTypeBase::IsSequenceCompatible
onnxruntime::NonTensorTypeBase::ToDataContainer
onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSchemaInternal
onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSet
onnxruntime::OpKernel::ComputeAsync
onnxruntime::OpKernelContext::GetOrCreateOutputMLValue
onnxruntime::OpKernelContext::Input
onnxruntime::OpKernelContext::OpKernelContext
onnxruntime::OpKernelContext::Output
onnxruntime::OpKernelContext::OutputMLValue
onnxruntime::OpKernelContext::RequiredInput
onnxruntime::OpKernelContext::RequiredOutput
onnxruntime::OpKernelContextInternal::OpKernelContextInternal
onnxruntime::OpKernelInfo::GetMemoryInfo
onnxruntime::optimizer_utils::GenerateRewriteRules
onnxruntime::optimizer_utils::GenerateRuleBasedGraphTransformer
onnxruntime::optimizer_utils::GenerateTransformers
onnxruntime::optimizer_utils::GenerateTransformersForMinimalBuild
onnxruntime::optimizer_utils::GetClipConstantMinMax::<lambda_4f21cebc490a3d885511ea724efbe189>::operator ()
onnxruntime::OptimizerExecutionFrame::Info::{ctor}::<lambda_4de083bd9feef97ef116b9ac6f248cfc>::operator ()
onnxruntime::OptimizerExecutionFrame::Info::Info
onnxruntime::OptionalTypeBase::GetDeleteFunc
onnxruntime::OptionalTypeBase::GetElementType
onnxruntime::OptionalTypeBase::IsCompatible
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Create
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Iterator::Iterator
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Iterator::operator *
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Create
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Iterator::Iterator
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Iterator::operator *
onnxruntime::OuterScopeNodeArgLocationAccumulator
onnxruntime::OuterScopeNodeArgLocationAccumulator::<lambda_23cd650266f5b996762e121f69bcde45>::operator ()
onnxruntime::OuterScopeNodeArgLocationAccumulator::<lambda_a191614639fd357df18cb9db7ec0bbb0>::operator ()
onnxruntime::OutputBroadcaster::OutputBroadcaster
onnxruntime::ParallelExecutor::Execute
onnxruntime::ParallelExecutor::RunNodeAsync
onnxruntime::PartitionOnnxFormatModelImpl
onnxruntime::PartitionOrtFormatModelImpl
onnxruntime::Path::Parse
onnxruntime::PlaceNode
onnxruntime::PlannerImpl::AllocPlan
onnxruntime::PlannerImpl::Buffer
onnxruntime::PlannerImpl::ComputeReusePlan
onnxruntime::PlannerImpl::ComputeUseCounts
onnxruntime::PlannerImpl::ComputeUseCounts::<lambda_c7328f9d78ba121fe15792ce469c1b69>::operator ()
onnxruntime::PlannerImpl::CreatePlan
onnxruntime::PlannerImpl::GenerateDeallocationPlan
onnxruntime::PlannerImpl::GeneratePlanForWeightsHelper
onnxruntime::PlannerImpl::GetElementSize
onnxruntime::PlannerImpl::GetLocationForNodeInput
onnxruntime::PlannerImpl::Index
onnxruntime::PlannerImpl::ProcessDef
onnxruntime::PlannerImpl::Reuse
onnxruntime::PlannerImpl::UseCount
onnxruntime::PlannerImpl::VerifyMemoryTimeSchedule
onnxruntime::PoolAttributes::ComputeSizePadDilations
onnxruntime::PoolAttributes::InferOutputSize
onnxruntime::PoolAttributes::PoolAttributes
onnxruntime::PoolAttributes::SetOutputSize
onnxruntime::PoolBase::Compute
onnxruntime::PoolProcessContext::init
onnxruntime::PrePackedWeights::GetHash
onnxruntime::PrepackedWeightsContainer::GetOrCreateAllocator
onnxruntime::PrepareForCompute
onnxruntime::PrepareForQDQ
onnxruntime::profiling::Profiler::EndProfiling
onnxruntime::profiling::Profiler::EndTimeAndRecordEvent
onnxruntime::profiling::Profiler::Initialize
onnxruntime::profiling::Profiler::Start
onnxruntime::ProviderLibrary::Get
onnxruntime::ProviderLibrary::Unload
onnxruntime::ProviderSharedLibrary::Ensure
onnxruntime::ProviderSharedLibrary::Unload
onnxruntime::QDQ::QOrDQNodeHasConstantScalarScaleAndZeroPoint
onnxruntime::QDQFinalCleanupTransformer::ApplyImpl
onnxruntime::QDQPropagationTransformer::ApplyImpl
onnxruntime::QDQS8ToU8Transformer::ApplyImpl
onnxruntime::ReduceKernelBase<0>::ReduceKernelBase
onnxruntime::ReduceKernelBase<1>::ReduceKernelBase
onnxruntime::RegisterCPUKernels
onnxruntime::RegisterOnnxOperatorKernels
onnxruntime::RegisterProducedNodesWithGraph
onnxruntime::ReleaseNodeMLValues
onnxruntime::RemoveDuplicateCastTransformer::ApplyImpl
onnxruntime::ReorderCastAndTranspose
onnxruntime::ReplaceWithNew::Run
onnxruntime::ReplaceWithNew::RunForSave
onnxruntime::Reshape::Compute
onnxruntime::ReshapeFusion::ApplyImpl
onnxruntime::ReshapeFusion::Fuse_Subgraph
onnxruntime::ReshapeHelper::ReshapeHelper
onnxruntime::ResultsNoTransposePrepareForReduce::ValidateNotEmpty
onnxruntime::rnn::detail::ComputeGemm
onnxruntime::rnn::detail::deepcpu::ActivationFuncByName
onnxruntime::rnn::detail::deepcpu::GruOutputGateFuncByName
onnxruntime::rnn::detail::deepcpu::GruResetGateFuncByName
onnxruntime::rnn::detail::deepcpu::LstmMergeGatesFuncByName
onnxruntime::rnn::detail::MakeDirection
onnxruntime::rnn::detail::NormalizeActivationArgumentAndGetAlphaBetaCount
onnxruntime::rnn::detail::SafeRawConstPointer
onnxruntime::rnn::detail::SafeRawPointer
onnxruntime::RuleBasedGraphTransformer::ApplyImpl
onnxruntime::RuleBasedGraphTransformer::ApplyRulesOnNode
onnxruntime::RuntimeOptimizationRecordContainer::LoadFromOrtFormat
onnxruntime::RuntimeOptimizationRecordContainer::SaveToOrtFormat
onnxruntime::SaveModel
onnxruntime::scan::detail::AllocateOutput
onnxruntime::scan::detail::CreateFeedsFetchesManager
onnxruntime::scan::detail::Info::Info
onnxruntime::scan::detail::IterateSequence
onnxruntime::scan::detail::IterateSequence::<lambda_2f3c8dfb82c3078faed3c459500f6cd5>::operator ()
onnxruntime::scan::detail::LoopStateVariable::Next
onnxruntime::scan::detail::OutputIterator::AllocateFinalBuffer
onnxruntime::scan::detail::OutputIterator::AllocateFinalOutput
onnxruntime::scan::detail::OutputIterator::GetOutput
onnxruntime::scan::detail::OutputIterator::Initialize
onnxruntime::scan::detail::OutputIterator::operator *
onnxruntime::scan::detail::OutputIterator::operator ++
onnxruntime::scan::detail::ReadDirections
onnxruntime::Scan<9>::Compute
onnxruntime::Scan<9>::Init
onnxruntime::Scan<9>::SetupSubgraphExecutionInfo
onnxruntime::ScanImpl::AllocateOutputTensors
onnxruntime::ScanImpl::CreateLoopStateVariables
onnxruntime::ScanImpl::Execute
onnxruntime::ScanImpl::Initialize
onnxruntime::ScanImpl::SetupInputs
onnxruntime::ScanImpl::TransposeOutput
onnxruntime::ScanImpl::ValidateInput
onnxruntime::ScatterNDDispatchTarget<__int64>::operator ()
onnxruntime::ScatterNDDispatchTarget<bool>::operator ()
onnxruntime::ScatterNDDispatchTarget<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::operator ()
onnxruntime::ScatterNDDispatchTarget<double>::operator ()
onnxruntime::ScatterNDDispatchTarget<float>::operator ()
onnxruntime::ScatterNDDispatchTarget<int>::operator ()
onnxruntime::ScatterNDDispatchTarget<short>::operator ()
onnxruntime::ScatterNDDispatchTarget<signed char>::operator ()
onnxruntime::ScatterNDDispatchTarget<struct onnxruntime::BFloat16>::operator ()
onnxruntime::ScatterNDDispatchTarget<struct onnxruntime::MLFloat16>::operator ()
onnxruntime::ScatterNDDispatchTarget<unsigned __int64>::operator ()
onnxruntime::ScatterNDDispatchTarget<unsigned char>::operator ()
onnxruntime::ScatterNDDispatchTarget<unsigned int>::operator ()
onnxruntime::ScatterNDDispatchTarget<unsigned short>::operator ()
onnxruntime::SelectorActionRegistry::RegisterSelectorAndAction
onnxruntime::SelectorActionTransformer::ApplySavedRuntimeOptimizations
onnxruntime::SelectorActionTransformer::ApplySelectorsAndActions
onnxruntime::SequenceTensorTypeBase::GetElementType
onnxruntime::SequenceTensorTypeBase::IsCompatible
onnxruntime::SequentialExecutor::Execute
onnxruntime::session_state_utils::DeserializeTensorProto
onnxruntime::session_state_utils::SaveInitializedTensors
onnxruntime::session_state_utils::SaveInitializedTensors::<lambda_6c4003787d982facc3e4a14cc0a1fb45>::operator ()
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping::<lambda_2314020bbb2bcb9dacfa0af3f7ebfa1d>::operator ()
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping::<lambda_f663e1cb5f92583d40a80c3711b532b4>::operator ()
onnxruntime::SessionState::AddOutputNameToNodeInfoMapping
onnxruntime::SessionState::AddSubgraphSessionState
onnxruntime::SessionState::CreateGraphInfo
onnxruntime::SessionState::CreateKernels
onnxruntime::SessionState::CreateSubgraphSessionState
onnxruntime::SessionState::FinalizeSessionState
onnxruntime::SessionState::FinalizeSessionStateImpl
onnxruntime::SessionState::GetNodeIndexInfo
onnxruntime::SessionState::GetNodeKernelCreateInfo
onnxruntime::SessionState::LoadFromOrtFormat
onnxruntime::SessionState::LoadFromOrtFormat::<lambda_22285d577ae7f88bffc3c4e6bbbe514e>::operator ()
onnxruntime::SessionState::PopulateKernelCreateInfo
onnxruntime::SessionState::PrepackConstantInitializedTensors::<lambda_4b2c19fdf6db3770ba085ad29d6de2dd>::operator ()
onnxruntime::SessionState::SaveToOrtFormat
onnxruntime::SessionState::SetupAllocators
onnxruntime::SessionState::UpdateToBeExecutedNodes
onnxruntime::SetEnableProfiling
onnxruntime::SetExecutionMode
onnxruntime::SetGraphOptimizationLevel
onnxruntime::SetInterOpNumThreads
onnxruntime::SetIntraOpNumThreads
onnxruntime::SimplifiedLayerNormFusion::ApplyImpl
onnxruntime::SkipLayerNormFusion::ApplyImpl
onnxruntime::SliceBase::Compute
onnxruntime::SliceBase::FillVectorsFromInput
onnxruntime::SliceBase::PrepareForCompute
onnxruntime::SliceBase::SliceBase
onnxruntime::SliceImpl::<lambda_0446c0939ee629ce947e593108d9f1b8>::operator ()
onnxruntime::SliceImpl::<lambda_23a04ec8efc34ba9c10f360679dafd19>::operator ()
onnxruntime::SliceImpl::<lambda_278f0fd775f8a53bdddcb46b93819006>::operator ()
onnxruntime::SliceImpl::<lambda_46348fe74d258edec532e2c838ffd5ed>::operator ()
onnxruntime::SliceImpl::<lambda_8cc359b57ce5115b939fcfb339a96061>::operator ()
onnxruntime::SliceIteratorBase::CopyInnermostAxisNonSolitaryInnerStep
onnxruntime::SliceIteratorBase::Init
onnxruntime::SliceSkips::SliceSkips
onnxruntime::Softmax<double>::ComputeImplOpset13
onnxruntime::Softmax<float>::ComputeImplOpset13
onnxruntime::sparse_utils::DenseTensorToSparseCoo
onnxruntime::sparse_utils::DenseTensorToSparseCsr
onnxruntime::sparse_utils::SparseCooToDenseTensor
onnxruntime::sparse_utils::SparseCsrToDenseTensor
onnxruntime::SparseTensor::AllocateBuffer
onnxruntime::SparseTensor::AsBlockSparse
onnxruntime::SparseTensor::AsCoo
onnxruntime::SparseTensor::AsCsr
onnxruntime::SparseTensor::Copy
onnxruntime::SparseTensor::GetCooIndexDims
onnxruntime::SparseTensor::GetSparseTensorFromOrtValue
onnxruntime::SparseTensor::MakeBlockSparseData
onnxruntime::SparseTensor::MakeBlockSparseStrings
onnxruntime::SparseTensor::MakeCooData
onnxruntime::SparseTensor::MakeCooStrings
onnxruntime::SparseTensor::MakeCsrData
onnxruntime::SparseTensor::MakeCsrStrings
onnxruntime::SparseTensor::UseBlockSparseIndices
onnxruntime::SparseTensor::UseCooIndices
onnxruntime::SparseTensor::UseCsrIndices
onnxruntime::SparseTensor::ValidateBlockSparseShapes
onnxruntime::SparseTensor::ValidateCsrIndices
onnxruntime::SparseTensorTypeBase::GetElementType
onnxruntime::SparseTensorTypeBase::IsCompatible
onnxruntime::Split::Compute
onnxruntime::Split::ComputeImpl
onnxruntime::SplitBase::SplitBase
onnxruntime::Squeeze::Compute
onnxruntime::SqueezeBase::ComputeOutputShape
onnxruntime::StridedCopy
onnxruntime::StridedCopy::<lambda_1a286ef6a47f06b31852d582b51b4ff5>::operator ()
onnxruntime::StridedCopy::<lambda_4f04249e04d07d50d630e12dc9f30f23>::operator ()
onnxruntime::StridedCopy::<lambda_6bbfc6268021e2bfd0f1bd3e4700889b>::operator ()
onnxruntime::StridedCopy::<lambda_aa638f082cd6e633ea8c394e1663fa60>::operator ()
onnxruntime::StridedCopy::<lambda_ab076180da33c991061bdac15a41448d>::operator ()
onnxruntime::StridedCopy::<lambda_b92cd1be17f8632fbcc9dec212afe76b>::operator ()
onnxruntime::StridedCopy::<lambda_c8779530b1b47f6b819a3c840cb70825>::operator ()
onnxruntime::StridedCopy::<lambda_d2c19ae18917b59844dd4110518387dd>::operator ()
onnxruntime::StridedCopy::<lambda_f0ea35f12b551ef953688db40e1f4b34>::operator ()
onnxruntime::StridedCopy::<lambda_f563daf0e095e96808b0280be50284eb>::operator ()
onnxruntime::StringToAutoPadType
onnxruntime::SyncProviders
onnxruntime::Tensor::Data
onnxruntime::Tensor::DataAsSpan
onnxruntime::Tensor::DataRaw
onnxruntime::Tensor::Init
onnxruntime::Tensor::MutableData
onnxruntime::Tensor::MutableDataAsSpan
onnxruntime::Tensor::MutableDataRaw
onnxruntime::Tensor::Reshape
onnxruntime::Tensor::SizeInBytes
onnxruntime::Tensor::Tensor
onnxruntime::TensorAllocator::TensorAllocator
onnxruntime::TensorAllocatorWithMemPattern::FinalizePlan
onnxruntime::TensorAllocatorWithMemPattern::Trace
onnxruntime::TensorSeq::Add
onnxruntime::TensorSeq::Get
onnxruntime::TensorSeq::SetType
onnxruntime::TensorShape::SizeFromDimension
onnxruntime::TensorShape::SizeToDimension
onnxruntime::TensorShape::Slice
onnxruntime::TensorTypeBase::GetElementType
onnxruntime::TensorTypeBase::IsCompatible
onnxruntime::Tile::Compute
onnxruntime::TopkOpset11ConstructorCommon
onnxruntime::ToUTF8String
onnxruntime::ToWideString
onnxruntime::TransformerMemcpyImpl::ProcessDefs
onnxruntime::TransformerMemcpyImpl::ProcessInitializers
onnxruntime::TransformerMemcpyImpl::ProcessInitializers::<lambda_055b4d24f8a1f4b549310d8384e8330c>::operator ()
onnxruntime::Transpose::Compute
onnxruntime::TransposeBase::TransposeBase
onnxruntime::TransposeOptimizer::ApplyImpl
onnxruntime::TypedDoTransposeEltWise
onnxruntime::Unsqueeze::Compute
onnxruntime::UnsqueezeBase::PrepareCompute
onnxruntime::UnsqueezeBase::UnsqueezeBase
onnxruntime::UnsqueezeElimination::Apply
onnxruntime::UntypedExpand
onnxruntime::UpdateConsumerCount
onnxruntime::UpdateSubgraphsWithinFunctionBody
onnxruntime::utils::BatchOrCopyMLValue
onnxruntime::utils::CalculateStaticCopyInfoForFeed
onnxruntime::utils::CalculateStaticCopyInfoForFeeds
onnxruntime::utils::ConstantNodeProtoToTensorProto
onnxruntime::utils::ContainerChecker::ContainerChecker
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,__int64,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,__int64> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,double,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,double> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,__int64> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,double> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::vector<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > >,class std::allocator<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::vector<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > >,class std::allocator<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > > > >::check
onnxruntime::utils::CopyInputsAcrossDevices
onnxruntime::utils::CopyOneInputAcrossDevices
onnxruntime::utils::CopyOutputsAcrossDevices
onnxruntime::utils::CopySparseData
onnxruntime::utils::DenseTensorToSparseTensorProto
onnxruntime::utils::detail::CopyLittleEndian
onnxruntime::utils::ExecuteGraph
onnxruntime::utils::ExecuteGraphImpl
onnxruntime::utils::FinalizeCopyInfoForFeeds
onnxruntime::utils::FinalizeCopyInfoForFetches
onnxruntime::utils::FindMemoryInfoForValue
onnxruntime::utils::GetElementTypeFromOptionalSeqTensor
onnxruntime::utils::GetElementTypeFromOptionalTensor
onnxruntime::utils::GetFileContent
onnxruntime::utils::GetMLDataType
onnxruntime::utils::GetShape
onnxruntime::utils::InitializeFeedFetchCopyInfo
onnxruntime::utils::mltype_dispatcher_internal::CallableDispatchableHelper::CheckCalledOnce
onnxruntime::utils::mltype_dispatcher_internal::UnsupportedTypeDefaultPolicy<class onnxruntime::common::Status>::operator ()
onnxruntime::utils::SparseTensorProtoToDenseTensorProto
onnxruntime::utils::TensorProtoToMLValue
onnxruntime::utils::TensorProtoToTensor
onnxruntime::utils::UnpackInitializerData
onnxruntime::utils::UnpackTensorWithExternalDataImpl
onnxruntime::ValidateCommonFastReduce
onnxruntime::ValidateFastReduceKR
onnxruntime::ValidateFastReduceKRK
onnxruntime::ValidateFastReduceRK
onnxruntime::ValidateFastReduceRKR
onnxruntime::ValidateKeepDims
onnxruntime::ValidateMustBeOverloaded
onnxruntime::ValidateNoTransposeReduce
onnxruntime::ViewerFunctionImpl::Body
onnxruntime::ViewerFunctionImpl::MutableBody
onnxruntime::WritableSliceIterator<__int64>::Init
onnxruntime::WritableSliceIterator<double>::Init
onnxruntime::WritableSliceIterator<float>::Init
onnxruntime::WritableSliceIterator<int>::Init
onnxruntime_profile_
onnxruntime_providers_cuda.dll
onnxruntime_providers_dnnl.dll
onnxruntime_providers_migraphx.dll
onnxruntime_providers_openvino.dll
onnxruntime_providers_rocm.dll
onnxruntime_providers_shared.dll
onnxruntime_providers_tensorrt.dll
ool)u
Op registered for 
Op with name (
op_kernel_info.GetAttr("axis", &axis_).IsOK()
op_kernel_info.GetAttr<float>("epsilon", &epsilon_).IsOK()
op_kernel_info.GetAttr<int64_t>("axis", &axis_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("largest", &largest_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("sorted", &sorted_temp).IsOK()
op_name
op_type
opaque
Opaque type is not a non_tensor type!!!
opaque(
opaque_type
open file 
OpenVINO_GPU
OpenVINOExecutionProvider
Operands
Operator '
OPH;OPH
OpKernel was null
opset id is null. Invalid ORT format model.
opset import domain is null. Invalid ORT format model.
opset_import_iter != domain_to_version_map.end()
opt_k_transpose perm attribute not matched
Optimization after layout transformation failed: 
optimization.enable_gelu_approximation
optimization.minimal_build_optimizations
optimizer_utils::GetClipConstantMinMax(state.graph, *activation, min, max)
Optional
optional
Optional 1D bias to be added to the convolution, has size of M.
Optional 1D bias to be added to the convolution, has size of M. Bias must be quantized using scale = x_scale * w_scale and zero_point = 0
Optional initial value of the cell. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
Optional initial value of the hidden. If not specified - assumed to be 0. It has shape `[num_directions, batch_size, hidden_size]`.
Optional input list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor if 'noop_with_empty_axes' is false, else act as an Identity op when 'noop_with_empty_axes' is true. Accepted range is [-r, r-1] where r = rank(data).
Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N).
Optional input tensor C. If not specified, the computation is done as if C is a scalar 0. The shape of C should be unidirectional broadcastable to (M, N). Its type is int32_t and must be quantized with zero_point = 0 and scale = alpha / beta * a_scale * b_scale.
Optional is expected to have an output.
Optional is expected to have either an input or the type attribute set.
Optional length of each output. Values should be >= 0.Sum of the values must be equal to the dim value at 'axis' specified.
Optional list of output lengths (see also arg 'split')
Optional position subgraph nodes number of outputs unexpected.
Optional position subgraph nodes Where node is expected to be the parent of Reshape.
Optional rescaling weight tensor. If given, it has to be a tensor of size C. Otherwise, it is treated as if having all ones.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]` 
Optional tensor specifying lengths of the sequences in a batch. If not specified - assumed all sequences in the batch to have length `seq_length`. It has shape `[batch_size]`.
Optional tensor specifying lengths of the sequences in a batch. If this input is not specified, all sequences are assumed to be of the maximum sequence length (the dimension of the sequence axis of the scan_input tensors).
Optional Type mismatch. Expected: 
optional(
optional(seq(tensor(bfloat16)))
optional(seq(tensor(bool)))
optional(seq(tensor(complex128)))
optional(seq(tensor(complex64)))
optional(seq(tensor(double)))
optional(seq(tensor(float)))
optional(seq(tensor(float16)))
optional(seq(tensor(int16)))
optional(seq(tensor(int32)))
optional(seq(tensor(int64)))
optional(seq(tensor(int8)))
optional(seq(tensor(string)))
optional(seq(tensor(uint16)))
optional(seq(tensor(uint32)))
optional(seq(tensor(uint64)))
optional(seq(tensor(uint8)))
optional(tensor(bfloat16))
optional(tensor(bool))
optional(tensor(complex128))
optional(tensor(complex64))
optional(tensor(double))
optional(tensor(float))
optional(tensor(float16))
optional(tensor(int16))
optional(tensor(int32))
optional(tensor(int64))
optional(tensor(int8))
optional(tensor(string))
optional(tensor(uint16))
optional(tensor(uint32))
optional(tensor(uint64))
optional(tensor(uint8))
optional_type
OptionalGetElement
OptionalGetElement must have an input element.
OptionalHasElement
OptionalHasElement is expected to have 1 input.
OptionalHasElement is expected to have 1 output.
or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.
org.pytorch.aten
Original tensor
OriginalFilename
ORT config json from the model: 
ORT model verification failed.
ORT optimization- Force fallback to CPU execution for node: 
ort_config
ORT_LOAD_CONFIG_FROM_MODEL
ort_value.Fence() == nullptr
ort_value.IsAllocated()
ort_value.IsTensor()
ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < alloc_plan.size()
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < all_values_size_
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < alloc_plan.size()
ort_value_name_idx_map.MaxIdx() > -1
OrtApis::CreateOpaqueValue
OrtApis::FillSparseTensorBlockSparse
OrtApis::FillSparseTensorCoo
OrtApis::FillSparseTensorCsr
OrtApis::GetOpaqueValue
OrtApis::GetTensorTypeAndShape
OrtApis::UseBlockSparseIndices
OrtApis::UseCooIndices
OrtApis::UseCsrIndices
OrtCreateMapMLValue
OrtCreateValueImplMapHelper
OrtCreateValueImplSeqHelper
OrtEnv::Release
OrtGetApiBase
OrtMemoryInfo is null
OrtMemoryInfo:[
ORTMH
OrtProgrammingProjection
OrtSessionOptionsAppendExecutionProvider_CPU
OrtSessionOptionsAppendExecutionProvider_Cuda: Failed to load shared library
OrtSessionOptionsAppendExecutionProvider_Rocm: Failed to load shared library
OrtSessionOptionsAppendExecutionProvider_TensorRT: Failed to load shared library
OrtValue has not been allocated so can't be sliced.
OrtValue indexes should have been populated.
OrtValue is TensorSequence type but has no element Tensor DataType.
OrtValue shape verification failed. Current shape:
OrtValue should contain a Tensor or a Sparse Tensor
OrtValue::Get
OrtValue::GetMutable
other_error
other_sum_input != nullptr
oublu
out of index
out_of_range
Outer index count must be rows + 1 or zero. Got: 
Outer indices must be M + 1. Got: 
Outer scope node arg name '
outer_num == (rows + 1)
outer_scope_node_arg != nullptr
outer_scope_node_args_consumed.empty()
Output
output
Output 
output = Cast (input)
output = Cast (X_greater)
output = NegativeLogLikelihoodLoss <reduction : string = @reduction, ignore_index : int = @ignore_index> (X_Log, labels)
output = NegativeLogLikelihoodLoss <reduction : string = @reduction, ignore_index : int = @ignore_index> (X_Log, labels, weights)
output == output_end
output and sum shape must match
Output buffer allocation failed
output buffer is too small. Use GetStringTensorDataLength.
Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #1: Y, running_mean, running_var (training_mode=True)
Output case #2: Y (test mode)
Output case #2: Y (training_mode=False)
Output channels M is not divisible by group.
output count mismatch, expected 2 outputs to be present for TopK operator
Output data after scaling
Output data tensor from average or max pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes. Floor value of the dimension is used
Output data tensor from Lp pooling across the input tensor. Dimensions will vary based on various kernel, stride, and pad sizes.
Output data tensor from pooling across the input tensor. Dimensions will be N x C x 1 x 1
Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. The first two dimensions of output shape are the same as the input (N x C), while the other dimensions are all 1.
Output data tensor from pooling across the input tensor. The output tensor has the same rank as the input. with the N and C value keep it value, while the otherdimensions are all 1.
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, and pad lengths.
Output data tensor that contains the result of the convolution. The output dimensions are functions of the kernel size, stride size, pad lengths and group count. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
Output data tensor that contains the result of the unpooling.
Output data tensor.
Output data.
Output data. If strings are input, the output values are integers, and vice versa.
Output edge count not expected for Add or MatMul in path v
Output edge count not expected for mask nodes
Output edge count not expected for nodes in gemm gather path
Output edge count not expected for nodes in gemm path
Output edge count not expected for nodes in past subgraph
Output edge count not expected for nodes in path 1 of position shape.
Output edge count not expected for nodes in path 1 of unidirectional mask
Output edge count not expected for nodes in path 2 of position shape.
Output edge count not expected for nodes in path v
Output edge count not expected for nodes in path1.
Output edge count not expected for Softmax
Output edge count not expected for squeeze_2/slices2/shape2 of unidirectional mask
Output edge count not expected for unsqueeze2 of unidirectional mask
Output edge count not expected for unsqueeze3 of unidirectional mask
output edges
Output element in the optional input.
output name cannot be empty
Output OrtValue has not been created for loop state variable output 
Output scale. It's a scalar, which means a per-tensor/layer quantization.
Output sequence that contains the inserted tensor at given position.
Output sequence that has the tensor at the specified position removed.
Output size mismatch.
Output tensor
output tensor
Output tensor (same size as X)
Output tensor at the specified position in the input sequence.
Output tensor containing the same value of the provided tensor.
Output tensor must have at least 2 dimensions
Output tensor of [N, C * blocksize * blocksize, H/blocksize, W/blocksize].
Output tensor of [N, C/(blocksize * blocksize), H * blocksize, W * blocksize].
Output tensor of random values drawn from normal distribution
Output tensor of random values drawn from uniform distribution
Output tensor of same shape and type as input.
Output tensor of shape (M, N).
Output tensor of shape specified by 'input'.If attribute 'value' is specified, the value and datatype of the output tensor is taken from 'value'.If attribute 'value' is not specified, the value in the output defaults to 0, and the datatype defaults to float32.
Output tensor of the same dimension and type as tensor input. output_dim[i] = input_dim[i] * repeats[i]
Output tensor of the same type and shape as the input tensor.
Output tensor of the same type as the input tensor. Shape of the output is * x M, where '*' is the shape of input indices, and 'M' is the embedding size.
Output tensor of the same type as 'x' with cumulative sums of the x's elements
Output tensor produced by casting the first input tensor to have the same type as the second input tensor.
Output tensor with clipped input elements
output tensor with shape (batch_size, num_heads, new sequence_length, head_size)
Output tensor with shape [batch_size, sample_size], where sample_size is the number of times to sample. Each value along the axis zero represents the outcome of the corresponding sample in a batch.
Output tensor with the same shape as input with type specified by the 'to' argument
Output tensor, same shape as input tensor T1.
Output tensor, which has the shape and type as input tensor
Output tensor.
Output tensor. Same dimension as inputs.
Output type is determined by the specified 'values_*' attribute.
Output type must be int32 or int64
Output vector incorrectly sized: output_names.size(): 
Output vector pointer is NULL
Output was expected to have tensor type. Got 
Output Y's scale. It's a scalar, which means a per-tensor/layer quantization.
Output Y's zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Output zero point. Default value is 0 if it's not specified. It's a scalar, which means a per-tensor/layer quantization.
Output zero point. It's a scalar, which means a per-tensor/layer quantization.
Output:
output_channels <= nchwc_output_channels
output_height
output_mlvalue
output_names_to_nodeinfo.empty()
output_node.OutputDefs().size() == 1
output_padding
output_ptr
output_sequence
output_shape
'output_shape' must be rank 1 tensor.
'output_shape' must have same number of elements as the shape of input tensor X.
output_size
output_type_shape
output_width
OutputDebugStringW
outputs
Outputs from Scan are not optional and should never be null.
outputs...
Overall chunks summary:
OxH;Oxu
p ;n 
p 9O(t
p AWH
P H+P
P I+P
p L+p
p UWATAVAWH
p value of the Lp norm used to pool over the input data, default is 2.0.
p value of the Lp norm used to pool over the input data.
p WATAUAVAWH
p WAVAWH
P(H;P0t
p.second
p:@M0
p\`} 
P^@ID
P^`ID
p_fetches->size(): 
p_int < base_int + memory_size_
p_int >= base_int
p_kernel_def
p_ml_value
p_op_kernel
p_provider
p_type != nullptr
p`r(p
p~|:]
p~zp|
P0+d+
P0EME
P0IcM0H
P0R4PY
p2`}/
P6 JD
p60$E
P6PiD
pA\^[
PA\_[
PA]_[
pA^][
PA^^[
PA^^]
PA^_^
pA^_^
PA^_^
pA^_^
PA^_^
pA^_^[]
PA^_^[]
pA^_^[]
PA^_^][
pA^_^][
PA^_^][
pA^_^][
PA^_^][
pA^_^][
PA^_^][
pA^_^][
PA^_^][
pA^_^][
PA^_^][
pA^A]]
PA__[
PA__^
pA__^
PA_A]A\][
PA_A^]
PA_A^^][
PA_A^_
PA_A^_][
PA_A^_^[
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
PA_A^A\][
PA_A^A\_^
pA_A^A\_^[]
PA_A^A\_^][
pA_A^A\_^][
PA_A^A\_^][
pA_A^A\_^][
PA_A^A\_^][
PA_A^A]_^][
PA_A^A]A\_
PA_A^A]A\_^[
pA_A^A]A\_^[
PA_A^A]A\_^[
pA_A^A]A\_^[
PA_A^A]A\_^[
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
Pad should be smaller than kernel.
pad_token_id
pad_value
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute.
Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.
Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0.The value represent the number of pixels added to the beginning and end part of the corresponding axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number ofpixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaultsto 0 along start and end of each spatial axis.
padding_idx
padding_mode
paddings
Pads has incorrect number of values
'pads' input must be a 1D (shape: [2 * input_rank]) tensor of type int64
'pads' input must be a 1D (shape: [2 * n_input_dims]) tensor of type int64
'pads' input must be a 1D (shape: [input_rank]) or 2D tensor (shape: [1, input_rank]) of type int64
pads[dim] < kernel_shape[dim] && pads[dim + kernel_shape.size()] < kernel_shape[dim]
Parallel execution mode does not support the CUDA Execution Provider. 
Parallel execution mode does not support the DML Execution Provider. 
Parallel mode
ParallelExecutor::Execute
parameter_size
ParametricSoftplus
parse
parse error
parse_error
ParseData type mismatch for tensor: 
parsing 
PartA_PrivTags
Pass 1 to enable broadcasting
Pass CheckNodesInPathK
Pass CheckNodesInPathQ
Pass CheckNodesInPathV
Pass MatchGemmSubgraph
Pass MatchInputMaskSubgraph
Pass MatchInputMaskSubgraphDistilBert
Pass MatchPastSubgraph
Pass MatchUnidirMaskSubgraph
Pass ValidateGemmInitializer
past state for key and value with shape (2, batch_size, num_heads, past_sequence_length, head_size).
past_k_gather indices != 0
past_k_transpose perm attribute not matched
past_v_gather and past_k_gather does not have same past input
past_v_gather indices != 1
patches
PathCchRemoveBackslash
PathCchRemoveFileSpec
Performs element-wise binary {name} on 8 bit data types (with Numpy-style broadcasting support).
perm.size() == gsl::narrow_cast<size_t>(shape_proto->dim_size())
perm: 
Permutation entry 
Permutation length 
Phttp://www.microsoft.com/pkiops/certs/Microsoft%20Time-Stamp%20PCA%202010(1).crt0
Please fetch output tensor with specified shape.
Please register the allocator as OrtDeviceAllocator even if the provided allocator has arena logic built-in. OrtArenaAllocator is reserved for internal arena logic based allocators only.
plugin_version
points_.empty()
pool_attrs_.kernel_shape.size() == 2
pool_int64s
pool_strings
Pooled size.
pooled_shape
pooled_size
Popularity of each node, used for performance and may be omitted.
position
Position embedding data type shall be float or float16.
Position embedding shape is not expected.
Position embedding shape not matched.
Position in the sequence where the new tensor is inserted. It is optional and default is to insert to the back of the sequence. Negative value means counting positions from the back. Accepted range in `[-n, n]`, where `n` is the number of tensors in 'input_sequence'. It is an error if any of the index values are out of bounds. It must be a scalar(tensor of empty shape).
Position of the tensor in the sequence. Negative value means counting positions from the back. Accepted range in `[-n, n - 1]`, where `n` is the number of tensors in 'input_sequence'. It is an error if any of the index values are out of bounds. It must be a scalar(tensor of empty shape).
position_ >= 0 && position_ < sequence_length_
position_embedding
position_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
position_embedding_quant
position_embedding_scale
position_embedding_zero_point
position_embeddings
position_ids
positive
post_transform
Pow takes input data (Tensor<T>) and exponent Tensor, and
pred_tokens
Predicted token ids from aggressive decoding
prefix_vocab_mask
PrefixShape = Slice (XShape, Zero1D, Axis1D)
PRelu
present
present state for key and value with shape (2, batch_size, num_heads, past_sequence_length + sequence_length, head_size)
present_k_transpose perm attribute not matched
present_k_unsqueeze axes value not expected
present_v_unsqueeze axes value not expected
prev_suffix_match_idx
Previous entry was not terminated.
Previous suffix match index
prob_a
prob_b
Processed beam scores for each vocabulary token at each generation step.Beam scores consisting of log softmax scores for each vocabulary token and sum of log softmax of previously generated tokens in this beam.Shape is (max_length - sequence_length, batch_size, num_beams, vocab_size)
Processed_STD
ProcessInfo
produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,
product
ProductName
ProductVersion
Profiler is disabled.
Profiler not started yet
projected_index.size() > 0
proto != nullptr
Protobuf parsing failed.
Protobuf serialization failed.
Provided allocator is null
provided axis. The resulting tensor has the same rank as the input if keepdims equal 1.
Provided OrtMemoryInfo is null
Provided type is not an optional sequence tensor
Provided type is not an optional tensor
provider
Provider 
Provider_SetHost
ProviderH9H
pRr(p
PXTjV
PyramidROIAlign_TRT
Q +Q0
q and v are not from same Split node
Q HcZ 3
q L+q
q root should be layer normalization
Q(+Q0
q\Q17
q_matmul and q_add shape not matched
q_or_dq_input_defs.size() >= 2
q_reshape const not matched
q_transpose perm attribute not matched
q_weight
Q0H+Q(H
q8+q(M
Q8H;Q@t
QAttention
QbQ}X
Qbr}X
QbreH
qdq_s8_to_u8_quant
qdq_s8_to_u8_zp_conversion
QDQFinalCleanupTransformer
QDQPropagationTransformer
QDQS8ToU8Transformer
QDQSelectorActionTransformer
QEmbedLayerNormalization
QEX82q'
QGemm
qk_div const not matched.
qkv_bias
qkv_hidden_sizes
qkv_hidden_sizes should have 3 elements
qkv_weights
QLinear
QLinearAdd
QLinearAveragePool
QLinearCL9
QLinearConcat
QLinearConv
QLinearGlobalAveragePool
QLinearLeakyRelu
QLinearLeakyRelu takes quantized input data (Tensor), an argument alpha, and quantize parameter for output,
QLinearMatMul
QLinearMul
QLinearReduceMean
QLinearSigmoid
QLinearSigmoid takes quantized input data (Tensor), and quantize parameter for output, and produces one output data 
Quant GEMM format: AIsSigned(
Quantized GEMM only support alpha equal to 1.0f and beta equal to 0.0f or 1.0f
Quantized matrix multiply results from a * b
Quantized output tensor
QuantizeLinear
query
QueryPerformanceCounter
r!fff
R$"&*$8"b(8**(l,@.*,
r$H9y
R_scale
R_zero_point
R0IcM0H
R0P0N
r1w/H
r3Hc>H
r6w4HcC(H
RaiseFailFastException
RandomNormal
RandomNormalLike
RandomUniform
RandomUniformLike
Range
Rank = Size (XShape)
Rank 1 tensor containing exactly two elements, in the format [off_value, on_value], where 'on_value' is the value used for filling locations specified in 'indices' input tensor, and 'off_value' is the value used for filling locations other than those specified in 'indices' input tensor. 
Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length alone the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
Rank 1 tensor of booleans to indicate which slices or data elements to be selected. Its length can be less than the input length along the axis or the flattened input size if axis is not specified. In such cases data slices or elements exceeding the condition length are discarded.
rank must be greater than axis
Rank of input 
Ranks inferred (
Ranks of input data are different, cannot concatenate them. expected rank: 
ratio
Ratio of Dropout must be a scalar.
raw_data
rbb}H
RbQ}X
ReadExternalRawData() failed: 
ReadFile
ReadFile 
Reading the provided model for the ORT config
Received invalid value for allow_spinning. Valid values are 0 or 1
Received invalid value for arena extend strategy. Valid values can be either 0, 1 or -1.
Received invalid value of arena_extend_strategy 
Received negative size from stat call
Received null OrtThreadingOptions
Received nullptr for custom registry
Received nullptr for exec provider
Received nullptr for name.
Received nullptr for OrtValue.
Received OrtValue is not a tensor. Only tensors are supported.
Reciprocal
Recurrent
Redmond1
reduced
Reduced output tensor with integer data type.
Reduced output tensor.
reduced_scale
reduced_zero_point
ReducedShape = Concat <axis = 0> (PrefixShape, SuffixShape)
ReduceL1
ReduceL2
ReduceLogSum
ReduceLogSumExp
ReduceMax
ReduceMean
ReduceMin
ReduceProd
ReduceSum
ReduceSumInteger
ReduceSumSquare
reduction
Reduction on all axes, output size should be 1.
RegisterCustomOps
RegisterCustomOpsLibrary: Entry point RegisterCustomOps not found in library
RegisterCustomOpsLibrary: Failed to load library
Regression outputs (one per target, per example).
Regression outputs (one score per target per example).
Release_State_
ReleaseSRWLockExclusive
ReluQuantRewrite
Remainder tensor
remainderf
RemoveDirectory() failed - path: 
RemoveDirectoryW
RemoveDuplicateCastTransformer
Removing initializer '
Removing NodeArg '
reorder
ReorderInput
ReorderOutput
'repeat' input tensor must be 1 dimensional
'repeat' input tensor must have the same length as the 'input' tensor
repeats
'Repeats' input has incorrect number of values. The number of values in 'repeats' must be equal to the number of input dimensions.
'Repeats' input must be 1D tensor of type int64
repetition_penalty
replaced_value_float
replaced_value_int64
Replaying the captured 
representative.output_index != kInvalidOutputIndex
Requested 
requested_shape[i] >= -1
Required attribute '
Required attribute axis is missing
Required input at index 
Required output at index 
reserved_chunks_.find(ptr) == reserved_chunks_.end()
Reserving memory in BFCArena for 
reshape
Reshape
reshape initializer value is not expected
reshaped
Reshaped data.
Reshaped tensor with same data as input.
ReshapeFusion
residual
Resize
Resolve subgraph failed:
result
Result buffer is not large enough
Result tensor.
Result, has same dimensions and type as A
Result, has same element type as two inputs
Result, has same shape and type as input
Result, has same type as input, with H and W dimensions reduced.
Return elements, either from X or Y, depending on condition.
ReturnHr
reused != reused_for
reverse
ReverseSequence
Right input tensor for the logical operator.
right operand cannot broadcast on dim 
right.NumDimensions() == 2
rintf
RknpuExecutionProvider
ROCMExecutionProvider
ROI pool output shape (height, width).
RoI pooled output 4-D tensor of shape (num_rois, channels, pooled_shape[0], pooled_shape[1]).
RoI pooled output, 4-D tensor of shape (num_rois, C, crop_height, crop_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
RoI pooled output, 4-D tensor of shape (num_rois, C, output_height, output_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
RoiAlign
RoIs (Regions of Interest) to pool over. Should be a 2-D tensor of shape (num_rois, 5) given as [[batch_id, x1, y1, x2, y2], ...].
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[x1, y1, x2, y2], ...]. The RoIs' coordinates are in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[y1, x1, y2, x2], ...]. The RoIs' coordinates are normalized in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
rois input tensor has wrong dimension
RoIs tensor must have 2 dimensions
Round
round_prefer_floor
rr*t(v:xXz
R's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
R's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
run_options.run_log_severity_level >= 0 && run_options.run_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
running (training) or estimated (testing) mean tensor of shape (C).
running (training) or estimated (testing) variance tensor of shape (C).
Running with tag: 
running_mean
running_mean = input_mean * momentum + current_mean * (1 - momentum)
running_var
running_var = input_var * momentum + current_var * (1 - momentum)
RUNTIME_EXCEPTION
RuntimeError
RuntimePerf
runtimeVersion
rztJv(t
S D9R0t
S H;S(H
S H;S(t
S H+S
s HcD$ H
's number of inputs is different from function body graph's number of input.
's number of outputs is different from function body graph's number of outputs.
s WATAUAVAWH
s WAVAWH
s(+s0
s(D+s0D
S@H;SHt
s\fff
s~H;_
S0Q0O
SafeIntExceptionHandler<class onnxruntime::OnnxRuntimeException>::SafeIntOnDivZero
SafeIntExceptionHandler<class onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow
SAME_LOWER
SAME_LOWH9
SAME_UPPER
SAME_UPPL9
sample_size
SampleOp
sampling_ratio
SATAUAWH
SATAWH
SaveAttributeOrtFormat: Unsupported attribute type: 
Saved inverse standard deviation used during training to speed up gradient computation.
Saved inverse standard variance used during training to speed up gradient computation.
Saved mean used during training to speed up gradient computation
Saved mean used during training to speed up gradient computation.
Saved mean used during training to speed up gradient computation. Should not be used for testing.
Saved variance used during training to speed up gradient computation.
Saved variance used during training to speed up gradient computation. Should not be used for testing.
saved_mean
saved_var
SaveMLValueNameIndexMapping
SaveValueInfoOrtFormat: value_info_proto for 
Saving initialized tensors.
sbetu=
SbreH
Scalar multiplier for input tensor C, the default value is 1.0.
Scalar multiplier for input tensor C.
Scalar multiplier for the product of input tensors A * B, the default value is 1.0.
Scalar multiplier for the product of input tensors A * B.
Scalar multiplier for the product of the input tensors.
Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor. The values in the 'indices' input tensor are expected to be in the range [0, depth). In case 'depth' is of non-integer type, it will be casted to int64 before use.
Scalar specifying the number of classes in one-hot tensor. This is also the size of the one-hot dimension (specified by 'axis' attribute) added on in the output tensor. The values in the 'indices' input tensor are expected to be in the range [-depth, depth-1]. In case 'depth' is of non-integer type, it will be casted to int64 before use.
Scalar. Exclusive upper limit for the range of output values.
Scalar. First entry for the range of output values.
Scalar. Value to step by.
Scale
scale
Scale and Zero-point must be a scalar
Scale and Zero-point must be of rank 1
Scale and Zero-point must be of rank 1 and the number of elements should be equal to the number of rows of the corresponding input.
Scale for 1D beta tensor
Scale for 1D gamma tensor
Scale for doing quantization to get 'y'. It can be a scalar, which means per-tensor/layer quantization, or a 1-D Tensor for per-axis quantization.
Scale for doing quantization to get 'y'. It could be a scalar or a 1-D tensor,which means a per-tensor or per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Scale for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization.
Scale for input 'x'. It can be a scalar, which means a per-tensor/layer dequantization, or a 1-D tensor for per-axis dequantization.
Scale for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Scale for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Scale for position embeddings
Scale for segment embeddings
Scale for word embeddings
scale must be 1D tensor with size 
'Scale' must contain exactly 2 values - (height, width)
Scale of output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.
scale of quantized input a
Scale of quantized input 'A'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.
Scale of quantized input 'A'. It is a scalar,which means a per-tensor quantization.
scale of quantized input b
Scale of quantized input 'B'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
scale of quantized input tensor. It's a scalar, which means a per-tensor/layer quantization.
Scale of quantized input 'X'. It must be a scalar.
scale of quantized output y
Scale of quantized output 'Y'. It must be a scalar.
scale of weight scale. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization
Scale tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
Scale tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Scale tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
Scale tensor of shape (C).
Scale tensor.
scale.Shape().NumDimensions() == 1 && scale.Shape()[0] == broadcast_dim
scale_grad_by_freq
Scale2D = Flatten <axis = 0> (Scale)
Scaled = Mul (NormalizedT, Scale2D)
Scaled output data.
scaledtanh
ScaledTanh
Scaler
scales
Scaling parameter.
Scaling value
Scan 'body' subgraph outputs should all be tensors but output 
Scan input 
Scan inputs have inconsistent sequence lengths. Previous value was 
scan_input_axes
scan_input_directions
scan_output_axes
scan_output_directions
Scatter
ScatterElements
ScatterND
Schema error: 
schemaVersion
Score threshold value.
score_activation
score_threshold
scores
scores must be a 3D tensor.
scores_out
scores_tensor
Second input does not have rank 2
Second input of Gather in path 1 of position shape should be a constant with value 0.
Second input of Gather in path 2 of position shape should be a constant with value 1.
Second input of Gather should be a constant with value 1. 
Second input operand for the logical operator.
Second input tensor has wrong dimension
Second operand, amounts of shift.
Second operand, power of the exponent.
Second operand.
Second operand. With broadcasting can be of smaller size than A. If broadcasting is disabled it should be of the same size.
Second set of probability coefficients. This array must be same size as prob_a.<br>If these are provided then output Z are probability estimates, otherwise they are raw scores.
Second, multiply by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.<br>Must be same length as 'offset'
Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.
Segment id is not valid. 
segment_embedding
segment_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
segment_embedding_scale
segment_embedding_zero_point
segment_ids
segment_ids input shall be 2 dimensions
select_last_index
selected indices from the boxes tensor. [num_selected_indices, 3], the selected index format is [batch_index, class_index, box_index].
Selected output data as an array
selected_indices
separators
seq(A
seq(map(int64, float))
seq(map(string, float))
seq(tensor(bfloat16))
seq(tensor(bool))
seq(tensor(complex128))
seq(tensor(complex64))
seq(tensor(double))
seq(tensor(float))
seq(tensor(float16))
seq(tensor(int16))
seq(tensor(int32))
seq(tensor(int64))
seq(tensor(int8))
seq(tensor(string))
seq(tensor(uint16))
seq(tensor(uint32))
seq(tensor(uint64))
seq(tensor(uint8))
seq_lengths
Sequence
Sequence enclosing the input tensors.
Sequence is missing type entry for its element
Sequence of (Tensor, Scale, ZeroPoint) tuples. The type is sequence of (T8, TF, T8).
Sequence of tensors for concatenation
sequence_lens
'sequence_lens' must have rank of 1
sequence_type
SequenceAt
SequenceConstruct
SequenceConstruct is expected to have at least 1 input.
SequenceEmpty
SequenceErase
SequenceInsert
SequenceLength
sequences
Sequences must have tensors of the same data type. There was at least one tensor in the input that was different.
sequences_scores
Sequential mode
SequentialExecutor::Execute
Serialization error. Graph attribute was serialized without Graph instance
Serialization of fused function body is not currently supported, 
Serialized version info is null. Invalid ORT format model.
Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.
Session
session-
Session has already been initialized.
Session not initialized.
Session successfully initialized.
Session was not initialized
session.disable_prepacking
session.disable_quant_qdq
session.dynamic_block_base
session.enable_quant_qdq_cleanup
session.inter_op.allow_spinning
session.intra_op.allow_spinning
session.load_model_format
session.qdqisint8allowed
session.save_model_format
session.set_denormal_as_zero
session.use_device_allocator_for_initializers
session.use_env_allocators
session.use_ort_model_bytes_directly
session_env.EnvCreatedWithGlobalThreadPools()
session_initialization
session_logger != nullptr
session_options
session_options_.session_log_severity_level >= 0 && session_options_.session_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
session_state
SessionCreation
SessionCreationStart
sessionId
SessionOptionsAppendExecutionProvider_MIGraphX: Failed to load shared library
SessionOptionsAppendExecutionProvider_OpenVINO: Failed to load shared library
SessionOptionsAppendExecutionProvider_Tensorrt: Failed to load shared library
SessionState for subgraphs is null. Invalid ORT format model.
SessionState is null. Invalid ORT format model.
SessionState should have saved the KernelCreateInfo prior to this running. NodeIndex:
SetFilePointerEx
SetFilePointerEx 
SetGraphAndCreateKernels must be called prior to GetExecutionInfo.
SetLastError
SetThreadAffinityMask
SetThreadDescription
setting data_type field (tensor name: 
Setting enable_profiling to 
Setting execution_mode to 
Setting graph_optimization_level to ORT_DISABLE_ALL
Setting graph_optimization_level to ORT_ENABLE_ALL
Setting graph_optimization_level to ORT_ENABLE_BASIC
Setting graph_optimization_level to ORT_ENABLE_EXTENDED
Setting inter_op_num_threads to 
Setting intra_op_num_threads to 
SetupSubgraphExecutionInfo should only be called once for each subgraph.
setvbuf
Shape
shape
shape != nullptr
shape && sp_tensor.DenseShape() == *shape
shape && tensor.Shape() == *shape
shape as a contiguous subset of the first tensor's shape. The starting of the
Shape inference error(s): 
'shape' input must be 1D tensor
Shape input must be a one-dimensional tensor.
shape is invalid
Shape mismatch attempting to re-use buffer. 
shape of layer norm bias tensor not expected
shape of left-hand-side argument. When broadcasting is specified, the second
Shape of the input tensor
shape.Size() must >=0
shape_.Size() == new_shape.Size()
shape_data_tensor.Shape().GetDims().size() == 1
Shape3D
shapeTensor->Shape().NumDimensions() == 1
sHL;sPu
Should be unreachable if CanRemoveNodeAndMergeEdges is in sync with the logic here.
Should not have entry in kernel create info with nullptr for kernel_def
Shouldn't be possible to have NodeArgs that haven't been handled already.
Shrink
sigmoid
Sigmoid
signal_ndim
SimplifiedLayerNormalization
SimplifiedLayerNormFusion
single_node_compute_func should have 1 element.
size != 0 && (input_shape.Size() % size) == 0
size >= 0
size is different
Size mismatch
Size mismatch for kernel create info node indexes and hashes. Invalid ORT format model.
Size mismatch validating subgraph inputs. Got 
Size mismatch:
Size mismatch: feed_names has 
size overflow
size_ == size
sizes
sJfff
skip is expected to have same shape as input
SkipLayerNormalization
SkipLayerNormFusion
Sleep
SleepConditionVariableSRW
sLfff
Slice
Slice does not have enough number of inputs
Slice ends is less than INT_MAX
Slice op must have either three, four or five inputs.
Slice parameter is not expected. Input index:
Sliced data tensor.
slope
Slope tensor. If `Slope` is of size 1, the value is sharedacross different channels
Slope tensor. The shape of slope can be smaller then first input X; if so, its shape must be unidirectional broadcastable to X
snprintf() failed with return value: 
snprintf_result > 0
snprintf_result > 0 && gsl::narrow_cast<size_t>(snprintf_result) == buffer_span.size() - 1
So disabling it for this session since it uses the DML Execution Provider.
So making the execution mode sequential for this session since it uses the CUDA Execution Provider.
So making the execution mode sequential for this session since it uses the DML Execution Provider.
softmax
Softmax
Softmax attribute axis is expected to be 3
Softmax(input, axis) = Exp(input) / ReduceSum(Exp(input), axis=axis, keepdims=1) 
softmax_axis
SoftmaxCPU inputs N, D and N * D must be < 
SoftmaxCrossEntropyLoss
Softplus
softplus
Softsign
softsign
Some nodes are not included in the topological sort, graph have a cycle.
sorted
source and destination buffer size mismatch
Source and target must both be tensors
source map type missing key type.
source map type missing value type.
source optional type missing element type.
source sequence type missing element type.
SpaceToDepth
Sparse format must not be set. Already contains format: 
Sparse indices int32 data size does not match expected
Sparse indices int64 data size does not match expected
Sparse Indices raw data size does not match expected.
Sparse initializer must have a name. This model is invalid
Sparse Initializer tensor is missing. Invalid ORT format model.
Sparse tensor (
Sparse Tensor does not contain sparse data
Sparse tensor indices (
Sparse tensor initializers must have a non-empty name
sparse tensor type 
Sparse tensor values (
sparse_tensor
SPARSE_TENSOR
sparse_tensor(
sparse_tensor(double)
sparse_tensor(float)
sparse_tensor(int32)
sparse_tensor(int64)
sparse_tensor(uint32)
sparse_tensor(uint64)
sparse_tensor_names_ not in sync with name_to_initial_tensor_
sparse_tensor_names_.count(tensor_name) == 0
sparse_tensor_proto
sparse_tensor_type
sparse_tensors
SPARSE_TENSORS
sparse_value
SparseTensor Allocation failed for size: 
SparseToDenseMatMul
spatial
spatial_scale
specific_subgraph_kernel_create_info_map != subgraphs_kernel_create_info_maps_.end()
Specified axis to insert a dimension
Specified device is not supported.
Specified domain and type names combination does not refer to a registered opaque type
Specified provider is not supported.
Specified shape for output.
Specifies a target value that is ignored and does not contribute to the input gradient. It's an optional value.
Specify batchs of sequence words to embedding
Specify bias of conv
Specify embedding vector of char
Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.
Specify weights of conv
Split
split
Split operator does not support 
split_tensor->Shape().NumDimensions() == 1
SplitToSequence
sqeuclidean
sqrtf
Square = Mul (XU, XU)
SquareOfMean = Mul (Mean2D, Mean2D)
Squeeze
Squeeze_1
Squeeze_11
Squeeze_13
squeeze_mask
squeeze_mask = Squeeze (mask, axes)
squeezed
Src and Dst must be of the same type
src and dst must have same shape and not be rank 0.
src and dst types must match
src.SizeInBytes() == dst.SizeInBytes()
src_node != nullptr
src_node || dst_node
src_tokens
Stacktrace:
start
Start CheckNodesInPathK
Start CheckNodesInPathQ
Start CheckNodesInPathV
Start FuseGptAttention
start in Range operator should be scalar like tensor, yet got shape:
Start MatchGemmSubgraph
Start MatchInputMaskSubgraph
Start MatchInputMaskSubgraphDistilBert
Start MatchPastSubgraph
Start MatchUnidirMaskSubgraph
Start the second Run() to capture the graph. The first one is for necessary memory allocation;The second one is for capturing the graph.
Start ValidateGemmInitializer
start_offset % span_size == 0 && real_end % span_size == 0
start_offset >= 0 && real_end >= 0 && start_offset <= real_end && real_end <= len
Starting indices of corresponding axis in `axes`
starts
Starts and axes shape mismatch
Starts and ends shape mismatch
Starts and steps shape mismatch
Starts must be a 1-D array
starts.size()=
starts_.empty() || start > ends_.back()
starts_.size() == ends_.size()
starts_.size() == ends_.size() + 1
stash_type
static_kv
statistics in inference mode (training_mode=False, default),
Stats: 
status.IsOK()
std::all_of(output_edges.cbegin(), output_edges.cend(), [&src_idx](const GraphEdge& edge) { return edge.src_arg_index == src_idx; })
std::all_of(split_sizes_.cbegin(), split_sizes_.cend(), [](int64_t value) { return value >= 0; })
std::count_if(subgraph_node.InputEdgesBegin(), subgraph_node.InputEdgesEnd(), [input_slot_index](const Node::EdgeEnd& entry) { return entry.GetDstArgIndex() == input_slot_index; }) == 0
std::exception: %hs
StdDev = Sqrt (VarPlusEpsilon)
'step' cannot be 0
'step' cannot be 0 for Slice
'step' value cannot be 0
steps
steps.size()=
stod argument out of range
stof argument out of range
stoi argument out of range
stol argument out of range
stoll argument out of range
stopwords
storage_order
stoull argument out of range
strcmp
strerror
Stride along each axis.
Stride along each spatial axis.
Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis.
Stride along each spatial axis. If not present, the stride defaults to 1 along each axis.
Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.
strides
strides.size() == kernel_shape.size()
string
STRING
string buffer allocation failed
STRING data (tensor name: 
string enum that cases output to be lowercased/uppercases/unchanged. Valid values are "LOWER", "UPPER", "NONE". Default is "NONE"
string literal
string tensor can not have raw data
string tensor can not use pre-allocated buffer
string tensor is not supported for copying between allocators
string too long
String value expected, but not found.
string_data
string_vocabulary
StringFileInfo
StringNormalizer
strings
STRINGS
Strings can only reside in CPU memory
Strings to tokenize
strncmp
strncpy_s
strnlen
strtod
strtof
strtol
strtoll
strtoull
SUATAVAWH
SUAWH
subgraph
Subgraph
subgraph for initialization of encoder and decoder. It will be called once before decoder subgraph.
Subgraph in 'body' produces 
Subgraph input missing type.
Subgraph must have the shape set for all outputs but 
Subgraph SessionState entry for 
Subgraph SessionState for 
Subgraph SessionState was not found for '
Subgraph SessionState was not found for 'body' attribute.
subgraphs_kernel_create_info_maps.find(local_subgraph_kernel_create_info_map_key) == subgraphs_kernel_create_info_maps.end()
subtraction
success
SUCCESS
suffix matching is assumed. 1-dim expansion doesn't work yet.
suffix_match_idx
SuffixShape = ConstantOfShape (NumReducedAxes)
Sum of split values not equal to 'input' dim size on 'axis'. 'axis' dim size=
sum of word_embedding and position_embedding without layer normalization
sum square
Sum Total of in-use chunks: 
sum(sqrd(x_i - x_avg)) / N
sum_node.GetOutputEdgesCount() == 0
sum_output_edge.src_arg_index == 0
Summary of in-use chunks by size: 
Support 2-D matrices only
Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations.
Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations. If index 0 represents the margin pixel, the reflected value at index -1 will be the same as the value at index 1. For location far away from the border, it will keep being reflected until becoming in bound. If pixel location x = -3.5 reflects by border -1 and becomes x' = 1.5, then reflects by border 1 and becomes x'' = 0.5.
Support vector coefficients.
support_vectors
Supported modes: `constant`(default), `reflect`, `edge`
SUVAUH
SUVWATAUAVAWH
SUVWATAVAWH
SUVWAVAWH
SUVWAVH
SUVWH
SUWATAUAVAWH
SUWAUAVH
SUWAWH
SVAUH
SVAVAWH
SVMClassifier
SVMRegressor
SVWATAUAVAWH
SVWAUAVAWH
SVWAVAWH
SVWAVH
SWATAUH
SWAUH
SWAVAWH
sXfff
SxH+SpH
syntax error 
System
system
system error number 
SystemError
t fff
t x"5
t"D85
t"fff
t#fff
t#Hc@(
t$ A^
t$ ATAVAWH
t$ AVH
t$ AWH
t$ D;
t$ D;u
T$ D9j0t
t$ E3
T$ E3
t$ E3
T$ E3
t$ E3
T$ E3
t$ E3
T$ E3
t$ E3
T$ E3
t$ E3
T$ E3
t$ E9t$(t
t$ fff
T$ H;
t$ H;
T$ H;
t$ H;
T$ H;
t$ H;
T$ H;
t$ H;
T$ H;
T$ H;CHt
T$ H+
t$ H9q
t$ HcU
t$ I;
T$ I;
t$ I;
T$ I;
t$ I;
t$ I+
T$ I+T$
T$ Ic
t$ L;
T$ L;
T$ L;l$0
T$ L9
t$ M;
T$ M;
T$ t(H
T$ tMH
t$ UH
t$ UWATAUAVH
t$ UWATAVAWH
t$ UWAUAVAWH
t$ UWAVH
t$ UWAWH
t$ WATAUAVAWH
t$ WAVAWH
t$ WAVH
t$ WH
t$ WHc|$0E3
t$ WL
t$$D;u
t$(@8w
T$(E3
t$(H;
T$(H;
t$(H;
T$(H;
t$(H;]
t$(H+
T$(H+
t$(H+
t$(I;
t$(I;~Pt
t$(L;
T$(L+
t$(M;
t$;y@s
t$@@2
t$@E3
T$@E3
t$@E3
T$@E3
t$@E3
T$@E3
T$@H;
t$@H;
T$@H;
T$@H+
t$@H+
T$@H+
t$@H+
T$@H+
t$@H+
T$@H+
t$@H+
t$@H9t$X
t$@I;
T$@I;
T$@I+
t$@I+
T$@I+
t$@Ii
t$@L;
T$@L;
t$@M;
t$@u?M;
T$`E;
t$`E3
T$`E3
T$`fH
T$`H;
t$`H+
T$`H+
T$`I+
t$`L;
T$<A;
t$0A^_
T$0D8D$8t
T$0D9J0t
T$0D9R,t
T$0D9R0t
T$0E3
t$0E3
T$0E3
t$0E3
T$0E3
t$0fD
t$0ff
t$0fff
T$0H;
t$0H;
T$0H;
t$0H;
T$0H;
t$0H;
T$0H;
t$0H;
T$0H;
t$0H;
T$0H;
T$0H;T$8t
T$0H+
t$0Hc
T$0Hc
T$0I;
t$0I;
T$0I;
t$0I;
T$0I;
t$0I;
T$0I;
T$0I+
T$0I9
t$0L;
T$0L;
t$0L;
T$0L;
t$0L+t$(I
T$0M;
t$0M;
t$0Mi
t$0ux
t$4fD
t$4I;N
t$8A_A^A\
T$8E3
t$8E3
T$8E3
t$8E3
T$8E3
t$8H;
T$8H;
t$8H;
T$8H;
t$8H;
t$8H;|$@
T$8H;T$@t
T$8H+
t$8H+
T$8H+
t$8H+
T$8H+
t$8H+
T$8H+
t$8H+
T$8H+
t$8H+
T$8H+
t$8H+
T$8H+
t$8H+
T$8H+
t$8H+
t$8Hc
t$8HcE,H;
t$8I;
t$8L;
T$8L;
t$AD8
t$BD2
t$DE3
t$H;\$8}
t$H9H(u
T$HA8
t$hE2
T$HE3
t$HE3
T$hE3
T$HE3
T$heL
t$Hfff
t$HH;
T$HH;
t$HH;
T$HH;
t$HH;
T$hH;T$pt
T$hH+
t$HH+
T$hH+
T$HH+
t$HH+
T$hH+
T$HH+
t$HH+
T$hH+
T$HH+T$@H
t$HI;
t$hI;
T$hI;
t$HI;
T$HI+
t$hL;
t$HL;d$`s
t$HL;d$h
T$HL+
T$HM+
t$HuAI
T$II+
T$lPn
T$p+U
t$pA8h
t$PE3
T$PE3
T$pE3
t$pE3
t$PE3
T$PE3
T$pH;
T$PH;
T$pH;
t$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
t$PH;
T$pH;
T$PH;
T$pH;
t$PH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
t$pH;
T$pH;
T$pH;T$xt
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
t$PHc
t$pI;
t$PI;
t$PL;
T$pL;
t$PL;
t$pL;
t$PL;l$H
t$pL+
t$pL9u
T$pPr
t$XE3
t$xE3
T$xE3
t$xE3
T$XE3
T$xff
T$xH;
t$XH;
t$XH;t$`t1L
T$xH;U
T$XH+
t$xH+
T$XH+
T$XH+T$PH
t$XI;
t$XL+
t$XM;
t%ba|H
t(HcF
t)H;V
t*ba|H
t*fff
t*HcA
t*HcC
t,HcW H
t.H;O
t:fff
t?fff
t\fD9"tV
t\fff
t^fff
t^HcC
t_fD9"tYH
t_fff
t_proto_p->dims()[0] == 1
t_proto_p->dims_size() == 1
t_SVWH
t+H;K
t+H;O
t+LcN
t=8D$ t
t>fff
t0H;E
t1ba|H
t4H91u/L
t4HkS
t4I9*u/M
t5#7?
t7fff
t8ba|H
t9fff
taHcC
tAHcD$ H
tAI;V
target
target map type missing key type.
target map type missing value type.
target optional type missing element type.
Target rank must be 1 less than the input rank.
target sequence type missing element type.
Target shape may not have multiple -1 dimensions
Target shape may not have multiple -1 dimensions.
Target tensor of shape (N) or (N, d1, d2, ..., dk). Target element value shall be in range of [0, C). If ignore_index is specified, it may have a value outside [0, C) and the target values should either be in the range [0, C) or have the value ignore_index.
target_ids
target_node != NodesToOptimizeIndices::kEmptyNodeIndex
target_nodeids
target_treeids
target_type
target_weights
target_weights_as_tensor
targets
tbD;H,t_L
tbD9H(t_L
tcba|H
tcfff
tEfff
tefff
tEfff
tEH;U
teHcL$ )KTH
temperature
TempSpace allocator not found
tensor
TENSOR
Tensor after padding.
tensor can either be of element size 1 (including a scalar tensor and any
tensor can't contain negative dims
Tensor does not have external data to read from.
Tensor element type mismatch. 
tensor failed memory size calculation
Tensor initializers must have a non-empty name
Tensor is expected to contain one of the primitive data types. Got: 
Tensor must always contain primitive types. Found: 
tensor of bool, which should be a scalar.
Tensor of data to extract slices from.
Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of int32/int64 indices, of any rank q. All index values are expected to be within bounds. It is an error if any of the index values are out of bounds.
Tensor of int32/int64 indices, of r >= 1 (same rank as input).
Tensor of int32/int64 indices, of r >= 1 (same rank as input). All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of int32/int64 indices, with the same rank r as the input. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
tensor of int64, which should be a scalar.
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]. `pads` format (1D example) should be as follow [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank]. `pads` format should be: [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pad values added at the beginning of axis `i` and xi_end, the number of pad values added at the end of axis `i`.
Tensor of rank one greater than input tensor 'indices', i.e. rank(output) = rank(indices) + 1. The data type for the elements of the output tensor is the same as the type of input 'values' is used.
Tensor of rank q + (r - 1).
Tensor of rank q + r - indices_shape[-1] - 1.
Tensor of rank q >= 1.
Tensor of rank q >= 1. All index values are expected to be within bounds [-s, s-1] along axis of size s. It is an error if any of the index values are out of bounds.
Tensor of rank q-1+r-indices[-1].
Tensor of rank r >= 1 (same rank as input).
Tensor of rank r >= 1.
Tensor of rank r >= 2.
Tensor of rank r >=1 (same rank and shape as indices)
Tensor of rank r if axis is specified. Otherwise output is a Tensor of rank 1.
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing the corresponding input tensor indices for the top K values.
Tensor of shape [a_1, a_2, ..., a_{axis-1}, k, a_{axis+1}, ... a_n] containing top K values from the input tensor
Tensor of shape [a_1, a_2, ..., a_n, r]
Tensor of shape equal to the broadcasted shape of condition, X, and Y.
Tensor of the same shape as indices.
Tensor proto with external data for value attribute is not supported.
tensor rank too small
Tensor sequence must contain only primitive types
Tensor shape cannot contain any negative value
Tensor size (
Tensor size mismatch
tensor size overflow
Tensor specifying lengths of the sequences in a batch. It has shape `[batch_size]`.
Tensor to copy input into.
tensor type 
Tensor type mismatch.
Tensor type mismatch. 
Tensor types should have been handled already
tensor with rank equal to or smaller than the first tensor), or having its
Tensor with same shape of input.
Tensor with shape information must be 1 dimensional.
tensor(
tensor(bfloat16)
tensor(bH
tensor(bool)
tensor(complex128)
tensor(complex64)
tensor(dM9
tensor(double)
tensor(float)
tensor(float16)
tensor(fM9
tensor(iH
tensor(int16)
tensor(int32)
tensor(int64)
tensor(int8)
Tensor(scalar, or dims=[1]). First entry in the range.
Tensor(scalar, or dims=[1]). Number that increments start. Defaults to 1.
Tensor(scalar, or dims=[1]). Upper limit of sequence, exclusive.
tensor(string)
tensor(uH
tensor(uint16)
tensor(uint32)
tensor(uint64)
tensor(uint8)
tensor_type
TensorProto ( tensor name: 
TensorProto (tensor name: 
TensorProto external data size mismatch. 
TensorProto external data size mismatch. Computed size: 
TensorProto type 
TensorProtoToMLValue() must take a pre-allocated MemBuffer!
TensorProtoToTensor() tensor shape mismatch!
TensorRT execution provider is not enabled in this build.
TensorrtExecutionProvider
tensors
TENSORS
Tensors with at least max(dims) dimensions.
Tensors.
TensorSeq: tensor to be added has a different data type.
ter!u53
terminate
tfD9P(u
tfH;=
TfIdfVectorizer
Tfpfr(t
tgD8"tbH
th@8=j
Thales TSS ESN:12BC-E3AE-74EB1%0#
than the operator set version 
t'HcS
The (first) input tensor will be cast to produce a tensor of the same type as this (second input) tensor.
The Alpha value in Celu formula which control the shape of the unit. The default value is 1.0.
The anchors input tensor.
The arccosine of the input tensor computed element-wise
The arcsine of the input tensor computed element-wise
The arctangent of the input tensor computed element-wise
The attention_v tensor in the attention mechanism. Should be of shape `[num_directions, am_attn_size]` 
The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.
The axis in which to compute the arg indices.
The axis in which to compute the arg indices. Accepted range is [-r, r-1] where r = rank(data).
The axis on which to apply normalization, -1 mean last axis.
The bias (or mask) as Tensor.
The bias as a 1-dimensional tensor of size C to be applied to the output.
The bias input data that is a 1D tensor.
The bias input, a vector with the same shape as last dim of data OR same shape with data
The bias tensor for input gate. Concatenation of `[Wb[iofc], Rb[iofc]]`, and `[WBb[iofc], RBb[iofc]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 8*hidden_size]`. Optional: If not specified - assumed to be 0.
The bias tensor for input gate. Concatenation of `[Wbi, Rbi]` and `[WBbi, RBbi]` (if bidirectional). The tensor has shape `[num_directions, 2*hidden_size]`. Optional: If not specified - assumed to be 0.
The bias tensor for the gates. Concatenation of `[Wb[zrh], Rb[zrh]]` and `[WBb[zrh], RBb[zrh]]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 6*hidden_size]`. Optional: If not specified - assumed to be 0
The bias value added to output. Default is 0.
The boxes input tensor.
The class score for each class, for each point, a tensor of shape [N,E].
The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if "mode" is "cubic".
The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.
The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
The cosine of the input tensor computed element-wise
The cropped patches output tensor.
The data type for the elements of the output tensor. Default is TensorProto::FLOAT.
The data type for the elements of the output tensor. If not specified, default is TensorProto::FLOAT.
The data type for the elements of the output tensor. if not specified, we will use the data type of the input tensor.
The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto
The detection_boxes output tensor.
The detection_classes output tensor.
The detection_scores output tensor.
The dimension with value zero exceeds the dimension size of the input tensor.
The distance metric to use. If a string, the distance function can be "braycurtis", "canberra", "chebyshev", "cityblock", "correlation", "cosine", "dice", "euclidean", "hamming", "jaccard", "jensenshannon", "kulsinski", "mahalanobis", "matching", "minkowski", "rogerstanimoto", "russellrao", "seuclidean", "sokalmichener", "sokalsneath", "sqeuclidean", "wminkowski", "yule".
The embedding matrix of size N x M. 'N' is equal to the maximum possible index + 1, and 'M' is equal to the embedding size
The environment variable contained the value: 
The epsilon value to use to avoid division by zero, default is 1e-5f.
The epsilon value to use to avoid division by zero.
The error function of the input tensor computed element-wise. It has the same shape and type of the input.
The exponent.
The exponential of the input tensor computed element-wise
The filled tensor
The first feature map input tensor.
The first input of Range should be a constant with value 0.
The first normalization dimension: normalization will be performed along dimensions axis : rank(inputs).
The fourth feature map input tensor.
The given version [%u] is not supported, only version 1 to %u is supported in this build.
The graph run each iteration. It has 2+N inputs: (iteration_num, condition, loop carried dependencies...). It has 1+N+K outputs: (condition, loop carried dependencies..., scan_outputs...). Each scan_output is created by concatenating the value of the specified output value at the end of each iteration of the loop. It is an error if the dimensions or data type of these scan_outputs change across loop iterations.
The graph run each iteration. It has N+M inputs: (loop state variables..., scan_input_elts...). It has N+K outputs: (loop state variables..., scan_output_elts...). Each scan_output is created by concatenating the value of the specified scan_output_elt value at the end of each iteration of the loop. It is an error if the dimensions of these values change across loop iterations.
The ground truth output tensor, with shape [batch_size], or [batch_size, D1, D2, ..., Dk], where K is the number of dimensions. Labels element value shall be in range of [0, C). If ignore_index is specified, it may have a value outside [0, C) and the label values should either be in the range [0, C) or have the value ignore_index.
The hyperbolic arccosine values of the input tensor computed element-wise
The hyperbolic arcsine values of the input tensor computed element-wise
The hyperbolic arctangent values of the input tensor computed element-wise
The hyperbolic cosine values of the input tensor computed element-wise
The hyperbolic sine values of the input tensor computed element-wise
The hyperbolic tangent values of the input tensor computed element-wise
The id of the end-of-sequence token
The id of the padding token
The id of the tree that each node is in.
The id of the tree that this node is in.
The index of the class list that each weight is for.
The index of the target that each weight is for
The indices, based on 0 as the first index of any dimension.
The initial values of any loop-carried dependencies (values that change across loop iterations)
The inner-most 2 dimensions must have the same size (mat_w:
The input 1-dimensional bias tensor of size C.
The input 1-dimensional scale tensor of size C.
The input 4-dimensional tensor of shape NCHW.
The input data as Tensor.
The input element.
The input is not evenly splittable
The input map that is to be cast to a tensor
The input must be a map from strings or integers to either strings or a numeric type. The key and value types cannot be the same.
The input must be a tensor of a numeric type or string. The output will be of the same tensor type.
The input must be a tensor of a numeric type, and of of shape [N,C] or [C]. In the latter case, it will be treated as [1,C]
The input must be a tensor of a numeric type, either [C] or [N,C].
The input must be a tensor of a numeric type.
The input must be a tensor of a numeric type. The output will be of the same tensor type.
The input must be a tensor of strings or integers, either [N,C] or [C].
The input must be an integer map to either string or float.
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`
The input sequences packed (and potentially padded) into one 3-D tensor with the shape of `[seq_length, batch_size, input_size]`.
The input tensor cannot be reshaped to the requested shape. Input shape:
The input tensor of rank >= axis.
The input tensor that's coerced into a 2D matrix of size (NxD) as described above.
The input type is a tensor of any shape.
The input type must be a tensor of a numeric type, either [C] or [N,C].
The input type must be a tensor of a numeric type, either [N,C] or [C]. The output type will be of the same tensor type and shape.
The input type must be a tensor of a numeric type.
The input type must be a tensor of integers or strings, of any shape.
The input values
The integers of the map. This sequence must be the same length as the 'cats_strings' sequence.
The kernel corresponding to the node 
The kernel type, one of 'LINEAR,' 'POLY,' 'RBF,' 'SIGMOID'.
The keys when using int keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The keys when using string keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The lambd value for the Shrink formulation. Default is 0.5.
The last output value of the cell. It has shape `[num_directions, batch_size, hidden_size]`.
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`.
The last output value of the hidden. It has shape `[num_directions, batch_size, hidden_size]`. 
The maximum length of the sequence to be generated. Shape is (1)
The maximum NGram size for suffix matching.
The mean of the normal distribution.
The minimum length below which the score of eos_token_id is set to -Inf. Shape is (1)
The minimum NGram size for suffix matching.
The model has input '
The Model Proto has already been checked for the ORT config json.
The Model Proto hasn't been checked for the ORT config json.
The most inner dimension in boxes must have 4 data.
The natural log of the input tensor computed element-wise
The negative log likelihood loss
The new GRU hidden state calculated by this op.
The NGram size.
The node id of each weight
The node is not placed on any Execution Provider. 
The node kind, that is, the comparison to make at the node. There is no comparison to make at a leaf node.<br>One of 'BRANCH_LEQ', 'BRANCH_LT', 'BRANCH_GTE', 'BRANCH_GT', 'BRANCH_EQ', 'BRANCH_NEQ', 'LEAF'
The normal input data.
The num_detections output tensor.
The number of batch dimensions. The gather of indexing starts from dimension of data[batch_dims:]
The number of channels to sum over
The number of graph input cannot be smaller than the number of node input
The number of returned sequences in the batch. Shape is (1)
The number of support vectors.
The only supported values for the environment variable 
The op type of a node cannot be empty
The optional input.
The optional output enclosing the input element.
The order of the normalization, only 1 or 2 are supported.
The ORT format model version [
the ort_value must contain a constructed sparse tensor
the ort_value must contain a constructed tensor
the ort_value must contain a constructed tensor or sparse tensor
The output 4-dimensional tensor of the same shape as input.
The output 4-dimensional tensor of the same shape as X.
The output array, elements ordered as the inputs.
The output is a 1-D tensor of string, float, or integer.
The output is a tensor of strings or integers. Its shape will be the same as the input shape.
The output map
The output mask of dropout.
The output mask.
The output mask. If is_test is nonzero, this output is not filled.
The output of each pooling window is divided by the number of elements (exclude pad when attribute count_include_pad is zero).
The output of each pooling window is divided by the number of elements exclude pad.
The output of each pooling window is maximum number of elements exclude pad.
The output of each pooling window is maximum number of elements exclude pad. 
The output scalar. Its value is true if all input tensors are finite. Otherwise, the output value would be false.
The output tensor of the same shape as input.
The output tensor of the same shape as X
The output tensor of the same shape as X.
The output type will be a tensor of strings or integers, and will have the same shape as the input.
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used.
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used. Its size will match the bactch size of the input.
The output values with the same shape as input tensor (the original size without coercion).
The output values with the same shape as the input tensor.
The output will be a sequence of string or integer maps to float.
The output will be a tensor of strings or integers.
The output will be a tensor of the value type of the input map. It's shape will be [1,C], where C is the length of the input dictionary.
The output.
The outputs are updated as follows when training_mode=True:
The pads attribute cannot be used simultaneously with auto_pad attribute
The parameter for repetition penalty. Default value 1.0 means no penalty. Accepts value > 0.0. Shape is (1)
The parent of shape nodes are expected to be input_ids.
The parent of two shape nodes are expected to be input_ids.
The pooling method. Two modes are supported: 'avg' and 'max'. Default is 'avg'.
The pooling method. Two modes are supported: 'bilinear' and 'nearest'. Default is 'bilinear'.
The preallocated buffer is too small. Requires 
The predicted outputs with shape [batch_size, class_size], or [batch_size, class_size, D1, D2 , ..., Dk], where K is the number of dimensions.
The previous GRU hidden state.
The provided PrePackedWeightsContainer instance to be added to the session is null
The ratio of random dropout
The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of input, which is typically the case during training.
The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of the scaled input, which is typically the case during training. It is an optional value, if not specified it will default to 0.5.
The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 4*hidden_size, hidden_size]`.
The recurrence weight tensor. Concatenation of `R[iofc]` and `RB[iofc]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, hidden_size, 4*hidden_size]`.
The recurrence weight tensor. Concatenation of `R[zrh]` and `RB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, hidden_size]`.
The recurrence weight tensor. Concatenation of `Ri` and `RBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, hidden_size]`.
The registered allocator for device-id 
The residual input, must have the same shape as data
The returned output tensor only has values 0 or 1, same shape as input tensor.
The running mean (training) or the estimated mean (testing) as a 1-dimensional tensor of size C.
The running mean after the BatchNormalization operator.
The running mean after the BatchNormalization operator. Must be in-place with the input mean. Should not be used for testing.
The running variance (training) or the estimated variance (testing) as a 1-dimensional tensor of size C.
The running variance after the BatchNormalization operator.
The running variance after the BatchNormalization operator. Must be in-place with the input var. Should not be used for testing.
The running variance after the BatchNormalization operator. This op uses the population size (N) for calculating variance, and not the sample size N-1.
The scale along height dimension. It takes value greater than or equal to 1.
The scale along width dimension. It takes value greater than or equal to 1.
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'.
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. If 'size' is needed, the user must set 'scales' to an empty tensor.
The scale array along each dimension. It takes value greater than 0. If it's less than 1, it's sampling down, otherwise, it's upsampling. The number of elements of 'scales' should be the same as the rank of input 'X'. One of 'scales' and 'sizes' MUST be specified and it is an error if both are specified. If 'sizes' is needed, the user can use an empty string as the name of 'scales' in this operator's input list.
The scale array along each dimension. It takes value greater than or equal to 1. The number of elements of 'scales' should be the same as the rank of input 'X'.
The scale as a 1-dimensional tensor of size C to be applied to the output.
The scale to apply.
The scaled hyperbolic tangent values of the input tensor computed element-wise
The scores input tensor.
The second feature map input tensor.
The sequence length of the input memory for the attention mechanism. Should be of `[batch_size]` 
The sequence of the memory (input) for attention mechanism. Should be of `[batch_size, max_memory_step, memory_depth]` 
The sequence output for the hidden is optional if 0. Default 0.
The sequence used as a prompt for the generation. Shape is (batch_size, sequence_length)
The session already has a PrePackedWeightsContainer instance
The shape format of inputs X, initial_h and outputs Y, Y_h. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size, num_directions, hidden_size].
The shape format of inputs X, initial_h, initial_c and outputs Y, Y_h, Y_c. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [batch_size, num_directions, hidden_size].
The shape of filled tensor
The shape of the convolution kernel. If not present, should be inferred from input W.
The shape of the convolution kernel. If not present, should be inferred from input 'w'.
The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads
The shape of the output can be explicitly set which will cause pads values to be auto generated. If 'output_shape' is specified, 'pads' values are ignored.
The shape of the output tensor.
The sign of the input tensor computed element-wise. It has the same shape and type of the input.
The sine of the input tensor computed element-wise
The size of each input in the input list
The size of the kernel along each axis.
The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. May only be set if 'scales' is set to an empty tensor.
The size of the output tensor. The number of elements of 'sizes' should be the same as the rank of input 'X'. Only one of 'scales' and 'sizes' can be specified.
The softsign (x/(1+|x|)) values of the input tensor computed element-wise
The standard deviation of the normal distribution.
The starting indexes of 1-grams, 2-grams, and so on in pool. It is useful when determining the boundary between two consecutive collections of n-grams. For example, if ngram_counts is [0, 17, 36], the first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36. This format is essentially identical to CSR (or CSC) sparse matrix format, and we choose to use this due to its popularity.
The storage order of the tensor. 0 is row major, and 1 is column major.
The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.
The strings of the map. This sequence must be the same length as the 'cats_int64s' sequence
The subgraph in 'body' requires 
The tangent of the input tensor computed element-wise
the tensor to be tiled using Tile OP must be atleast 1 dimensional
The tensor to split
The third feature map input tensor.
The third input of Range should be a constant with value 1.
The timestep for this operation.
The total number of regression targets, 1 if not defined.
The total number of targets.
The type of tensor: 
The type of the output tensor is integer.
The value for the elements of the output tensor in sparse format.
The value for the elements of the output tensor.
The value for the sole element for the scalar, float32, output tensor.
The value for the sole element for the scalar, int64, output tensor.
The value for the sole element for the scalar, UTF-8 string, output tensor.
The value used to module the next token probabilities. Accepts value > 0.0. Shape is (1)
The values for the elements for the 1D, float32, output tensor.
The values for the elements for the 1D, int64, output tensor.
The values for the elements for the 1D, UTF-8 string, output tensor.
The weight for each target
The weight for the class in class_id.
The weight tensor for input gate. Concatenation of `Wi` and `WBi` (if bidirectional). The tensor has shape `[num_directions, hidden_size, input_size]`.
The weight tensor for peepholes. Concatenation of `P[iof]` and `PB[iof]` (if bidirectional) along dimension 0. It has shape `[num_directions, 3*hidde_size]`. Optional: If not specified - assumed to be 0.
The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, 4*hidden_size, input_size]`.
The weight tensor for the gates. Concatenation of `W[iofc]` and `WB[iofc]` (if bidirectional) along dimension 0. The tensor has shape `[num_directions, input_size, 4*hidden_size]`.
The weight tensor for the gates. Concatenation of `W[zrh]` and `WB[zrh]` (if bidirectional) along dimension 0. This tensor has shape `[num_directions, 3*hidden_size, input_size]`.
The weight tensor of the memory layer in the attention mechanism. Should be of shape `[num_directions, memory_depth, am_attn_size]` 
The weight tensor of the query layer in the attention mechanism. Should be of shape `[num_directions, am_query_depth(hidden_size of lstm), am_attn_size]` 
The weight tensor that will be used in the convolutions; has size (C x M/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the weight shape will be (C x M/group x k1 x k2 x ... x kn), where (k1 x k2 x ... x kn) is the dimension of the kernel. The number of channels in the output should be equal to W.shape[1] * group (assuming zero based indices of the shape array)
The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. Assuming zero based indices for the shape array, X.shape[1] == (W.shape[1] * group) == C and W.shape[0] mod G == 0. Or in other words FILTER_IN_CHANNEL multiplied by the number of groups should be equal to DATA_CHANNEL and the number of feature maps M should be a multiple of the number of groups G.
The weight tensor that will be used in the convolutions; has size (M x C/group x kH x kW), where C is the number of channels, and kH and kW are the height and width of the kernel, and M is the number of feature maps. For more than 2 dimensions, the kernel shape will be (M x C/group x k1 x k2 x ... x kn), where (k1 x k2 x ... kn) is the dimension of the kernel. Optionally, if dimension denotation is in effect, the operation expects the weight tensor to arrive with the dimension denotation of [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, FILTER_SPATIAL, FILTER_SPATIAL ...]. X.shape[1] == (W.shape[1] * group) == C (assuming zero based indices for the shape array). Or in other words FILTER_IN_CHANNEL should be equal to DATA_CHANNEL. 
The weighting criteria. It can be one of "TF" (term frequency), "IDF" (inverse document frequency), and "TFIDF" (the combination of TF and IDF)
The weights of attention layer in the attention wrapper. If exists, should be of shape `[num_directions, memory_depth+hidden_size, aw_attn_size]. Please note that attention mechanism context depth is also memory_depth in the attention mechanism.` 
The zero-padding added to one side of the output. This is also called adjs/adjustment in some frameworks.
then_branch
then_branch and else_branch produce different number of outputs. 
then_feeds_fetches_manager_ && else_feeds_fetches_manager_
There are five required inputs 'X', 'scale', 'B', 'input_mean' and
there are multiple cases for the number of outputs, which we list below:
There are multiple cases for the number of outputs, which we list below:
There is no location for this node arg in the outer scope location map
There must be one (and only one) dynamic typed input to the custom op. Its type info at runtime will be used to infer the type info of this dynamic typed output which is required for the success of the model loading step. More than one dynamic typed inputs are currently not supported as differing types at runtime means the output type cannot be inferred without which model loading cannot proceed.
There's no data transfer registered for copying tensors from 
this API does not support strings
This API supports Tensors or SparseTensors
This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
This instance should not be empty
This is an invalid model. At top level graph without matching NodeArg that subgraph consumes. Name=
This is an invalid model. Error: Duplicate definition of name (
This is an invalid model. Error: the graph is not acyclic.
This is an invalid model. Error: two nodes with same node name (
This is an invalid model. Failed to find NodeArg in all parent graphs. Name=
This is an invalid model. Graph output (
This is an invalid model. In Node, 
This is an invalid model. Model input (
This is an invalid model. Node (
This is an invalid model. Tensor does not have type information.
This is an invalid model. The sum of input arg count is not equal to size of input defs in node (
This is an invalid model. Type Error: Type '
This may prevent some of the graph optimizations, like const folding. 
This method does not expect allocator to be set
This method should follow a call to constructor that supplies the allocator
This number of op outputs should be 1 when Training_mode = False, but it is not.
This number of op outputs should be 3 when Training_mode = True, but it is not.
This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernal shape.
This operator has **optional** inputs/outputs. See [the doc](IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.
This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](Broadcasting.md).
This optimizer does not support external data for unidirectional mask right now
This session already contains a loaded model.
This session cannot use the CUDA Graph feature as requested by the user 
This session cannot use the CUDA Graph feature as requested by the user  as all the graph nodes have not been partitioned to the CUDA EP.
This session cannot use the CUDA Graph feature as requested by the user  as the model has control flow nodes which can't be supported by CUDA Graphs.
This session has already been initialized.
This session will use the allocator registered with the environment.
This session will use the CUDA Graph feature as requested by the user.
this tensor already has populated sparse_indices
This transformer is already registered 
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
thisProto->value_case() == TypeProto::ValueCase::kMapType
thisProto->value_case() == TypeProto::ValueCase::kOptionalType
thisProto->value_case() == TypeProto::ValueCase::kSequenceType
thisProto->value_case() == TypeProto::ValueCase::kSparseTensorType
thisProto->value_case() == TypeProto::ValueCase::kTensorType
thread_scheduling_stats
Three interpolation modes: bilinear (default), nearest and bicubic.
Three interpolation modes: nearest (default), linear and cubic. The "linear" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The "cubic" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor).
Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array
Three modes: constant(default), reflect, edge
threshold
Threshold value
thresholdedrelu
ThresholdedRelu
Thresholds to do the splitting on for each node.
Tile doesn't have an implementation yet for the type: 
Tile doesn't support string type yet
tiles
time_axis
tionProvH
tionProvH9H
tionProvH9P
tj9h ueH
tJba|H
tKba|H
tkfff
tkK9<
tMI9:uHM
tnD8"tiH
tnfff
to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.
to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
to.custom_join_thread_fn
TO_FLOAT
TO_INT64
TO_STRING
tofff
tokenexp
Tokenized strings
Tokenizer
tokens
tolower
Too many produced nodes in the runtime optimization record.
TorchEmbedding
Total allocated bytes: 
Total fused Attention node count: 
Total fused reshape node count: 
Total Gelu Approximation (FastGelu) node count: 
Total number of elements of the input tensor
TotalAllocated:           
totalRunDuration
totalRuns
tpfff
tqfff
tQfff
TraceAllocation for ort_value_idx=
TraceFree for ort_value_idx=
training_mode
training_mode of Dropout must be a scalar.
transA
transB
transBatchA
transBatchB
transform_targets
Translation
Transpose
Transpose not implemented for empty tensors.
Transpose of element size not supported in this build. Size=
Transpose optimizer failed: 
Transpose Optimizer is adding an unexpected node: 
Transpose optimizer is expected to add only onnx domain ops. Domain: 
Transpose_1
Transpose_13
transpose_node.InputDefs().size() == 1
transposed
Transposed output.
TransposeMatMul
TransposeOptimizer
Tree id for each node.
TreeEnsembleClassifier
TreeEnsembleRegressor
tried creating tensor with negative value in shape
tried Filling sparse tensor with negative value in block sparse indices shape
tried Filling sparse tensor with negative value in values shape
tried to allocate 0 bytes
Tried to allocate without valid type information, ort_value index=
Trilu
true literal
Trying to allocate memory for unused optional inputs/outputs
Trying to get a SparseTensor, but got: 
Trying to get a Tensor, but got: 
Trying to get a TensorSeq, but got: 
Trying to register schema with name 
tUba|H
tufff
TvmExecuH9
TvmExecutionProvider
Two inputs should have same rank and rank >= 3 if transBatchA or transBatchB is true
Two interpolation modes: nearest (default), and linear (including bilinear, trilinear, etc)
Two interpolation modes: nearest(default), bilinear
two paths share the same shape
txfff
txH+A
tyfD9"tsH
tyfff
type == dtype_
type case mismatch. existing=
type case unsupported for symbolic shape inference. inferred=
type case unsupported. existing=
Type Error: Data in initializer '
Type Error: Shape of initializer 
Type Error: Type (
Type Error: Type parameter (
type field and data field mismatch in attribute 
Type mismatch. Current=
type must be number, but is 
Type of Mean and InvStdDev tensors.
Type of reduction to apply to loss: none, sum, mean (default). 'none': the output is the loss for each sample. 'sum': the output will be summed. 'mean': the sum of the output will be divided by the sum of applied weights.
Type of reduction to apply to loss: none, sum, mean(default). 'none': no reduction will be applied, 'sum': the output will be summed. 'mean': the sum of the output will be divided by the number of elements in the output.
Type of reduction to apply: none (default), add, mul. 'none': no reduction applied. 'add':  reduction using the addition operation. 'mul': reduction using the multiplication operation.
Type of the element in the optional output
type used for stash mean/inv_std_var
Type:
type: 
type_error
type_id_counter == 1
type_proto
type_proto is not of type map!
type_proto is not of type sequence!
type_protos
TypeAndShapeInferenceFunction implementation incomplete: this line should never be reached.
TypeProto must have shape for this to run
Tz|h~^
tZI90t
U H;U(
u HcI(
U I+U
u!bA-@
u$H;Q
U(A+U0A
u(bA-@
u(E+u0E
u.H;C
u.H;P
U/H;U7
u:A9P(t)H
u:fff
u;H;C
u?fff
u[G9<3uUH
u`H9A
u0fff
U0S0Q
u2.7Q 
u4A8F
u7H;H
U8H;U@t
u9E8U
u-9H(u
u-A9P(t[H
uA9P(u<H
UATAUAVAWH
UAUAVH
UAVAWH
ubE9g0
uBfff
uCH;Q
udE;n0t
uEL9RHu?E8U
u-fff
uFL;B r@I
ui9w(t%H
uint16
uint32
uint64
uint64_data
uint8
uKH;Q
uKL;B rELcL$(I
ukL9-[
uL9t$ u
Unable to convert strings tensor to a sparse tensor that is not on CPU
Unable to convert strings tensor to a sparse tensor that not on CPU
Unable to find a data transfer for copying from device type: 
Unable to find compiled kernel hash for node '
Unable to find kernel hash for node:
Unable to get an allocator
Unable to serialize model as it contains compiled nodes. Please disable any execution providers which generate compiled nodes.
Unable to shrink arena: 
Unable to write the provided PrePackedWeights instance into the container
Unactivated gate outputs from forget, update, and output gates, pre-activation.
UNDEFINED
unexpected 
Unexpected attribute type.
Unexpected data type for Clip input of 
Unexpected data type for Clip 'min' input of 
Unexpected data type for QuantizeLinear input y_zero_point of 
Unexpected element size of 
unexpected failure
Unexpected input data type. Actual: (
Unexpected literal type.
Unexpected type.
ungetc
Unhandled type: %d
unidir mask is not constant
unidir mask shape not expected
unidirectional
unimplemented activation: 
Unique
unk__
unknown
Unknown AutoPadType String
unknown error
Unknown error during EndProfiling()
Unknown exception
Unknown exception in Load()
Unknown exception was caught by catch-all handler.
unknown kernel type
unknown token
unknown_dim == -1
UnknownEvent
Unloading DSO 
unnamed_thread_pool
unordered_map/set too long
UnpackTensor: the pre-allocate size does not match the size in proto
UnpackTensor: the pre-allocated size does not match the raw data size, expected 
Unrecognized attribute: 
Unrecognized data_type (tensor name: 
Unrecognized type value case (value_info name: 
Unsqueeze
UnSqueeze_1
UnSqueeze_11
UnSqueeze_13
unsqueeze_after_gather axes value not expected
UnsqueezeElimination
UnsqueezeElimination cannot remove node 
UnsqueezeElimination_
Unsuported type proto value case.
Unsupported attribute value type of 
Unsupported AutoPad Type.
Unsupported convolution size.
Unsupported data type: 
unsupported data type: 
Unsupported device allocator in the context of pre-packed weights caching: 
Unsupported device id in the memory arena shrink list: 
Unsupported device specified in the memory arena shrink list: 
Unsupported element size: 
Unsupported execution_mode value in ORT config: 
Unsupported graph_optimization_level value in ORT config: 
Unsupported indices_format passed
Unsupported input data type of 
Unsupported input type
Unsupported model IR version: 
Unsupported non-raw-data data type!
Unsupported ONNX opset
Unsupported optimization level: 
Unsupported OrtValue type to copy between device.
Unsupported OrtValue type.
Unsupported output datatype with size: 
Unsupported output type of 
Unsupported pooling size : 
Unsupported pooling size.
Unsupported Source/Target type=
Unsupported sparse tensor data type of 
Unsupported type
Unsupported type:
Unsupported type: 
Unsupported value attribute datatype with size: 
Unsupported value attribute datatype: 
Unsupported value for enable_profiling option: 
Unsupported value for inter_op_num_threads: 
Unsupported value for intra_op_num_threads: 
Unsupported version '
Unsupported X type: 
Unsupported Y type: 
uo9w(t%H
uPA9A(t)H
updates
updates shape: 
updates tensor should have shape equal to indices.shape[:-1] + data.shape[indices.shape[-1]:]. 
UpdateTypeShapeInference is not intended to be used with control flow nodes containing subgraphs
upfff
upper
Upper boundary of the output values.
Upsample
Use GetStringTensor*() API to retrieve strings
Use MakeBlockSparseStrings
Use MakeCooStrings
Use MakeCsrStrings
use_approximation
use_past
usefp16
Using an input in multiple nodes on different devices is not supported currently. Input:
Using cached version of pre-packed weight for constant initializer: 
Using global/env threadpools since use_per_session_threads_ is false
Using transpose optimized pattern
Using user supplied initializer with name (
USVWATAUAVAWH
USVWATAVAWH
USVWAVAWH
USVWAVH
USVWH
UTCReplace_AppSessionGuid
UTF-8 Normalized strings
UTF-8 strings to normalize
utils::HasDataType(t_proto)
utils::HasElemType(thisProto->optional_type())
utils::HasElemType(thisProto->sequence_type())
utils::HasElemType(thisProto->sparse_tensor_type())
utils::HasElemType(thisProto->tensor_type())
utils::HasKeyType(thisProto->map_type())
utils::HasName(sparse_tensor)
utils::IsPrimitiveDataType<T>(dtype_)
uTL9~
U'u<I+
uUL9}h
UUUUUUU
UVATAVAWH
UVAUI
UVAVAWI
UVAVH
UVAWH
UVWATAUAVAW
UVWATAUAVAWH
UVWATAWH
UVWAVAWH
UWATAUAVH
UWATAUAWH
UWATAVAWH
UWAUAVAWH
UWAVH
UWAWH
uxfff
uXL9t$h
uy9E(t)H
V +V0
v >= 0 && static_cast<uint64_t>(v) <= std::numeric_limits<size_t>::max()
v D+v0D
v fff
V H;V(t
V H+V
v I+v
V(+V0
V(A+V0A
v(D+v0D
v?fD;
v@xjz
v_final_and_scan_outputs
v_initial
v_reshape initializer value is not expected
V8H;V8tiH
VALID
valid
ValidateUnidirMask returns false for mask_slice
Validating no unexpected access using an invalid node_index. Got:
value
Value expected but not found.
Value of alpha
Value of alpha default to 0.2
Value of alpha.
Value of attribute 
Value of beta
Value of beta default to 0.5
Value of beta.
value of k must not be negative
Value type is not supported yet: 
Value type of map input 
Value type of map input was unknown
Value used for extrapolation, when applicable. Default is 0.0f. 
Value(s) to change to
Value(s) to change to.
value_cache
value_float
value_floats
value_info
value_int
value_ints
value_proto != nullptr
value_string
value_strings
value_type
value_type != nullptr
Values
values
Values greater than this are mapped to 1, others to 0.
values in 'axes' are beyond the bounds of the computed output shape
values of data_type '
values selected at indices where condition is False
values selected at indices where condition is True
Values size 
Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same data type. The `then_branch` and `else_branch` may produce tensors with the same element type and different shapes. If corresponding outputs from the then-branch and the else-branch have static shapes S1 and S2, then the shape of the corresponding output variable of the if-node (if present) must be compatible with both S1 and S2 as it represents the union of both possible shapes.For example, if in a model file, the the first output of `then_branch` is typed float tensor with shape [2] and the first output of `else_branch` is another float tensor with shape [3], If's first output should have (a) no shape set, or (b) a shape of rank 1 with neither `dim_value` nor `dim_param` set, or (c) a shape of rank 1 with a unique `dim_param`. In contrast, the first output cannot have the shape [2] since [2] and [3] are not compatible.
Values that are live-out to the enclosing scope. The return values in the `then_branch` and `else_branch` must be of the same shape and same data type.
values_count == index_size
values_floats
values_int64s
values_strings
Var = Sub (MeanOfSquare, SquareOfMean)
VarFileInfo
Variance
VarPlusEpsilon = Add (Var, Epsilon)
VATAUAVAWH
VATAUAWH
VAVAWH
VbbeH
vb'vb'v
VCRUNTIME140_1_APP.dll
VCRUNTIME140_APP.dll
vdtLr
vector too long
vector<bool> too long
vectors_per_class
Version number of the TRT plugin.
Vfvjx
VhH;VptoL
vhxfz(
via some custom implementation such as CuDNN.
VitisAIEH9
VitisAIExecutionProvider
VIWEF
vlxfz(||v
VnXbZ(b
VnXtZ,\
vocab_mask
VPI;VXt
vPx(vA
vPx8v
VS_VERSION_INFO
VUUUUUUUH
vvx<v
VWATAUAVH
VWATAUAWH
VWATAVAWH
VWAUAVAWH
VWAVH
VWAWH
VXI;V`t)L
VxX(`fT
vzx~z$|
W +W0
W H+W
W I;W(t
W(+W0
w(D+w0D
W(fff
W(H;W0t
W(H;W0tH
W(H;W0tL
W(H9h u0H
W@H;WHt
w_^[]
W_scale
w_scale
w_zero_point
W_zero_point
w+fff
W0H;W8t
wA\A]A^_^[]
WaitForSingleObject
WaitRevoke
WakeAllConditionVariable
WakeConditionVariable
WARNING
Warning: Checker does not support models with experimental ops: 
'was added but does not exist. 
Washington1
WATAUAVAWH
WAVAWH
wcsftime
We do not expect duplicate registration of types for: 
We do not support type [
We don't expect custom allocators for non-tensor types, so a shape is mandatory here.
weight
weight and zero_point pair is expected to have same type.
Weight buffer for initializer '
Weight point must be constant
Weight rank must be 1.
Weight zero point must be zero
weight_gather
weight_gather = Gather (weight, target)
weight_gather = Squeeze (weight_gather_temp_1, axes)
weight_gather = Where (squeeze_mask, const_zero_casted, const_one_casted)
weight_gather = Where (squeeze_mask, const_zero_float, const_one_float)
weight_gather_sum
weight_gather_temp
weight_gather_temp = Gather (weight, transform_targets)
weight_gather_temp_1
weight_gather_temp_1 = Where (mask, const_zero_casted, weight_gather_temp)
weight_gather_temp_1 = Where (mask, const_zero_float, weight_gather_temp)
weight_scale
weight_zero_point
Weighted loss float Tensor. If reduction is 'none', this has the shape of [batch_size], or [batch_size, D1, D2, ..., Dk] in case of K-dimensional loss. Otherwise, it is a scalar.
weights
Weights of the intercepts, if used.
Weights of the model(s).
weights.quant_para_
weights_to_be_filled_in.buffers_.size() > 0
When computing the output of the hidden gate, apply the linear transformation before multiplying by the output of the reset gate.
When coordinate_transformation_mode is "tf_crop_and_resize" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f.
When the session is not configured to use per session threadpools, the env must be created with the the CreateEnvWithGlobalThreadPools API.
When training_mode=False, extra outputs are invalid.
When training_mode=False:
When True (nonzero), yield X, otherwise yield Y
Where
Where behaves like
where const not matched.
where N is the population size (this formula does not use sample size N - 1).
where:
Whether A should be transposed
Whether A should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication
Whether A should be transposed on the last two dimensions before doing multiplication
Whether B should be transposed
Whether B should be transposed on the 1st dimension and batch dimensions (dim-1 to dim-rank-2) before doing multiplication
Whether B should be transposed on the last two dimensions before doing multiplication
Whether C should be broadcasted
Whether every token can only attend to previous tokens. Default value is 0.
Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.
Whether the operator should behave like fmod (default=0 meaning it will do integer mods); Set this to 1 to force fmod treatment
Whether to return the elements in sorted order.
Whether to return the top-K largest or smallest elements.
Whether to select the last index or the first index if the {name} appears in multiple indices, default is False (first index).
Whether to use ceil or floor (default) to compute the output shape.
Which axis to concat on
Which axis to concat on.  Default value is 1.
Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs)..
Which axis to concat on. Accepted range in `[-r, r - 1]`, where `r` is the rank of input tensors. When `new_axis` is 1, accepted range is `[-r - 1, r]`. 
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Which axis to split on
Which axis to split on. 
Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1] where r = rank(input).
Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1].
which does not equal the specified override of 
while parsing 
WhL;O
WideCharToMultiByte
width_scale
window
with a fixed dimension size 
with activation 
with three parameters.
Word embedding shape not expected.
Word IDs of generated sequences. Shape is (batch_size, num_return_sequences, max_sequence_length)
word_embedding
word_embedding should have 2 dimensions and dimension size is known.
word_embedding_quant
word_embedding_scale
word_embedding_zero_point
WordConvEmbedding
Works on NHWC layout or not? Default not.
WpH;Wxt
WqVNHE
Writing profiler data to file 
Wrong op_type name for running propagation: 
W's scale. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
W's zero point. Its size is [num_directions] for per-tensor/layer quantization, or [num_directions, 4*hidden_size] for per-channel quantization on the axis input_size.
Wwhere the function `Sigmoid(x) = 1 / (1 + exp(-x))` 
WXH;W`t
WXO0O
X != nullptr
X ;{ H
X ;k 
x 9K(u
x ATAVAWH
x AVH
x H+x
X num_dims does not match W num_dims.
x UATAUAVAWH
x UAVAWH
X UVWATAUAVAWH
x(D$@
x(L$0
x(T$ 
X(Z*X
X(ZxR
x)D$@
x)L$0H
x)T$ Hk
x)T$`H
X@f(h j(`
X@Z(b d(`\T
x_^[]
X_^[]
x_^][
X_^][
X_bias = Add (X, bias)
X_bias = Identity (X)
X_greater = Greater (X_random, input)
X_Log
X_LogSM
X_LogSM_NCD
X_NCD
X_NDC
x_original = (x_resized + 0.5) / scale - 0.5, <br/>
x_original = (x_resized + 0.5) / scale, <br/>
x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>
x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1).
x_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>
x_original = x_resized / scale, <br/>
x_ptr != nullptr
X_random = RandomUniformLike <low = 0.0, high = 1.0, seed = @seed> (input)
X_rank == 4
X_ReduceMax = ReduceMax <keepdims = 1> (input)
X_scale
x_scale
X_shape
X_shape.NumDimensions() == 4
X_squared
X_variance
X_zero_point
x_zero_point
x_zero_point must be null or 1D tensor with size 
x_zero_point must be null or a scalar or 1D tensor or size 1.
X<Z"\
X0V0T
X2D = Flatten (X)
XA\_^[
xA\_^[
XA]A\_[
XA^^][
XA^_][
xA^_^[
XA^_^[
xA^_^[
XA^_^[
xA^_^[
XA_A^_^][
xA_A^_^][
XA_A^_^][
XA_A^A]_][
xA_A^A]A\_^[]
XA_A^A]A\_^[]
xA_A^A]A\_^[]
XA_A^A]A\_^][
xA_A^A]A\_^][
XA_A^A]A\_^][
xA_A^A]A\_^][
XA_A^A]A\_^][
X-device copy of strings not supported
xecutionH9H
Xf\j^
XHZj\~^zbjd~fzjjl~nTrjt~vTzj|~~J
XjZ,\(^,`Xb
XLZ@\
XNT6R>P
XShape = Shape (X)
xSu$W
XT`(X<T
XU = Cast (X2D)
XV`(X
xVz*|(~,
XX\j^
XZZFX
XZZj\
Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B
Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B
Y = Reshape (Biased, XShape)
y(+y0A
y_scale
Y_scale
Y_zero_point
y_zero_point
Y8H+Y0H
Y's scale.
Y's zero point.
yxxxxxxxH
yxxxxxxxI
z X"f 4
z(u&H;
z)u'H;
z.u,H;
Z@\(^$`(X
Z@l(n `(XHT
z\|.z
z\uZA
Z^\,^
Z^\,h
z2F4L6
z2l4.6
z3u1I;
z5u3I;
zcuaA
Zero Point for 1D beta tensor
Zero Point for 1D gamma tensor
Zero point for doing quantization to get 'y'. It could be a scalar or a 1-D tensor, which means a per-tensoror per-axis quantization. If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for doing quantization to get 'y'. It's a scalar, which means a per-tensor/layer quantization. Default value is uint8 typed 0 if it's not specified.
Zero point for doing quantization to get 'y'. Shape must match y_scale. Default is uint8 with zero point of 0 if it's not specified.
Zero point for input 'x'. It could be a scalar or a 1-D tensor, which means a per-tensor or per-axis quantization.If it's a 1-D tensor, its number of elements should be equal to the dimension value of 'axis' dimension of input 'x'.
Zero point for input 'x'. It's a scalar, which means a per-tensor/layer quantization. It's optional. 0 is the default value when it's not specified.
Zero point for input 'x'. Shape must match x_scale. It's optional. Zero point is 0 when it's not specified.
Zero point for position embeddings
Zero Point for segment embeddings
Zero point for word embeddings
zero point of quantized input a
zero point of quantized input b
zero point of quantized input tensor.It's a scalar, which means a per-tensor/layer quantization.
zero point of quantized output y
zero point of quantized weight tensor. It's a scalar or a 1D tensor, which means a per-tensor/per-column quantization.Its size should be 3 * hidden_size if it is per-column quantization
Zero point tensor for input 'A'. It is a scalar.
Zero point tensor for input 'A'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'A'.
Zero point tensor for input 'A'. It's optional and default value is 0. It could be a scalar or N-D tensor. Scalar refers to per tensor quantization whereas N-D refers to per row quantization. If the input is 2D of shape [M, K] then zero point tensor may be an M element vector [zp_1, zp_2, ..., zp_M]. If the input is N-D tensor with shape [D1, D2, M, K] then zero point tensor may have shape [D1, D2, M, 1]. 
Zero point tensor for input 'B'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor or per-column quantization. If it's a 1-D tensor, its number of elements should be equal to the number of columns of input 'B'.
Zero point tensor for input 'B'. It's optional and default value is 0. It could be a scalar or a N-D tensor, Scalar refers to per tensor quantization whereas N-D refers to per col quantization. If the input is 2D of shape [K, N] then zero point tensor may be an N element vector [zp_1, zp_2, ..., zp_N]. If the input is N-D tensor with shape [D1, D2, K, N] then zero point tensor may have shape [D1, D2, 1, N]. 
Zero point tensor for input 'w'. It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M).
Zero point tensor for input 'w'. It's optional and default value is 0.  It could be a scalar or a 1-D tensor, which means a per-tensor/layer or per output channel quantization. If it's a 1-D tensor, its number of elements should be equal to the number of output channels (M)
Zero point tensor for input 'X'. It must be a scalar.
Zero point tensor for input 'x'. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for input 'x'. It's optional and default value is 0. It's a scalar, which means a per-tensor/layer quantization.
Zero point tensor for output 'Y'. It is a scalar, which means a per-tensor quantization. It is optional. The output is full precision(float32) if it is not provided. Or the output is quantized.
Zero point tensor for output 'Y'. It must be a scalar.
Zero point tensor for output 'y'. It's a scalar, which means a per-tensor/layer quantization.
zero_point == nullptr || std::all_of(zero_point, zero_point + x_zero_point->Shape().Size(), [](int32_t zp) { return zp == 0; })
zero_point_ptr == nullptr || (zero_point_ptr->Shape().NumDimensions() == 1 && zero_point_ptr->Shape()[0] == broadcast_dim)
zero_point_ptr == nullptr || IsScalarOr1ElementVector(zero_point_ptr)
Zero1D = Constant()
zeros
ZipMap
ZLb(Z
ZLb(ZvV
zoU H
zP|(z
zP|(z-
zP|(z6v
zP|(zfv
zP|(znv
zRuPI
z-u+H;
