      
        
            
              
                    [
                    [0.0, 0.0, 1.0, 1.2],
                    [0.0, 0.0, 2.3, 3.4],
                    [0.0, 0.0, 4.5, 5.7],
                    [1.0, 1.2],
                    [2.3, 3.4],
                    [4.5, 5.7],
                    ]
                    ],
                cond_out = Identity (cond)
                current = Add (prev, delta)
                CX = Mul (C, X)
                ERFCX = Erf (CX)
                ERFCXPlus1 = Add (ERFCX, One)
                input_x = [2, 1, 1, 3, 4, 3]
                output_counts = [1, 2, 2, 1]
                output_idx = [0, 1, 1, 2, 3, 2]
                output_uniques = [2, 1, 3, 4]
                PhiX = Mul (ERFCXPlus1, Half)
                range = Identity (prev)
                T1 = Mul (X_bias, X_bias)
                T2 = Mul (c, T1)
                T3 = Add (b, T2)
                T4 = Mul (X_bias, T3)
                T5 = Tanh (T4)
                T6 = Add (one, T5)
                T7 = Mul (X_bias, T6)
                Y = Mul (a, T7)
                Y = Mul (X, PhiX)
              }>
              <body = loop_body_attribute (int64 i, bool cond, prev) => (cond_out, current, range) {
              Example:
              Finds all the unique values (deduped list) present in the given input tensor.
              of each value of the input in 'uniques'.
              sorted in the same order that they occur in the input.
              The first output tensor 'uniques' contains all of the unique elements of the input,
              The second output tensor 'idx' is the same size as the input and it contains the index
              The third output tensor 'counts' contains the count of each element of 'uniques' in the input.
              This operator returns 3 outputs.
            C = Or (O1, O2)
            ceil_result = Ceil (div_result)
            ceil_result_relu = Relu (ceil_result)
            ceil_result_relu_bool = Cast <to = 9> (ceil_result_relu)
            ceil_result_relu_int = Cast <to = 7> (ceil_result_relu)
            data = [
            delta_casted = Cast <to = 1> (delta)
            div_result = Div (sub_result_casted, delta_casted)
            Example:
            Given `data` tensor, pads, mode, and value.
            HS_X = HardSigmoid<alpha = 0.16666667163372, beta = 0.5>(X) 
            Insert 0 pads to the beginning of the second dimension.
            O1 = Less (A, B)
            O2 = Equal (A, B)
            output = [
            pads = [0, 2, 0, 0]
            sub_result = Sub (limit, start)
            sub_result_casted = Cast <to = 1> (sub_result)
            variadic_output, output = Loop (ceil_result_relu_int, ceil_result_relu_bool, start)
            Y = Mul (X, HS_X)
           Clipped_ZeroPoint_FP = Clip (Initial_ZeroPoint_FP, Q_Min, Q_Max)
           Initial_ZeroPoint_FP = Sub (Q_Min, Min_Scaled)
           Min_Scaled = Div (X_Min_Adjusted, Scale)
           Q_Max = Constant<value = float {255.0}>()
           Q_Min = Constant<value = float {0.0}>()
           Rounded_ZeroPoint_FP = Round (Clipped_ZeroPoint_FP)
           Scale = Div (X_Range, Q_Max)
           X_Max = ReduceMax <keepdims = 0> (x)
           X_Max_Adjusted = Max (X_Max, Q_Min)
           X_Min = ReduceMin <keepdims = 0> (x)
           X_Min_Adjusted = Min (X_Min, Q_Min)
           X_Range = Sub (X_Max_Adjusted, X_Min_Adjusted)
           y = QuantizeLinear (x, Scale, Zeropoint)
           y_scale = Identity (Scale)
           y_zero_point = Identity (Zeropoint)
           Zeropoint = Cast <to = 2> (Rounded_ZeroPoint_FP)
          {
          }
          E_Xsquared = ReduceMean <axes : ints = @axes> (X_squared)
          Epsilon = Constant <value = float {1e-9}>()
          EX_squared = Pow (X_RM, Exponent)
          Exponent = Constant <value = float {2.0}>()
          Processed_STD = Add (STD, Epsilon)
          STD = Sqrt (Variance)
          Variance = Sub (E_Xsquared, EX_squared)
          X_RM = ReduceMean <axes : ints = @axes> (X)
          X_squared = Pow (X, Exponent)
          X_variance = Sub (X, X_RM)
          Y = Div (X_variance, Processed_STD)
        (possibly with aspect ratio change) to a common output size specified by crop_height and crop_width.
        {
        }
        <requestedExecutionLevel level='asInvoker' uiAccess='false' />
        a fixed size = [crop_height, crop_width]. The result is a 4-D tensor [num_boxes, crop_height, crop_width, depth].
        Extracts crops from the input image tensor and resizes them using bilinear sampling or nearest neighbor sampling
        Returns a tensor with crops from the input image at positions defined at the bounding box locations in boxes.
        The cropped boxes are all resized (with bilinear or nearest neighbor interpolation) to
        The resizing is corner aligned.
       for a dictionary of fixed size.
      [1, 2, 3, 4],
      [2, 3, 4],
      [5, 6, 7, 8],
      [5, 6, 7],
      </requestedPrivileges>
      <requestedPrivileges>
      All other elements in the matrix are set to zero.
      Based on Torch operator Embedding, creates a lookup table of embedding vectors of fixed size,
      Currently, only spatial (4-D) inputs are supported. For `input` with shape (N, C, H, W) and `grid` with shape (N, H_out, W_out, 2),
      For each output location `output[n, :, h, w]`, the size-2 vector `grid[n, h, w]` specifies `input` pixel locations `x` and `y`,
      Given an `input` and a flow-field `grid`, computes the `output` using `input` values and pixel locations from `grid`.
      If k = 0, the triangular part on and above/below the main diagonal is retained.
      If upper is set to false, a positive k retains the lower triangular matrix including k diagonals above
      If upper is set to true, a positive k retains the upper triangular matrix excluding k diagonals above
      of the elements on and above the given diagonal (k). The lower triangular part consists of elements on and below the diagonal.
      Returns the upper or lower triangular part of a 2-D matrix, or batches of 2-D matrices. If the attribute "upper" is set to true,
      See also in [torch.nn.functional.grid_sample](https://pytorch.org/docs/master/generated/torch.nn.functional.grid_sample.html#torch-nn-functional-grid-sample).
      the `output` will have shape (N, C, H_out, W_out).
      The GridSample operator is often used in doing grid generator and sampler in the [Spatial Transformer Networks](https://arxiv.org/abs/1506.02025).
      the main diagonal. A negative k value excludes as many diagonals below the main diagonal.
      the main diagonal. A negative k value includes as many diagonals below the main diagonal.
      the upper triangular matrix is retained. Lower triangular matrix is retained otherwise. Default value for upper is true.
      Trilu takes one input tensor of shape [*, N, M], where * is zero or more batch dimensions. The upper triangular part consists
      which are used to interpolate the output value `output[n, :, h, w]`.
    </security>
    <security>
   ' 0 8 ; > A C G Q S S U ^ 
  - Ct = ft (.) Ct-1 + it (.) ct
  - ct = g(Xt*(Wc^T) + Ht-1*(Rc^T) + Wbc + Rbc)
  - ft = f(Xt*(Wf^T) + Ht-1*(Rf^T) + Pf (.) Ct-1 + Wbf + Rbf)
  - Ht = (1 - zt) (.) ht + zt (.) Ht-1
  - Ht = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Wbi + Rbi)
  - ht = g(Xt*(Wh^T) + (rt (.) (Ht-1*(Rh^T) + Rbh)) + Wbh) # when linear_before_reset != 0
  - ht = g(Xt*(Wh^T) + (rt (.) Ht-1)*(Rh^T) + Rbh + Wbh) # default, when linear_before_reset = 0
  - Ht = ot (.) h(Ct)
  - it = f(Xt*(Wi^T) + Ht-1*(Ri^T) + Pi (.) Ct-1 + Wbi + Rbi)
  - ot = f(Xt*(Wo^T) + Ht-1*(Ro^T) + Po (.) Ct + Wbo + Rbo)
  - rt = f(Xt*(Wr^T) + Ht-1*(Rr^T) + Wbr + Rbr)
  - zt = f(Xt*(Wz^T) + Ht-1*(Rz^T) + Wbz + Rbz)
  "R*Y
  "separators" is a list of strings which are regular expressions. "tokenexp" is a single regular expression.
  (NOTE: Below are optional)
  * 2-D inputs or
  * 3-D inputs ('Bilinear', 'Trilinear') or
  * 4-D inputs with the corresponding outermost 2 scale values being 1 or the corresponding outermost and innermost scale values being 1 or
  * 5-D inputs with the corresponding outermost 2 scale values being 1in the 
  ["Hello World", "I love computer science !"] whose shape is [2],
  </trustInfo>
  <trustInfo xmlns="urn:schemas-microsoft-com:asm.v3">
 ' 0 C E Q S ^ } ~ 
  09az
  Affine(x)              - alpha*x + beta
  axes = [0, 1]
  data    = [[[0,1],[2,3]],[[4,5],[6,7]]]
  data    = [[0,1],[2,3]]
  data = [
  Elu(x)                 - x if x >= 0 else alpha*(e^x - 1)
  ends = [-1, 1000]
  ends = [2, 3]
  HardSigmoid(x)         - min(max(alpha*x + beta, 0), 1)
  If input is
  If input is ["Hello", "World"],
  If the maximum number of tokens found per input string is D, the output shape would be [N, C, D] when input shape is [N, C].
  indices = [[[0,1]],[[1,0]]]
  indices = [[0,0],[1,1]]
  indices = [[0,1],[1,0]]
  indices = [[1],[0]]
  LeakyRelu(x)           - x if x >= 0 else alpha * x
  Let's assume "separators" is [" "] and consider an example.
  Let's consider another example to illustrate the effect of setting "mark" to true.
  output  = [[[2,3]],[[4,5]]]
  output  = [[2,3],[0,1]]
  output  = [[2,3],[4,5]]
  output  = [0,3]
  Relu(x)                - max(0, x)
  result = [
  ScaledTanh(x)          - alpha*Tanh(beta*x)
  shape(A) = (2, 3, 4, 5), shape(B) = (,), i.e. B is a scalar tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (1, 1), i.e. B is an 1-element tensor
  shape(A) = (2, 3, 4, 5), shape(B) = (2), with axis=0
  shape(A) = (2, 3, 4, 5), shape(B) = (3, 4), with axis=1
  shape(A) = (2, 3, 4, 5), shape(B) = (4, 5)
  shape(A) = (2, 3, 4, 5), shape(B) = (5,)
  Sigmoid(x)             - 1/(1 + e^{-x})
  Similarly, if input shape is [C] then the output should be [C, D]. Tokenizer has two different operation modes.
  Softplus(x)            - log(1 + e^x)
  Softsign(x)            - x/(1 + |x|)
  starts = [0, 1]
  starts = [1, 0]
  Tanh(x)                - (1 - e^{-2x})/(1 + e^{-2x})
  The first mode is selected when "tokenexp" is not set and "separators" is set. If "tokenexp" is set and "separators" is not set,
  the second mode will be used. The first mode breaks each input string into tokens by matching and removing separators.
  then the corresponding output would be [0x02, "Hello", "World", 0x03].
  then the output would be
  This implies that if mark is true, [C]/[N, C] - input's output shape becomes [C, D+2]/[N, C, D+2].
  ThresholdedRelu(x)     - x if x >= alpha else 0
  Tokenizer divides each string in X into a vector of strings along the last axis. Allowed input shapes are [C] and [N, C].
 !!"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 != mat_h:
 &"H(D&
 ( ) / / _ _ 
 (0:<
 (0>|TY
 (08@HPX`hpx
 (08@J
 (6|TY
 (65+_
 (actual) rounded_bytes:
 (domain: 
 (falsenode).
 (node 
 (node_version: 
 (requested) num_bytes: 
 (truenode).
 (weights).
 ) is different from what is supplied (
 )`Q_
 * . ` d f o 
 *!+!2!2!N!N!`!
 *0-0
 *EQts
 , or optional typed entities
 , or sparse tensors
 . Got: 
 .",*
 .",4
 .|TY
 / / _ _ 
 : : 
 ["I", "love", "computer", "science", "!"]]
 [["Hello", "World", padvalue, padvalue, padvalue],
 [seqno=
 [truncated]
 |,},o-o-/./.
 ~044
 <"<$
 = Constant()
 > dense_size: 
 0$4&,(8*
 9 9 
 A]_^
 A^^]
 A^_^
 A^_^][
 A^A\_^]
 A^A]_
 A^A]A\_^
 A_A^^
 A_A^_
 A_A^_^]
 A_A^A\
 A_A^A\^]
 A_A^A\_^
 A_A^A\_^][
 A_A^A]
 A_A^A]_^
 A_A^A]_^][
 A_A^A]A\^
 A_A^A]A\^][
 A_A^A]A\_
 A_A^A]A\_^]
 Actual:
 already exist.
 already exists.
 and 
 and Output 
 and the number of 
 and then launches another search starting from the first remained character after the first matched token.
 and type (
' appeared multiple times.
 appears in graph inputs and will not be treated as constant value/weight. 
 are '0' and '1'. 
 are '0' and '1'. The environment variable contained the value: 
 arena_extend_strategy: 
 as it still has output edges.
 at line 
 at pos=
 attribtues in LabelEncoder 
' attribute.
 Attribute:
 Axis is 
 axis value 
 Axis=
 BackUp() can only be called after Next().
 because the CPU execution path is deemed faster than overhead involved with execution on other EPs 
 BFC Arena shrunk by 
 bins of max chunk size 
 broadcasting: (
 but 
 but different TensorProto.
 but expected 
 but has 
 but has rank 
 but input '
 but is of type: 
 but ngram_indexes size: 
 but subgraphs produce 
 but the actually size is: 
 but the node in the model has the following type (
 but usage of initializer in graph expects 
 bytes for 
 bytes were able to be read.
 bytes.
 bytes. 
 can not be writen into Tensor type 
 cannot be safely updated to 
 Can't back up over more bytes than were returned by the last call to Next().
 capable of executing this node
 Char embedding size: 
 char_embedding_size attribute: 
 column: 
 combination in the memory arena shrink list: 
 combination is not an arena based allocator: 
 conv filter size: 
 conv kernal size 1: 
 Conv kernal size 2 : 
 conv_window_size attribute: 
 d f p t ~ 
 data_type: 
 DeviceId:
 did not match batch size of 
 did not return correct number of compiled functions
 did not.
' dimension 
 dimension != 
 Dimension=
 dimensions or more but input had shape of 
 dimensions.
 does not align with rank of input data: 
 does not contain a graph.
 does not match actual shape of 
 does not match existing output type of 
 does not match input batch size 
 does not match rank 
 does not match the actual size
 does not match the equation indices.
 does not match type of output: 
 does not match. 
 does not specify a valid type.
 does not.
 doesn't have an implementation that can cache computed pre-packed weights
 doesn't have an implementation that can consume provided pre-packed weights
' doesn't support memcpy 
 dst_size: 
 E E } } 
 elements.
 else=
 embedding_size attribute: 
 Encountered following errors: (
 entries which doesn't match the number of fetches the frame was initialized with of 
 error message: 
 exceeded maximum protobuf size of 2GB: 
 Expected 
 Expected DENSE or SPARSE
 expected size 
 Expected std::map<int64_t, float> or std::map<int64_t, std::string>
 expected to be of type: 
 expected to have optional type
 expected to have rank 
 expected to have rank >
 expected to have sequence type
 expected to have tensor or sparse tensor type
 expected to have tensor or sparse tensor type. Got: 
 expected to have tensor or sparse tensor type: 
 expected to have tensor or sparse type
 expected to have tensor type
 expected to have type but instead is null
 expected to have: 
 Expected TO_FLOAT, TO_STRING or TO_INT64
 Expected:
 Expected: 
 ExplicitInputs:
 fail, errcode = 
 fail: unexpected end
 failed
 failed.
 failed. Error:
 failed. File doesn't exist
 failed. Only 
 failed:
 failed: 
 filter_number: 
 for attribute 
 For each input string, the second mode searches matches of "tokenexp" and each match will be a token in Y.
 for input shape 
' for NCHWc Upsample
 for operator 
 for output 
 for SizeFromDimension. Tensor has 
 for the following indices
 found!
 Found:
 Got:
 got: 
 Got: 
 Graph may not conform to the ONNX spec and contain initializers that are not graph inputs.
 group: 
 h _Y
 H"2  $
 H;\$(u
 H;=[
 H;D$8u
 H;k(u
 H;T$@
 H3E H3E
 has already been loaded.
 has already been registered.
 has batch size of 
' has been deprecated since version 
' has been used as graph input names multiple times.
' has been used as output names multiple times.
 has Compile error: 
' has element type 
 has inconsistent type 
 has length of 
 has mismatched dimensions of 
 has unknown expected type
 has unsupported type 
 Hct$PI
 Hiy`@!
 However the types are incompatible.
 http://www.microsoft.com/windows0
 I;^pu
 I;h0|
 I;V 
 id: 
 If "separators" contains a single empty string, the Tokenizer will enter into character tokenezation mode. This means all strings
 If no match found, this operator will remove the first character from the remained string and do another search.
 Implicit input name 
 ImplicitInputs:
 in AddToThreadq
 in 'Constant' node '
' in custom op '
 in function opset imports.
 in initializer but not in graph input
 in KernelRegistryManager
 in node 
 in node (
 in one of the subgraphs.
 in step
 in the same dimension
 in the supported version range
 in tree 
 Index:
 index: 
 inferred output shape:
 inferred=
 initial_growth_chunk_size_bytes: 
 initializer name is not unique
 Input dim value: 
 input dimensions instead
 Input shape=
 input with name 
 Input=
 inputs and requires 
 inputs but 
 inputs but Scan was only given 
 inputs but subgraph has 
 inputs. Either provide all subgraph inputs, or just the required inputs.
 inputs. Found:
' instead of '
 into softmax(input + bias)
 is already there.
 is defined.
 is deprecated in domain_version of 
' is expected to have field 'floats'
' is expected to have field 'g'
' is expected to have field 'graphs'
' is expected to have field 'ints'
' is expected to have field 'sparse_tensor'
' is expected to have field 'strings'
' is expected to have field 't'
' is expected to have field 'tensors'
' is expected to have field 'type_proto'
' is expected to have field 'type_protos'
 is expected to have type: 
 is greater than input dim=
 is incompatible in the dimension 
 is invalid for a tensor of rank 
 is invalid.
 is marked single but has an empty string in the graph
 is missing type info.
' is missing.
 is missing. Invalid ORT format model.
 is NaN
' is not a graph input, initializer, or output of a previous node.
 is not a registered function/op
 is not a valid date
 is not a valid day
 is not a valid year
 is not compatible with 
 is not currently registered or supported
 is not expected to be of type sparse tensor.
 is not expected to be of type tensor sequence.
 is not expected to be of type tensor.
 is not implemented
 is not in (0, 
 is not in valid range [-
 is not output of any previous nodes.
 is not present.
 is not supported
 is not supported currently
 is not supported yet
 is not supported.
 is not the same as this node's index:
 is not used by any node.
 is null
 is null. Invalid ORT format model.
 is null. Type info is expected.
 is out of bounds of lhs_right: 
 is out of bounds of out_left: 
 is out of bounds.
 is outside range.
 is repeated.
 is required but missing.
 is required to be non-empty.
 is smaller than requested bytes of 
 is till opset 
 is undefined so it cannot be parsed.
 is under development and support for this is limited. The operator schemas and or other functionality could possibly change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain 
 is unrecognized, acceptable values are TF,IDF,TFIDF
 is used by node 
 kernel channels: 
 kernel is not supported in 
 kernel start version: 
 kernel_end_version: 
 kernel_shape: 
 known by the checker.
 L;|$ 
 L;|$hs
 Lc\$pE3
 Left shape override: 
 line 
 Max:
 max_dead_bytes_per_chunk: 
 memory limit: 
 MemoryType:
 message of type "
 Microsoft Corporation. All rights reserved.
' Model is invalid.
 model may run depending upon legacy support of some older opset version operators.
 model uses the deprecated attribute
 models with experimental operators: 
 must be 1 instead of 
 must be either specified in graph inputs or graph initializers.
 must be equal to or twice the values size: 
 must be less than total buffer size: 
 must be of equal size
 must be within the inclusive range [
 must have shape {
 N"v$
 node '
 node. Name:'
 node_version: 
' not found
 not found.
 not in allowed input sizes.
 not in allowed output sizes.
 not in range [min=
 not specified
 Note that the input at most can have two axes, so 3-D and higher dimension are not supported.
 Num entries in 'split' (must equal number of outputs) was 
 num_input_channels: 
 NumOutputs=
' of 
' of input parameter (
 of node 
' of node: 
 Operating System
 optype 
' optype 
' OpType:
 OpType: 
 or UNDEFINED. Got: 
 OrtAllocatorType:
 OrtMemType:
 out of bounds for shape 
 Output dim value: 
 outputs but Scan expects 
 outputs so the subgraph requires 
 outputs which doesn't match the subgraph's 
 outputs.
 outputs. Expected 
 P!_!
 P"j&
 Parameter to BackUp() can't be negative.
 Please fix either the inputs or the model.
 Provider: [
 referenced by function body node 
 Requested shape:
 returned nullptr
 Right shape override: 
 Right shape: 
 row[
 rows: 
 rows[
 should be of integer type and specify a type.
' should be stored in field '
 should specify a shape
 size: 
 size=
' source:
 source=
 sparse initializer name is not unique across initializers and sparse_initializers
 specified. It should be either avg or max
 specified. It should be either bilinear or nearest
' Status Message: 
 Sum of sizes in 'split' (must equal size of selected axis) was 
 sum of split values=
 T&D4
 t>I;
 target:
 target=
 Target=
 tDE3
 Tensor=
 The matching of "tokenexp" is conducted greedily (i.e., a match should be as long as possible).
' the model will use the latest encountered initializer
 The production MUST never overflow. The accumulation may overflow if and only if in 32 bits.
 the same as values size: 
 The total allocated bytes is now 
 then=
 This op has been implemented only for the following types (
 This operator searches for the first match starting from the beginning of the considered string,
 This procedure will be repeated until reaching the end of the considered string.
 to be equal to values blocks: 
 to device type: 
 to have different number of elements
 type: 
 typestr: 
 unknown
 used in the node: 
 v"J$@&L 
 Value=
 values, but NNZ is 
 Version mismatch.
 version: 
 vs inner_B: 
 vs. 
 was 
' was 
 was false.
 was not
 was not a tensor.
 was not found. Defaulting to a rank 1 shape of {0}.
 were provided
 were provided.
 which is of op type: 
 whose shape is [2, 5] because you can find at most 5 tokens per input string.
 will be broken part into individual characters.
 Windows
 with domain_version of 
 with following configs: initial_chunk_size_bytes: 
 z"H$V 
 z,V(8&5
!#!%!%!'!'!)!)!.!.!:!;!@!D!J!M!O!O!
!#!%!%!'!'!)!)!.!.!:!;!J!J!L!M!O!O!
!#%'**,,./:;?@\\
!#%*,/:;?@[]__{{}}
!$!$!&!&!(!(!*!-!/!9!<!?!E!I!N!N!
!$!$!&!&!(!(!*!-!0!3!>!?!E!E!
!%!'!)!,!1!3!M!O!_!
!&$@$J$`$
!(isinf_only && isnan_only)
!(it.GetName().empty())
!/!/!4!4!9!9!<!=!F!I!N!N!
!/:@[`{~ ~
!-:L$
!@!D!K!K!
!]_0t
!|$(I
!0,^,a,a,e,f,h,h,j,j,l,l,q,q,s,t,v,{,
!allow_zero
!ba|H
!c->in_use() && (c->bin_num != kInvalidBinNum)
!c->in_use() && (c->bin_num == kInvalidBinNum)
!c1->in_use() && !c2->in_use()
!char_tokenezation_ || mincharnum_ < 2
!chunk->in_use()
!coefficients_.empty()
!current_parallel_section
!D$`D
!D$PD
!D$XM
!found
!graph.GetInitializedTensor(new_initializer.name(), existing)
!GwQN
!H !H$H!H(H
!has_axes || attr_axes_.size() == attr_starts_.size()
!helper.HaveTwoTensorInputs()
!input_tensor.IsDataType<std::string>()
!is_concrete_shape_
!is_train_ || ((!saved_mean && !saved_inv_std) || (saved_mean && saved_inv_std))
!IsNonTensor(*node_output)
!l$ H
!mask || mask->Shape() == X_shape
!node_consumers.empty()
!normalize_
!op_type.empty()
!points_.empty()
!pool_strings.empty()
!rpJN
!scale_.empty()
!separators.empty()
!sum_input_moved
!sw.empty()
!T$TI!S
!This program cannot be run in DOS mode.
!TkjE
!tokenexp.empty()
!using_counters_
!utils::HasExternalData(t_proto)
" """$J
" "&L
" "(L
" "(P
" "(R
" ",R
" #!#|#|#
" $""&P
" : "
" because it is missing required fields: 
" not supported, expect bilinear, nearest or bicubic
" not supported, expect zeros, border or reflection
" when trying to load "
"""""""
""$j&
", "block_size": [
".$^(
-"<04
">dB4D2J
"2$^(
"2$> 
"6&F(B&t(B&V"
"args" : {
"bQ}X
"core": 
"D d$i
"dur" :
"F$P&}
"l$>"%
"l&b*P@
"Microsoft Window
"name" :"
"num_run": 
"P$D&
"P$X"$&@(.&t*
"ph" : "X",
"pid" :
"rv9c
"thread_id": "
"thread_pool_name": "
"tid" :
"ts" :
"V h$
"v.V*8(]
"x H(` 
"z$ &
"Z$|(
#"#(#+#{#}#
#&$@$J$
#(#+#&$@$J$
#)#)#h'h'j'j'l'l'n'n'p'p'r'r't't'
#)#*#h'u'
#*#*#i'i'k'k'm'm'o'o'q'q's's'u'u'
#6t%r
#bAmX
#bQ}X
#wht^
$ """$P
$ "*R
$ ".R
$ x"N$b&
$$++<>^^``||~~
$$M9A@
$@&v*(,
$@ba~H
$@bA~H
$@ba~H
$]Y`H
$^&h(d,@.d2>4`8d:
$< t6<$t,<+t"<vt
$0bR~J
$6(^*n,T.
$bR}H|
$H&|*.,
$H90u
$HcK$H
$Iba|H
$IbB}H
$l(.,N.
$L9@ s
$Microsoft Ireland Operations Limited1
$N:<d
$Nba|H
$p&f.
$qbB~J
$r&"$
$x&((
$y&D4G!o/H/
$z*z0
-%-'-'-----
%.0Lf
%~3a*
-%-'-'-----0-g-o-o-
-%-'-'-----A
%b %d %H : %M : %S %Y
%d / %m / %y
%g6HHj`m
%H : %M
%H : %M : %S
%hs!%p: 
%hs(%d) tid(%x) %08X %ws
%hs(%u)\%hs!%p: 
%I : %M : %S %p
%I64u
%i9&#
%m / %d / %y
%Microsoft Windows Production PCA 2011
%Microsoft Windows Production PCA 20110
%o&o&
%Y-%m-%d_%H-%M-%S
&!&!e
&$("*
&$P&.(,
&&(<&q
&((d&
&(*\(,
&(*\(`
&,(2&R*,,4*h,"*|,:.T0T*D2T4
&,H2Z0-
&:((*(,..z0
&^jwv
&~*4.}
&EglX
&f*.,,
&f<\@NB
&h*^,
&h<\@Nz
&n&p&g'
&Rich
&S|9a
&TpxAD
(  "($
( ""($
(([[{{
(){}[]*+?|.^$\
(*P6.8,
(*T,..,@(DTF.H,@
(;Qh|
(?HaveMatch:%d)
(?-m:$)
(?-m:^)
(?n2*
(\$PD
(\$PH
(^*^,d.X0n2
(_^][
(|$ D
(|$ H
(|$ I
(|$ L
(|$@A
(|$@D
(|$@H
(|$@I
(|$`D
(|$`I
(|$0D
(|$0H
(|$0I
(|$PD
(|$pE
(|$PH
(|$pI
(|$pL
(~,@.L(~,@.$
(08@HV
(08@HVa+_
(08@HVK+_
(6')_
(6\*_
(6|TY
(6=)_
(6=,_
(60*_
(6F*_
(6i,_
(6o)_
(6S,_
(6V)_
(6w+_
(A_A^_^][
(A_A^A]A\_^][
(B*"(l
(bQ}X
(caller: %p) 
(cannot determine missing fields for lite message)
(channels % 4) == 0
(D$ B
(D$ D
(D$ f
(D$ H
(D$ L
(D$@f
(D$@fE
(D$@H
(d$`D
(D$`D
(d$`D
(D$`D
(d$`D
(D$`D
(d$`D
(D$`f
(D$`fA
(D$`H
(d$`H
(D$`H
(D$`L
(D$0D
(D$0f
(d$0f
(D$0f
(D$0H
(D$PA
(D$pA
(D$PD
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(D$Pf
(D$pf
(default) or 
(float, default 0.5) the ratio of random dropout
(fmod == 0) || (fmod == 1)
(H+D$XA
(inputs_.size() - 1) == i
(int, default 0) if nonzero, run dropout in test mode where the output is simply Y = X.
(items % ngram_size == 0)
(J*J,j0
(j*z,!
(L$ D
(L$ f
(L$ H
(L$@D
(L$@f
(L$`f
(L$0D
(l$0f
(L$0f
(L$0L
(l$pD
(L$pD
(l$pD
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$Pf
(L$pf
(L$pH
(line: 
(local_source >= source) && (local_source < source + num_blocks * blocksize)
(local_source >= source) && (local_source < source + num_blocks * num_elts_in_block)
(local_source >= source) && (local_source < source + num_blocks)
(local_source >= source) && (local_source < source + sizeof(T) * num_blocks)
(name: 
(null)
(op_type:
(Optional) A scalar or rank 1 tensor containing a single value to be filled if the mode chosen is `constant` (by default it is 0.0).
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor.
(Optional) Axis along which one-hot representation in added. Default: axis=-1. axis=-1 means that the additional dimension will be inserted as the innermost/last dimension in the output tensor. Negative value means counting dimensions from the back. Accepted range is [-r-1, r] where r = rank(indices).
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected.
(Optional) Axis along which to take slices. If not specified, input is flattened before elements being selected. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
(Optional) By default, when any value in the 'shape' input is equal to zero the corresponding dimension value is copied from the input tensor dynamically. allowzero=1 indicates that if any value in the 'shape' input is set to zero, the zero value is honored, similar to NumPy.
(Optional) Ending axis for slicing the shape. Negative value means counting dimensions from the back. If omitted, sizes of all axes upto (including) the last one will be included.
(Optional) Index of the diagonal to be populated with ones. Default is 0. If T2 is the output, this op sets T2[i, i+k] = 1. k = 0 populates the main diagonal, k > 0 populates an upper diagonal,  and k < 0 populates a lower diagonal.
(Optional) Seed to the random generator, if not specified we will auto generate one.
(Optional) Specify which axis is batch axis. Must be one of 1 (default), or 0.
(Optional) Specify which axis is time axis. Must be one of 0 (default), or 1.
(Optional) Starting axis for slicing the shape. Default value is 0.Negative value means counting dimensions from the back.
(Optional) The axis of the dequantizing dimension of the input tensor. Ignored for per-tensor quantization. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
(Optional) The axis of the quantization dimension of the input tensor. Ignored for per-tensor quantization. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
(Optional) The data type for the elements of the output tensor, if not specified, we will use int32.
(Optional) The data type for the elements of the output tensor, if not specified, we will use the data type of the input tensor.
(Optional) The data type for the elements of the output tensor. If not specified,the data type of the input tensor T1 is used. If input tensor T1 is also notspecified, then type defaults to 'float'.
(Optional) The data type of the tensors in the output sequence. The default type is 'float'.
(Optional) The dimension to apply unique. If not specified, the unique elements of the flattened input are returned. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
(Optional) The value of the output elements.Should be a one-element tensor. If not specified, it defaults to a tensor of value 0 and datatype float32
(Optional) Whether map negative infinity to true. Default to 1 so that negative infinity induces true. Set this attribute to 0 if negative infinity should be mapped to false.
(Optional) Whether map positive infinity to true. Default to 1 so that positive infinity induces true. Set this attribute to 0 if positive infinity should be mapped to false.
(Optional) Whether to sort the unique elements in ascending order before returning as output. Must be one of 0, or 1 (default).
(outputs_.size() - 1) == i
(static_cast<size_t>(X_shape[1]) < nchwc_block_size) || ((X_shape[1] % nchwc_block_size) == 0)
(t$ H
(t$@~cM
(T$@D
(t$@H
(T$@H
(t$@H
(t$@I
(t$@L
(t$`H
(t$`L
(t$0H
(T$0H
(t$0L
(t$pD
(t$PD
(t$PH
(t$pH
(t$PH
(t$pH
(t$PI
(t$pL
(t*2(
(Tensor<float>) whose value is the input data tensor scaled element-wise.
(Tensor<T>) where the affine function, y = alpha * x + beta,
(Tensor<T>) where the softplus function, y = alpha * ln(exp(beta * x) + 1), is applied to
(unknown type)
(X*t,
(X_shape[1] % MlasNchwcGetBlockSize()) == 0
) != (
) != new size (
) != split_dim_size (
) : (
) + (
) + bottom_border (
) + bottomBorder (
) + right_border (
) + rightBorder (
) + scale[0] (
) + scale[1] (
) + scale_[0] (
) + scale_[1] (
) -> (
) and node 
) and outputs (
) and the split dimension of the input (
) are not at boundary of span with size:
) attribute (
) because the ORT planned memory location device 
) bound to different types (
) dimensions are not positive.
) does not exist in the graph.
) does not have type information set by parent node.
) does not have type information.
) does not match expected type (
) does not match number of inputdimensions values (
) does not match the data size(
) does not match the number of channels (
) first dimension size does not equal NNZ.
) for attribute 'axis'
) for tensor of length:
) from file 
) has 
) has input size 
) has more inputs (
) has more outputs (
) has no index values.
) has output size 
) has zero input and zero output.
) in kernel registries for 
) in node (
) in op definition.
) in proto
) index value at position [
) input arg (
) is 0-element but contains data!
) is invalid.
) is not equal to number of scan inputs (
) is not equal to number of scan outputs (
) is not equal to the existing dim value (
) is not equal to the existing rank value (
) is required but not specified.
) is stored externally and should not have data field.
) is stored externally but doesn't have a location.
) must have a dense-rank > 0
) must have INT64 type.
) must have rank 1 or 2.
) must have rank 1.
) must have the same length. 
) needs to be greater than or equal to the left_border (
) needs to be greater than or equal to the leftBorder (
) needs to be greater than or equal to the top_border (
) needs to be greater than or equal to the topBorder (
) node with name '
) of node (
) of operator (
) of Optype (
) of output arg (
) Op (
) or 1
) output arg (
) second dimension size does not match rank of tensor.
) should be stored in 
) should contain one and only one value field.
) should not be stored in raw_data field
) should not contain more than one value field.
) should refer to attribute in parent node.
) specified for sequence of size (
) than declared (
) to UNDEFINED is not allowed
) type inference failed
) vs (
)".".$.$.&.&.(.(.B.B.
)#.#.%.%.'.'.).).
)) , expected: (
))]]}}
), but the current device does not support 16-bit float.
), input tensor data type (
)\$ f
)\$@A
)\$`D
)\$PD
)\$pD
)\$PD
)\$PH
)\$PJ
)|$ H
)|$ I
)|$@D
)|$@H
)|$`E
)|$`H
)|$0D
)|$0H
)|$PD
)|$PE
)|$PI
)bQ}X
)D$ 3
)D$ D
)D$ f
)D$ H
)D$ H9i
)D$ L
)D$@f
)D$@H
)d$`D
)D$`D
)d$`D
)D$`D
)d$`D
)D$`f
)D$`H
)D$`H+
)d$`J
)D$`M
)d$0D
)D$0E
)D$0f
)D$0H
)D$0L
)d$pD
)d$PD
)d$Pf
)D$pfH
)d$PH
)D$PN
)Hct$`
)Hct$P
)jpKG$'
)l$ D
)L$ f
)l$@D
)l$@H
)l$`D
)L$0A
)L$0D
)L$0f
)L$pD
)l$pD
)l$PD
)l$pD
)L$pH
)L+$8L+d9
)Microsoft Root Certificate Authority 20100
)'s input 
)'s output 
)s+v+
)t$ H
)t$ I
)t$ M
)T$@3
)T$@D
)t$@D
)T$@D
)T$@H
)t$@H
)t$@I
)t$@L
)t$`D
)t$`H
)t$`I
)t$`M
)t$0D
)t$0H
)T$0H
)t$0M
)T$PA
)t$pD
)t$PD
)t$pH
)T$PH
)t$pH
)t$PH
)t$PI
*",P.-
*$,X*
*$,x.N0R>:<V8
*$L& (
*&,B.
*(&@$
**,H&5
*\6X*
*`.@0
*~ H.
-*0/0
*0+D+G+L+)
-*0-0
*F,**P&
*J,0*
*L$0I
*L$0L
*L$0M
*l$hb
*L$HH
*n,b8
*out_size >= 0
*r,~.02Q
, am_attn_size}, Got:
, aw_attn_size}. Got:
, block in memory pattern size is: 
, but it doesn't exist or is not accessible.
, but it is already registered from file 
, but it its domain is not
, but it its version is higher
, but its domain is not
, but its version is not 
, column 
, data shape: 
, Error 
, error code: 
, expect 2
, external_data.length: 
, fall back to default allocation behavior
, Got 
, got 
, has unsupported type: 
, indices shape: 
, max supported IR version: 
, max=
, node name: 
, requested shape:
, type: 
, Z"4$2
,"(n"P$
,"4P,4"
,$I;ppsrH
,&L( *
,.,`,`,b,d,g,g,i,i,k,k,m,p,r,r,u,u,~,
,.,0,^,
,.,0,^,`,
,0Z24428
,1FtJaprpAFx4r2VNzGR99PSWe/bR9Cbqb+B64roV0dA=0Z
,A9<$u&I;
,H.2, 0
,h0P.v0B.
,P.Q.
,p-p-
. . .
'. 0 == forward. 1 == reverse.
. batch_size=
. bin_num:
. Can't constant fold 
. Dimension 0 is 
. Do you have duplicated calls to SessionState::AddInitializedTensor function?
. Error message 
'. Error message 
. Execution Provider must generate unique names across the entire model.
. Execution will fail if ORT does not have a specialized kernel for this op
. Expected:
. Falling back to lenient merge.
. Ignoring allocator from 
. Index:
. Input rank=
. Input tensor rank was 
. Invalid ORT format model.
. It can only be 
'. It is no longer used by any node.
'. It is not used by any node and should be removed from the model.
. Must be 0 or 1
'. Must be one of 'forward', 'reverse', or 'bidirectional'.
. No opset import for domain
. No schema registered for this operator.
. Num args is 
. Output tensor rank was 
. Please, fix your model.
. Shape:
. shape=
. The shape is: 
'. Valid values are 'LEFT' or 'RIGHT'.
. Validate usage of dim_value (values should be > 0) and dim_param (all values with the same string should equate to the same size) in shapes in the model.
. Value must be in range [0,
.!.!.
."~&.(,
.*...0.9.<.?.A.A.C.O.R.R.
...0.O.R.R.
.:.;.@.@.
.?AU?$Abs@_J@functors@onnxruntime@@
.?AU?$Abs@_K@functors@onnxruntime@@
.?AU?$Abs@C@functors@onnxruntime@@
.?AU?$Abs@E@functors@onnxruntime@@
.?AU?$Abs@F@functors@onnxruntime@@
.?AU?$Abs@G@functors@onnxruntime@@
.?AU?$Abs@H@functors@onnxruntime@@
.?AU?$Abs@I@functors@onnxruntime@@
.?AU?$Abs@M@functors@onnxruntime@@
.?AU?$Abs@N@functors@onnxruntime@@
.?AU?$Ceil@M@functors@onnxruntime@@
.?AU?$Celu@M@functors@onnxruntime@@
.?AU?$default_delete@VBFCArena@onnxruntime@@@std@@
.?AU?$default_delete@VCPUExecutionProvider@onnxruntime@@@std@@
.?AU?$default_delete@VIAllocator@onnxruntime@@@std@@
.?AU?$default_delete@VIExecutionProvider@onnxruntime@@@std@@
.?AU?$default_delete@VModel@onnxruntime@@@std@@
.?AU?$Elu@M@functors@onnxruntime@@
.?AU?$Exp@M@functors@onnxruntime@@
.?AU?$Exp@N@functors@onnxruntime@@
.?AU?$Floor@M@functors@onnxruntime@@
.?AU?$HardSigmoid@M@functors@onnxruntime@@
.?AU?$LeakyRelu@M@functors@onnxruntime@@
.?AU?$Log@M@functors@onnxruntime@@
.?AU?$Log@N@functors@onnxruntime@@
.?AU?$MaxPool1DTask@C@onnxruntime@@
.?AU?$MaxPool1DTask@E@onnxruntime@@
.?AU?$MaxPool1DTask@M@onnxruntime@@
.?AU?$MaxPool1DTask@N@onnxruntime@@
.?AU?$MaxPool2DTask@C@onnxruntime@@
.?AU?$MaxPool2DTask@E@onnxruntime@@
.?AU?$MaxPool2DTask@M@onnxruntime@@
.?AU?$MaxPool2DTask@N@onnxruntime@@
.?AU?$MaxPool3DTask@C@onnxruntime@@
.?AU?$MaxPool3DTask@E@onnxruntime@@
.?AU?$MaxPool3DTask@M@onnxruntime@@
.?AU?$MaxPool3DTask@N@onnxruntime@@
.?AU?$MaxpoolWithMask1DTask@M@contrib@onnxruntime@@
.?AU?$MaxpoolWithMask2DTask@M@contrib@onnxruntime@@
.?AU?$MaxpoolWithMask3DTask@M@contrib@onnxruntime@@
.?AU?$Neg@_J@functors@onnxruntime@@
.?AU?$Neg@C@functors@onnxruntime@@
.?AU?$Neg@H@functors@onnxruntime@@
.?AU?$Neg@M@functors@onnxruntime@@
.?AU?$Neg@N@functors@onnxruntime@@
.?AU?$ParametricSoftplus@M@functors@onnxruntime@@
.?AU?$Pool1DTask@MVLpPool@onnxruntime@@@onnxruntime@@
.?AU?$Pool2DTask@MVLpPool@onnxruntime@@@onnxruntime@@
.?AU?$Pool3DTask@MVLpPool@onnxruntime@@@onnxruntime@@
.?AU?$Powx@M@functors@onnxruntime@@
.?AU?$QLinearPool1DTask@EVAveragePool@onnxruntime@@@contrib@onnxruntime@@
.?AU?$QLinearPool2DTask@EVAveragePool@onnxruntime@@@contrib@onnxruntime@@
.?AU?$QLinearPool3DTask@EVAveragePool@onnxruntime@@@contrib@onnxruntime@@
.?AU?$QLinearPoolNhwc1DTask@EVAveragePool@onnxruntime@@@contrib@onnxruntime@@
.?AU?$QLinearPoolNhwc2DTask@EVAveragePool@onnxruntime@@@contrib@onnxruntime@@
.?AU?$QLinearPoolNhwc3DTask@EVAveragePool@onnxruntime@@@contrib@onnxruntime@@
.?AU?$Reciprocal@M@functors@onnxruntime@@
.?AU?$Reciprocal@N@functors@onnxruntime@@
.?AU?$Relu@C@functors@onnxruntime@@
.?AU?$Relu@H@functors@onnxruntime@@
.?AU?$Relu@M@functors@onnxruntime@@
.?AU?$Relu@N@functors@onnxruntime@@
.?AU?$ScaledTanh@M@functors@onnxruntime@@
.?AU?$Selu@M@functors@onnxruntime@@
.?AU?$Sigmoid@M@functors@onnxruntime@@
.?AU?$Sigmoid@N@functors@onnxruntime@@
.?AU?$Softplus@M@functors@onnxruntime@@
.?AU?$Softsign@M@functors@onnxruntime@@
.?AU?$Sqrt@M@functors@onnxruntime@@
.?AU?$Sqrt@N@functors@onnxruntime@@
.?AU?$Tanh@M@functors@onnxruntime@@
.?AU?$Tanh@N@functors@onnxruntime@@
.?AU?$ThresholdedRelu@M@functors@onnxruntime@@
.?AU_Crt_new_delete@std@@
.?AUctype_base@std@@
.?AUException@Ort@@
.?AUhresult_access_denied@winrt@@
.?AUhresult_canceled@winrt@@
.?AUhresult_changed_state@winrt@@
.?AUhresult_class_not_available@winrt@@
.?AUhresult_class_not_registered@winrt@@
.?AUhresult_error@winrt@@
.?AUhresult_illegal_delegate_assignment@winrt@@
.?AUhresult_illegal_method_call@winrt@@
.?AUhresult_illegal_state_change@winrt@@
.?AUhresult_invalid_argument@winrt@@
.?AUhresult_no_interface@winrt@@
.?AUhresult_not_implemented@winrt@@
.?AUhresult_out_of_bounds@winrt@@
.?AUhresult_wrong_thread@winrt@@
.?AUmessages_base@std@@
.?AUmoney_base@std@@
.?AUNodeCompare@onnxruntime@@
.?AUPriorityNodeCompare@onnxruntime@@
.?AUtime_base@std@@
.?AV?$_Iosb@H@std@@
.?AV?$_Mpunct@_W@std@@
.?AV?$_Mpunct@D@std@@
.?AV?$_Mpunct@G@std@@
.?AV?$basic_filebuf@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ios@DU?$char_traits@D@std@@@std@@
.?AV?$basic_ostream@DU?$char_traits@D@std@@@std@@
.?AV?$basic_streambuf@DU?$char_traits@D@std@@@std@@
.?AV?$codecvt@_WDU_Mbstatet@@@std@@
.?AV?$codecvt@DDU_Mbstatet@@@std@@
.?AV?$codecvt@GDU_Mbstatet@@@std@@
.?AV?$collate@_W@std@@
.?AV?$collate@D@std@@
.?AV?$collate@G@std@@
.?AV?$ctype@_W@std@@
.?AV?$ctype@D@std@@
.?AV?$ctype@G@std@@
.?AV?$messages@_W@std@@
.?AV?$messages@D@std@@
.?AV?$messages@G@std@@
.?AV?$money_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$money_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$money_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$money_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$money_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$money_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$moneypunct@_W$00@std@@
.?AV?$moneypunct@_W$0A@@std@@
.?AV?$moneypunct@D$00@std@@
.?AV?$moneypunct@D$0A@@std@@
.?AV?$moneypunct@G$00@std@@
.?AV?$moneypunct@G$0A@@std@@
.?AV?$num_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$num_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$num_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$num_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$num_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$num_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$numpunct@_W@std@@
.?AV?$numpunct@D@std@@
.?AV?$numpunct@G@std@@
.?AV?$time_get@_WV?$istreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$time_get@DV?$istreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$time_get@GV?$istreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV?$time_put@_WV?$ostreambuf_iterator@_WU?$char_traits@_W@std@@@std@@@std@@
.?AV?$time_put@DV?$ostreambuf_iterator@DU?$char_traits@D@std@@@std@@@std@@
.?AV?$time_put@GV?$ostreambuf_iterator@GU?$char_traits@G@std@@@std@@@std@@
.?AV_Facet_base@std@@
.?AV_Generic_error_category@std@@
.?AV_Iostream_error_category2@std@@
.?AV_Locimp@locale@std@@
.?AV_System_error@std@@
.?AV<lambda_0031e1631721c75a1f7a0e71cb748ed7>@@
.?AV<lambda_006f042491572090b778a6887556c541>@@
.?AV<lambda_007f5166efe630b2b34ea6bece4c38ea>@@
.?AV<lambda_00b59445cb71ad9abff9006cdec65ab0>@@
.?AV<lambda_0251dfdaad61cfa5b2a46c99b78d27e8>@@
.?AV<lambda_02cf852cc5a543f808433f03632ba155>@@
.?AV<lambda_0311f58d27b0724e7aff1c8a092d73e4>@@
.?AV<lambda_031e8dfd8d6a123502d9ec2194443e60>@@
.?AV<lambda_0385abfaef506cac5165d4d2b4c7ecc3>@@
.?AV<lambda_038eb253b7f4e93118566e43dda81530>@@
.?AV<lambda_03c53d5c540d06d25e58298bd3e2675f>@@
.?AV<lambda_03e7406b29b220fa131a6585ce48dcd2>@@
.?AV<lambda_0443539308e5b1117b55e6de227ed40c>@@
.?AV<lambda_0457fc55cb15f22bdcba75f54e0aa1c1>@@
.?AV<lambda_048b899a3305cb2c0c070dd18e5b4d17>@@
.?AV<lambda_04a053d9287fc146500ea7158f178603>@@
.?AV<lambda_05232ca3edd0818f9993e6f6f14300f3>@@
.?AV<lambda_05564eb259071976ee09610f192b6712>@@
.?AV<lambda_05c8e068d08f49052da87d86b6e09131>@@
.?AV<lambda_05f437c6028bdce22a59a3bca2849370>@@
.?AV<lambda_06471b7954288b9dda9f9d99a72bb7c6>@@
.?AV<lambda_066c50938341a8bc4180c44723e9e561>@@
.?AV<lambda_06e5eb766e97cbbd1e9836fc044820b5>@@
.?AV<lambda_07364fb607ea89235f416789a046b92d>@@
.?AV<lambda_0736746d817c31c51fce207b52ada565>@@
.?AV<lambda_076f399d54601fd1059236c6a3813828>@@
.?AV<lambda_0847b334bbfd42737aafe7ba61663e74>@@
.?AV<lambda_087f7d76293e9eae88f0507abf2d5be6>@@
.?AV<lambda_08b89006bb2cd45177aec966a5a64a25>@@
.?AV<lambda_08db83bf9ac8665fc4de47cb08668b85>@@
.?AV<lambda_0920e8c792b09e0b2fbd0035321589a5>@@
.?AV<lambda_099bb0573d1376fbed683cceb180bb81>@@
.?AV<lambda_099f8dd4d33b6b91bc0ee51d86ed6c1a>@@
.?AV<lambda_0a0326aaa0c17e1dc10459d8b6c3398c>@@
.?AV<lambda_0a3d98e003a8310444f50c395f4ee870>@@
.?AV<lambda_0a786afdc494302a03a8347211af4f5e>@@
.?AV<lambda_0aa1cbb10b7e27c8eaa9e1c4d936a012>@@
.?AV<lambda_0aeb3b3202e2e34a7d6b98b623e6a327>@@
.?AV<lambda_0af4c846dd5af6632beb77ffbd6469c9>@@
.?AV<lambda_0afff8b6c40408852605b1495798325e>@@
.?AV<lambda_0b3e445014abdc00ff4fcef82b0ddb16>@@
.?AV<lambda_0b4cc153b058489c05500d0b394c47a0>@@
.?AV<lambda_0b84cd883df2cf8f5da7751da99be58c>@@
.?AV<lambda_0ba48c1f3299a5f4228b96a5876e6f39>@@
.?AV<lambda_0c6b04fd5867b05b63eee5705dade40a>@@
.?AV<lambda_0d57079c5084d18bf7b57a312b9c6ff1>@@
.?AV<lambda_0e262c4f5599939b5b120509b5d5183b>@@
.?AV<lambda_0e9a1a7b6965f6b0c97b479e18664de1>@@
.?AV<lambda_0eb1c82669a9a9098341056a7159769f>@@
.?AV<lambda_0eb6d36a1e572b96903c06e9975f6aa3>@@
.?AV<lambda_0f2ad18a551e793a8bddf1de1dc21689>@@
.?AV<lambda_0f569c3741dec4cbd25547f5cfa47a1f>@@
.?AV<lambda_0f619f3ff08e9e7659a763308b991cbe>@@
.?AV<lambda_0fb4e93f4014e9a9ed52287648f86c91>@@
.?AV<lambda_1038cf6b5b3a06f7836c03470cc73cfe>@@
.?AV<lambda_104e5d4f3c346a5807a7db11389af990>@@
.?AV<lambda_10d9e40dd67492c4fb3c3f078abc9bd8>@@
.?AV<lambda_11002e821957b929b79aa649ecf0a381>@@
.?AV<lambda_113fc5cdb3f9f5e45a498eccec03db60>@@
.?AV<lambda_1147aa6d38b42c0a8559813b3004180f>@@
.?AV<lambda_115059020db09aa13bab825ad518034e>@@
.?AV<lambda_11b6908471b85c842f67ae917be35bc8>@@
.?AV<lambda_11e4c67999de7fde8000f344864dbedb>@@
.?AV<lambda_1221b4097effa32a8dd388b4455dd2c1>@@
.?AV<lambda_1249aa664b6dd8c7cf40d23fbaec080e>@@
.?AV<lambda_12dd4c4dcfd6c2d8effe6071c823bd43>@@
.?AV<lambda_13046178b359e9c81742cfc406e97a28>@@
.?AV<lambda_138b12d2a19d941ed2e5665ad50fc6cb>@@
.?AV<lambda_13bf14abed62c4ddb7d24aa834c66cd3>@@
.?AV<lambda_140ab31565a9f257f202ece6453c4bfd>@@
.?AV<lambda_1418b315018aac3af0babe6c70e31132>@@
.?AV<lambda_14407bcf8cfc66db9a85fd2745a31d94>@@
.?AV<lambda_1476157c6a284e4f379191854345eea5>@@
.?AV<lambda_14ab4d68c965e23bff80a9edfde3b16e>@@
.?AV<lambda_1642adc2d95a594ec2d1ca1c1679605d>@@
.?AV<lambda_166f6feb25832b61746c79ccdee9d41a>@@
.?AV<lambda_16aeacf7ad4b53ba550defbc9c03abde>@@
.?AV<lambda_16bdac8a01801cd7a5fcb1f21cc7a9f0>@@
.?AV<lambda_18a3b6757625880e23566c26c3f789bc>@@
.?AV<lambda_18dbcf0a6112b471cd3435637c32f0f8>@@
.?AV<lambda_18e0b70d8d5a276d72055cc8661094dd>@@
.?AV<lambda_18f6d57bac34239d650ddbef707551e4>@@
.?AV<lambda_19a25a0e0bced01a01388502a5fb897a>@@
.?AV<lambda_1aa88cfbcf551c26b6ab6d047872e0e0>@@
.?AV<lambda_1ab7060bf709e6890ff53a0d80bb8cf5>@@
.?AV<lambda_1ab7e6f52b1232ea373dc4337562f767>@@
.?AV<lambda_1abf5a492f2ce98320288d0a19f9a732>@@
.?AV<lambda_1c17b461588ff1b22a6f9497bff5b28b>@@
.?AV<lambda_1c511d989171b0ae840c900d36af6cdf>@@
.?AV<lambda_1c5d7bebb1a95dc207aab085d9327beb>@@
.?AV<lambda_1cd5cfe6b76bb3ba1c53203d58a4eedd>@@
.?AV<lambda_1cd6b5a2cebd273f7225f466512c43d5>@@
.?AV<lambda_1cdda74d195f4dc7bbdbaed3ee174bf7>@@
.?AV<lambda_1d718ae1c6eee88a5015989ae3eac075>@@
.?AV<lambda_1d7aed3977eb6b0e8500a44cbf6dc587>@@
.?AV<lambda_1e22b51977a7614afcc7ec75b14da756>@@
.?AV<lambda_1e6c58f2c47fbfdcb340ca8aa595e354>@@
.?AV<lambda_1f1cad28f5d50542c82767124ccbbeb8>@@
.?AV<lambda_1f3bf02585dcf20edf66f391042bccc5>@@
.?AV<lambda_1f77acb4e34034b00a5a2150384c9d77>@@
.?AV<lambda_1f8675d15ee5efaa8f5579945c6d118a>@@
.?AV<lambda_1fd04ff7ed408ca4ebed6e8107f19670>@@
.?AV<lambda_20ce3835ea17537cf13d089eb1a443c1>@@
.?AV<lambda_217211e0b9216fbae93bbaf0026e78ee>@@
.?AV<lambda_21ca116bba4007835cdddfee631b7f69>@@
.?AV<lambda_221457049dd6e599b1e592be3898266a>@@
.?AV<lambda_22485ec429c0920bef998442ed4b0141>@@
.?AV<lambda_22aeb0e20ec618f43aaa785665edaa1d>@@
.?AV<lambda_233c5a0f74ca58f834bb6474e700daf3>@@
.?AV<lambda_233e1075753dae9e4f22e739be4a8921>@@
.?AV<lambda_2369389c848e11c0cf2fa8c55ee9bc1b>@@
.?AV<lambda_2369f292b0f42fbecffef8359e85ebdc>@@
.?AV<lambda_23a1bb0478ab7117c6dff4712434f02b>@@
.?AV<lambda_2422fe451725e3fbdcc33016dd64f43f>@@
.?AV<lambda_242966bc823a6ea57016299e4846b19a>@@
.?AV<lambda_245134a5955e4a8621bc7afd20ddbe70>@@
.?AV<lambda_25395042ec336ff6c2d2bf12e6e33481>@@
.?AV<lambda_253a3836eec6c1ddbcb7d28211e21bd6>@@
.?AV<lambda_25a8a9072228ef7a32b8c1b14c49de58>@@
.?AV<lambda_265c7b3426b87aef377811f8829e6fd7>@@
.?AV<lambda_26de9b5e95466f00708e3ae83a84c608>@@
.?AV<lambda_273270d63d2edeeb9cb50e9432a42c00>@@
.?AV<lambda_27a631d2450c357a52927c1dfbd2efda>@@
.?AV<lambda_27ef1fccba899a27fb3728ede329f8f9>@@
.?AV<lambda_28d76a4078a4a8dbd4ec44ed08d36b25>@@
.?AV<lambda_29460ba72c9a9f61937f695b212c2385>@@
.?AV<lambda_2997ea06f466f3cb7af7580139e0e9b1>@@
.?AV<lambda_29a27f66e5d65fb36ed8965e3fa92ded>@@
.?AV<lambda_29ab6b1128939dd8bf0359853abfeea8>@@
.?AV<lambda_2a0432e2f861fdcc4b7f759b0200b6a4>@@
.?AV<lambda_2a220a526da965cfd243a774de182b4f>@@
.?AV<lambda_2a3f9f19c48a100998729328075237dc>@@
.?AV<lambda_2a976ac88d60c988f6c82762c8669484>@@
.?AV<lambda_2bed918e0092d38de095a3dfcc39bb6a>@@
.?AV<lambda_2bf767e58fd6076f82b597352ebe6a94>@@
.?AV<lambda_2cc7c01007d8f546fc79115b36c9098b>@@
.?AV<lambda_2cdbc5f873c2ce32c36481fab53d6870>@@
.?AV<lambda_2d30aee68f6d7fc70a227ffb90481678>@@
.?AV<lambda_2d5080a6f5d70d1027512848632ba44f>@@
.?AV<lambda_2d779c3a3c8b726adf3efb1bfd3cbb40>@@
.?AV<lambda_2da95d9a6f78440b51d048ed6c8e3561>@@
.?AV<lambda_2db246e2ce365efa8cc2cf5d40338a67>@@
.?AV<lambda_2dc16cf30de15202e0434934c8ec0571>@@
.?AV<lambda_2dc68f98e6942dc4cba921733a4cc521>@@
.?AV<lambda_2e098a1c981ad02f01e4203abb39ccc3>@@
.?AV<lambda_2e20e62e8d812957e92321838accac54>@@
.?AV<lambda_2e36b47c0b35a1b78ab3e2daaa7c5208>@@
.?AV<lambda_2ed99b1b7f84cedcec6ea06ce6c01dc5>@@
.?AV<lambda_2f4103e1c4a1773101a6c1f055d56df4>@@
.?AV<lambda_2f6217725d36a8fee3233a5a3a8acbc4>@@
.?AV<lambda_2fd31ca8bad4e5f142a2b5dfaff21801>@@
.?AV<lambda_3050f982855d87e103d3099ed68136e7>@@
.?AV<lambda_305677983a5a9935addb16bf86321e8d>@@
.?AV<lambda_30c9eb05d9fe297e7d682ba8ba94fa4d>@@
.?AV<lambda_30e1101d7025e2d839d1daa9ac434cd1>@@
.?AV<lambda_310ceee0e4c58a7a83d7d00319ed9410>@@
.?AV<lambda_31e4b4a2d49d229e0e58bbade49550ff>@@
.?AV<lambda_32373635de60f77359e703c4d10576a4>@@
.?AV<lambda_33215563a6aacb86deff746a6aa28a6c>@@
.?AV<lambda_3354f944db7877754471d985be3fe29b>@@
.?AV<lambda_3361a7c3c06ae8fda0091b29a15bc377>@@
.?AV<lambda_337593ad4f874bae98bb3aa9ea22758d>@@
.?AV<lambda_33763db33c7430e0074fd25b65b4479f>@@
.?AV<lambda_33ab9233a6e2a6fe6c24d1963cbc3111>@@
.?AV<lambda_33c11271a908f4f215dd361ca0be165e>@@
.?AV<lambda_3410038a349fbad62fb0cd42ca2fc595>@@
.?AV<lambda_3423f833df7359f6a2b95a8c9a7b5302>@@
.?AV<lambda_3435a69bc2a4a58cf25c9601fa916799>@@
.?AV<lambda_348952d4e8cb4d6ca40b91f67d9fe4cc>@@
.?AV<lambda_348a4c4053fb0e4fb238401e94ac3418>@@
.?AV<lambda_349643858d539033044d1d649dec237b>@@
.?AV<lambda_3525a67688acab3a16549c70f50b343d>@@
.?AV<lambda_3540305bd5a2ea6a94f5bc650b8b92bf>@@
.?AV<lambda_3569b04d379d95c345dffc147f7b94dd>@@
.?AV<lambda_35b4ad7503a02f4a81944df838e5a579>@@
.?AV<lambda_35df272685e40c7e2ea40583b6906dbe>@@
.?AV<lambda_36945aef9b69b8bc246158e60ded74ff>@@
.?AV<lambda_36dd25e706f1ff93211e6de0438e06c6>@@
.?AV<lambda_3737cccf52f52050f818e2f26f25ffea>@@
.?AV<lambda_37fc46271b5a9d577e78557058b76819>@@
.?AV<lambda_37fc51724b8ab138f4abea1c86c474be>@@
.?AV<lambda_38b12892f84528e9b72f8a8f101b77ee>@@
.?AV<lambda_3928e725003c7a62c76f41f34cee3234>@@
.?AV<lambda_399e4ac9a8be74e8d14d0d5e67b02a32>@@
.?AV<lambda_39a308a33350cfe399318acb8bdc0850>@@
.?AV<lambda_3a80fca790cdb0fce14ddaedefa20351>@@
.?AV<lambda_3ad3f00f380cbc79acdede7031c2b35c>@@
.?AV<lambda_3b79ba1930d9045b1d0a1c3e7b558aa7>@@
.?AV<lambda_3b97251de202434e86d007c33f9345a1>@@
.?AV<lambda_3bf9d7b5239a137326d2c5fa821fa737>@@
.?AV<lambda_3ce4407e5879111e6c1a6435d36077e4>@@
.?AV<lambda_3e2860b55958cf532cc6672e843fd5e5>@@
.?AV<lambda_3e5e22c83296c8f56ae7effebfec7009>@@
.?AV<lambda_3f0ef66d0b0de67b55e854d697da2fff>@@
.?AV<lambda_3f4423c10a0d6dd8a4ce69efd4c952cf>@@
.?AV<lambda_3f6b039d1c2a9ddc0c4edd40a4875e7e>@@
.?AV<lambda_3f7b31cb30bf909ba725ac6373c24d17>@@
.?AV<lambda_3f849c6f51e31293c619565ac636bda7>@@
.?AV<lambda_404d0fe71cc8d7867c9f1bc290b28bbd>@@
.?AV<lambda_4092000fa2c851eb2ddefc1b6efbf1fc>@@
.?AV<lambda_40d7d549b7296d37bd8a375a6a32735f>@@
.?AV<lambda_40f74427ec28f20a5d59b70a3f7ba162>@@
.?AV<lambda_414b2f36cd6ead6cc1f643a6940e8f0c>@@
.?AV<lambda_41ebeab5da8beef13ef5472118318ec8>@@
.?AV<lambda_42085d5d1ab621f3e103058b343368b0>@@
.?AV<lambda_423c7f4514cb0f580d17c1969d94ab4d>@@
.?AV<lambda_42580b4f3e49f7dcfbf37d76233bd856>@@
.?AV<lambda_429bffec90bbca49494510e27e518b79>@@
.?AV<lambda_42f0399bf2e271e6e951294a5aec23bb>@@
.?AV<lambda_42fa4ee951b97f0e77b9de9f38db0750>@@
.?AV<lambda_43ae18272140dc808ee2ad7756791834>@@
.?AV<lambda_43d76a454d7e446551a32b163679964a>@@
.?AV<lambda_453060ceb0954e510c893eb1eaf9ed24>@@
.?AV<lambda_458163864faccd230ccf1ce10d3e187d>@@
.?AV<lambda_45cc7b6c8716d6954bcc2af58f76cf68>@@
.?AV<lambda_45e1f6e47762148b282b3bb16964d9a7>@@
.?AV<lambda_464b0c569b5e14ad1c13cf083ce55247>@@
.?AV<lambda_46a0ec34ba455071cbedc5983343a291>@@
.?AV<lambda_46ed12fdb2868a9b6a9a32861936f36d>@@
.?AV<lambda_46f2340c6974a9abf9bf427b63a5b9bc>@@
.?AV<lambda_47f0845d7b66643be4c58515f34249ea>@@
.?AV<lambda_486023130535c54dc87259934f24df6e>@@
.?AV<lambda_48813fe4537d3b115d868f99a1d25e0d>@@
.?AV<lambda_4888e52cfaab8cdad25ecea017b54d57>@@
.?AV<lambda_4ae79009ffed4baaf3b13205e614d6ec>@@
.?AV<lambda_4b2e976425c8109a05bca3d80983d4bb>@@
.?AV<lambda_4b6703e7c30870568a65367efbb3ac2f>@@
.?AV<lambda_4b94da34bdfcb505ddcef5cb50b95e3d>@@
.?AV<lambda_4bd02c7b372889e26c922fb97a0c9ac3>@@
.?AV<lambda_4bfaa77b47cc3b72c0199e4158dcfdd3>@@
.?AV<lambda_4c0362c3e20008eb9ad4ca148d83f23f>@@
.?AV<lambda_4c0d5472c0e9893aea307d804bd55070>@@
.?AV<lambda_4c81a7b179f9e26e2d05ebefbb83c381>@@
.?AV<lambda_4cb6536179ac33ff59d8db68f89e6d48>@@
.?AV<lambda_4cd868df938477ea9946d2d55c43c695>@@
.?AV<lambda_4d2bb8b4b91e7c65b08948d705bb6118>@@
.?AV<lambda_4d5e8f52539d7b1512da825129736cac>@@
.?AV<lambda_4e978ba75a8a0f3f4d2d1e75d74ac4de>@@
.?AV<lambda_4ee11195e6ac34d8802828c9de8931d7>@@
.?AV<lambda_4f3d7353e76f345aa194bb4f18efcd6f>@@
.?AV<lambda_4f73d17b3441bd9f7aa60fe28450311a>@@
.?AV<lambda_5033badb7240167b30b90523bec68adf>@@
.?AV<lambda_5098c7ffb45473bd83c761c41e1ce9c0>@@
.?AV<lambda_50ac1bbabd41636fda9e1bf36b1fc455>@@
.?AV<lambda_50bf1563c4f2a658d5a1f8997cf7d841>@@
.?AV<lambda_51049cb5fa4b41211d9b2f4f400d5578>@@
.?AV<lambda_510b48fcc953c4af1dbcb4b8cf19756a>@@
.?AV<lambda_5151cdb5e2d0e967b0ff9b516f4dde5e>@@
.?AV<lambda_5169332acacd2cda6014329563a49097>@@
.?AV<lambda_51967558c7fd075e660195f4e6702ce2>@@
.?AV<lambda_519fe9cae569b1ad1c3f73288fa352d4>@@
.?AV<lambda_51f7b34ad2d14ff9bfb03559ccadc81f>@@
.?AV<lambda_522944c70ac483ca59ad2373ac030c86>@@
.?AV<lambda_5275443c3995dec7145dee969221190f>@@
.?AV<lambda_52be072c62487a4543b8a1a3d2fbad23>@@
.?AV<lambda_535c714f3912f6e19812f86aced1c234>@@
.?AV<lambda_53687b87e8fc26669694bb154ed06213>@@
.?AV<lambda_53958a524045125d538038a834c170f9>@@
.?AV<lambda_539862c5b8039ccfff5acf2ed512ba97>@@
.?AV<lambda_54c52b5102f405f26b86736abc33d9dc>@@
.?AV<lambda_55516238922eb666def71419d606fbee>@@
.?AV<lambda_556d3d9e1da4d900ac4beace2594775f>@@
.?AV<lambda_55c350adfde8ac6bd9a00204b24ba96a>@@
.?AV<lambda_56054d16adda54f2046f2f8778fd36d1>@@
.?AV<lambda_56112085461402060b9fcd1813ada6f0>@@
.?AV<lambda_564e08730d4bd4a97b43e8c38a06cf59>@@
.?AV<lambda_56c3ac63d8a5c9a2d5ed84f082ef3cf5>@@
.?AV<lambda_57033b6e8d5e4d038ed6204609dd48c9>@@
.?AV<lambda_577697c65f7f30ab5c890fb5e643c3c6>@@
.?AV<lambda_57b4e734a8f319c201f732e76dc19318>@@
.?AV<lambda_57db475e5df80ef36653d188ca9951ac>@@
.?AV<lambda_581e172f6e6bf6d53a792d4f2adbb4c0>@@
.?AV<lambda_5820733bf712edf4856ad2454498e68c>@@
.?AV<lambda_58e45bcf81f2eb4f6ae6b3f124defb13>@@
.?AV<lambda_58fbb8df4116cc5ed49a05a90528c0bc>@@
.?AV<lambda_598c6d249dbd14226af8e69fe738f910>@@
.?AV<lambda_59a791f3e63b70edef38fb68dcebe7ec>@@
.?AV<lambda_59d0c8449581e17e31aa5d36d4e1dfcc>@@
.?AV<lambda_59d8acbb35668d76553fcdb87d75be9b>@@
.?AV<lambda_5a4a1a47e435bf53505cb70a52e252af>@@
.?AV<lambda_5bd441e42294bfab33849ec1b22ce125>@@
.?AV<lambda_5c5ac1f6c71d812ad45802a5c8ea5757>@@
.?AV<lambda_5c90896dede9afea4c2bfc57d475c2a5>@@
.?AV<lambda_5d23ede476722136670b473ee395a3f1>@@
.?AV<lambda_5dc4cb1bad49b465af07c0f2ab16f9e0>@@
.?AV<lambda_5dddc316c01bb02791c37b03fa523bb0>@@
.?AV<lambda_5e0adb550519bb305a282a49bc052ff5>@@
.?AV<lambda_5e0f6565dc7aa7f6ebc79fe2fd37d8ea>@@
.?AV<lambda_5e5c9b62498f5c77e97a236dcd93889a>@@
.?AV<lambda_5e986d8d54ac11e9537c3be07a635569>@@
.?AV<lambda_5f4d12f5625f87c7fb1ce2d7795c65fa>@@
.?AV<lambda_5fe773ac1f878f81aadf16bc155901d0>@@
.?AV<lambda_6105a132d5626ddb9b2ed4958c88e1e2>@@
.?AV<lambda_61155733672bad5b1a1677020dbf30f2>@@
.?AV<lambda_61a830e6f94472550f401a07bc054c29>@@
.?AV<lambda_62526b7eac31a4fea5091c2f348a5e23>@@
.?AV<lambda_626154954c9dc0ff299a2c8aed4cd9a3>@@
.?AV<lambda_626d338c2f6a43327586cf0d89586aa1>@@
.?AV<lambda_62f1ce9bc208e37c7e5739c8f36388ed>@@
.?AV<lambda_633219a9b94f8dda3496215bc66b7f88>@@
.?AV<lambda_6367df6aa050372a33bd7465b9bffebf>@@
.?AV<lambda_63db87e2da8ecf77c1c67b6ddf9097c0>@@
.?AV<lambda_63f3e31790fe0f5095d7914472878fdf>@@
.?AV<lambda_64826d400df5e2683a863a4dbb954602>@@
.?AV<lambda_64e20fef6bc734aa72d77b8028e3b077>@@
.?AV<lambda_65379b8fe5c982ca5593c72a9026c7e8>@@
.?AV<lambda_655336b29940dd8dbdcd42ec2ee05996>@@
.?AV<lambda_65ea036252223d30a37862dfd4f7bc69>@@
.?AV<lambda_6665c408830d0dff611752f43635ad2f>@@
.?AV<lambda_66cabf3c04f8f57705ecc5d1dde38596>@@
.?AV<lambda_670b81b0a20483d6e6a649cadb77d57d>@@
.?AV<lambda_6711c07c0f8ab9cb8e9a7125cbe3a01a>@@
.?AV<lambda_672376956558218714cb97c30f1f09fd>@@
.?AV<lambda_673e4ce19ce5833538c9ec8e56f2275c>@@
.?AV<lambda_6744a0008aca8ce8a0b29db8f1c01fa1>@@
.?AV<lambda_67b6bf510365b722acc4b67b8d30f927>@@
.?AV<lambda_68094969648d2e0eeda4bdcc6834405e>@@
.?AV<lambda_680b87823779380f32485d5ed8cbcf84>@@
.?AV<lambda_68f8064281287c2a20e44f23c72be5d5>@@
.?AV<lambda_6922b57be4edd39a89a7cea9e2ebb658>@@
.?AV<lambda_69aea4466e4a2bbb44bce5c61e2a37d2>@@
.?AV<lambda_6a32611970906250c6b47d8292ad00e7>@@
.?AV<lambda_6a3bd940152ae2677fd2b897f7b984e8>@@
.?AV<lambda_6a4c61f2b4befdad04c4488376ee8ba7>@@
.?AV<lambda_6aeba50936d3f6c7b11f3c24b58165e0>@@
.?AV<lambda_6b0122b627329aed747a7281e017781a>@@
.?AV<lambda_6b9436f4089e82f5864d5365b56a5e02>@@
.?AV<lambda_6bb3fafba21860621ead2400f83d0ab0>@@
.?AV<lambda_6be077fd6f7f433aafd1dffeee52eb1a>@@
.?AV<lambda_6bf7af48e7a4158e20b4f833c15de130>@@
.?AV<lambda_6c3806e2f5558f0233ccf8d05c3ab49e>@@
.?AV<lambda_6c91c6f34bd8327dc22f6b7f8735fd5b>@@
.?AV<lambda_6d0547d7d9e564311a780ca9dc7db655>@@
.?AV<lambda_6d1012bc8b744ad9b0ac1bd49c915596>@@
.?AV<lambda_6da49eb0f8069eb4bbc177d850fb6dbc>@@
.?AV<lambda_6dcde8f3935fcb410660f26c17172b9a>@@
.?AV<lambda_6dd6cf995614bc7c2e490d548728e197>@@
.?AV<lambda_6e1c302e281819ac6b1fb7e30f673d0c>@@
.?AV<lambda_6e3cb65d29853e95007cf81c805209f2>@@
.?AV<lambda_6f010deb824d03b6370449d6f782b9da>@@
.?AV<lambda_6f05a8b4f6851ad7c85a3a3bcb9b9104>@@
.?AV<lambda_6f564a616944b22adda71fa903488618>@@
.?AV<lambda_707bfdc8d86f0538343a2653cbf5c062>@@
.?AV<lambda_70c2e06a8338c9df9aac1ab5670853c3>@@
.?AV<lambda_712b3a1726a5ab1ce39d1b3e7f50d979>@@
.?AV<lambda_7134bef299e596690440ce2c3fc8b019>@@
.?AV<lambda_716d92b2455b6dca0a3e195a50699167>@@
.?AV<lambda_71991a52be6daf389db1437901b4b4a6>@@
.?AV<lambda_71a7fcf63fe63e7115dc2b32c5b3bde5>@@
.?AV<lambda_71c3b665db06d94a27cb005b95351a30>@@
.?AV<lambda_71ef653055b00e102f19330e0f78a252>@@
.?AV<lambda_724cddc9d8a43266aca46c0c40c5f2b8>@@
.?AV<lambda_727130accb380845b50f2c19a2b46d02>@@
.?AV<lambda_72e83488395612e0f6a2602b726a187c>@@
.?AV<lambda_73119717ae86d28cb548ac4543eb73ed>@@
.?AV<lambda_7361ba811d5ff92bf50e102c73312480>@@
.?AV<lambda_739930acb5d4a4b1d92f387c9190b820>@@
.?AV<lambda_73b1da0ad8cd1f5530ce77a072f70a46>@@
.?AV<lambda_73cc642ed8afaa2889c4f09584fca345>@@
.?AV<lambda_745ebee95180d242f8918f6ee05b1702>@@
.?AV<lambda_747f5a5054cea5042105b3988bb8e54a>@@
.?AV<lambda_74a481eac2e8d64c2bfb5722b5b1cb89>@@
.?AV<lambda_76259788010337ce84c7523a6ac9ea2f>@@
.?AV<lambda_76f850960fe6ac327acd4613d41835f7>@@
.?AV<lambda_77a9c78e94cd40cde2d9c67f51886975>@@
.?AV<lambda_77bbe4874254ed84a312b5fa826a83d3>@@
.?AV<lambda_780872346d96977900f5c40310e7966f>@@
.?AV<lambda_786b2ff03846fcfa21d00bf234deaff2>@@
.?AV<lambda_78d2ff8fcf22c6166aa97abbb5fd0d75>@@
.?AV<lambda_7965ceabe5f45db89655ad0a7fd04cd6>@@
.?AV<lambda_796aa6c99df67f823c02a52131c10530>@@
.?AV<lambda_79b1e3e4a047d410dc120a32d9f13caa>@@
.?AV<lambda_79f39293405ab41c7ab7de2e65eb25d5>@@
.?AV<lambda_7a5892277686c5fc70de8922cd945035>@@
.?AV<lambda_7ad2abdb9d04286d775eb1928c7b7267>@@
.?AV<lambda_7adac37e31393d4ac6b5bca719f468e8>@@
.?AV<lambda_7adcd22a7346287699992d30bc8e4d12>@@
.?AV<lambda_7afdd6f6db24c890469fd5278509941d>@@
.?AV<lambda_7b13e0aa9183a7266252ed7dbdd54f99>@@
.?AV<lambda_7c393e0ced2515f63b0674de1e1229b1>@@
.?AV<lambda_7c61692eadeb4ccd34c8bb00529bfb83>@@
.?AV<lambda_7ca26f875a5bd8018609c044fb5616a1>@@
.?AV<lambda_7d49a6264e4dd01effe57235ddc8a797>@@
.?AV<lambda_7d629299b17d3241cda0057fa57cac3b>@@
.?AV<lambda_7d6518c90c18530c7c0fbad83575bf00>@@
.?AV<lambda_7d68ba7556ef690147168e00d959e2c9>@@
.?AV<lambda_7d7cf49bce0e19787ec70235e54b100e>@@
.?AV<lambda_7dbc984020fde247f30ce0431c9445e7>@@
.?AV<lambda_7e025ee819bdcb60549ba1616bfeecb8>@@
.?AV<lambda_7e035611e18f01e9b8525a9410df245f>@@
.?AV<lambda_7ead2e94d57d06076dc8b6a379103042>@@
.?AV<lambda_7ecdffb9bc3f419b33196d548224f0a4>@@
.?AV<lambda_7fb11eaf1ed7921e4b12c72edf5431c8>@@
.?AV<lambda_7ff2aca09375d1b200a4b303c393fea9>@@
.?AV<lambda_7ff9bfb547edbeaca72e6699608f2c7b>@@
.?AV<lambda_8052aa8f31d91e8553d059cc8a579374>@@
.?AV<lambda_814de60c7177af03b3ddc9e5c36d561a>@@
.?AV<lambda_81de0b469ab0f1e7bc6d7cfef2665991>@@
.?AV<lambda_8205a59784c4f81abae5636754370a87>@@
.?AV<lambda_8226f92ae14eb377c8291a622693e68d>@@
.?AV<lambda_8237b7c0f78776c2c7d6d683d4112edc>@@
.?AV<lambda_825b24178740a83899599d9a15262ad0>@@
.?AV<lambda_82a82efebe07e5ae66c1dba7f7b1d0eb>@@
.?AV<lambda_82b38e81208f4cf45ccff9cab1f1ab56>@@
.?AV<lambda_83fc98e77223d87948a3045c6a6d1977>@@
.?AV<lambda_845fb0d365668e61a65e09bae6280c09>@@
.?AV<lambda_8470282d05918db64db57459ab19a88b>@@
.?AV<lambda_848709f5f960f280f7c825f9d75fc06e>@@
.?AV<lambda_84e0d1c8300760043597f8486883bb16>@@
.?AV<lambda_85740bb65c1a7256d972833e138b25dd>@@
.?AV<lambda_85b8c9439e9295f048404909acdf29d3>@@
.?AV<lambda_860b5cff89ff5f292872db2aaa19c52a>@@
.?AV<lambda_86617ae40692259734b57fa8efa0566a>@@
.?AV<lambda_86dd40270c718f299cd5113909653b31>@@
.?AV<lambda_8711802b90051c34567904599fdbb25a>@@
.?AV<lambda_874d535e153c7e2cc7bc8cf3f159ba49>@@
.?AV<lambda_87d1adad0ec3c9a329fb0c8dabf3ed17>@@
.?AV<lambda_881846c2025fe9fdf21e10df8ef1aed7>@@
.?AV<lambda_8859cd3c08b6a8e9d40267fbf61322d1>@@
.?AV<lambda_885bb33b10cbcb0918c52bed48f8fb4d>@@
.?AV<lambda_886ae0b3214e69bc84deedbcd54da95c>@@
.?AV<lambda_888c8332848e83c225ef5f5587c3b38e>@@
.?AV<lambda_88a6c98d89234a715cc9be63a4bfcb6b>@@
.?AV<lambda_88b1496ecc213c07fd24b30bb5c856e7>@@
.?AV<lambda_88cacdca8b660ada94d8f522e9f11bdd>@@
.?AV<lambda_88f211d79a091f6a481688e49635f453>@@
.?AV<lambda_893ec3becb9cd41d9efbc7eea98d41c9>@@
.?AV<lambda_8a900b8b41180a41f1571bb2c4cf6f8e>@@
.?AV<lambda_8ac5cfcccd347e512ac9419fd63346cb>@@
.?AV<lambda_8af3a30942023f4a3511597660fac0f0>@@
.?AV<lambda_8b24a914bf112352c9369f2b44e2ccd1>@@
.?AV<lambda_8baa7635c058d848d4bb5868b5a1e31c>@@
.?AV<lambda_8bbb4bb940b6248f0079a061cca5209e>@@
.?AV<lambda_8c661b8920511802b1aec6c4164a8422>@@
.?AV<lambda_8d52f2d53a04afb64fff4765a2f91d21>@@
.?AV<lambda_8d89ab19f4dfa0ecffb29771863af791>@@
.?AV<lambda_8da16acda159d2aa36f9e917947c501e>@@
.?AV<lambda_8da27afb1f9e2f39230ce8504a3b22f1>@@
.?AV<lambda_8dc767ccba8e089e41f89b04cb108c10>@@
.?AV<lambda_8e138b7d90664b9b073b07f3b9a88877>@@
.?AV<lambda_8e20fcb5fdbadf86ea27e51f9059dbee>@@
.?AV<lambda_8e2d345faf08aedb7570dd988fdca755>@@
.?AV<lambda_8f0d91faf2fd476a9a61179d9b72837d>@@
.?AV<lambda_8fae3093696facd3fe41e8e37858828d>@@
.?AV<lambda_8fef7dbb6b3e81cda489ebe45ab449bb>@@
.?AV<lambda_8ffce33af8696a7a42fa073f6875aacb>@@
.?AV<lambda_9022553a6e1ed5607e95f6ae7eff7128>@@
.?AV<lambda_906a138de2e03121b208fb0df261e1f8>@@
.?AV<lambda_90811df5034c6b064f00ff028e410b34>@@
.?AV<lambda_90e67d7cf9c8fca59bac4a84fc304da2>@@
.?AV<lambda_90fa7e4386c5622637b0b1880f5ca8f3>@@
.?AV<lambda_913ebb992bc3e09bdf2737529cebbf5a>@@
.?AV<lambda_9148a73a32272a5a33edca914c11c2a4>@@
.?AV<lambda_9162731c94ecaf479f99be17541de90c>@@
.?AV<lambda_91a43e75998e3a49d1905d29f4a7bae4>@@
.?AV<lambda_91fdf8e96bd0363c4307fa79933bf9ee>@@
.?AV<lambda_922ea2af44b61076061b9738fd44abd8>@@
.?AV<lambda_9283763b81fbf1c4441399956127b6eb>@@
.?AV<lambda_9289ae269610356b68d5c3f46e89bf66>@@
.?AV<lambda_929181c452e7cbade815a0403dd15e2f>@@
.?AV<lambda_92ce44a6835ab59773e2e1a9e5082039>@@
.?AV<lambda_930475321813e9ecf1d2127c957da4f8>@@
.?AV<lambda_930b54dfc8a64c42da270936f80e56b0>@@
.?AV<lambda_939f4702fdcc80c80258913a08838422>@@
.?AV<lambda_941839df63e63f7ba66293e51c31a750>@@
.?AV<lambda_957302132dd7fea31b11af321304eee3>@@
.?AV<lambda_959b8361497e19898ca852a4058b29b4>@@
.?AV<lambda_95aae9bbb822c713ca9677b3a07b3381>@@
.?AV<lambda_95c74ffd32a4d994a62a191daf0fff27>@@
.?AV<lambda_95d4c31e5917c076b85b93f005fcb675>@@
.?AV<lambda_95dd41682914710e4e8d31623057e7d3>@@
.?AV<lambda_965a3b769c39b0bedf189a3ea0545ea9>@@
.?AV<lambda_96fa572628c59e4d078744e93c0f7196>@@
.?AV<lambda_96fe9f03daad80a6076c498e634c5f49>@@
.?AV<lambda_97d1f16f53a6cde81773c5f27deb1fd2>@@
.?AV<lambda_97f1aa20e78dc8680c319e9629ef8e8e>@@
.?AV<lambda_9800a6d45ddc69dc425addf83da8e9e3>@@
.?AV<lambda_98f67966096a245ba60cb535f4355420>@@
.?AV<lambda_99b6e836d69b69305b62d8ff2093a102>@@
.?AV<lambda_9a0964aea19bb920233e6fe5b8fa95e2>@@
.?AV<lambda_9a122db8c0c6f400c116ad5d2cdaf0bc>@@
.?AV<lambda_9a2786289a4d18fa33a8facc5fc736fa>@@
.?AV<lambda_9a36e00d72a5d737ec77f3dedc2d9072>@@
.?AV<lambda_9a4c460641eeb4213d39e91aec522d90>@@
.?AV<lambda_9ad4dd46fb7ebf522a3e85e715143745>@@
.?AV<lambda_9ba9dde4e941db1311dbefb477d19165>@@
.?AV<lambda_9c03d71b3e2a72420d0112f6f3840dd4>@@
.?AV<lambda_9c23f807f5b88acf4c74334fd51de3b9>@@
.?AV<lambda_9cc2379234b917d77614797746e75684>@@
.?AV<lambda_9cf24a11d7a47ec83a2235f766fd2a5c>@@
.?AV<lambda_9d8771d050eb3774da949f76ff7b2f7a>@@
.?AV<lambda_9d98759a86a1a6c70a5f6713a8d099cc>@@
.?AV<lambda_9dc7af5c7bcff785bd9190f2cb464b36>@@
.?AV<lambda_9de7ed3747c068fd694551112d802911>@@
.?AV<lambda_9e7e87298c6741b4ec8ed0a6456adc35>@@
.?AV<lambda_9ea68d0a3164c0f7bc2786cdbb58d687>@@
.?AV<lambda_9f22cccb787c8b0be66f7b40706128ae>@@
.?AV<lambda_9f3412b7c8b5e0fcfb6de75e19c2b20a>@@
.?AV<lambda_a0141ca4a0ba6481b8b376c6bbe9398a>@@
.?AV<lambda_a047e4fa7a019da5da5dcb5093bd2da9>@@
.?AV<lambda_a1b033c1238f74f04d136673bf3141a7>@@
.?AV<lambda_a26d879b56b4c4dd33ee8f6ff5f1da50>@@
.?AV<lambda_a32f11f3f6edc3a900d9d34015d67705>@@
.?AV<lambda_a345bf27d2a96610b3b006a123df813d>@@
.?AV<lambda_a38954a3fc0168033639a5d3db4af77f>@@
.?AV<lambda_a4015e490e3e9078f9108a810d677815>@@
.?AV<lambda_a45f274125d5aab3ada44bd6d91ed7f6>@@
.?AV<lambda_a47ee9eece330f845238b622e01ff20a>@@
.?AV<lambda_a4ad4e98f1a94b9237ebaa976e8eb831>@@
.?AV<lambda_a4fb1c1b5f905e04c31cbbe6c165878a>@@
.?AV<lambda_a4fe3bd39dcd0107f90455cb45c21429>@@
.?AV<lambda_a5fbe571a251fb604ad2b480580cc76b>@@
.?AV<lambda_a6a543117948c3dcb0421140d52311d6>@@
.?AV<lambda_a6d62ed7a3aadce21a3a08f0b111f7e9>@@
.?AV<lambda_a78c243175fca46a2a1734032bceca35>@@
.?AV<lambda_a7a0686f23e7f9337eaa10f069ee321b>@@
.?AV<lambda_a7f558f1dd0bc6dfbc34073d8010b2d2>@@
.?AV<lambda_a8b00e76dfe980214923eafc43926fd4>@@
.?AV<lambda_a935037996bf9e3d7f1925320992d343>@@
.?AV<lambda_a983769408c484edae48835df1b06ffa>@@
.?AV<lambda_a9ad92a14c7791713a13c8f77948b581>@@
.?AV<lambda_aa09ae9ae5ea9fb0f1758a92a75aceb3>@@
.?AV<lambda_aa831217bcc44892538d39aae8c330f6>@@
.?AV<lambda_aa88e462824a3ef64606c92b2b205d10>@@
.?AV<lambda_aadcf5996f45fb531b26c6d69998fa55>@@
.?AV<lambda_ab7cc530eb49a3a15082dbc27eb613da>@@
.?AV<lambda_abb9581c367ec240a8c0e5afd8181e99>@@
.?AV<lambda_ac55c4ccc442f0bccdc9fc717158ade1>@@
.?AV<lambda_acccfeb1e0041e26bf01c6097464f8c5>@@
.?AV<lambda_acdb2664af6229da1e4c43d330c314d8>@@
.?AV<lambda_ad8ca076531a0e62bdc4758313aec8ec>@@
.?AV<lambda_adbb0ed82c3e353a2ef8b51f4773ed3d>@@
.?AV<lambda_adedb98ee19cb4d9a4a46a5fd17584b5>@@
.?AV<lambda_adf0943a801eb39c6b17ffecdea2343f>@@
.?AV<lambda_ae0d8b5a2da4af67276477f8d17abe42>@@
.?AV<lambda_aec81523952d967a50c07470b5814993>@@
.?AV<lambda_aecfda1830c0ee30e0e4a23c265062da>@@
.?AV<lambda_af2c39467b4484bc2a2f611cf533daa7>@@
.?AV<lambda_af999ce2e03a2039dbf31c1ff13e0675>@@
.?AV<lambda_b090b097d440a4b2445143675bf63aa8>@@
.?AV<lambda_b0c700b83742c00837801ebad88797d0>@@
.?AV<lambda_b0ef8716b08a7c90da37b162fe225b7a>@@
.?AV<lambda_b0f9e3c706f87be7af57692823441e06>@@
.?AV<lambda_b140c53d8f404b9fcf24fe0f4b06052b>@@
.?AV<lambda_b1b7fca51e482a233c6ad913e37a4670>@@
.?AV<lambda_b1c0cff63caf505f6536baee30943a62>@@
.?AV<lambda_b24067cfb776b28c2465a46fad4c39cd>@@
.?AV<lambda_b2b5b00a4ad3647a9a40b4f0dbb0745d>@@
.?AV<lambda_b31abea9b0adc93fa794390a998569d7>@@
.?AV<lambda_b32e5f2bc2fafd58a4afcda5e8537c65>@@
.?AV<lambda_b346f4e5faa3c794cd68f36eadcb5c6c>@@
.?AV<lambda_b35f6304ab9b91e067de16d773b507fb>@@
.?AV<lambda_b3cbfd0276cf0ad6f3b58532d60f239f>@@
.?AV<lambda_b3ffb2b19f45444139b13fc0568f9537>@@
.?AV<lambda_b48de96003057f4b051b72f0b9baa2ee>@@
.?AV<lambda_b4e1f5c6fdfb97123733fced30ecae42>@@
.?AV<lambda_b51cf357ad6acfdf19263dcdcc3d9e57>@@
.?AV<lambda_b5274db9239c093417e22b13869d2ad7>@@
.?AV<lambda_b58abd66dfb794261458d2caeeba2a75>@@
.?AV<lambda_b6dee4d13517d8cf66ef1e240c3ec6a4>@@
.?AV<lambda_b765106161737954a77d8a171216f44e>@@
.?AV<lambda_b79d623619c8b488913a18719fb07ba7>@@
.?AV<lambda_b83bed438099179cd13c5a6033b90f7d>@@
.?AV<lambda_b86aa8ef1de0593a5547f08d792c1565>@@
.?AV<lambda_b881ee6a3336741e3e3697374c374936>@@
.?AV<lambda_b8bff811421756f68bf0701ba18268e9>@@
.?AV<lambda_b9ad0ccbf56c00a46342640cba7cdc2c>@@
.?AV<lambda_b9d9aa3891683438224b1c5285b28a19>@@
.?AV<lambda_bb1f7ff97f0a93bd0d62291fdf3e87e2>@@
.?AV<lambda_bb245b6c588ba3a259962707ee90e1f2>@@
.?AV<lambda_bb618da91ef45dc5293c089a74c35488>@@
.?AV<lambda_bb6f1fa388d8f370137cb6c6519f955b>@@
.?AV<lambda_bbed65651851398ae9e91eb41072a5f9>@@
.?AV<lambda_bbef96c8b3d94b60dcc7c27fac153a49>@@
.?AV<lambda_bc30b190ccdc11003b68eaf48bc55331>@@
.?AV<lambda_bc9f77b95219f5c687a91541f1ceb31c>@@
.?AV<lambda_bcef20d2b13b7b49fdebd823a7e734e1>@@
.?AV<lambda_bd3b717d06eb8cb8c6cdeb6f2f75dbb9>@@
.?AV<lambda_be7339191ce398a59cd58925b90c786f>@@
.?AV<lambda_be82f0d3082d1770e6fe9b6560ab180a>@@
.?AV<lambda_be9619b5fb1d1db7cf718b1fda3d5e82>@@
.?AV<lambda_beb991e0fd9fa3631b6b17fe3b5d669c>@@
.?AV<lambda_c007df17e8115f08c5c6e2ce7e2201c0>@@
.?AV<lambda_c09531cdd6b30fb34e9285a274065481>@@
.?AV<lambda_c162c83b8e727b7911e302875a688c52>@@
.?AV<lambda_c21643d1fb44758b12325da46a2d32c5>@@
.?AV<lambda_c23a6e376db7c7388aa04e9eb8ee3aca>@@
.?AV<lambda_c24ed35691635f968e92d6373ba271aa>@@
.?AV<lambda_c2634be0290355aa32c42903b822d942>@@
.?AV<lambda_c273bcba413eb077d5fb961b15132175>@@
.?AV<lambda_c277816ed3e96f001ac0003fb11da190>@@
.?AV<lambda_c2fef1cfbd08e9e21bcb74b985df87e6>@@
.?AV<lambda_c327e8b0febe30d927a0cd8dc39dba92>@@
.?AV<lambda_c3e7b02a987d92f0e0ac021ea93b35b9>@@
.?AV<lambda_c4798eecc829775e009cc44f3c8c2dfd>@@
.?AV<lambda_c4dc4b2967ca7204e8ba49b0607e0250>@@
.?AV<lambda_c5677617c2b0074bdccd3f6596388b76>@@
.?AV<lambda_c5a2356ebe34f9c7c2244082de94d017>@@
.?AV<lambda_c646dd14edaacae64487e0b96ad575f5>@@
.?AV<lambda_c6728963f8bb91595df67d14c61fd8fa>@@
.?AV<lambda_c6a4c758ec4a05da2df0a96bda1f195f>@@
.?AV<lambda_c6a56551a85732582804098ed80c9fb0>@@
.?AV<lambda_c6cc7a538d9c817426d2f4671032805a>@@
.?AV<lambda_c765ee4079d8132e5b64fd41ad2c9a7d>@@
.?AV<lambda_c7733fbf1e7357c5a2b00aac2ede4865>@@
.?AV<lambda_c82e3cf5ea414565c5fa19321839dc2c>@@
.?AV<lambda_c85c3af868013f6aa9c56e9cdc2b9874>@@
.?AV<lambda_c883cb8d41543031ae666c752948f20d>@@
.?AV<lambda_c89cf3298587f6daa5b2556ad200a769>@@
.?AV<lambda_c89e6783ea7ba65dd2bbca371d42018d>@@
.?AV<lambda_c8a671616559eac778e178004f6bff38>@@
.?AV<lambda_c9cc85b6189178098c01bbceb71ba127>@@
.?AV<lambda_c9d64b63a4c10e55647e3707de8acb40>@@
.?AV<lambda_c9e45910c6dad78e6e958bb0527b44e1>@@
.?AV<lambda_c9fe283d46d2f293dcb8573f075d3809>@@
.?AV<lambda_ca37d5ec199e35c30b080471c345d05e>@@
.?AV<lambda_ca87e505bf8a7e1f26579083c3683d94>@@
.?AV<lambda_ca9d22ac690a049ddaf8ded26ec4c6e4>@@
.?AV<lambda_cc4bc3c6927d9351454759e8077d0a48>@@
.?AV<lambda_cc7060560dae87f5475ce357b0faca8e>@@
.?AV<lambda_cc810076352af54d8ab1334d58ef2ac8>@@
.?AV<lambda_cc9e076beb57119667e5b07bb3c48707>@@
.?AV<lambda_cd453f5abbb4020fb3775475830cd8d1>@@
.?AV<lambda_cdd7645d3312922b8a49e2d3407b04a1>@@
.?AV<lambda_cee3b4dd214c58e3bda89cd1d17f2a33>@@
.?AV<lambda_cf0d99f02d80c9fcb9d4fc5032f5b198>@@
.?AV<lambda_cfa93eededd189da5db0d1b9a54368f6>@@
.?AV<lambda_cfed9ddc735eea0f8e4086ea879d678b>@@
.?AV<lambda_d01149748d9826af2bd1bb0ff765444d>@@
.?AV<lambda_d05fc65af5c668ab358a5dd1d3066029>@@
.?AV<lambda_d08789fec1ddb2ea31a7e42b01821aaa>@@
.?AV<lambda_d0c5713ac46ee06d27e6324a463b7bee>@@
.?AV<lambda_d0fdf4211aa9516cbe57f435cdbb747f>@@
.?AV<lambda_d125101b1e77d289ab0937ad814f16d4>@@
.?AV<lambda_d16d0ed0a77c40b384d41d6d45ea4e55>@@
.?AV<lambda_d28af58e0ad2f8f0bc7e5ddeac947360>@@
.?AV<lambda_d2a63565f05cd53c8bbd857da251fdac>@@
.?AV<lambda_d2aedfced5017e33ef2fd58df23b739b>@@
.?AV<lambda_d2d693a490e9887da5a024c703dc8e3e>@@
.?AV<lambda_d2e668c941b29e0c58674cef7fa23f2c>@@
.?AV<lambda_d30ba908d7a4df45178218a83c8b90aa>@@
.?AV<lambda_d36243265aa636655717da0233970d95>@@
.?AV<lambda_d3c7976f3f38539a50838a16dd62ccb2>@@
.?AV<lambda_d44234032f9da3a8e659111375d4b0b2>@@
.?AV<lambda_d48cb9baeb37d51a45fff2e006fd2ed3>@@
.?AV<lambda_d49bbfb4942fd85adb6441f849e70bf8>@@
.?AV<lambda_d522df09ab9335db57f0cfc8c09d6630>@@
.?AV<lambda_d5d62f4b858abcded92348c54a906570>@@
.?AV<lambda_d63de458c7355252fdf7dac6af546a6c>@@
.?AV<lambda_d655da6f0498ff82874b3d8a213ddf66>@@
.?AV<lambda_d66f152e4f615234b99e6bc843b096a4>@@
.?AV<lambda_d6d6a472b26fc7f192d382e93bba1d57>@@
.?AV<lambda_d70c00502c59385fd81a95257fd26b78>@@
.?AV<lambda_d73f309e1e17ba4988eef7d15e33e2b5>@@
.?AV<lambda_d76be7c6120a299959b7772916785631>@@
.?AV<lambda_d77ac61f6238a68ec5589d982d5615ac>@@
.?AV<lambda_d7d65f11678621cb189879800cf53faf>@@
.?AV<lambda_d8059ce711ce14c36533947d64fa5a34>@@
.?AV<lambda_d843aae243ab497a4cddae9c413aa41d>@@
.?AV<lambda_d846c7c2d29b00ef66091f3bac323c48>@@
.?AV<lambda_d86f3bcde641b4c18df519c60bc10d09>@@
.?AV<lambda_d8a9ac16dd775f4bb1f670ae469711dc>@@
.?AV<lambda_d8b96520499b24df75ab37992af46b4d>@@
.?AV<lambda_d8c2999bab01791ce81720c649701452>@@
.?AV<lambda_d8eff5d1bd9e672f484ebde0931bf7c8>@@
.?AV<lambda_d902441fd504c26b65d8c745d975f617>@@
.?AV<lambda_d9adada7822ba67bc618dd6220c7e11e>@@
.?AV<lambda_da44d2eb11bc9a9612e675a392ec65da>@@
.?AV<lambda_da7c0e243075d823e83aad5424aee4f1>@@
.?AV<lambda_daa97a08fba16356a015278e0f3ca1ed>@@
.?AV<lambda_dcbbb46dcb2ccb38f1b7e3e89a0ca172>@@
.?AV<lambda_dcbbb9aee7454d5a0feb975df66a7001>@@
.?AV<lambda_dccf783802d22b3c48245e980c348c0b>@@
.?AV<lambda_dce07c92cb28f757c3a0051d00763d8e>@@
.?AV<lambda_dd5302d9bd2c63a8d4a2f6d1a555d2e8>@@
.?AV<lambda_ddff9a77cb22aafff303a88b4705bee2>@@
.?AV<lambda_de00575298e9c7ead3b243890c596395>@@
.?AV<lambda_de0690e164792b53d65bc1c1d051a1bb>@@
.?AV<lambda_dec8978adb68f88cd37c14b215792fcb>@@
.?AV<lambda_df8f09957380fda37bd75205e74ab017>@@
.?AV<lambda_dfdd7885f2409b865180b051dead44b8>@@
.?AV<lambda_e021ada2350e9ccd28f4a55f38144d36>@@
.?AV<lambda_e08a75ecff8a2a27b308be3f8dfddc66>@@
.?AV<lambda_e11d46aec76c9403409fa1a1f5912552>@@
.?AV<lambda_e15d10c4385b9adab7c3b2967076a5a0>@@
.?AV<lambda_e1a7abf114b955966097bd83c14de705>@@
.?AV<lambda_e1a8783767138f2900763c385a76ace5>@@
.?AV<lambda_e1f234778fb80305bf70a017789747a5>@@
.?AV<lambda_e208f59e21e2ff58477196ea2ca2b8a9>@@
.?AV<lambda_e256c24a178e1d4e49acb7fa7090a7cb>@@
.?AV<lambda_e2d9c65f3423a9c8d6e3cd7ee2b26307>@@
.?AV<lambda_e318b9a1ac6011cec45976779008bc1d>@@
.?AV<lambda_e3ece229d743061e7008260e800aa786>@@
.?AV<lambda_e41de5887194c6f47359224ea1f4265d>@@
.?AV<lambda_e4de1e6d15c53abac777de14725b2d0a>@@
.?AV<lambda_e4e123e3dee0f37ab953d7fa4e244426>@@
.?AV<lambda_e4fd1e1090be16100e1685f2f4877667>@@
.?AV<lambda_e576f81a67738395c7b2b5774df9a9e6>@@
.?AV<lambda_e62e49b67792d3da4dce72eb9a07615b>@@
.?AV<lambda_e6687d53b2ff8a73e462a3df53da446b>@@
.?AV<lambda_e74921842af68f126d6a963647d9b662>@@
.?AV<lambda_e775dbf0393ee07909539154c7f76d40>@@
.?AV<lambda_e77a57374f1e055f8281ce5dd65e8ebd>@@
.?AV<lambda_e7ad5c511f7f0ca88484948ab82410f1>@@
.?AV<lambda_e7f381725b47e4a5cf7649db595fbdf3>@@
.?AV<lambda_e8839f5b62d1db724c93bfffb9ea115d>@@
.?AV<lambda_e8dabe6ee14f0907c4413646f291102d>@@
.?AV<lambda_ea5f658f0d872dbd3ae3afb1f1fd1122>@@
.?AV<lambda_ea638a800acf5ef947d9895c94c04562>@@
.?AV<lambda_eb610ec4c1ba2ee2f371c8f8541bff95>@@
.?AV<lambda_eb887415aed41a3927a754246db16d35>@@
.?AV<lambda_ec14091c8d829910b5be28a833d6a3dd>@@
.?AV<lambda_ecc9b9120eb4793427a94169f5623a5b>@@
.?AV<lambda_ecee2654318c52376f803bc94d6bc4ee>@@
.?AV<lambda_edcbc83438e6dd39d1d927db086748d9>@@
.?AV<lambda_ee954de93bf759bd8b1f4b4c9716ded3>@@
.?AV<lambda_ee988755aabf6d6b8cbe1162f42f9b60>@@
.?AV<lambda_ef1755d3dc9c2a6da40e08422cf4f664>@@
.?AV<lambda_ef1b5ee9690bf60d6d8ba03dec70f0fc>@@
.?AV<lambda_ef38ddcc46989e690851ddf31e835397>@@
.?AV<lambda_ef5c424a4193a85193eb7ea4c70aae69>@@
.?AV<lambda_ef9ce4d0dc32ab06ddd4426fedb787f1>@@
.?AV<lambda_f013722fb06ba87b6ded393d910c85c6>@@
.?AV<lambda_f01e87ef597d7dc3f33e6877997ee749>@@
.?AV<lambda_f0421a9025619b3b88dddf09f010b1ec>@@
.?AV<lambda_f0be09c6ec8e17e7ac33afa3db53ce78>@@
.?AV<lambda_f0e713d705dc904f2cc82277f166b6ca>@@
.?AV<lambda_f1490410ee527b42f3bd28e691dae2a7>@@
.?AV<lambda_f1cb7db0116015e247debfb13b06187d>@@
.?AV<lambda_f20c684c9a749a148b4d30f212c71a01>@@
.?AV<lambda_f273d4d4788dd6d522544c26d76a5ae4>@@
.?AV<lambda_f2842527842316c8394eef731b560fea>@@
.?AV<lambda_f29d64af0687bfdd6e3496c166444014>@@
.?AV<lambda_f2eae863f75038e08c50232c3c3d8f28>@@
.?AV<lambda_f30a6117225d3cb8e4a11f826263726e>@@
.?AV<lambda_f3e7e1c16a77783b35cd48a7c1464d44>@@
.?AV<lambda_f418dafe297dbbe0e3ada3e20a715a40>@@
.?AV<lambda_f4b2ad37b32ce448782bd96a2cfadb78>@@
.?AV<lambda_f4c664674d3291639f6f1c524accc00e>@@
.?AV<lambda_f4d85bd911255cc25b789888dd092506>@@
.?AV<lambda_f53ebd8978e979af788fa5865dbc2cd1>@@
.?AV<lambda_f55fed088cc6887bf534564a0809769f>@@
.?AV<lambda_f5db0169896386e7220581461257fa02>@@
.?AV<lambda_f60a4fa32157d6fa8e2622fa2d06d23c>@@
.?AV<lambda_f65b8c2fd23e2320c311133a80f471c4>@@
.?AV<lambda_f711efc9e33c8814de65d5fed61d7d7b>@@
.?AV<lambda_f78d8769dd40946ef61ad5956cbf10fe>@@
.?AV<lambda_f79206f00cb74e35e11935d1c0ff9449>@@
.?AV<lambda_f7fefea6bfb8182e95c707a77e7f4a8f>@@
.?AV<lambda_f80caf07313f1968c393099405f1b983>@@
.?AV<lambda_f8241a17ccaf97c109b664362fd083d5>@@
.?AV<lambda_f8822893c953bd42037266e93f73744e>@@
.?AV<lambda_f8dbfaed9d55440bb15cbf009ac934a6>@@
.?AV<lambda_f8f4a9a0b8865f5f39e8ba472bf52edc>@@
.?AV<lambda_f90b302c32ce6f81af3f56ee1f3a9b51>@@
.?AV<lambda_f93cfe7b83a07df5e5ec33ddaf08e7ff>@@
.?AV<lambda_f9b942c519c5abdf8c9e76770faf15a7>@@
.?AV<lambda_f9fcc66b14829c5756eb43c20bdf984b>@@
.?AV<lambda_fa9cea3a5917d32ed85305ced3e8f02e>@@
.?AV<lambda_fb6fdddab5054d64688b53a561efd684>@@
.?AV<lambda_fbf4f22e77a262ac13623763b425fa95>@@
.?AV<lambda_fc16ad7b44878e0662f1cac062e6f66b>@@
.?AV<lambda_fc59cfd6180e7962f9dbfcf6d01970a3>@@
.?AV<lambda_fcb655464ad0e43ce2671f06c665bb0e>@@
.?AV<lambda_fcea8697154110af19f3c4ff33f69c67>@@
.?AV<lambda_fcf7b72cb8688ac639f6066c6f9347c9>@@
.?AV<lambda_fd07f717d8be7a0b4ac28d8863ca11e3>@@
.?AV<lambda_fd266a9166d0b10d35a0d8f14994daa2>@@
.?AV<lambda_fd2f32690f4c94955691e93dd0de8250>@@
.?AV<lambda_fd4f2bbf00caf507fea1cc6053ab984e>@@
.?AV<lambda_fdb0134f4d01b5f723238dd45cc4059f>@@
.?AV<lambda_fe5b044a59055ca66e7af958ee5f5bc3>@@
.?AV<lambda_ff1ccdcb7441249452b8640b2e9dfe31>@@
.?AVbad_alloc@std@@
.?AVbad_array_new_length@std@@
.?AVbad_cast@std@@
.?AVbad_exception@std@@
.?AVbad_function_call@std@@
.?AVbad_optional_access@std@@
.?AVbad_variant_access@std@@
.?AVcodecvt_base@std@@
.?AVerror_category@std@@
.?AVexception@detail@nlohmann@@
.?AVexception@std@@
.?AVfacet@locale@std@@
.?AVfailure@ios_base@std@@
.?AVFatalException@protobuf@google@@
.?AVInferenceError@onnx@@
.?AVinvalid_argument@std@@
.?AVinvalid_iterator@detail@nlohmann@@
.?AVios_base@std@@
.?AVlength_error@std@@
.?AVlogic_error@std@@
.?AVNotImplementedException@onnxruntime@@
.?AVOnnxRuntimeException@onnxruntime@@
.?AVother_error@detail@nlohmann@@
.?AVout_of_range@detail@nlohmann@@
.?AVout_of_range@std@@
.?AVparse_error@detail@nlohmann@@
.?AVrange_error@std@@
.?AVResultException@wil@@
.?AVruntime_error@std@@
.?AVSchemaError@onnx@@
.?AVstl_critical_section_interface@details@Concurrency@@
.?AVstl_critical_section_win7@details@Concurrency@@
.?AVsystem_error@std@@
.?AVtype_error@detail@nlohmann@@
.?AVtype_info@@
.?AVValidationError@checker@onnx@@
.\2^4j6
.0/0#
.0/011
.00cfg
.5AsH
.5ut3
.b H0
.CRT$XCA
.CRT$XCC
.CRT$XCL
.CRT$XCU
.CRT$XCZ
.CRT$XDA
.CRT$XDZ
.CRT$XIA
.CRT$XIC
.CRT$XIZ
.CRT$XLA
.CRT$XLC
.CRT$XLD
.CRT$XLZ
.CRT$XPA
.CRT$XPZ
.CRT$XTA
.CRT$XTZ
.d0~2.4
.d2442&
.data
.data$r
.data$rs
.didat$2
.didat$3
.didat$4
.didat$5
.didat$6
.didat$7
.E9f ~ZA
.edata
.gehcont
.gfids
.giats
.H+9H
.h0t2
.idata$2
.idata$3
.idata$4
.idata$5
.idata$6
.json
.L02.V402
.P6A?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV01@0@Z
.P6A?AV?$OrtValueTensorSlicer@$$CBUOrtValue@@@onnxruntime@@AEBUOrtValue@@_J1@Z
.P6A?AV?$OrtValueTensorSlicer@UOrtValue@@@onnxruntime@@AEAUOrtValue@@_J1@Z
.P6A?AV?$unique_ptr@VTensor@onnxruntime@@U?$default_delete@VTensor@onnxruntime@@@std@@@std@@AEBVTensor@onnxruntime@@_J1V?$shared_ptr@VIAllocator@onnxruntime@@@1@PEAX@Z
.P6A?AV?$unique_ptr@VTensor@onnxruntime@@U?$default_delete@VTensor@onnxruntime@@@std@@@std@@AEBVTensor@onnxruntime@@V?$span@$$CB_J@gsl@@_NV?$shared_ptr@VIAllocator@onnxruntime@@@1@PEBVTensorShape@3@PEAVThreadPool@concurrency@3@PEAX@Z
.P6A?AVStatus@common@onnxruntime@@AEBV?$vector@_KV?$allocator@_K@std@@@std@@AEBVTensor@2@AEAV52@PEBVTensorShape@2@PEAX@Z
.P6A?AVStatus@common@onnxruntime@@AEBVNode@2@AEAVGraph@2@AEBV?$vector@PEBVTypeProto@onnx@@V?$allocator@PEBVTypeProto@onnx@@@std@@@std@@AEAV56@AEBUResolveOptions@42@@Z
.P6A?AVStatus@common@onnxruntime@@AEBVTensor@2@AEAV32@PEAX@Z
.P6A?AVStatus@common@onnxruntime@@PEAXAEAV?$vector@UOrtValue@@V?$allocator@UOrtValue@@@std@@@std@@0_K@Z
.P6A?AVStatus@common@onnxruntime@@PEB_J0PEA_J_K222222PEAVThreadPool@concurrency@2@PEAX@Z
.P6A?AVStatus@common@onnxruntime@@PEBH0PEAH_K222222PEAVThreadPool@concurrency@2@PEAX@Z
.P6A?AVStatus@common@onnxruntime@@PEBM0PEAM_K222222PEAVThreadPool@concurrency@2@PEAX@Z
.P6A?AVStatus@common@onnxruntime@@PEBN0PEAN_K222222PEAVThreadPool@concurrency@2@PEAX@Z
.P6A_NAEBUFunctionBodyBuildContext@onnx@@AEBVOpSchema@1@AEAVFunctionProto@1@@Z
.P6AMMMM@Z
.P6APEAVOpKernel@onnxruntime@@AEBVOpKernelInfo@1@@Z
.P6AXAEAUDataPropagationContext@onnx@@@Z
.P6AXAEAUInferenceContext@onnx@@@Z
.P6AXAEAVOpSchema@onnx@@@Z
.P6AXPEAX@Z
.pdata
.qxSo
.rdata
.rdata$r
.rdata$T
.rdata$voltmd
.rdata$zETW0
.rdata$zETW1
.rdata$zETW2
.rdata$zETW9
.rdata$zzzdbg
.rsrc$01
.rsrc$02
.rtc$IAA
.rtc$IZZ
.rtc$TAA
.rtc$TZZ
.text
.text$di
.text$mn
.text$mn$00
.text$x
.text$yd
.tls$
.tls$ZZZ
.UT!Rm
.xdata
.xdata$x
/,[L$9/V
-/./.
/D$xv
/KD`)
/Sr`8hy
/T|G$=
: <X:
: Conflict with existing kernel def hash.
: Conflicting with a registered kernel with op versions.
: 'Cubic' mode only support 2-D inputs ('Bicubic') or 4-D inputs with the corresponding outermost 2 scale values being 1.
: failed validating the check: 
: 'Linear' mode only support 2-D inputs or 3-D inputs ('Bilinear', 'Trilinear') or 4-D inputs or 5-D inputs with the corresponding outermost 2 scale values being 1.
:+cB\
:AM:am:PM:pm
:D$1uVH
:D`H.J,D&FPH.J,6&8P:.<
:Jan:January:Feb:February:Mar:March:Apr:April:May:May:Jun:June:Jul:July:Aug:August:Sep:September:Oct:October:Nov:November:Dec:December
:l<>:4
:LEAFu
:Loopt
:Please, install necessary language-pack-XX and configure locales
:Sun:Sunday:Mon:Monday:Tue:Tuesday:Wed:Wednesday:Thu:Thursday:Fri:Friday:Sat:Saturday
:Tp(D
; expected 
; last read: '
;\$`r
;0|kH
;ba~H
;ba=@
;D$ t
;D$ u
;D$@u
;D$0u
;D$tu
;D$xu
;E(|WA
;I9}(tiH
;J7@.
;w }ELc
;w,~d
;w8}ELc
;y(|:
? @ T T 3
?)5Uk
?\u8A
?333333
?H;58)*
?H+)H
?H+)M
?H+1H
?H9Gp
@ ;D$p
@ 9A 
@ 9p 
@ D9x u
@ D9x u'
@ H;B 
@ H;B t_A
@ H+A
@ H9B 
@ Hc@ H
@ HcX H
@ I;A u
@ v&.(,
@&j((
@(A9A
@)F$EKQ
@,A9A
@.data
@.didat
@.reloc
@.rsrc
@?*BL?fff?
@@8t$0E
@@H90t
@@HPX`h
@@QLinearGlobalAveragePool ImageSize too large!
@>|TY
@0^j(l(
@08@H
@08@HPX
@08@HPX`hr
@08@HPXb
@08~|TY
@08N|TY
@0I;@8t9I
@0I;U
@0I;W
@0I9@(
@0I9@(u
@0L9 
@1OwW
@2|0G
@6|TY
@6a~]
@6Ex]
@6Hf^
@6jA]
@7R$Kw
@8@HP
@8@HPX`
@8@HPX`hpx
@8@HPZ
@8{%@
@8|$ 
@8|$ t
@8|$ t}M+
@8|$ tnL+
@8|$ ttL+
@8|$(
@8|$@t
@8|$P
@8|$Q
@8}wt
@8~0t
@8=WGg
@80tx@
@8h:(<(>$@*B
@8k t*LcK
@8k,H
@8n8u
@8o tNH
@8o tvH
@8oXt)
@8p8t
@8p8t$H
@8s tX
@8sDt
@8t$(u
@8t$@
@8t$@t
@8t$@t]I
@8t$@tPI
@8t$At
@8t$Bt
@8t$D
@8t$pt^H
@8t$pt9H
@8t$q
@8t$Xt
@8u't
@8w`ui@8o t*H
@8w8t
@8w8u
@8x8t~H
@A^^]
@A^_]
@A^_^
@A^_^[]
@A^_^][
@A^A\_
@A^A\_^]
@A__^
@A_A^]
@A_A^^
@A_A^_
@A_A^_^[
@A_A^_^]
@A_A^A\
@A_A^A\^]
@A_A^A\_^
@A_A^A\_^][
@A_A^A]A\^
@A_A^A]A\_
@A_A^A]A\_^[
@A_A^A]A\_^]
@bq|H
@bq|I
@bQ~I
@da`Xl#
@f|TY
@H;T$P
@Hc@(L;
@Hc\$pH
@HPX 
@HPX =
@HPXb
@K@X\i
@L+ip
@SUVATAUAVAWH
@SUVWATAUAVAWH
@SUVWATAVAWH
@SUVWAUAVAWH
@SUVWAVAWH
@SUVWAVH
@SUVWH
@SUWAVAWH
@SVATAUAVAWH
@SVATAVAWH
@SVAVH
@SVWATAUAVAWH
@SVWATAUAVH
@SVWATAVAWH
@SVWAUAVAWH
@SVWAVAWH
@SVWAVH
@SVWH
@t*H;
@UAUH
@UAVAWH
@USVATAUAVAWH
@USVATAVAWH
@USVWATAUAVAW
@USVWATAUAVAWH
@USVWATAUAVH
@USVWATAUAWH
@USVWATAVAWH
@USVWATAVH
@USVWATH
@USVWAUAVAWH
@USVWAVAWH
@USVWAVH
@USVWAWH
@USVWH
@USWATAUAVAWH
@USWH
@Utx|
@UVWATAUAVAWH
@UVWAVAWH
@X90~
@X98~
@XH9BX
[ UVWATAUAVAWH
[ UVWAVAWH
[ UVWH
[ VATAUAVAWH
[ VWAVH
[%hs(%hs)]
[%hs]
'[', '{', or a literal
[:^alnum:]
[:^alpha:]
[:^ascii:]
[:^blank:]
[:^cntrl:]
[:^digit:]
[:^graph:]
[:^lower:]
[:^print:]
[:^punct:]
[:^space:]
[:^upper:]
[:^word:]
[:^xdigit:]
[:alnum:]
[:alpha:]
[:ascii:]
[:blank:]
[:cntrl:]
[:digit:]
[:graph:]
[:lower:]
[:print:]
[:punct:]
[:space:]
[:upper:]
[:word:]
[:xdigit:]
[]^-\
[^\x00-\x{10ffff}]
[7O(#
[E+K 
[HcJXH;L$ht
[hHcCtL
[hHcCtL;
[json.exception.
[libprotobuf %s %s:%d] %s
[Memory] SessionStateInitializer statically allocates 
[ONNXRuntimeError]
[ParseError at position 
[ShapeInferenceError] 
[T&' 
[TypeInferenceError] 
\$ 8Y
\$ A;
\$ D3
\$ E3
\$ H;
\$ H;]gH
\$ H+
\$ H+y
\$ I;
\$ Ic
\$ L;
\$ Lc
\$ M;
\$ UH
\$ UVATAVAWH
\$ UVWATAUAVAWH
\$ UVWATAVH
\$ UVWATAWH
\$ UVWAUAVH
\$ UVWAUAWH
\$ UVWAVAWH
\$ UVWAVH
\$ UVWH
\$ UVWL
\$ VATAUAVAWH
\$ VWATAVAWH
\$ VWAVH
\$ VWAVI
\$ VWI
\$ WATAUAVAWH
\$ WH
\$ WL
\$(E3
\$(H;
\$(H;\$0
\$(H+\$ H
\$(I;
\$(Ic
\$(L;
\$)fD
\$@fD
\$@H!T$ M
\$@H;
\$@H;U
\$@H+
\$@I+
\$`H+
\$`H9
\$`L;
\$`L;u
\$0@8{
\$0@8s
\$0_^
\$0E3
\$0H;
\$0H+
\$0H+\$(H
\$0HcH
\$0I;
\$0I+
\$0L;
\$0M+
\$4I;
\$8E3
\$8H;
\$8HcC
\$8I+
\$8Mc
\$h@8s
\$h@8t$@u;H
\$HA_A^A]A\_^]
\$HE3
\$hE3
\$hH;
\$HH;
\$HH;U8t
\$hI;
\$hI+
\$HMi
\$hu~H
\$p@8~0t
\$pA9pxu`M
\$pE2
\$PE3
\$PfD
\$PH;
\$pH;
\$PH;\$h
\$PH;}(t
\$pH;u
\$PH+
\$PH9
\$PHi
\$PI+
\$pL;
\$PL9 u
\$pL9 u
\$PM;
\$TE3
\$x;C0s
\$xE3
\$XE3
\$xH;
\$XH;\$h
\$xH;E
\$xI#
\$xI;
\$xL;
\$XL9 u
\$xM;
\\`Nb
\3JCy7
\Mm},
\x%02x
\X,>Y
\x^~m
\x{%x}
] != number of classlabels[
] (usually, this means you 
] already exists with value [
] because it's the graph's output.
] for now
] is not supported this build 
] is not supported!
] is not supportted!
] not in lexicographic sorted order.
] not in sorted order.
] op_type [
] out of range [0, 
] out of range.
] should not be greater than specified axis dim value [
]*ds,
], "core": 
], could not find NodeArg 
], Value=
], while 
]. Actual value is 
]. It will be overwritten
]. Its actual value is: 
]/H;_
]@H;]H
]@H+]8H
]@H9]Hu
]0H9YPA
]8H+]0H
]g@0,
]HH+]@H
]hI;]
]HJ)u
]ovI)P'
]PfE9e
]PH;]ht*I
]pHcEhL
]w*A@
]X@#bBUX@
]X@#bQ}H
^ H+^
^ I+^
^ IcF
^ IcN
^(+^0
^(A+^0A
^(H9_@~B
^|*W?
^8H9_@
^hH9_@
^lbrd(fZh2l
^pNO7
^r/1r60
^yS!g
_ I+_
_@tEI
_@uAN
_@uBN
__strncnt
_<zKG
_8I+_0H
_bn_nchwc
_Cast
_DmlExecutionProvider
_DmlExecutionProvider_
_dummy
_fence_after
_fence_before
_FusedMatMulAndScale
_initterm
_initterm_e
_Int32
_kernel_time
_lock_locales
_min_zero_constant
_nchwc
_o____lc_codepage_func
_o____lc_collate_cp_func
_o____lc_locale_name_func
_o____mb_cur_max_func
_o___acrt_iob_func
_o___pctype_func
_o___std_exception_copy
_o___std_exception_destroy
_o___stdio_common_vfprintf
_o___stdio_common_vsnprintf_s
_o___stdio_common_vsprintf
_o___stdio_common_vsprintf_s
_o___stdio_common_vswprintf
_o__aligned_free
_o__aligned_malloc
_o__beginthreadex
_o__callnewh
_o__calloc_base
_o__cexit
_o__close
_o__configure_narrow_argv
_o__create_locale
_o__crt_atexit
_o__dclass
_o__difftime64
_o__errno
_o__execute_onexit_table
_o__fdclass
_o__fdsign
_o__free_base
_o__free_locale
_o__fseeki64
_o__fstat64i32
_o__get_errno
_o__get_stream_buffer_pointers
_o__Getdays
_o__Getmonths
_o__Gettnames
_o__gmtime64_s
_o__initialize_narrow_environment
_o__initialize_onexit_table
_o__invalid_parameter_noinfo
_o__invalid_parameter_noinfo_noreturn
_o__localtime64_s
_o__lock_file
_o__malloc_base
_o__mktime64
_o__purecall
_o__read
_o__realloc_base
_o__register_onexit_function
_o__seh_filter_dll
_o__set_errno
_o__sopen_s
_o__stat64i32
_o__Strftime
_o__strnicmp
_o__strtoi64
_o__towlower_l
_o__towupper_l
_o__unlock_file
_o__W_Getdays
_o__W_Getmonths
_o__W_Gettnames
_o__wcsdup
_o__Wcsftime
_o__wfsopen
_o__write
_o__wsopen_s
_o_abort
_o_acosf
_o_acoshf
_o_asinf
_o_asinhf
_o_atanf
_o_atanhf
_o_bsearch
_o_calloc
_o_ceil
_o_ceilf
_o_cosf
_o_coshf
_o_exp
_o_expf
_o_fclose
_o_fflush
_o_fgetc
_o_fgetpos
_o_floor
_o_floorf
_o_fmod
_o_fmodf
_o_fputc
_o_fread
_o_free
_o_frexp
_o_fseek
_o_fsetpos
_o_fwrite
_o_isalnum
_o_isalpha
_o_isdigit
_o_islower
_o_isspace
_o_isupper
_o_iswspace
_o_ldexp
_o_localeconv
_o_log
_o_log2
_o_log2f
_o_logf
_o_malloc
_o_nearbyintf
_o_pow
_o_powf
_o_remainderf
_o_rint
_o_rintf
_o_roundf
_o_scalbn
_o_scalbnf
_o_setlocale
_o_setvbuf
_o_sin
_o_sinf
_o_sinhf
_o_sqrt
_o_sqrtf
_o_strerror
_o_strncpy_s
_o_strtod
_o_strtof
_o_strtol
_o_strtoll
_o_strtoull
_o_tanf
_o_tanh
_o_tanhf
_o_terminate
_o_tolower
_o_ungetc
_o_wcsftime
_RDATA
_RuleBasedTransformer
_sum_transformed
_token_
_transformed
_unlock_locales
_Unused
` .",
` AUAVAWH
` UAUAVH
` UAUAWH
` UAVAWH
`.rdata
`:(4?
`:`>0@.
`:h:J
`@33{@33{@33{@33{@
`>`(^
`>|TY
`0^0\
`08@H
`4tTM
`6"_^
`6$A^
`6.8,
`6.b^
`6_a^
`6|TY
`65:]
`6CY^
`6Db^
`6Gu]
`6Ia^
`6m=]
`6-Y^
`8@HP
`8@HPX`hpx
`A^_^
`A^_^[]
`A__^[]
`A_A^^
`A_A^_^[
`A_A^_^]
`A_A^A\_^[]
`A_A^A\_^][
`A_A^A]_^[]
`A_A^A]_^][
`A_A^A]A\_^[
`A_A^A]A\_^]
`anonymous-namespace'::GetDataTransfer
`anonymous-namespace'::GetExternalDataInfo
`anonymous-namespace'::GetIndicesTensor
`anonymous-namespace'::ReadExternalDataForTensor
`anonymous-namespace'::ValidateFillInputArgs
`c` - cell gate
`f` - forget gate
`h` - hidden gate
`H` - Hidden state
`h~|TY
`i` - input gate
`jb0`<ZdF
`L;t$0
`num_directions` - 2 if direction == bidirectional else 1
`o` - output gate
`P[iof]`  - P peephole weight vector for input, output, and forget gates
`PB[iof]`  - P peephole weight vector for backward input, output, and forget gates
`R[iofc]` - R recurrence weight matrix for input, output, forget, and cell gates
`R[zrh]` - R recurrence weight matrix for update, reset, and hidden gates
`r` - reset gate
`Rb[iofc]` - R bias vectors for input, output, forget, and cell gates
`RB[iofc]` - R recurrence weight matrix for backward input, output, forget, and cell gates
`Rb[zrh]` - R bias vectors for update, reset, and hidden gates
`RB[zrh]` - R recurrence weight matrix for backward update, reset, and hidden gates
`RBb[iofc]` - R bias vectors for backward input, output, forget, and cell gates
`RBb[zrh]` - R bias vectors for backward update, reset, and hidden gates
`RBbi` - RR bias vectors for backward input gate
`Rbi` - R parameter bias vector for input gate
`RBi` - R recurrence weight matrix for backward input gate
`Ri` - R recurrence weight matrix for input gate
`t` - time step (t-1 means previous time step)
`tf_half_pixel_for_nn` is deprecated since opset 13, 
`W[iofc]` - W parameter weight matrix for input, output, forget, and cell gates
`W[zrh]` - W parameter weight matrix for update, reset, and hidden gates
`Wb[iofc]` - W bias vectors for input, output, forget, and cell gates
`WB[iofc]` - W parameter weight matrix for backward input, output, forget, and cell gates
`Wb[zrh]` - W bias vectors for update, reset, and hidden gates
`WB[zrh]` - W parameter weight matrix for backward update, reset, and hidden gates
`WBb[iofc]` - W bias vectors for backward input, output, forget, and cell gates
`WBb[zrh]` - W bias vectors for backward update, reset, and hidden gates
`WBbi` - WR bias vectors for backward input gate
`Wbi` - W parameter bias vector for input gate
`WBi` - W parameter weight matrix for backward input gate
`Wi` - W parameter weight matrix for input gate
`X` - input tensor
`z` - update gate
{ ATAVAWH
{ AVH
{ H+{
{"cat" : "
{"main_thread": {
{%d,%d}
{%d,}
{-&'c
{(H;w
{(Lcc E
{additionalDocumentation}
{bQ}X
{HcH(H
{hHcCtH;
{l9gM
{name}
{pLcchM
'{qk5
{XLccPM
|$ @8y
|$ 9y0tZ
|$ A;
|$ ATAVAWH
|$ AUAVAWH
|$ AVH
|$ D!
|$ E3
|$ fD
|$ H!\$(
|$ H;
|$ H+
|$ L;
|$ M;
|$ M+
|$ UATAUAVAWH
|$ UATAVH
|$ UATAWH
|$ UAUAVH
|$ UAVAWH
|$ UH
|$$9x
|$$E2
|$$H;
|$(A^
|$(E3
|$(H;
|$(H;|$0L
|$(H;V t
|$(L;
|$@;|$D
|$@;|$P
|$@A_A^A]A\
|$@E3
|$@fD
|$@H;
|$@H;|$H
|$@H;U
|$@H+
|$@H+U(H
|$@I;
|$@L;
|$@vkL
|$` u[H
|$` u]H
|$` u_H
|$` ubH
|$` ucH
|$` uHH
|$` uKH
|$` uMH
|$` uNH
|$` usH
|$` uSH
|$` uWH
|$`@8
|$`E3
|$`H;|$x
|$`H+
|$`I;
|$`M;
|$0A_A^
|$0A9
|$0E3
|$0H!\$8
|$0H;
|$0H;S
|$0H;T$pt/H
|$0H;W
|$0H+
|$0H9
|$0L!L$(M
|$0L;
|$0L;|$H
|$0M;
|$4H9]
|$8;3
|$8@2
|$8A_A^A\
|$8E3
|$8fA
|$8H;
|$8H;\$0t
|$8M;
|$h@8t$@
|$HD8{
|$HE3
|$hE3
|$HE3
|$hH;
|$HH;
|$HH;]
|$HH;U
|$HH+
|$hH9
|$HI+
|$HI9_ thL
|$HL;
|$HL+
|$hL9S0
|$hM;
|$HM;
|$p+}
|$PD8
|$PE3
|$pE3
|$PfF
|$PH#MPH
|$PH;
|$PH;]0t
|$PH;u
|$pH+
|$PH+
|$PH9
|$pHc
|$PHi
|$pI;
|$pL;
|$PL;
|$pL;
|$PL9
|$PLi
|$pM+
|$t@8|$pt
|$tHc
|$x!u
|$XA;
|$xE3
|$xH;
|$xH9
|$XHc
|$XI;
|$XI+
|$XL9{(
|$XM;
|$xM+
|(xZp`tD~
|(zvthvV~
|}HL}
|=byi
|7ICx/
|g/{}{
|H(L"
|H9q8vvH
|JD;/|EA
|u"L;
} 8\$0t
} A8Y
} D!e(H
} D!m(H
} for per-channel quantization. Actual:
} for per-tensor/layer quantization or shape {
} HcK0H
} IcE
}(A+}0A
}, "sub_threads": {
}, actural: 
}, Got: 
}, input shape = {
}. Actual:
}. Got: 
}/I;Ihs I
}@HcE8M
}`L+}XI
}0|$0J
}0t$ 
}4I;Ihs I
}7I;Ihs(I
}E(=?
}HH;}
}HH9|$`
}HX"b
}HX"br]HQ
}HX$"b
}HX$*b
}HX$:b
}HX$:bb]HQ
}HX$2b
}HX$2bb]HQ
}HX\I
}HX\K
}jI;Pxs[I
}nI;Qxs_I
}SHcN
}SM;Q`s?I
}UHcG
}xL+}pI
}xL9}
~ |$L&z
~ HcF
~!LcA
~$McL$0H
~%H;]
~%L9g@
~(+~0
~(A+~0A
~(D+~0D
~(E+~0E
~(H;~0tGA
~)@8wbt#L
~*L!D$ L!D$(
~*L9g@
~:I;]
~;A8Y$t
~+L9{
~>D9k(t
~3a*~3a*~3a*~3a*
~6H;B 
~7D!u
~FH;>r
~hH;>r$D8v8u
~hHc3D
~HoD$
~HoL$
~HoL2
~HoT2
~HoTr
~L$ H
~'L9g@
~o] I
~oL$ I
~PM;~Xt6
~ppu%L
~T$ f
~tpu.H
~WL9g@
~XHcnP3
~XL9g@
+/+E+F+M+s+v+
+|$ H
++<>||~~
++index < c.size()
++Q5@.
++Q5@.Q5@.Q5@.Q5@.
+ba~H
+bA~H
+ba~H
+BL9JLH
+D$DA
+G:*?c
+G`Lc
+Lq6i
+v$x+v$xv$+xv+$xv$+x+$vx+$vx$v+x+$vx$+vx+v $+v $v $+v +$v $++$ v+$ v$ v++$ v$+ v+xv$+ v$v$ +v+ $v$ ++x$v+ $v$v ++ $v$ +v
<  "X$e
< u\A
<%ujL
</assembly>
<:u,H
<:u0H
<:w/H
<:wLH
<?xml version='1.0' encoding='UTF-8' standalone='yes'?>
<]u"E
<}w\I
<}w^I
<2?~>
<6@^BvDHF
<assembly xmlns='urn:schemas-microsoft-com:asm.v1' manifestVersion='1.0'>
<bQ}X
<CbA~H
<dmcw
<H>2< @A
<Nba|H
<p@6B
<p_fd> is less than 0.
<p_fd> less than 0.
<P>R<M
<parse error>
<QufH
<-u!E
<U+%.4X>
<uninitialized>
<xuL@
<xuyH
=;-kkZ@
==> Context: 
=4?~?
=t4A+
>.@,4h>.@,
>.@,4t>.@,4h>.@,Dt>.@,4h>.@
>.t/I
>`@jBdD.FxD
>|@bB
>A}DG
>bA|I
>D9o(t
>HHp>HJp>HLp>HNp>HPp>HRp>HTp>HVp>HXp>HZp>H\p>H^p>H`p>Hbp>Hdp>Hfz>Hh
>HiL$@
>HiL$@x
>HiL$8
>http://www.microsoft.com/pki/certs/MicRooCerAut_2010-06-23.crt0
>i4hW
>L@lB
>NGdx
>r@B>J
>UoML7V
0 <= p && p_int < shape_proto->dim_size()
0 == center_point_box_ || 1 == center_point_box_
0 == memory_size % kMinAllocationSize
0 0 06070>0?0
0 00070<0?0
0!0)080:0
0!0)080;0
0"2jDB^!
0"6X.
0$"&0((*0,(.00(20446
0$L& (
0.0f <= ratio_value && ratio_value < 1.0f
0.2,,v0.2
0?XZ_
0@zSW
0\4X6
0< t6<$t,<+t"<vt
0<0<0A0
0=0=0
00000
00000=0=0
01050;0;0
01050;0<0A0
0123456789-
0123456789-+Ee
0123456789ABCDEFabcdef-+Xx
0123456789ABCDEFabcdef-+XxPp
0123456789abcdefghijklmnopqrstuvwxyz
040904E4
0624<
08@HP
08@HPX
08@HPX`hpx
08@HPX`hr
08@HPZ
08@P^|TY
08~|TY
09AZ__az!~
09AZ__az09AFafAZ
09AZaz
0A^_]
0A^_^
0A^_^[]
0A^_^][
0A^A\_^]
0A^A]A\_^
0A^A]A\_^[]
0A_A^_
0A_A^_^[
0A_A^_^]
0A_A^A\
0A_A^A\^]
0A_A^A\_]
0A_A^A\_^
0A_A^A\_^][
0A_A^A]
0A_A^A]_^[]
0A_A^A]A\^
0A_A^A]A\_
0A_A^A]A\_^[
0A_A^A]A\_^]
0B2j6 8p:V<
0bQ~I
0f2|4
0fA9v
0-g-o-p-
0H;s s
0H;t$Pt
0l2V6
0Lcc(D
0Tj(lN
0tmfE
0Vj lNQ
1 == capability.nodes.size()
1 2)2H2O2Q2_2
1 2_2
1(0&0
1.10.0
1.10.220126-2359.1.dml-1.8.89dd732
1/0-0
1/111
1[a&e
111019184142Z
1bB~J
1D input tensor
1D output tensor
1-D tensor of 2 elements: [crop_height, crop_width]. All cropped image patches are resized to this size. Both crop_height and crop_width need to be positive.
1-D tensor of axes that `starts` and `ends` apply to.
1-D tensor of ending indices (exclusive) of corresponding axis in axes
1-D tensor of floats
1-D tensor of shape (num_rois,) with each element denoting the index of the corresponding image in the batch.
1-D tensor of starting indices of corresponding axis in `axes`
1-ed.\
1R-Eij
1rpJN
2"4.6(8r6z2":~<":
2)tLH
2*2G2P2P2`2
2,JB2y
2.4,,j2.4
2.4,.v2.4,$
2\6N8
2^6L8
2`2~2`
20220506184635Z
20220506222256.735Z0
20220507184635Z0w0=
210930182225Z
211202190523Z
220310192419Z
230228190523Z0
230308192419Z0p1
232770+4695750
261019185142Z0
2B4"2J
2bb}H
2D matrix with shape (K,N)
2D matrix with shape (M,N)
2D8&t-L
2D9&t-L
2-dimensional sparse matrix A. Either COO or CSR format
2H;q }hI+
2h082
2H422 6i
2J4J6l8h:p>v@D>zBD>zDV>^F
2L9&t-L
2N6T<
2P4.6,0
2wDt8
2z8z>
300930183225Z0|1
32-bit hash value.
3333333
3a57?
3bb}H
3bQ}X
3HcF(;E(u
3http://www.microsoft.com/pkiops/Docs/Repository.htm0
4"6F8]
4)t%H
4*6"8|:H<X
4*T,..,
4.6 8L4D:
4.6,,
4.6,0j4.6,:
4.6,0j4.6,0j4.6
4:6V(
4;L;t$@}|H
4\8N:e
4`0~.
40&2(P\TNVtZ&\B^
4A9r8t
4D mask in attention cpu kernel is not supported
4-D tensor of shape (N, C, H, W), where N is the batch size, C is the numbers of channels, H and W are the height and width of the input data.
4-D tensor of shape (N, C, H_out, W_out).
-4ePx
4h@DA
5!8!0-g-
50xWk^
5JNi>
5L9}Pu
5Ly!p!DS
5rCdiF"
5rpJN
'5VVN
6"80:6<X>-
6(4x*b,
6)tsH
6,ik/oY
6:8$:<<0>,@0B,D0F0H
6;Exv
65%gK5
66:`<^>N@
66842
6bA|H
6bQ}X
6H826 :I
6HcB8H;D$ht
6JCy7JCy7JCy7JCy7
6Q1"t
6R:.<,>,@:D<FY
6rziC
7)>(&
74L$})[E
7D9f(t
7D9n(t
'7JCy7
7L9g8
'7nlH
'7onnxruntime::SkipLayerNormFusion::ApplyImpl
8 h"h$T&
8,:28R<,>.<T>"<n>:@TBT<DDTF
8,u5H
8.:L4
8.@$B&@
8@HPX
8@HPX,
8@HPX`
8@HPX`hp
8@HPX`hpx
8@HPX`hpz
8@HPX`j
8@HPX0
8@HPZ
8@HXf|TY
8@JPe
8\$(t6I
8\$(u
8\$0u
8\$1t
8\$1u
8\$au
8\$XtBH
8]tmH
8^ t7H
8^,t4HcF
8^u7H
8_^][
8{usH
81CBx
89:uH
8A^_^[
8A_A^_^][
8A_A^A]A\_^][
8Anu$
8d3d12.dll
8giP9giP9giP9giP9
8H:28 <=
8igY0
8IyN+0
8K~-]
8L! H
8MwtFI
8N!46j0
8NONEu
8Q tXH
8QPt8H
8ScanuF
8SOFTu
8T$@I
8TwX1
8-uCH
8-uGH
8-uuH
8VHt^3
8Yielu
8zQOD
9)~P3
9?]0W
9?7/m[
9\$ u H
9\$`viD
9\$Pu
9\$Tu
9]'u,H
9`Vk:
9{(~3H
9{(t8H
9{(u1H
9}`uH
9~Pvk
93u<H
95@$)
961c151d2e87f2686a955a9be24d316f1362bf21 3.9.1
99~CE
9A tu
9C(t:H
9C(t;H
9C(t=H
9d.j1p
9F(t:H
9h(t7H
9k ~GD8{
9K(t;H
9L$@u 9
9o ~/H
9p ~GD8x
9p(t;H
9p(t7H
9p@u+
9qHtQ@8q&
9r(u1H
9rHuVL
9rpJN
9s(t7H
9s8~pE3
9t$Pu
9u@~aH
9x(t7H
9x(t8H
9x(ubH
9Z(ujH
9z(uUH
9zv2H
A != nullptr && B != nullptr
A + (M * K) <= A_end
A + (M * lda - (lda - K)) <= A_end
A 0-D bool tensor. If given, this will scale gradients by the inverse of frequency of the indices (words) in the mini-batch. Default  is ``False``
A 0-D scalar tensor. If specified, the entries at `padding_idx` do not contribute to the gradient; therefore, the embedding vector at `padding_idx` is not updated during training, i.e. it remains as a fixed pad.
A 0-D tensor containing a single value corresponding to the number diagonals above or the main diagonal to exclude or include.Default value is 0 if it's not specified.
A 1-D input tensor that is to be processed.
A 1-D INT64 tensor containing the the count of each element of 'uniques' in the input 'x'
A 1-D INT64 tensor of the same size as 'x' containing the indices for each value in 'x' in the output 'uniques'
A 1-D tensor of the same type as 'x' containing all the unique values in 'x' sorted in the same order that they occur in the input 'x'
A 1-D values of (height, width).
A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder).
A 2D Matrix that represents the distance between each pair of the two collections of inputs.
A 9s(H
A 9s(t7H
A 9X 
A 9X t
A collection of intercepts.
A collection of weights of the model(s).
A Conv/ConvTranspose node has both 'auto_pad' and 'pads' attributes
A D9`(
A dimension cannot be less than -1, got 
A dso with name 
A E;X 
A float.
A H;B t
A H;B tN
A H+A
A H9A
A H9X
A H9YPD
A H9YPH
A high-performing neural network activation function.The GELU nonlinearity is
A list of 2 (or 4 if bidirectional) activation functions for update, reset, and hidden gates. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
A list of 3 (or 6 if bidirectional) activation functions for input, output, forget, cell, and hidden. The activation functions must be one of the activation functions specified above. Optional: See the equations for default if not specified.
A list of floats.
A list of integers, along which to reduce. The default is to caculate along axes [0,2,3] for calculating mean and variance along each channel. Two variables with the same C-coordinate are associated with the same mean and variance.
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor.
A list of integers, along which to reduce. The default is to reduce over all the dimensions of the input tensor. Accepted range is [-r, r-1] where r = rank(data).
A list of integers. By default, reverse the dimensions, otherwise permute the axes according to the values given.
A list of ints.
A list of labels.
A list of strings. One and only one of 'keys_*'s should be set.
A list of strings. One and only one of 'value_*'s should be set.
A node with a function body within a subgraph within another function body is currently not supported in ORT
A shape tensor must be a vector tensor.
A string indicating the desired element type of the output tensor, one of 'TO_FLOAT', 'TO_STRING', 'TO_INT64'.
A string to use when an input integer value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
A string vocabulary array.<br>One and only one of the vocabularies must be defined.
A string.
A target node must be set.
A value that needs replacing.
A$rpJN
A(A9A
A(H+A H
A(I+A H
A)B(4?
A*+s[
a,#Kvx
A,A9A
A:8ucI
A;@(u
A;@,t
A;|$8|
A;A(u
A;A,u
A;A0t
A;P |
A;Q |
A@A!AHI
A\_^[]
A\A]A^_^[]
A\A]A^A__^[]
A\A^_^[]
A]A\]
A]A\_^[]
A^_^[
A^_^[]
A^_^]
A^_^][
A^A\]
A^A\_
A^A\_^[]
A^A\_^]
A^A]]
A^A]_^]
A^A]A\]
A^A]A\_]
A^A]A\_^[
A^A]A\_^[]
A__^[]
A_A\]
A_A\_^]
A_A]]
A_A]_^]
A_A]A\_]
A_A]A\_^[
A_A]A\_^[]
A_A^]
A_A^_
A_A^_^[
A_A^_^[]
A_A^_^]
A_A^_^][
A_A^A\
A_A^A\^[]
A_A^A\^]
A_A^A\_]
A_A^A\_^
A_A^A\_^[
A_A^A\_^[]
A_A^A\_^][
A_A^A]
A_A^A]^]
A_A^A]_]
A_A^A]_^
A_A^A]_^[
A_A^A]_^[]
A_A^A]_^][
A_A^A]A\]
A_A^A]A\^
A_A^A]A\^[
A_A^A]A\^[]
A_A^A]A\_
A_A^A]A\_[]
A_A^A]A\_^[
A_A^A]A\_^[]
A_A^A]A\_^]
A_A^A]A\_^][
A_scale
a_scale
A_zero_point
a_zero_point
A`@80
A`H+AXH
A|U@ 
A+>Hc
A+M0A
A+O0A
A<X@@
A0D8p:t
A0H+A(H
A0H9A(t;H
A0H9A(u
A0I9A(u
A0L#D$(L
A0LcA
A0t:I
A4XH 
A5XH 
a7>.B
A8@8u
A8^1u
A8<$tkI
A8>"\
A84>u
A8A8u
A8C8u
A8F0thH
A8H+A0H
A8q8t8D
A8UPt
A8vduaA
A8vPt
A8VPt
A8WPt
A8x u
A8Y u
A9@(u
A9@,u
A9|$8~_3
A9}(u
A9A(u
A9H(u$I
A9l$(u-H
A9p(u;I9p u5H
A9t$(
A9u(t8I
ACLExecuH9
ACLExecutionProvider
Acosh
AcquireSRWLockExclusive
AcquireSRWLockShared
across_channels
activation
activation and leaky_relu_alpha.
Activation functions:
activation.
activation_
activation_alpha
activation_beta
activation_func_names.size() == static_cast<size_t>(num_directions_) * 2
activation_func_names.size() == static_cast<size_t>(num_directions_) * 3
activation_gamma
activation_params
activation_params count mismatch
activation_size
ActivationDescCount
ActivationDescs
activations
activations, avoiding computation if the input is invalid (as in, the
activations_.size() == static_cast<size_t>(num_directions)
adapterLuidHighPart
adapterLuidLowPart
add_B_tensor_proto
Added in transpose optimizer
AddFoldedRange recurses too much.
Adding default CPU execution provider.
AddInitializedTensor already has tensor with name 
addition
Additional elements added to the side with higher coordinate indices in the output. Each padding value in "output_padding" must be less than the corresponding stride/dilation dimension. By default, this attribute is a zero vector. Note that this attribute doesn't directly affect the computed output values. It only controls the selection of the computed values, so changing this attribute only adds or removes output elements. If "output_shape" is explicitly provided, "output_padding" does not contribute additional size to "output_shape" but participates in the computation of the needed padding amount. This is also called adjs or adjustment in some frameworks.
address family not supported
address in use
address not available
Adlam
affine
Affine
Affine takes one input data (Tensor<T>) and produces one output data
aggregate_function
AHH+A@H
AhH+y
ai.of
ai.onnx
ai.onnx.ml
ai.onnx.preview.training
ai.onnx.training
align_corners
AlignRegionsToCorners
All implicit inputs should have OrtValue instances by now. 
All inputs must have the same shape
All inputs to Concat must have same rank
All inputs to 'Range' op must be of the same type
All nodes have been placed on [
All scan outputs MUST be tensors
All Tensor and Sequence types
All Tensor types
All Tensor, Sequence, and optional types
all types
Allocated memory at 
Allocation of memory pattern buffer for 
Allocation of tensor types requires a shape.
allocator
allocator != nullptr
Allocator already registered for 
allocator_ != nullptr
allocator_for_caching.get() != nullptr
allocator_ptr_
AllocPlan(ml_value_idx).program_counter.Ends().back() == program_counter
ALLOW_RELEASED_ONNX_OPSET_ONLY
Allowed values are 'half_pixel' and 'output_half_pixel'. Use the value 'half_pixel' to pixel shift the input coordinates by -0.5 (the recommended behavior). Use the value 'output_half_pixel' to omit the pixel shift for the input (use this for a backward-compatible behavior).
allowed_activations.find(activations_[direction]) != allowed_activations.end()
allowed_directions.find(direction_) != allowed_directions.end()
allowzero
alpha
Alpha
alpha == 1.0f && (beta == 0.0f || beta == 1.0f)
alpha_ > 0.0f
already connected
AMDiuA
An allocator for this device has already been registered for sharing.
An attribute specifying the number of scan_inputs M. 
An axes tensor must be a scalar or a 1-D tensor.
An axes tensor must be a vector tensor.
An axis tensor must be a scalar tensor.
An input tensor to hash.
An integer to use when an input string value is not found in the map.<br>One and only one of the 'default_*' attributes must be defined.
An integer vocabulary array.<br>One and only one of the vocabularies must be defined.
An integer.
An optional list of K flags, one for each scan_output. The i-th element of the list specifies whether the i-th scan_output should be constructed by appending or prepending a new value in each iteration: 0 indicates appending and 1 indicates prepending. If omitted, all scan_output tensors will be produced by appending a value in each iteration.
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output.
An optional list of K flags. The i-th element of the list specifies the axis for the i-th scan_output. The scan outputs are accumulated along the specified axis. If omitted, 0 will be used as the scan axis for every scan_output. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1].
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input.
An optional list of M flags. The i-th element of the list specifies the axis to be scanned (the sequence axis) for the i-th scan_input. If omitted, 0 will be used as the scan axis for every scan_input. Negative value for an axis means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
An optional list of M flags. The i-th element of the list specifies the direction to be scanned for the i-th scan_input tensor: 0 indicates forward direction and 1 indicates reverse direction. If omitted, all scan_input tensors will be scanned in the forward direction.
an optional list of strings attribute that contains a list of separators - regular expressions to match separators Two consecutive segments in X connected by a separator would be divided into two tokens. For example, if the input is "Hello World!" and this attribute contains only one space character, the corresponding output would be ["Hello", "World!"]. To achieve character-level tokenization, one should set the 'separators' to [""], which contains an empty string.
An optional string. Token's regular expression in basic POSIX format (pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html#tag_09_03). If set, tokenizer may produce tokens matching the specified pattern. Note that one and only of 'tokenexp' and 'separators' should be set.
An OrtValue for this name has already been added.
An split tensor must be a vector tensor.
Anatolian_Hieroglyphs
and the running statistics in training mode (training_mode=True).
Another operand has a dim value of 
Ap$"<
ApH+9H
APH+AHH
APH9AH
APH9AHt]H
APH9AHtMH
API+AHH
api-ms-win-core-com-l1-1-0.dll
api-ms-win-core-debug-l1-1-0.dll
api-ms-win-core-errorhandling-l1-1-0.dll
api-ms-win-core-fibers-l1-1-0.dll
api-ms-win-core-file-l1-1-0.dll
api-ms-win-core-file-l1-2-0.dll
api-ms-win-core-handle-l1-1-0.dll
api-ms-win-core-heap-l1-1-0.dll
api-ms-win-core-heap-l2-1-0.dll
api-ms-win-core-interlocked-l1-1-0.dll
api-ms-win-core-libraryloader-l1-2-0.dll
api-ms-win-core-libraryloader-l1-2-1.dll
api-ms-win-core-localization-l1-2-0.dll
api-ms-win-core-memory-l1-1-0.dll
api-ms-win-core-path-l1-1-0.dll
api-ms-win-core-processenvironment-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-0.dll
api-ms-win-core-processthreads-l1-1-1.dll
api-ms-win-core-processthreads-l1-1-3.dll
api-ms-win-core-processtopology-obsolete-l1-1-0.dll
api-ms-win-core-profile-l1-1-0.dll
api-ms-win-core-rtlsupport-l1-1-0.dll
api-ms-win-core-string-l1-1-0.dll
api-ms-win-core-synch-l1-1-0.dll
api-ms-win-core-synch-l1-2-0.dll
api-ms-win-core-sysinfo-l1-1-0.dll
api-ms-win-core-sysinfo-l1-2-0.dll
api-ms-win-core-util-l1-1-0.dll
api-ms-win-crt-locale-l1-1-0.dll
api-ms-win-crt-math-l1-1-0.dll
api-ms-win-crt-private-l1-1-0.dll
api-ms-win-crt-runtime-l1-1-0.dll
api-ms-win-crt-string-l1-1-0.dll
api-ms-win-eventing-provider-l1-1-0.dll
ApL+Q
apply softmax to elements for dimensions softmax_axis or higher
apTo'!
AQ5@.
Arabic
arena_extend_strategy
ArfLN)
arg_num < arg_counts.size()
ArgMax
ArgMin
Argument is not a tensor
argument list too long
Argument mismatch when removing edge.
argument out of domain
Argument type mismatch when adding edge.
Armenian
ArmNNExecutionProvider
array
Array of sequence lengths.  len(seq_lengths) should equal batch size N.
ArrayFeatureExtractor
as.,k{n?,
AScaleTensor
Asinh
asymmetric
At least one element in the sequence is of a type different from others.
At least one output should be requested.
At least two inputs are needed, and each input must be (tensor, scale, zero_point) tuple!
At most one dimension can be -1.
Atanh
ATAVAWH
ATensor
Attempt to retrieve final output before it was set.
Attempt to use DefaultLogger but none has been registered.
Attempting to broadcast an axis by a dimension other than 1. 
Attempting to get an input that does not exist.
Attempting to get an output that does not exist.
Attempting to get index by a name which does not exist:
Attention
Attention cannot have past sequence and extra add qk
Attention layer weight shape error! Expected: {
Attention mechanism memory sequence lengths must have shape {
Attention mechanism memory sequence lengths value must in (0, 
Attention mechanism memory shape error! Expected: {
Attention memory layer weight shape error! Expected:{
Attention query layer weight shape error! Expected:{
Attention v weight shape error! Expected:{
AttentionFusion
Attibute name and type don't match
AttnLSTM
attr->has_tp()
Attribute 
Attribute '
Attribute (name: 
Attribute `broadcast=1` needs to be passed to enable broadcasting.
Attribute axes has incorrect length
Attribute blocksize is not set.
Attribute border needs to be specified with four border elements, got 
attribute case_change_action has invalid value
attribute case_change_action is not set
Attribute dilations has incorrect size
Attribute dtype should be of integer type and specify a type.
Attribute expected to have a one-dim sparse tensor
Attribute expected to have a one-dim tensor
Attribute expected to have tensor or sparse tensor type
attribute is_case_sensitive is not set
Attribute kernel_shape has incorrect size
Attribute kernel_shape has incorrect size.
Attribute kernel_shape must be specified
Attribute kernel_shape must be specified.
attribute mark is not set
attribute mincharnum is not set
attribute mincharnum must have a positive value
Attribute name and type don't match for '
attribute pad_value is not set
Attribute pads has incorrect length
Attribute pads has incorrect size
Attribute pads has incorrect size.
Attribute perm of Transpose has an invalid value. Value 
Attribute pooled_shape has incorrect length
Attribute pooled_shape must be specified
Attribute 'scales' is required.
Attribute 'scales' must have floats type.
Attribute shape is not set.
Attribute specification type mismatch.
Attribute strides has incorrect size
Attribute strides has incorrect size.
Attribute to is not set.
Attribute 'type' should be a TypeProto and it should specify a type.
Attribute value for pads is required
Attribute 'value' of Constant node must exist with 'Tensor' data.
Attribute 'value_float' expect a float.
Attribute 'value_floats' expect a list of floats.
Attribute 'value_int' expect an integer.
Attribute 'value_ints' expect a list of integers.
Attribute 'value_string' expect a string.
Attribute 'value_strings' expect a list of strings.
Attribute: 
AUAVAWH
Authu
auto_pad
auto_pad == AutoPadType::NOTSET
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = ceil(input_shape[i] / strides[i])` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that `output_shape[i] = input_shape[i] * strides[i]` for each axis `i`. The padding is split between the two sides equally or almost equally (depending on whether it is even or odd). In case the padding is an odd number, the extra padding is added at the end for SAME_UPPER and at the beginning for SAME_LOWER.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding. DEPRECATION NOTE: auto_pad is only intended to support legacy uses, and for framework authors, one is explicitly encouraged to use explicit padding specified in the pads attribute.
auto_pad must be either NOTSET, SAME_UPPER, SAME_LOWER or VALID. Where default value is NOTSET, which means explicit padding is used. SAME_UPPER or SAME_LOWER mean pad the input so that the output spatial size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding.
Available memory of 
AVERAGE
AveragePool
Avestan
AX98~
axes as an input and attribute cannot be specified at the same time.
'axes' attribute must not contain any duplicates
'axes' has a duplicate axis
'axes' has an axis outside of the tensor dimension count
'axes' has an out of range axis
'axes' has duplicates
Axes input is null
Axes that `starts` and `ends` apply to. It's optional. If not present, will be treated as [0, 1, ..., len(`starts`) - 1].
axes_right_stride >= 0 && static_cast<uint64_t>(axes_right_stride) < std::numeric_limits<size_t>::max()
axes_tensor != nullptr
axes_tensor->Shape().NumDimensions() == 0 || axes_tensor->Shape().NumDimensions() == 1
axes_tensor->Shape().NumDimensions() == 1
axis 
axis <= X_NumDims && axis >= -X_NumDims
axis == 1 || axis == largest
axis >= -tensor_rank && axis <= tensor_rank - 1
Axis has less than the requested k elements.
'axis' must be in [
axis must be in [-r, r-1]
'axis' must be in [-rank(indices), rank(indices)-1]
'axis' must be in [-rank(indices)-1, rank(indices)]
axis must be in [-rank, rank)
axis must be in [-rank, rank-1].
axis must be in [-rank, rank-1]. input rank was 
Axis must be within range [
axis tensor can be int32 or int64 only
Axis tensor must be provided to the CumSum op
Axis tensor should be 0D or 1D
Axis tensor should be of type `int32_t` or `int64_t`
axis_tensor->Shape().IsScalar()
Axis1D = Constant()
AxisCount
AxisDirection
AXL9I`t
AZeroPointTensor
b .",(r*L,@.
B + (N * ldb - (ldb - K)) <= B_end
B F+U
B H;A t
B H+B
B H9A
B H9G 
B I;@ u
b J"J
B L9H
b"-@,
B(>4<
B(>f<l\"^H`2d
-B(4?
B(9C(u
B(A9@
b(H;]
b(H^:rDH`
B(I9A(u
b(XxRzTfd
B,9C,u
B,A9@
B.~&)`
B\$XH
B_scale
b_scale
b_scale_shape.NumDimensions() == 0 || (b_scale_shape.NumDimensions() == 1 && (b_scale_shape[0] == 1 || b_scale_shape[0] == helper.N()))
b_scale_shape.NumDimensions() == b_zp_shape.NumDimensions() && (b_scale_shape.NumDimensions() == 0 || (b_scale_shape[0] == b_zp_shape[0]))
b_zero_point
B_zero_point
b_zp_shape.NumDimensions() == 0 || (b_zp_shape.NumDimensions() == 1 && (b_zp_shape[0] == 1 || b_zp_shape[0] == helper.N()))
B`9A`
b},4C
b}.<C
b}/<C
b}-4C
B09C0t
B0D^F H
B0I;@
B2D = Flatten <axis=0> (B)
b33f88f7-c464-43e3-8692-97ac832bb14a
b33fd0fa-cd7b-4b10-ae5a-df64cabfe1f8
B84:u
b8H;u
ba$@]
ba$@_
ba$@Y
ba,@]
ba,@_
ba,@Y
ba|H(
ba<@]
ba<@_
ba<@Y
ba4@]
ba4@_
ba4@Y
bad address
bad allocation
Bad args: nsubmatch=
bad array new length
Bad call to ParseState::ParsePerlFlags
bad cast
bad conversion
bad dimensions
bad exception
bad file descriptor
Bad final char: 
bad function call
Bad hex digit 
bad locale name
bad message
Bad node spec for node. Name: 
Bad optional access
Bad reference count 
bad repetition operator
Balinese
Bamum
Base values for classification, added to final class score; the size must be the same as the classes or can be left unassigned (assumed 0)
base_values
Bassa_Vah
Batak
Batch dimension should match for MatMul;
batch_axis
batch_axis != time_axis
batch_axis < 2
batch_dims
batch_indices
batch_indices shape input tensor has wrong dimension
batch_size is < 1
BatchDimensionCount
BatchIndicesTensor
BatchNormalization
BatchNormalizationAddFusion
BatchNormalizationMulFusion
Batchwise recurrent operations (layout == 1) are not supported. If you need support create a github issue with justification.
bb]HQ
bB]X@C
bB]X@K
bb}H{
bb}HQ
bb}HX
bb}HX'H
bbeHQ
bbuHQ
bBUX@[
bBUX@{
bBUX@c
bBUX@k
bBUX@s
BD[?j
Begin execution
Bengali
Bernoulli
beta is expected to have 1 dimension, got 
beta is expected to have 1 dimensions, got 
beta is expected to have size of 
Beta scale must be a scalar or 1D tensor of size 1
Beta should be of shape (hidden_size). 
beta should have 1 dimension, dimension size known, and same hidden size as word_embedding.
Beta zero point must be a scalar or 1D tensor of size 1
beta_ > 0.0f
beta_quant
beta_scale
beta_zero_point
Beta1
Beta2
bfloat16
bfloat16H
bGDJK
Bhaiksuki
BHDjF\D
BhH9Ah
Bias applied to each channel, same size as C.
Bias Gelu.
bias is expected to have 1 dimension, got 
Bias size (
Bias tensor.
BiasDropout
BiasDropoutFusion
Biased = Add (Scaled, B2D)
Biased = Identity (Scaled)
BiasGelu
BiasGeluFusion
BiasGeluH
BiasSoftmax
BiasSoftmaxFusion
BiasTensor
bicubic
bidirectional
BifurcationDetector
BILINEAR
bilinear
bilinearH
bilinearH9
Binarizer
binary
BinForSize(bin_size * 2 - 1) == BinFromIndex(b)
BinForSize(bin_size * 2) != BinFromIndex(b)
BinForSize(bin_size + 255) == BinFromIndex(b)
BinForSize(bin_size) == BinFromIndex(b)
BinFromIndex(c->bin_num)->free_chunks.erase(h) > 0
BitShift
bkg!\
Blocks of [blocksize, blocksize] are moved.
BlockSize
blocksize
Blocksize must be positive
bn_B_tensor_proto
bn_mean_tensor_proto
bn_scale_tensor_proto
bn_scaleH
bn_var_tensor_proto
bodyD
Bool to determine if hidden state is zeroes or passed along for timesteps past the given sequence_length.
boolean
Boolean whether to mark the beginning/end character with start of text character (0x02)/end of text character (0x03).
Boolean. Indicates whether upper or lower part of matrix is retained. Default is true.
Boolean. Whether the identification of stop words in X is case-sensitive. Default is false
Bopomofo
border
'Border' attribute must be present and must contain exactly 4 values - (left_border, top_border, right_border, bottom_border)
Both `data` and `indices` input tensors in GatherND op need to have rank larger than 0.
Both attributes isinf_only and isnan_only cannot be set. Unset both to check for both conditions.
both data and indices tensor need to have rank larger than zero.
boxes
boxes and scores should have same num_batches.
boxes and scores should have same spatial_dimension.
boxes must be a 3D tensor.
boxes_tensor
Bp9Ap
BPD.F0D9
bq$H]
bq$H_
bq$HX\
bq$HY
bq,H]
bq,H_
bq,HXS
bq,HY
bQ|H[
bQ}H[
'bQ}X
bQ<@_
bq<H]
bq<H_
bQ<HX@
bq<HY
bq4H]
bq4H_
bQ4HXL
bq4HY
BQhI+
br]HQ
br}H{
br}HQ
Brahmi
Braille
BRANCH_EH9
BRANCH_GI
BRANCH_LI
breHQ
bReX@{
bReX@3b
bReX@3bQ}H
broadcast
broadcast bias across input for dimensions broadcast_axis to softmax_axis-1
Broadcast Output range [
broadcast_axis
BroadcastLooper requires two tensors as input.
broken pipe
Brr\7<
bruHQ
BScaleTensor
BTensor
Buffer containing the initializer must be owned by the user.
buffer size is too small for string element
buffers_.find(location) == buffers_.end()
buffers_.size() == buffer_sizes_.size()
Buginese
Buhid
bumped the operator version but 
BvDHP
BxH+i
BxL+I
by either re-generating the model with latest exporter/converter 
BYhI+
bytemap range 
bzdHbJ&
BZeroPointTensor
C + (M * ldc - (ldc - N)) <= C_end
C +C0
C = ((A - A_zero_point) * (B - B_zero_point)) * (A_scale * B_scale)/C_scale + C_zero_point
C = (A_scale * (A - A_zero_point) + B_scale * (B - B_zero_point))/C_scale + C_zero_point
C 9A 
C 9H 
C 9o(u
C 9P 
C D80
C D9f(
C H+C
C H98
C H9C
C HcL
C I+C
C L+C
C L9@
C$QF,3
C(@8{1H
C(+C,
C(+C0
C(D+C0D
C(D80t
C(D90
C(H9C@u
c(Lcs,H
C@f99H
C@H;U
C@H+1H
C@H+C8H
C@H9{Ht
C_scale
c_shape != nullptr
c_shape is required if c_data is provided
C_zero_point
C`D8`
C`H+CPH
C++/WinRT version:2.0.201201.7
c->in_use() && (c->bin_num == kInvalidBinNum)
C0D80u
C0H!C(H!C0H
C0HcH
c2->prev == h1
C8<!u
C8D80
C8D80uwM
c8H;u
C8H+9H
C8H+C0H
CallContext:[%hs] 
called_ == 1
cAMDt
Can broadcast 0 by 0 or 1. 
Can not digest separators: 
Can not digest tokenexp: 
Can not find the execution provider 
Can not find the node 
Can not get shape initializer data!
Can not multiply A and B as inner dimension does not match. inner_A: 
Can not use strings in pre-allocated memory. Use CreateSparseTensorAsOrtValue() to allocate memory inside and copy
Can only add a new input at the end of the current ones.
Canadian_Aboriginal
Candidate for fallback CPU execution: 
candidate_output.Shape().Size() == output_shape.Size()
candidate_output_dims[iter] == 1
Cannot apply CumSum operator on a scalar
cannot compare iterators of different containers
Cannot concatenate scalars
cannot find allocator
Cannot find missing input: 
Cannot find NodeArgs for [
cannot get value
Cannot infer type and shape for function
Cannot parse data from external tensors. Please 
Cannot parse the diagonal elements along dims 
Cannot replace concat node with initializer:
Cannot reshape initializer 
Cannot scale 0 by any factor to generate a non-zero value. 
Cannot slice scalars
Cannot split using values in 'split' attribute. Axis=
cannot use at() with 
Cannot use 'edge' mode to pad dimension with a value of 0. Input shape:
cannot use erase() with 
cannot use key() for non-object iterators
Cannot use 'reflect' mode to pad dimension with a value of 0. Input shape:
Cannot use SearchOnePass for unanchored matches.
Cannot use the same name as both a subgraph initializer and subgraph input: 
Cannot use user supplied initializer with name: (
Can't 
can't constant fold 
Can't find node with index 
Can't happen
Can't merge shape info. Both source and target dimension have values but they differ. Source=
Can't reduce on dim with value of 0 if 'keepdims' is false. Invalid output shape would be produced. input_shape:
Can't remove node 
Can't slice a non-tensor OrtValue. Type was 
Can't use func with null ptr
Carian
Carries out batch normalization as described in the paper
Case not handled in ComputeSimple: 
case_change_action
cast != nullptr
Cast Input from int64 to int32
Cast mask from int64 to int32
cast node to cast from float16 to float32 on cpu
cast output of layer norm
cast scale of layer norm
Cast_Scale
cast_to
CastElimination
CastFloat16Transformer
CastLike
CastMap
CategoryMapper
cats_int64s
cats_strings
Caucasian_Albanian
Caught exception while destructing CustomOpsLoader with message: 
Caught exception while loading custom ops with message: 
CbQ~I
CD$`H
CD$PH
CDist
ceil_mode
Cell clip threshold. Clipping bounds the elements of a tensor in the range of [-threshold, +threshold] and is applied to the input of activations. No clip if not specified.
CellMemInitTensor
center_point_box
center_point_box only support 0 or 1
ChA;|
Chakma
ChannelCount
channels
channels_ <= X_shape[1]
channels_ > 0
channels_last
channelsH
Char embedding size does not match char_embedding_size attribute.
Char embedding size does not match conv kernal size 2.
char_embedding_size
CHECK failed: !is_closed_: 
CHECK failed: (backup_bytes_) == (0): 
CHECK failed: (buffer_used_) == (buffer_size_): 
CHECK failed: (count) <= (buffer_used_): 
CHECK failed: (count) >= (0): 
CHECK failed: (index) < (current_size_): 
CHECK failed: (min_bytes) <= (std::numeric_limits<size_t>::max() - SerialArena::kBlockHeaderSize): 
CHECK failed: backup_bytes_ == 0 && buffer_.get() != NULL: 
CheckNodesInPathK returns false
CheckNodesInPathQ returns false
CheckNodesInPathV return false
CheckSliceParameters return false
CheckSliceParameters return false for slice2
CheckSliceParameters returns false for last_slice
CheckSliceParameters returns false for mask_slice
CheckSliceParameters returns false for slice1
checksum
Cherokee
ChH+9H
ChH+C`H
CHH+C8H
ChH+q
ChHcCtL;
Child node if expression is false
Child node if expression is false.
Child node if expression is true
Child node if expression is true.
ChL+1H
ChL+A
Chorasmian
Chosen support vectors
Chttp://www.microsoft.com/pkiops/crl/MicWinProPCA2011_2011-10-19.crl0a
CKS-/7
CL$ L
CL$(3
CL$(H
CL$`L
CL$hE3
CL$PL
Class labels if using integer labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels if using string labels.<br>One and only one of the 'classlabels_*' attributes must be defined.
Class labels when using integer labels. One and only one 'classlabels' attribute must be defined.
Class labels when using string labels. One and only one 'classlabels' attribute must be defined.
class_ids
class_nodeids
class_treeids
class_weights
classes.size() == 2 || classes.size() == 1
classes_strings
classlabels_int64s
classlabels_ints
classlabels_strings
classlabels_strings_.empty() ^ classlabels_int64s_.empty()
classlabels_strings_.size() > 0 || classlabels_ints_.size() > 0
clip_ > 0.f
ClipThreshold
close() failed: 
CloseHandle
CM/L+
Cn0:Z>LJ
CoalesceWalker::ShortVisit called
CoCreateFreeThreadedMarshaler
code != static_cast<int>(common::OK)
Coefficient of ELU default to 1.0.
Coefficient of ELU.
Coefficient of leakage default to 0.01.
Coefficient of leakage.
Coefficient of SELU default to 1.0507.
Coefficient of SELU default to 1.05070102214813232421875 (i.e., float32 approximation of 1.0507009873554804934193349852946).
Coefficient of SELU default to 1.6732.
Coefficient of SELU default to 1.67326319217681884765625 (i.e., float32 approximation of 1.6732632423543772848170429916717).
coefficients
coefficients_.size() > 0
com.microsoft
com.microsoft.
com.microsoft.dml
com.microsoft.experimental
com.microsoft.nchwc
com.microsoft.QLinearAdd
com.microsoft.QLinearAveragePool
com.microsoft.QLinearConcat
com.microsoft.QLinearGlobalAveragePool
com.microsoft.QLinearLeakyRelu
com.microsoft.QLinearMul
com.microsoft.QLinearReduceMean
com.microsoft.QLinearSigmoid
combase.dll
Common
CommonSubexpressionElimination
CompanyName
CompareStringEx
Compiled kernel hashes must be provided
compiled_kernel_hashes != nullptr
Compiler::Copy called!
complex128
complex64
ComplexMul
ComplexMulConj
Compress
Compute_
compute_info_->create_state_func(&context, &func_state_) == 0
Computed size: 
ComputePad: pad type not supported.
Computes an one-layer GRU. This operator is usually supported via some custom
Computes an one-layer LSTM. This operator is usually supported via some
Computes an one-layer simple RNN. This operator is usually supported
Computes the indices of the {name} elements of the input tensor's element along the
Concat
concat first input value is not -1
Concat of 
concat_after_gather does not have expected number of inputs or output edges
concat_after_gather input 2 does not have expected value
concat_result
ConcatFromSequence
Concretely, given the (fused) inputs X (TxNxD), the previous hidden
condition
ConditionTensor
Config key is empty or longer than maximum length 128
Config value is longer than maximum length 1024
Config with key [
Conflicting free dimension overrides.
connection aborted
connection already in progress
connection refused
connection reset
const_ignore_index
const_one
const_one_casted
const_one_float
const_transpose_optimizer
const_zero
const_zero_casted
const_zero_float
const_zero_target_typed
constant
Constant
Constant initializer NodeArg shape should not be null. NodeArg: 
constant_value
ConstantFill
ConstantFolding
ConstantOfShape
Constrain bias type to 32-bit integer tensor.
Constrain filter type to 8-bit integer tensor.
Constrain index tensor to int64
Constrain indice type to int32 or int64
Constrain indices to integer types
Constrain input a and its zero point data type to 8-bit integer tensor.
Constrain input A and its zero point types to 8 bit tensors.
Constrain input A data type to 8-bit integer tensor.
Constrain input A data types as 16-bit integer tensor
Constrain input A, b_scale and output Y data type as float tensor.
Constrain input a_scale, b_scale and output Y data type as float tensor.
Constrain input and output  types to float tensors.
Constrain input and output float tensors types.
Constrain input and output integer tensors types
Constrain input and output to all tensor types.
Constrain input and output types (except mean and inv_std_var) to float tensors.
Constrain input and output types to 8 bit signed and unsigned tensors.
Constrain input and output types to 8 bit tensors.
Constrain input and output types to all numeric tensors and bool tensors.
Constrain input and output types to all numeric tensors.
Constrain input and output types to all numerical tensor types.
Constrain input and output types to all tensor and sequence types.
Constrain input and output types to all tensor types (including bfloat).
Constrain input and output types to all tensor types.
Constrain input and output types to all tensor, sequence, and optional types.
Constrain input and output types to all tensors.
Constrain input and output types to any tensor type.
Constrain input and output types to float and 8 bit tensors.
Constrain input and output types to float and float16 tensors.
Constrain input and output types to float or half tensors.
Constrain input and output types to float tensors
Constrain input and output types to float tensors.
Constrain input and output types to float/int tensors.
Constrain input and output types to float32 tensors.
Constrain input and output types to floating-point tensors.
Constrain input and output types to high-precision and 8 bit numeric tensors.
Constrain input and output types to high-precision numeric tensors.
Constrain input and output types to int8 tensors.
Constrain input and output types to integer tensors.
Constrain input and output types to numeric tensors.
Constrain input and output types to signed numeric tensors.
Constrain input and output types to singed/unsigned int8 tensors.
Constrain input and output types.
Constrain input b and its zero point data type to 8-bit integer tensor.
Constrain input B and its zero point types to 8 bit tensors.
Constrain input B data type to 8-bit integer tensor.
Constrain input B data types as 16-bit integer tensor
Constrain input C to 32 bit integer tensors.
Constrain input 'ratio' types to float tensors.
Constrain input type to 8-bit integer tensor.
Constrain input type to unsigned or signed 32-bit integer tensor, or string tensor. It should be utf-8 encoded if using unicode.
Constrain input types and output Y type to float tensors.
Constrain input types to 8 bit signed and unsigned tensors.
Constrain input types to all tensor types.
Constrain input types to any tensor type.
Constrain input types to common numeric type tensors.
Constrain input types to float tensors.
Constrain input types.
Constrain input types. Casting from complex is not supported.
Constrain input types. Casting from strings and complex are not supported.
Constrain input types. Strings and complex are not supported.
Constrain input w and its zero point data type to 8-bit integer tensor.
Constrain input x and its zero point data type to 8-bit integer tensor.
Constrain input X and output types to float/int tensors.
Constrain input 'X' and output 'Y' to all tensor types.
Constrain input Y types to float/int tensors.
Constrain input, weight, and output types to floating-point tensors.
Constrain input0 and output types to float tensors
Constrain key_padding_mask to bool tensors.
Constrain mask index to integer types
Constrain mean and inv_std_var to be float tensors.
Constrain mean and inv_std_var to float tensors.
Constrain mean and variance types to float tensors.
Constrain mean and variance types to float tensors. It allows all float type for U.
Constrain output data type to 32-bit integer tensor.T2 must be tensor(uint32) when T1 is tensor(uint8),or must be tensor(int32) when T1 is tensor(int8).
Constrain output mask types to boolean tensors.
Constrain output 'mask' types to boolean tensors.
Constrain output to int64 tensor, which should be a scalar though.
Constrain output to int64 tensor.
Constrain output to integral tensor. It must be a scalar(tensor of empty shape).
Constrain output type to 8-bit integer tensor.
Constrain output type to all tensor or sequence types.
Constrain output type to float32 or 8 bit tensors.
Constrain output type to unsigned and signed 32-bit integer tensor.
Constrain output types to 32 bit tensors.
Constrain output types to all numeric tensors and bool tensors.
Constrain output types to all tensor types.
Constrain output types to any tensor type.
Constrain output types to be numerics.
Constrain output types to bool, int32, int64, float16, float, double tensors.
Constrain output types to boolean tensors.
Constrain output types to float tensors.
Constrain output types to integral tensors.
Constrain output types. Casting to complex is not supported.
Constrain output types. Casting to strings and complex are not supported.
Constrain output types. Strings and complex are not supported.
Constrain output y and its zero point data type to 8-bit integer tensor.
Constrain output Y data type as 32-bit integer tensor.
Constrain output y data type to 32-bit integer tensor.
Constrain output Y data types as 32-bit integer tensor.T3 must be tensor(uint32) when both T1 and T2 are tensor(uint16),or must be tensor(int32) when either T1 or T2 is tensor(int16).
Constrain output zero point types to 8 bit tensors.
Constrain position to integral tensor. It must be a scalar(tensor of empty shape).
Constrain repeat's type to int64 tensors.
Constrain roi type to float or double.
Constrain scale and bias types to float tensors.
Constrain scale types to any float tensor type.
Constrain scale types to float tensors.
Constrain scores input and output types to float tensors.
Constrain seq_lens to integer tensor.
Constrain seq_lens to integral tensors.
Constrain split size to integral tensor.
Constrain target to integer types
Constrain the output to a boolean tensor.
Constrain tiles and axis's type to int64 tensors.
Constrain to all fixed size tensor and sequence types. If the dtype attribute is not provided this must be a valid output type.
Constrain to all tensor types.
Constrain to any tensor type.
Constrain to any tensor type. If the dtype attribute is not provided this must be a valid output type.
Constrain to boolean tensors.
Constrain to integer types
Constrain to integer types.
Constrain to tensor(float).
Constrain to tensor(int32).
Constrain types to float tensors.
Constrain types to int tensors.
Constrain weights types to 8 bit tensors.
Constrain 'x' and 'x_zero_point' to 8-bit integer tensors.
Constrain 'x' to float or int32 tensor.
Constrain 'x' to float tensor.
Constrain 'x', 'y_scale' to float tensors.
Constrain 'x_zero_point' and 'x' to 8-bit/32-bit integer tensor.
Constrain 'y', 'x_scale' to float tensors.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensor.
Constrain 'y_zero_point' and 'y' to 8-bit integer tensors.
Constrain 'y_zero_point' and 'y' to 8-bit unsigned integer tensor.
Constrains input and output to only numeric types.
Constrains input to boolean tensor.
Constrains input to float tensors.
Constrains input to integral tensors.
Constrains input to only numeric types.
Constrains input type to all tensor and sequence types.
Constrains input type to optional tensor and optional sequence types.
Constrains input types to all numeric tensors.
Constrains input/output to boolean tensors.
Constrains output to a boolean tensor.
Constrains output to boolean tensor.
Constrains output type to all optional tensor or optional sequence types.
Constrains to boolean tensors.
consumed_inputs
Container for generated shape data cannot be nullptr when enable_data_propagation option is set.
context does not contain text
Conv filter size does not match embedding_size attribute.
Conv kernal size 1 does not match conv_window_size attribute .
conv_B_tensor_proto
conv_W_tensor_proto
conv_window_size
ConvActivationFusion
ConvAddFusion
ConvAddFusion_Add_B_
ConvAddFusion_B_
ConvBNFusion
ConvBnFusion_BN_B_
ConvBnFusion_W_
ConvD
Conversion Error
ConvInteger
ConvMulFusion
ConvMulFusion_Mul_B_
ConvMulFusion_W_
ConvTranspose
ConvTransposeWithDynamicPads
COO indices must be 2-D, got: 
COO k index: 
COO m index: 
coordinate_transform_mode:[
coordinate_transformation_mode
Coptic
Copy from/to host memory
copy_info.size() == num_feeds
CoreMLExecutionProvider
corrupted protobuf data: tensor shape size(
CoTaskMemAlloc
Could not finalize session options while constructing the inference session. Error Message: 
Could not find a CPU kernel and hence 
Could not find an implementation for 
Could not find chunk in bin
Could not find OrtValue with idx '
Could not find OrtValue with name '
Could not find Region for 
Could not find Region for: 
Could not infer data type from input tensor with data type 
Could not parse model successfully while constructing the inference session
Could not write a profile because no model was loaded.
count == 1
count_include_pad
counter.current_offset == last
counts
Couple the input and forget gates if 1, default 0.
Couple the input and forget gates if 1.
CoupleInputForget
CpD8P
CPD8X
CPH+)H
CpH+9H
CPH+CHH
CpH+i
CPI+CHH
CPI+CHL
CpL+Q
CPL+q
CPUExecuH9
CPUExecutionProvider
Create_State_
Created a new Cast node to interchange Cast and Transpose nodes
Created a new Transpose node to interchange Cast and Transpose nodes
CreateDirectoryA
CreateDirectoryW
CreateDXGIFactory2
CreateEventW
CreateFeedsFetchesManager must be called prior to execution of graph.
CreateFile2
CreateMutexExW
CreateSemaphoreExW
Creating 
Creating and using per session threadpools since use_per_session_threads_ is true
Creating BFCArena for 
Crop and image to the specified spatial dimensions. If scale is given,
crop_size
crop_size shape input tensor has wrong dimension
CropAndResize
cross device link
CrossChannel
CT$ L
CT$@L
CT$0L
CT$8L
CT$XL
CTensor
cubic
'Cubic' mode only support 2-D inputs ('Bicubic') or 4-D inputs with the corresponding outermost 2 scale values being 1 in the 
cubic_coeff_a
CUDA and/or ROCM execution provider is either not enabled or not available.
CUDAExecutionProvider
cudaMalloc
CudaPinned
CumSum
Cuneiform
cur + size <= end
cur_index == &*indices_data.cend()
cur_input == end_input || cur_input->first >= 0
cur_iteration_ < num_iterations_
cur_out == end_out
cur_tokens
cur1 == end1
current <= buffer_size_
current_mean = ReduceMean(X, axis=all_except_channel_index)
current_var =  ReduceVar(X, axis=all_except_channel_index)
Currently do not support dims higher than 2 dimensions: 
Currently support only COO and CSR(x64) formats
Currently supporting only 2-D matrices
custom implementation such as CuDNN.
custom join thread function not set
custom join thread function not set for inter op thread pool
custom join thread function not set for intra op thread pool
custom op registered at runtime
custom_create_thread_fn returned invalid handle.
custom_logger != nullptr
CX9{Pu
CXH;CXu
CXH+1H
CXH+Q
CXI9FX
Cypriot
Cyrillic
d .",
D D R R z | 
D!}'H
D"@J>n@LJ
D$ ;D$ u
D$ 8UwI
D$ 9E0uFH
D$ A8{
D$ A8z
d$ D!
D$ D9H,t
D$ D9k0
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
d$ E3
D$ E3
D$ fD
D$ fH
D$ H;
D$ H;C
D$ H;D$ u
D$ H;S
D$ H;U
d$ H;U
D$ H;U't
D$ H;W
D$ H+
D$ H9
D$ HcH
D$ I;
d$ I;
D$ I;
D$ I;L$0w
D$ I+
D$ I+G
D$ L;
D$ L+
D$ Mc
D$ tl
D$$9|$(
D$$H;
D$$H;WHt
D$$L;
D$&H;
D$(D;X(
D$(D;X(|
d$(E3
D$(E3
D$(fD
D$(H;
D$(H;Q`t4H
D$(H;S
D$(H;U
D$(H;W
D$(H+
D$(H+D$0
D$(Hc
D$(I;
D$(I+
D$(I9
D$(I9z0
D$(L#
D$(L;
D$(L+
D$(L9H }
D$(Lc
D$(Lc@
D$(Li
D$(permD
D$*E3
D$,H;
D$:E3
D$@E3
d$@E3
D$@E3
d$@E3
D$@E3
d$@E3
D$@H;
D$@H;H
D$@H;U
D$@H+
D$@H+D$8H
D$@H+G
D$@H9
D$@H9E
D$@Hc
D$@HcR
D$@I;
D$@IcV
D$@L;
D$@L;H8r3I
D$@L;m
D$@L+
d$@L+d$8I
d$@L9
D$@L9d$8
d$@L9e
D$@Lc
D$@M;
d$@M;
D$@M;
D$@M+
d$@M9fxt
D$@Mc
D$@Mc@
D$\@B
D$`!D$dH
D$`+D$d
D$`A;
D$`bn_B
D$`D8`
D$`D9`
D$`E;
D$`E3
D$`fB
D$`fD
D$`H;
D$`H+
D$`H+D$XH
D$`H9
D$`Hc
D$`HcH
D$`I;
D$`I+
D$`I9~ht
D$`L;
D$`L+
D$`Lc
D$`M;
D$`permD
d$`t&H
d$<D;d$T
D$<E3
D$=H!S
D$0!D$4H
D$0]A
D$0=A
D$08P
D$08X
D$09H }
D$09P
D$09P }
D$0ATen@
D$0body
D$0bodyD
D$0Conv
D$0D;
D$0D9P0t
D$0E3
D$0fH
D$0Gemm
D$0H!|$8
D$0H!E
D$0H!X
D$0H;
D$0H;Cxt
D$0H;H
D$0H;SHt
D$0H;T$pt
D$0H;U
D$0H;W
d$0H;W
D$0H;W
D$0H+
D$0H+D$(H
D$0H+G
D$0H9H s
D$0H9P }
D$0H9p }
D$0H9P }
D$0H9P s
D$0H9x }
D$0HcH
D$0high
D$0I;
D$0I;G
D$0I;V
D$0I+
d$0I+
D$0Ic
D$0L;
d$0L;
D$0L;
d$0L+
D$0L+
D$0Lc
D$0M;
D$0M+
D$0mean
D$0NONE
D$0NONED
D$0norm
D$0perm
D$0seed@
D$0seedD
D$0type
D$0x`H;
d$1E3
D$1L!m
d$48\$<tDH
d$4A9~(u
d$4D8l$1u
d$4D8t$1u
d$4E3
D$4Hc
D$8!D$<H
d$8E;
d$8E3
D$8E3
d$8E3
D$8E3
d$8E3
D$8H;
D$8H+
D$8H+D$0H
D$8H+D$xH
d$8H9]
D$8H9CX
D$8H9D$0
D$8H9t$@
D$8Hc
D$8highD
D$8I;
D$8I+
D$8I9z(
D$8L;
d$8L;
D$8L;
d$8L;
D$8L;
D$8L+
d$8L+d$0I
D$8L+D$0I
D$8L9
d$8L9u
D$8Lc
D$8meanD
D$8Nc$
D$8permD
D$8seedD
d$8tCH
D$d+D$`
d$dD;d$ltY
D$DDtRH
d$DE9e
d$DE9g
D$DH;
D$HA;M
D$HA;O
D$HD9
D$hE2
D$hE3
D$HE3
D$hE3
D$HE3
D$hE3
D$HE3
D$hE3
d$HE3
D$hE3
d$HE8
D$HfD
D$HH;
D$hH;
D$HH;
D$hH;
D$HH;
D$HH;]
D$hH;D$p
D$hH;D$ptQH
D$hH;D$X
D$HH;u
D$HH;U8t
D$hH+
D$HH+
D$hH+
D$HH+
D$hH+
D$HH+
D$hH+
D$HH+
D$hH+
D$HH+
D$hH+
D$HH+
D$hH+
D$HH+
D$HH+D$@H
D$hH+D$`H
D$hHc
D$HI;
D$hI;
D$HI+
D$hI+
D$HI+
D$HI97
d$HIc
D$hJ9
d$hL;
D$HL;
D$hL;
D$HL;
D$hL;
d$hL;
D$HL;X8r0L
D$HL;X8r5L
d$HL+
D$HL+
D$hL9f
D$HL9gXt
D$HL9p
D$hM;
d$KHc
D$LE3
d$LHc
D$P%H
D$p;X
D$p+E
d$PA;
D$PConv@
D$PD;@
d$PE2
D$PE3
D$pE3
d$pE3
D$PE3
d$pE3
D$PE3
D$pE3
d$PE3
D$PE3
D$pE3
D$PE3
d$PE3
D$pE3
D$PE3
D$PfD
D$PGemm
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$pH;
D$PH;
D$PH;}(t
D$pH;F
D$PH;Fxt
D$pH;l$`|
D$PH;V(t
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$PH+
D$pH+
D$pH+D$hH
D$PH+D$HH
D$PH9
D$PH9p s
d$PHc
D$PHc
D$pHc
d$PHc
D$pHcH
D$pHcX
D$pI;
D$PI;
D$pI;
D$PI;
D$pI;
d$PI;
D$PI;
d$PI;
D$PI;
D$PI;W
D$PI+
D$pI+
D$PI+
D$pI+
D$PI+
D$pIc
D$PIc
D$PL;
D$pL;
D$PL;
D$pL;
D$PL;
D$pL;
D$PL;
D$PL;E
D$PL;t
D$PL+
D$pL+
D$PLc
D$pLc
D$PLc
D$pLc
D$PLc
D$PM;
D$pM;
d$pM;
d$PM;
D$pM;
d$pM+
D$PNONE
D$PNONED
D$QE3
D$qL;l$x
D$RE3
D$RH9D$@u
D$t;D$pu
D$t8Bt
D$tHcD$t
D$tLc)A
D$u8Bu
D$X;D$`u
D$x;E
D$x@8|$`t
D$x@8~0t
D$X@8x)t
D$XA;
D$XD8`
D$xD8`
d$XD9a8
D$XE2
D$XE3
D$xE3
D$XE3
D$xE3
D$XE3
d$XE9|$8
d$XE9f8~VA
D$XfA
D$xfD
D$XfH
D$xH;
D$XH;
D$XH;D$`
D$xH;E
D$XH;P
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+
D$xH+
D$XH+D$PH
D$xH+D$pH
D$XH9
D$XH9]
D$XH9Q
D$XH9x }
d$XHc
D$XHc
d$XHc
D$XI;
D$xI;
d$XI;
D$XI;
d$XI;
D$xI;
d$XI;
D$xI;
d$XI;}
D$xI+
D$XI+
D$xI9
D$XL;
D$XL;`
D$XL+
D$xL+D$pI
D$xL9~ 
D$xLc
D$XtXI;
d(br\b^
D,$< 
D,0< 
d.,N.P\TNV>XNZ6\&^B`
d.f,R(T
D.FX>
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\controlflow\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\controlflow\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\generator\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\generator\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\logical\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\logical\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\math\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\math\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\nn\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\nn\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\object_detection\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\object_detection\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\optional\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\quantization\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\quantization\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\reduction\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\reduction\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\rnn\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\rnn\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\sequence\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\tensor\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\tensor\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\traditionalml\defs.cc
D:\a\_work\1\s\engine\lotus\cmake\external\onnx\onnx\defs\traditionalml\old.cc
D:\a\_work\1\s\engine\lotus\cmake\external\protobuf\src\google/protobuf/parse_context.h
D:\a\_work\1\s\engine\lotus\cmake\external\protobuf\src\google/protobuf/repeated_field.h
D:\a\_work\1\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\arena.cc
D:\a\_work\1\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream.cc
D:\a\_work\1\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl.cc
D:\a\_work\1\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\io\zero_copy_stream_impl_lite.cc
D:\a\_work\1\s\engine\lotus\cmake\external\protobuf\src\google\protobuf\message_lite.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2/walker-inl.h
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\bitstate.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\compile.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\dfa.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\nfa.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\onepass.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\parse.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\prog.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\re2.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\regexp.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\simplify.cc
D:\a\_work\1\s\engine\lotus\cmake\external\re2\re2\tostring.cc
D:\a\_work\1\s\engine\lotus\cmake\external\wil\include\wil/wrl.h
D:\a\_work\1\s\engine\lotus\cmake\external\wil\include\wil\resource.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/common/const_pointer_container.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/common/logging/logging.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/framework/data_types.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/framework/data_types_internal.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/framework/op_kernel_context.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/framework/ort_value.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/framework/tensor.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/graph/graph.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/optimizer/graph_transformer.h
D:\a\_work\1\s\engine\lotus\include\onnxruntime\core/platform/EigenNonBlockingThreadPool.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops/cpu/activations.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops/cpu/crop_and_resize.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\bahdanau_attention.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\deep_cpu_attn_lstm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\attnlstm\deep_cpu_attn_lstm.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\bert\attention.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\bert\attention_base.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\bert\attention_cpu_base.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\bert\bias_gelu.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\bert\bifurcation_detector.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\bert\embed_layer_norm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\bert\ngram_repeat_block.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\bert\qembed_layer_norm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\cdist.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\cpu_contrib_kernels.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\crop.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\element_wise_ops.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\expand_dims.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\fused_conv.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\fused_gemm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\grid_sample.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\image_scaler.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\layer_norm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\math\sparse_dense_matmul.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\matmul_integer16.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\maxpool_with_mask.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\murmur_hash3.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\nchwc_ops.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\nchwc_ops.h
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\qlinear_binary_op.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\qlinear_concat.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\qlinear_global_average_pool.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\qlinear_lookup_table.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\qlinear_pool.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\quantization\attention_quant.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\quantization\dynamic_quantize_lstm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\quantization\dynamic_quantize_matmul.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\quantization\nhwc_max_pool.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\quantization\quant_gemm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\skip_layer_norm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\tokenizer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\contrib_ops\cpu\word_conv_embedding.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core/common/safeint.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/bfc_arena.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/execution_frame.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/execution_providers.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/feeds_fetches_manager.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/func_kernel.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/mem_pattern_planner.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/mldata_type_utils.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/node_index_info.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/op_kernel_context_internal.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/ort_value_tensor_slicer.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/sequential_execution_plan.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/tensorprotoutils.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/framework/TensorSeq.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/graph/function_impl.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/graph/model_load_utils.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/optimizer/attention_fusion_helper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/optimizer/initializer.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/optimizer/selectors_actions/helpers.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/platform/path_lib.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/common.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/activation/activations.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/controlflow/scan_utils.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/element_wise_ranged_transform.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/generator/constant_of_shape_base.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/generator/random.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/math/clip.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/math/element_wise_ops.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/math/gemm_helper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/math/matmul_helper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/ml/cast_map.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/ml/category_mapper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/ml/dictvectorizer.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/ml/feature_vectorizer.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/ml/label_encoder.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/ml/ml_common.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/ml/normalizer.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/batch_norm.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/conv_attributes.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/conv_transpose_attributes.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/dropout_op.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/flatten.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/instance_norm.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/lp_norm.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/lrn.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/pool_attributes.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/pool_base.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/roi_pool.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/shrink.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/nn/unpool.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/reduction/reduction_ops.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/deep_cpu_gru.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/rnn.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/rnn/rnn_helpers.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/copy.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/identity_op.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/mean_variance_normalization.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/reshape.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/reverse_sequence.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/slice.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/space_depth_ops.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/split.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/squeeze.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/transpose.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/unsqueeze.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/upsample.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/cpu/tensor/utils.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/dml/OperatorAuthorHelper/MLOperatorAuthorHelper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/dml/OperatorAuthorHelper/OperatorHelper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/providers/dml/OperatorAuthorHelper/SchemaInferenceOverrider.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core/session/inference_session.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\common\helper.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\common\logging\logging.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\common\path.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\common\profiler.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\common\status.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\common\threadpool.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\flatbuffers\flatbuffers_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\allocation_planner.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\allocator.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\allocatormgr.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\bfc_arena.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\config_options.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\data_transfer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\data_transfer_manager.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\data_types.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\endian_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\ex_lib_loader.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\execution_frame.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\execution_provider.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\fallback_cpu_capability.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\feeds_fetches_manager.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\fuse_nodes_funcs.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\graph_partitioner.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\kernel_def_builder.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\kernel_registry.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\mldata_type_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\node_index_info.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\op_kernel.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\op_kernel_info.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\op_node_proto_helper.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\ort_value_tensor_slicer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\parallel_executor.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\prepacked_weights.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\prepacked_weights_container.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\sequential_executor.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\session_state.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\session_state_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\sparse_tensor.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\sparse_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\tensor.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\tensor_shape.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\tensor_type_and_shape.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\tensorprotoutils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\framework\utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\contrib_ops\contrib_defs.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\contrib_ops\nchwc_schema_defs.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\contrib_ops\nhwc_schema_defs.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\contrib_ops\quantization_defs.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\dml_ops\dml_defs.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\function.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\graph.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\graph_flatbuffers_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\graph_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\graph_viewer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\model.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\graph\schema_registry.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\attention_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\bias_dropout_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\bias_gelu_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\bias_softmax_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\common_subexpression_elimination.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\constant_folding.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\conv_activation_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\conv_add_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\conv_bn_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\conv_mul_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\dynamic_quantize_matmul_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\embed_layer_norm_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\fast_gelu_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\free_dim_override_transformer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\gelu_approximation.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\gelu_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\gemm_activation_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\gemm_sum_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\graph_transformer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\graph_transformer_mgr.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\graph_transformer_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\initializer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\insert_cast_transformer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\layer_norm_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\matmul_add_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\matmul_integer_to_float.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\matmul_scale_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\matmul_transpose_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\nchwc_transformer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\nhwc_transformer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\optimizer_execution_frame.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\qdq_transformer\qdq_propagation.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\qdq_transformer\qdq_s8_to_u8.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\relu_clip_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\reshape_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\rule_based_graph_transformer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\selectors_actions\actions.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\selectors_actions\helpers.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\selectors_actions\selector_action_transformer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\skip_layer_norm_fusion.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\transformer_memcpy.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\transpose_optimizer\api_impl.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\transpose_optimizer\ort_transpose_optimizer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\optimizer\unsqueeze_elimination.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\platform\windows\env.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\activation\activations.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\if.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\loop.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_8.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_9.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\controlflow\scan_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\cpu_execution_provider.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\generator\constant_of_shape.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\generator\random.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\clip.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\cumsum.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\det.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\einsum.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\einsum.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\einsum_utils\einsum_auxiliary_ops.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\einsum_utils\einsum_compute_preprocessor.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\einsum_utils\einsum_typed_compute_processor.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\element_wise_ops.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\gemm_base.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\gemm_helper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\hardmax.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\matmul.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\matmul_integer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\quantize_linear_matmul.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\softmax.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\math\top_k.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\cast_map.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\feature_vectorizer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\imputer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\linearclassifier.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\linearregressor.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\ml_common.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\onehotencoder.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\scaler.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmclassifier.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmclassifier.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\svmregressor.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\tree_ensemble_aggregator.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\tree_ensemble_common.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\ml\zipmap.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\conv.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\conv_integer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\conv_transpose.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\instance_norm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\lrn.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\pool.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\qlinearconv.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\roi_pool.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\string_normalizer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\tfidfvectorizer.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\nn\Unpool.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\non_max_suppression.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\object_detection\roialign.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\optional\optional_ops.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\optional\optional_ops.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\reduction\reduction_ops.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\deep_cpu_gru.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\deep_cpu_lstm.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\lstm_base.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\lstm_base.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\rnn.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\rnn\rnn_helpers.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\sequence\concat_from_sequence.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\sequence\sequence_ops.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\cast_op.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\compress.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\concat.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\concatbase.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\dynamicquantizelinear.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\gather.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\gather_elements.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\gather_elements.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\gather_nd.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\gatherbase.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\isinf.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\nonzero_op.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\onehot.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\pad.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\padbase.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\quantize_linear.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\reshape_helper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\reverse_sequence.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\scatter.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\scatter_nd.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\slice.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\space_depth_ops.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\split.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\tile.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\transpose.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\trilu.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\trilu.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\unsqueeze.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\cpu\tensor\upsample.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\dml_provider_factory.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\AbiCustomRegistry.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\BucketizedBufferAllocator.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\CommandAllocatorRing.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\DescriptorPool.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\DmlCommandRecorder.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\DmlCommon.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\ExecutionContext.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\ExecutionProvider.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\External/DirectMLHelpers/ApiHelpers.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\External/DirectMLHelpers/ApiTraits.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\External/DirectMLHelpers/GeneratedSchemaHelpers.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\External/DirectMLHelpers/SchemaHelpers.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\FusedGraphKernel.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\GpuEvent.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\GraphDescBuilder.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\GraphKernelHelper.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\GraphPartitioner.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\GraphTransformer.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\MLOperatorAuthorImpl.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\MLOperatorAuthorImpl.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperator.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorActivation.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorAffine.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorBatchNormalization.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorCast.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorConcat.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorConstantOfShape.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorConvInteger.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorConvolution.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorCopy.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorCrop.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorCumSum.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorDepthToSpace.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorDynamicQuantizeLinear.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorEinSum.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorElementWise.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorExpand.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorEyeLike.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorGather.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorGemm.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorInstanceNormalization.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorLocalResponseNormalization.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorLpNormalization.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorMatMul.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorMatMulInteger.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorMaxUnpool.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorMeanVarianceNormalization.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorMemcpy.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorNeg.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorOneHot.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorPadding.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorPooling.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorQLinearAdd.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorQLinearConv.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorQLinearMatMul.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorRange.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorRecurrentNeuralNetwork.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorReduce.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorResize.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorReverseSequence.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorRoiAlign.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorRoiPooling.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorScatter.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorSlice.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorSpaceToDepth.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorSplit.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorTile.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorTopk.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorTranspose.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\DmlOperatorValueScale2D.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\OperatorRegistration.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\Operators\OperatorUtility.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\PooledUploadHeap.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\ReadbackHeap.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\TensorDesc.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\GraphTransformers\GraphTransformerHelpers.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\OperatorAuthorHelper\MLOperatorAuthorHelper.h
D:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\OperatorAuthorHelper\OperatorHelper.cpp
D:\a\_work\1\s\engine\lotus\onnxruntime\core\session\custom_ops.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\session\environment.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\session\inference_session.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\session\inference_session_utils.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\session\IOBinding.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\session\onnxruntime_c_api.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\session\ort_env.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\session\provider_bridge_ort.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\util\math_cpu.cc
D:\a\_work\1\s\engine\lotus\onnxruntime\core\util\thread_utils.cc
D:\a\_work\1\s\engine\lotus\winml\adapter\winml_adapter_dml.cpp
D:\a\_work\1\s\engine\lotus\winml\adapter\winml_adapter_session.cpp
D:HHJ*L8N
D;|$ u
D;|$H|
D;|$PL
D;0|`I
D;B(|
D;C(|
D;C8|
D;e |
D;H,tKH
D;I$}
D;J t
D;kHs
D;l$0uWH
D;l$PH
D;m(|
D;mH|
D;Q0t
D;r(u
D;S$|
D;s@s-H
D;t$@
D;t$pu
D;X uDI
D;y |
d@>B$
D\$8H
D\$hH
D\$PH
D\$pH
D\$XH
D\BtPdJd
D|$XH
D|$xH
D|$XH
D|$xH
D+L$PA
D+t$0A
D1X0I
D4h< t <$
D8#tZL
D8,>u
D8,8~
D8,8u
D8@4tfH
D8{=H
D8{5H
D8{5t
D8{6tgLcC$M
D8}ptrI
D8<*u
D8<.u
D8<:u
D8<>u
D8<1u
D83tYL
D840u
D848u
D849u
D8A@t
D8A0t
D8A0tFD8A1t+
D8A1u!
D8APtfH
D8APtgH
D8D$0
D8D$8tzH
D8d$ptxI
D8d$tt1
D8e@t.
D8eptvI
D8F,tBH
D8fPt
D8G$A
D8H }
D8h8u
D8K|t+L9
D8l$@
D8l$@A
D8L$0uP
D8l$4uSH
D8l$AA
D8l$p
D8l$x
D8nDt
D8nPt
D8nPtmH
D8o t
D8P5u
D8Q(uRH
D8q8t
D8qhu
D8Qqt;HcB
D8Qqt@
D8Qqt=
D8Qqt>
D8Qqt5HcB
D8Qqt7HcB
D8Qqt8HcB
D8r8t*
D8r8t.
D8RHu
D8RIt
D8RPtv
D8sPt_H
D8SQtUL
D8t$0
D8T$XL
D8v8t
D8v8u
D8vPt
D8wDt
D8yhu
D8Yqt(HcB
D8Yqt)HcB
D8Yqt*HcB
D8Yqt,HcB
D8ZHu
D9 uHH
D9;v 
D9;v!
D9?uMH
D9?uOH
D9@(u
D9`(t
D9`(t8H
D9`(t9H
D9`(u
D9`(u 
D9{(t
D9{(t:H
D9{(t8H
D9{0u<L
D9{8t9H
D9|$`
D9}(u
D9}`t
D9}xu
D9~(t8H
D9>v'
D9>v%
D95A:'
D95M$'
D95O)'
D95T*'
D9A(t
D9a(u
D9A(u
D9a(u
D9A(u
D9a(u
D9b(u
D9c(~
D9c(t
D9c(t8H
D9C8~73
D9e`t'
D9e8u
D9eH~eL
D9ehu
D9f(t
D9F(u
D9f(u,H
D9f(ufH
D9g(t
D9g(t8H
D9h u
D9H$|
D9h(t
D9h(t8H
D9h(t9H
D9h(u
D9HHt
D9hht
D9HHt1
D9I$|
D9I(t
D9i(u
D9k ~%L
D9k(t
D9k(t?H
D9K(t=H
D9k(t8H
D9k(t9H
D9k(u
D9kh~%L
D9kP~%L
D9L$`}kH
D9l$0
D9l$8
D9L$P}
D9m ~eA
D9m(~\I
D9n(t
D9o t
D9o(u
D9p(t
D9p(t8H
D9p(t9H
D9p(u
D9P(u
D9p(u
D9P0t
D9Q |
D9q ~!H
D9q(u
D9R(u%I
D9s(t
D9s(t:H
D9s(u
D9sp~!H
D9sP~!H
D9v ~/H
D9v(~
D9v@~
D9VLvYA+
D9vp~
D9vp~vA
D9vX~
D9w ~/H
D9w(t
D9x |
D9x }
D9x(A
D9x(t
D9x(t8H
D9x(t9H
D9x(u
D9x(u>H
D9x,I
D9X,tMH
D9X0H
D9Y$|
D9y(u
D9Y0t
D9z(u
Data for input  
Data of TensorProto ( tensor name: 
data overflow
Data size mismatch. Tensor: 
data tensor must have rank >= 1
data type 
Data type for starts and ends inputs' is not supported in this build. Got 
data type is different from updates type
data type is not supported
Data type mismatch
Data type of the input tensor MUST be same as that of the input sequence. Sequence data type (
Data types of the inputs must match for MatMul
data_0
data_1.Shape() == shape
DATA_BATCH
data_n.Shape() == shape
data_rank * 2 == pads.size()
data_rank > 0
data_scale
data_transfer registered is nullptr.
data_type
data_zero_point
DataTypeUtils::FromDataTypeString - Received invalid data type string 
DbQ}X
dbU}M
DBxI;Bx
DC(H;C(
DC8I;C8t
DCR (default) for depth-column-row order re-arrangement. Use CRD for column-row-depth order.
DD$PH
ddaS7
DeadState in RunStateOnByte
DebugBreak
DecodePointer
DecoderAttention
decomposed_QLinearSigmoid_DequantizeLinear_
decomposed_QLinearSigmoid_input_
decomposed_QLinearSigmoid_output_
decomposed_QLinearSigmoid_QuantizeLinear_
decomposed_QLinearSigmoid_Sigmoid_
default 1; Pooled output Y's height.
default 1; Pooled output Y's width.
Default logger already set. 
default_float
default_int64
default_logger_id must be provided if instance_type is InstanceType::Default
default_string
Defines behaviour if 'axes' is empty. Default behaviour with 'false' is to reduce all axes. When axes is empty and this attribute is set to true, input tensor will not be reduced,and the output tensor would be equivalent to input tensor.
Defines how to aggregate leaf values within a target. <br>One of 'AVERAGE,' 'SUM,' 'MIN,' 'MAX.'
DeleteCriticalSection
DeleteFile() failed - path: 
DeleteFileW
delta
delta in Range operator can not be zero!
delta in Range operator should be scalar like tensor, yet got shape:
Denote x_resized as the coordinate of axis x in the resized tensor, x_original as the coordinate of axis x in the original tensor, length_original as the length of the original tensor in axis x, length_resized as the length of the resized tensor in axis x, roi_x = (start_x, end_x) of the axis x in input "roi", scale = length_resized / length_original, <br/>
DENSE
dense shape must 2-D. Got: 
depth
Depth is negative.
DepthToSpace
DepthToSpace op: only 'DCR' and 'CRD' modes are supported
DepthToSpace requires input depth to be a multiple of (block_size * blok_size)
DequantizeLinear
DequantizeLinear with type int32 should have no zero point or all zero points should be 0
deque<T> too long
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size
Describes the axis of the inputs when coerced to 2D; defaults to one because the 0th axis most likely describes the batch_size. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Deseret
Deserialize tensor 
DeserializeTensorProto() takes either pre-allocated buffer or an allocator!
destination address required
Destination must have a CPU allocator set
Destination should be empty
detect_negative
detect_positive
Devanagari
Deviation = Sub (XU, Mean2D)
device or resource busy
Device:[
DeviceType:
DF H;F t!L
DFA out of memory: 
DFF JNL P
dffJt
DG`I;G`tkM
DGxH;Gx
DGxH;Gxt
DHp(Dh:HD(pf:HD(p
DHp(DX:bDHp(D*:(rp:tDHp(DP:
DictVectorizer
Did not find an arena based allocator registered for device-id 
Did not find session options in the model file to be used while running the model
Dilation not supported for AutoPadType::SAME_UPPER or AutoPadType::SAME_LOWER.
Dilation value along each spatial axis of filter.
Dilation value along each spatial axis of filter. If not present, the dilation defaults to 1 along each spatial axis.
dilation value along each spatial axis of the filter.
dilation value along each spatial axis of the filter. If not present, the dilation defaults is 1 along each spatial axis.
dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each axis.
dilation value along each spatial axis of the filter. If not present, the dilation defaults to 1 along each spatial axis.
dilations
Dilations
Dilations dimensions should match kernel shape
dilations.size() == kernel_shape.size()
dim_iter == rank
dim_param value with no name. Invalid ORT format model.
dim_size > 0
dim0_offset < dim0_size
dimension <= num_dims
Dimension could not be inferred: incompatible shapes
dimension for each axis in the list of axes, it uses this information to
Dimension mismatch in unification between 
Dimension of input 
Dimension on which to do the sort.
Dimension on which to do the sort. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(input).
Dimension value inferred (
dimension. If the value passed to start or end is larger than the `n` (the
Dimension: 
DimensionCount
dims.size() == extents.size() && dims.size() >= steps.size()
dims.size() == extents_.size()
dims.size() == starts.size()
dims.size() == starts.size() && dims.size() == extents_.size() && dims.size() >= steps.size()
dims.size() == steps.size()
dims.size()=
dims[d_i] < d_max
dimstart <= dimend && dimend <= values_.size()
direction
Direction
Direction of moving bits. It can be either "RIGHT" (for right shift) or "LEFT" (for left shift).
directions
directions.size() == num_entries
DirectML.dll
directory not empty
discarded
Distribution
DistributionEnqueue
Div and Shape does not have edge
Div and Shape1 does not have edge
div_inputs.size() == 2
Dives_Akuru
Divide by zero
DivMulFusion
dj(lN
DML CPU
Dml::ComputationCapacityFromPartition
Dml::ExecutionProviderImpl::CopyTensors
Dml::GraphTransformer::ApplyImpl
DML_OPERATOR_ACTIVATION_CELU
DML_OPERATOR_ACTIVATION_ELU
DML_OPERATOR_ACTIVATION_HARD_SIGMOID
DML_OPERATOR_ACTIVATION_HARDMAX
DML_OPERATOR_ACTIVATION_IDENTITY
DML_OPERATOR_ACTIVATION_LEAKY_RELU
DML_OPERATOR_ACTIVATION_LINEAR
DML_OPERATOR_ACTIVATION_LOG_SOFTMAX
DML_OPERATOR_ACTIVATION_PARAMETERIZED_RELU
DML_OPERATOR_ACTIVATION_PARAMETRIC_SOFTPLUS
DML_OPERATOR_ACTIVATION_RELU
DML_OPERATOR_ACTIVATION_RELU_GRAD
DML_OPERATOR_ACTIVATION_SCALED_ELU
DML_OPERATOR_ACTIVATION_SCALED_TANH
DML_OPERATOR_ACTIVATION_SHRINK
DML_OPERATOR_ACTIVATION_SIGMOID
DML_OPERATOR_ACTIVATION_SOFTMAX
DML_OPERATOR_ACTIVATION_SOFTPLUS
DML_OPERATOR_ACTIVATION_SOFTSIGN
DML_OPERATOR_ACTIVATION_TANH
DML_OPERATOR_ACTIVATION_THRESHOLDED_RELU
DML_OPERATOR_ADAM_OPTIMIZER
DML_OPERATOR_ARGMAX
DML_OPERATOR_ARGMIN
DML_OPERATOR_AVERAGE_POOLING
DML_OPERATOR_AVERAGE_POOLING_GRAD
DML_OPERATOR_BATCH_NORMALIZATION
DML_OPERATOR_BATCH_NORMALIZATION_GRAD
DML_OPERATOR_BATCH_NORMALIZATION_TRAINING
DML_OPERATOR_BATCH_NORMALIZATION_TRAINING_GRAD
DML_OPERATOR_CAST
DML_OPERATOR_CONVOLUTION
DML_OPERATOR_CONVOLUTION_INTEGER
DML_OPERATOR_CUMULATIVE_PRODUCT
DML_OPERATOR_CUMULATIVE_SUMMATION
DML_OPERATOR_DEPTH_TO_SPACE
DML_OPERATOR_DEPTH_TO_SPACE1
DML_OPERATOR_DIAGONAL_MATRIX
DML_OPERATOR_DYNAMIC_QUANTIZE_LINEAR
DML_OPERATOR_ELEMENT_WISE_ABS
DML_OPERATOR_ELEMENT_WISE_ACOS
DML_OPERATOR_ELEMENT_WISE_ACOSH
DML_OPERATOR_ELEMENT_WISE_ADD
DML_OPERATOR_ELEMENT_WISE_ADD1
DML_OPERATOR_ELEMENT_WISE_ASIN
DML_OPERATOR_ELEMENT_WISE_ASINH
DML_OPERATOR_ELEMENT_WISE_ATAN
DML_OPERATOR_ELEMENT_WISE_ATAN_YX
DML_OPERATOR_ELEMENT_WISE_ATANH
DML_OPERATOR_ELEMENT_WISE_BIT_AND
DML_OPERATOR_ELEMENT_WISE_BIT_COUNT
DML_OPERATOR_ELEMENT_WISE_BIT_NOT
DML_OPERATOR_ELEMENT_WISE_BIT_OR
DML_OPERATOR_ELEMENT_WISE_BIT_SHIFT_LEFT
DML_OPERATOR_ELEMENT_WISE_BIT_SHIFT_RIGHT
DML_OPERATOR_ELEMENT_WISE_BIT_XOR
DML_OPERATOR_ELEMENT_WISE_CEIL
DML_OPERATOR_ELEMENT_WISE_CLIP
DML_OPERATOR_ELEMENT_WISE_CLIP_GRAD
DML_OPERATOR_ELEMENT_WISE_CLIP_GRAD1
DML_OPERATOR_ELEMENT_WISE_CLIP1
DML_OPERATOR_ELEMENT_WISE_CONSTANT_POW
DML_OPERATOR_ELEMENT_WISE_COS
DML_OPERATOR_ELEMENT_WISE_COSH
DML_OPERATOR_ELEMENT_WISE_DEQUANTIZE_LINEAR
DML_OPERATOR_ELEMENT_WISE_DIFFERENCE_SQUARE
DML_OPERATOR_ELEMENT_WISE_DIVIDE
DML_OPERATOR_ELEMENT_WISE_ERF
DML_OPERATOR_ELEMENT_WISE_EXP
DML_OPERATOR_ELEMENT_WISE_FLOOR
DML_OPERATOR_ELEMENT_WISE_IDENTITY
DML_OPERATOR_ELEMENT_WISE_IF
DML_OPERATOR_ELEMENT_WISE_IS_INFINITY
DML_OPERATOR_ELEMENT_WISE_IS_NAN
DML_OPERATOR_ELEMENT_WISE_LOG
DML_OPERATOR_ELEMENT_WISE_LOGICAL_AND
DML_OPERATOR_ELEMENT_WISE_LOGICAL_EQUALS
DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN
DML_OPERATOR_ELEMENT_WISE_LOGICAL_GREATER_THAN_OR_EQUAL
DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN
DML_OPERATOR_ELEMENT_WISE_LOGICAL_LESS_THAN_OR_EQUAL
DML_OPERATOR_ELEMENT_WISE_LOGICAL_NOT
DML_OPERATOR_ELEMENT_WISE_LOGICAL_OR
DML_OPERATOR_ELEMENT_WISE_LOGICAL_XOR
DML_OPERATOR_ELEMENT_WISE_MAX
DML_OPERATOR_ELEMENT_WISE_MEAN
DML_OPERATOR_ELEMENT_WISE_MIN
DML_OPERATOR_ELEMENT_WISE_MODULUS_FLOOR
DML_OPERATOR_ELEMENT_WISE_MODULUS_TRUNCATE
DML_OPERATOR_ELEMENT_WISE_MULTIPLY
DML_OPERATOR_ELEMENT_WISE_NEGATE
DML_OPERATOR_ELEMENT_WISE_POW
DML_OPERATOR_ELEMENT_WISE_QUANTIZE_LINEAR
DML_OPERATOR_ELEMENT_WISE_QUANTIZED_LINEAR_ADD
DML_OPERATOR_ELEMENT_WISE_RECIP
DML_OPERATOR_ELEMENT_WISE_ROUND
DML_OPERATOR_ELEMENT_WISE_SIGN
DML_OPERATOR_ELEMENT_WISE_SIN
DML_OPERATOR_ELEMENT_WISE_SINH
DML_OPERATOR_ELEMENT_WISE_SQRT
DML_OPERATOR_ELEMENT_WISE_SUBTRACT
DML_OPERATOR_ELEMENT_WISE_TAN
DML_OPERATOR_ELEMENT_WISE_TANH
DML_OPERATOR_ELEMENT_WISE_THRESHOLD
DML_OPERATOR_FILL_VALUE_CONSTANT
DML_OPERATOR_FILL_VALUE_SEQUENCE
DML_OPERATOR_GATHER
DML_OPERATOR_GATHER_ELEMENTS
DML_OPERATOR_GATHER_ND
DML_OPERATOR_GATHER_ND1
DML_OPERATOR_GEMM
DML_OPERATOR_GRU
DML_OPERATOR_JOIN
DML_OPERATOR_LOCAL_RESPONSE_NORMALIZATION
DML_OPERATOR_LOCAL_RESPONSE_NORMALIZATION_GRAD
DML_OPERATOR_LP_NORMALIZATION
DML_OPERATOR_LP_POOLING
DML_OPERATOR_LSTM
DML_OPERATOR_MATRIX_MULTIPLY_INTEGER
DML_OPERATOR_MAX_POOLING
DML_OPERATOR_MAX_POOLING_GRAD
DML_OPERATOR_MAX_POOLING1
DML_OPERATOR_MAX_POOLING2
DML_OPERATOR_MAX_UNPOOLING
DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION
DML_OPERATOR_MEAN_VARIANCE_NORMALIZATION1
DML_OPERATOR_NONZERO_COORDINATES
DML_OPERATOR_ONE_HOT
DML_OPERATOR_PADDING
DML_OPERATOR_PADDING1
DML_OPERATOR_QUANTIZED_LINEAR_CONVOLUTION
DML_OPERATOR_QUANTIZED_LINEAR_MATRIX_MULTIPLY
DML_OPERATOR_RANDOM_GENERATOR
DML_OPERATOR_REDUCE
DML_OPERATOR_RESAMPLE
DML_OPERATOR_RESAMPLE_GRAD
DML_OPERATOR_RESAMPLE1
DML_OPERATOR_REVERSE_SUBSEQUENCES
DML_OPERATOR_RNN
DML_OPERATOR_ROI_ALIGN
DML_OPERATOR_ROI_ALIGN_GRAD
DML_OPERATOR_ROI_ALIGN1
DML_OPERATOR_ROI_POOLING
DML_OPERATOR_SCATTER
DML_OPERATOR_SCATTER_ND
DML_OPERATOR_SLICE
DML_OPERATOR_SLICE_GRAD
DML_OPERATOR_SLICE1
DML_OPERATOR_SPACE_TO_DEPTH
DML_OPERATOR_SPACE_TO_DEPTH1
DML_OPERATOR_SPLIT
DML_OPERATOR_TILE
DML_OPERATOR_TOP_K
DML_OPERATOR_TOP_K1
DML_OPERATOR_UPSAMPLE_2D
DML_OPERATOR_VALUE_SCALE_2D
DMLCreateDevice1
DmlExecutionProvider
DmlFusedNode_
DmlFusedNodeDomain
DnnlExecutionProvider
DnP.R,@
DnP.R,@(DPJ.L
DoCoalesce failed: r1->op() is 
DoCoalesce failed: r2->op() is 
does not have the graph for key 
Dogra
Domain already set in registry
domain_version != -1
domainToVersionMap
Done saving initialized tensors
Done saving OrtValue mappings.
double
double_data
DOXH;
drop_states
Dropout
DRPI;RP
DSHI9SHt
dst.DataType() == src.DataType()
dst_implicit_input_idx < (int)node->ImplicitInputDefs().size()
dst_strides.size() == src_strides.size() && src_strides.size() == copy_shape.size() && !copy_shape.empty()
Dt$0H
Dt$HD;
dtype
dtype_ != nullptr
dtype_attribute->second.has_i()
dup_replacements.find(&arg) == dup_replacements.end()
Duplicate constant node sparse initializer name: '
Duplicate initializer (dense or ConstantNode): '
Duplicate initializer (dense, sparse or ConstantNode): '
Duplicate ngram detected, size: 
Duplicate of FusedMatMul. Going forward FusedMatMul should be used. This OP will be supported for backward compatibility.
Duplicate sparse_tensor_initializer: '
Duplicate stopwords not allowed
Duplicate type constraint name
duplicated allocator
duplicated allocator: 
duplicated ort_value index:
Duployan
dxgi.dll
DynamicQuantizeLinear
DynamicQuantizeLSTM
DynamicQuantizeLSTM : 
DynamicQuantizeMatMul
DynamicQuantizeMatMulFusion
DynamicSlice
DYXbO8
E H;]
E H;E(t
E H+E
E I+E
E I9E
E IcE
E LcF
E M+E
E$IcM$
E$IcM$A
e%6E)
E(A9D$(
E(H+E H
E(H9E u L
e)tMH
E/L+E'I
E/ueH
E;|$8
E;<$}
E;A(|
E;E(D
E;H$}
E;J$|
E;l$8
E;P |
E;t$(
E;Y$}
E@!D$@
E@A8Z
E@H;G
E@H+E8H
E@perm@
e_2YR
E_Xsquared
E`!D$0
E`!D$p
E`H!D$PL
E`H!D$XL
E`H;Eht
E`H+EXH
E`H9E0
E`H9EXu!H
e}>]U
e0A_A^A]_^[]
E0D8F t
E0H+E(H
E0HcH
E0Lc`
E0NONED
E0perm
E8,>u
E8,7u
E8,8u
E8,9u
E8/tpH
E8`8t
E8<0u
E8<6u
E8<8u
E88MHH
E8A(u.M
E8f,t
E8f1u
E8fPt
E8H;EH
E8H;M
E8l$8
E8Mjt
E8o8I
E8o8L
E8uPt
E8UtH
E8UtL
E8wHu
E8y u
E9`(u
E9`(uOD9't7H
E9}(t
E9<$t H
E9<$u
E9A(~
E9A(u
E9f(u
E9g(u
E9i(~#I
E9l$(
E9n(u
E9P(u
E9t$(t;I
E9t$8
Each element of the sequence should be either tensor or map.
EB0D9h(
EB0D9p(
edge_it->GetDstArgIndex() == 0 && edge_it->GetSrcArgIndex() == 0 && edge_it->GetNode().Index() == down_node.Index()
Ef&Ch
EgH;SHt
Egyptian_Hieroglyphs
Eh!D$`
eH+|$0H
E'H+E
EH09q(
EH09Y(t
EH0D9Q(t+H
E'H9E
EHH!E(H
EhH;Ept
EHH+E@H
EHL+E@I
EhmeanD
Ehttp://crl.microsoft.com/pki/crl/products/MicRooCerAut_2010-06-23.crl0Z
Ehttp://www.microsoft.com/pkiops/certs/MicWinProPCA2011_2011-10-19.crt0
Einsum
Einsum expression string.
Einsum op: An implementation for the input type 
Einsum op: Could not copy the intermediate output's buffer into the op's output buffer. Error: 
Einsum op: Exception during MatMul operation: 
Einsum op: Input dimensions must be equal along an axis to be reduced across all inputs
Einsum op: Input shapes do not align
Einsum op: The candidate output cannot be reshaped into the op's output
Einsum op: The candidate output does not match the actual output's shape
Einsum op: There must be atleast one input
Einsum op: Transpose failed: 
Einsum op: Unsupported data type for Diagonal 
Einsum operands could not be broadcast together. Please check input shapes/equation provided.Input shape of operand 
Einsum subscripts does not contain enough subscript labels and there is no ellipsis for input 
Einsum subscripts string contains too many subscript labels when compared to the rank of the input
Einsum subscripts string contains too many subscript labels when compared to the rank of the input 
Either both scale and offset can be of feature size (
Either one of the separators OR tokenexp attributes required but none is set
Either scales or sizes MUST be provided as input.
Either the key tensor or the value tensor has NumDimensions > 1
EJx(k
Elbasan
elem_proto != nullptr
elem_type
elem_type_ != nullptr
element index is out of bounds
Element type of input 
Element type of input was unknown
Element type of inputs are expected to be the same.
Element type of optional input 
Element type of sequence input 
Element type of tensor or sparse tensor input was unknown
Element_size of: 
elements, but feeds has 
EliminateDropout
EliminateIdentity
EliminateSlice
Ellipsis must indicate a fixed number of dimensions across all inputs
Ellipsis represents incompatible dimensions.
else_branch
Elu_Result
Elymaic
embedding_size
embedding_sum
EmbedLayerNormalization
EmbedLayerNormFusion
Empty dimensions for input tensor
Empty graph proto from deserialization of ORT format model
Empty input dimensions.
Empty scale in attributes
Empty stopwords not allowed
Empty value of imputed values.
Enable broadcasting
enable_profiling
enable_profiling option in the model file must be an integer
enabled_
EnableOrtCustomOps: Custom operators in onnxruntime-extensions are not enabled
EncodePointer
Encountered unknown exception in Initialize()
Encountered unknown exception in Load()
Encountered unknown exception in Run()
end >= starts_.back()
end of a dimension with unknown size, it is recommended to pass in `INT_MAX`.
end of input
end_idx >= start_idx && end_idx <= total_items
Ending indices (exclusive) of corresponding axis in axes`
EndPadding
endpos: 
Ends must be a 1-D array
Engine failed to create a model!
ENGINE_ERROR
EnterCriticalSection
entiu
entry != initialized_tensors_to_allocate.end() && entry->second->data_type() != ONNX_NAMESPACE::TensorProto_DataType_STRING
entry != kernel_create_info_map.cend()
entry != kernel_create_info_map_.cend()
entry != node_to_subgraph_ss.second.cend()
entry != nullptr
entry != regions_.end()
Entry exists in node 
entry.program_counter.HasValidEntries()
en-US
Env is null
env_ptr == p_instance_
Environment dependent string that denotes the locale according to which output strings needs to be upper/lowercased.Default en_US or platform specific equivalent as decided by the implementation.
Eo9F@
EP!D$@
Ep@8uhJ
EP_FAIL
EP0D9R(t2H
epA^_^[]
epE8|$
EPH!D$hL
EpH;}
EpH;C
EPH;E`
EPH;u
EPH;U0t
Epsilon
epsilon
epsilon_ >= 0
EQ09Z(
EQ0D9J(taH
EQ0D9R(t+H
Equal
equal const not matched.
equation
Equations (Default: f=Sigmoid, g=Tanh):
Equations (Default: f=Sigmoid, g=Tanh, h=Tanh):
Equations (Default: f=Tanh):
ERROR
Error compiling '
Error context: 
Error during EndProfiling(): 
Error mapping feeds: 
Error mapping output names: 
Error merging shape info for output. '
Error parsing '
Error parsing function body:
Error parsing node:
Error parsing TensorProto (expected a tensor shape).
Error parsing TensorProto (expected a tensor type).
Error parsing TensorProto shape (expected numeric dimension).
Error reverse compiling '
Error unexpected extra input in node:
Error: Duplicate definition-site for (
errorCategory
errorCode
errorMessage
eT:Jy
Et8Bt
Ethiopic
Eu8Bu
euclidean
EvaluationStart
EvaluationStop
EventRegister
EventSetInformation
EventUnregister
EventWriteTransfer
Evf9Bv
Ex!D$P
EX_squared
Example 1:
Example 2:
Example 3:
Example 4:
Exception
Exception caught: 
Exception during initialization: 
Exception during loading: 
Exception running nodes starting at 
exclude_outside
exclude_outside can be set to 1 only when mode is CUBIC. Current mode is set to 
exclusive
exec_plan_index
exec_plan_ptr
executable format error
Execution frame was null
Execution providers must be registered before the session is initialized.
Execution providers must be registered before the session is initialized. 
Execution type '
execution_mode
execution_mode is not valid
execution_mode option in the model file must be an integer
ExecutionProviderEvent
executionProviderIds
ExH;V
ExH9Epu!H
Existing entry in compiled kernel hashes for 
Existing registration with name 
existing_entries.find(attribute_name) == existing_entries.cend()
existing->second == &tensor
Exiting due to terminate flag being set to true.
EXL+EPI
ExL+EpI
EXL+EPI
EXMcd$
Expand
ExpandBroadcastLooper should only have a shape for the second input.
ExpandDims
ExpandDims echo operator.
expanded
expanded_target
expanded_target_int64
ExpandElimination
Expect mask data type is uint8 or float
Expect to have present state output when past state input is given
expected a registered ONNX type
Expected a single float value!
Expected a single int64 value!
Expected a single string value!
Expected AllocateFinalOutput to have been called to before we increment the iterator
Expected AllocateFinalOutput to have been called to before we read the OrtValue from the iterator.
Expected character 
Expected 'replace_value_int64' attribute since 'imputed_values_int64' is specified
Expected 'replaced_value_float' attribute since 'imputed_value_floats' is specified
Expected shape from model of 
Expected value:
Expecting 2xValues == indices
Expecting a non-empty tokenexp
Expecting activation to be one of Affine, Relu, LeakyRelu, ThresholdedRelu, Tanh, ScaledTanh, Sigmoid, HardSigmoid, Elu, Softsign, Softplus. Got 
Expecting all elements to be tensors. Got: 
Expecting COO 2-D indices shape
Expecting data type to be set as string
Expecting fully sparse tensors to have indices shape {0}
Expecting fully sparse tensors to have value shape {0}
Expecting index blocks: 
Expecting indices to be equal the number of values or be twice as many
Expecting indices to have 2-D shape . Got: 
Expecting inner index size: 
Expecting inner indices to be same as nnz. Got: 
Expecting one index. Got: 
Expecting the same number NNZ == size of Inner indices
Expecting to contain one index, got: 
Expecting to have at lest 3-D shape. Got:
Expecting two indices. Got: 
Exponent
ExponentTensor
Extended allocation by 
Extending BFCArena for 
extents.size()=
External data type cannot be UNDEFINED or STRING.
External data type must not be UNDEFINED or STRING.
Extra unparsed input unexpected.
extra_add
extra_shape
extrapolation_value
EyeLike
EyeLike : Input tensor dimension is not 2
f 4"2
F D9$
F F ~ ~ 
F H;F(t
F H;G 
F H+F
F HcL
F I+F
F IcF
F L+F
f M+f
f P"4
f#L$@f
F(9_(
F(A8^1t
F(A9G
f(br\b^
f(D+f0D
F(D+F0D
f(H0:
F(Hn:bDHd
F(IcF E
f,`8.:,
F,A9G
F,Z$FZZ(F
f.P0)
f;)s*f9Y
f;2s+fD9z
F@A8^@t
F@H+F8H
f}ymB
f0B~.
F0H9F(t
f0M+f(I;
F8,6u
F89_(
F8H+F0H
F8LcF H
f9,Yu
f9<Au
f9Bvu$A
f9Hvu
f9Ovu'
fA9,@u
fA9|U
fA90u
fA94Qu
fA99}
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum), default is 0.9f.
Factor used in computing the running mean and variance.e.g., running_mean = running_mean * momentum + mean * (1 - momentum).
Faild to find path to qkv_matmul
Faild to find path v
Faild to find path v to Split
Faild to match concat node for Gather paths
Faild to match gemm gather path
Faild to match gemm path
Faild to match path 1 for unidirectional mask
Faild to match path 2 for unidirectional mask
Faild to match path 3 for unidirectional mask
Faild to match path 4 for unidirectional mask
Faild to match the path (Div-->Where-->Add) for unidirectional mask
Failed in match input mask subgraph
Failed in match Transpose attribute perm. Expected: 0, 2, 1, 3
Failed in match v_matmul and v_add input shape
Failed in match v_transpose attribute perm. Expected: 0, 2, 1, 3
Failed memory size calculation
Failed since multiple edges matched:
Failed to add kernel for 
Failed to allocate memory for requested buffer of size 
Failed to analyze start state.
Failed to construct locale with name:
Failed to convert dense initializer to sparse
Failed to convert mask to int32
Failed to copy tensor to 
Failed to create output tensor for 
Failed to create output tensor for If output 
Failed to create output tensor for output #
Failed to create the inter-op thread pool for the parallel executor, setting ExecutionMode to SEQUENTIAL
Failed to find a free memory block despite calling Extend. rounded_bytes=
Failed to find allocator for device 
Failed to find initializer for name: 
Failed to find initializer to reshape with name 
Failed to find input name in the mapping: 
Failed to find kernel def hash (
Failed to find kernel for 
Failed to find mask path
Failed to find path 1 of position shape.
Failed to find path 2 of position shape.
Failed to find path for k
Failed to find path for mask
Failed to find path for past_k
Failed to find path for present_k
Failed to find path for present_v and past_v
Failed to find path for q
Failed to find reshape shape path 1
Failed to find reshape shape path 2
Failed to find shape path
Failed to find Softmax node
Failed to find symbol in library, error code: 
Failed to get allocator for optimizer
failed to get first output!
Failed to get initializer tensor.
Failed to get position embedding weights.
Failed to get size of TensorProto
Failed to load model because protobuf parsing failed.
Failed to load model with error: 
Failed to load Q, K and V bias tensors, or data type is not float or float16.
Failed to load Q, K and V weights, or data type is not float or float16.
Failed to match position embedding subgraph.
Failed to match position subgraph.
Failed to match Shape node. 
Failed to match v_concat
Failed to obtain detect_negative
Failed to obtain detect_positive
Failed to parse model file!
Failed to parse model stream!
Failed to parse path root: 
Failed to remove node.
Failed to serialize model!
Failed to set node op schema.
Failed to unload DSO: 
Failed to write value with snprintf().
FailFast
false
false literal
falsH
fast_gelu_output
fast_shape.size() == 2
fast_shape.size() == 3
fast_shape[0] * fast_shape[2] == output.Shape().Size()
fast_shape[0] == output.Shape().Size()
fast_shape[1] == output.Shape().Size()
FastGelu
FastGeluFusion
FastGeluH
FATAL
Fatal error: 
Fatal error: 0 count processors from GetLogicalProcessorInformation
Fatal error: 0 count processors from GetSystemInfo
fB94zu
fbQ}X
fbs_attr cannot be null
fbs_node_arg_names cannot be null
fC9D}
fD;!s
fD;)s
fD;*s
fD;:s
fD;1s
fD;9s
fD;9s*f9i
fD;9s+fD9q
fD9 t
fD9$Ou
fD9,Pu
fD94Ou
fD99sD
fD9Bv
FdJ.L
fE; s
fE9!t A
fE9.u
Feature id for each node.
FeatureVectorizer
feed_locations.size() == copy_info.size()
feeds.size() == feed_mlvalue_idxs.size()
feeds_fetches_manager_
feeds_fetches_manager_ && info_
fetch_alloc_info.size() == copy_info.size()
Fetches vector passed to GetOutputs contains 
fetches.empty() || fetches.size() == fetch_mlvalue_idxs_.size()
fetches.size() == node->OutputDefs().size()
fF9<Ju
fffff
ffffff
fffffff
fg:SM
FHIcT
FHlt_
Field '
fIH,-
file exists
File not found!
file too large
file_path == nullptr
FileDescription
filename too long
FileVersion
filter number not equal to input channel number.
filter_info_ == nullptr
FilterScaleTensor
FilterTensor
FilterZeroPointTensor
final_output_mlvalue_
final_state_and_scan_outputs
FindClose
FindFirstFileW
FindNextFileW
First dimension (num_rois) of batch_indices and rois don't match
First input does not have rank 2
first input tensor has wrong dimension
First input tensor must have rank 3
First set of probability coefficients.
First, offset by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.
fj lNm
Flag indicating whether the regression is a one-class SVM or not.
Flatten
float
FLOAT
float_data
float16
float16)L9H
FLOATFLOATSGRAPHGRAPHSINTINTSSPARSE_TENSORSPARSE_TENSORSSTRINGSTRINGSTENSORTENSORSTYPE_PROTOTYPE_PROTOSUNDEFINED
FLOATS
floats
floor
Floor
FlsAlloc
FlsFree
FlsGetValue
FlsSetValue
Flush-to-zero and denormal-as-zero are 
fmod attribute must be true for floating point types
fmod must have value either 0 or 1
Fop_name
For each node, define what to do in the presence of a missing value: if a value is missing (NaN), use the 'true' or 'false' branch based on the value in this array.<br>This attribute may be left undefined, and the defalt value is false (0) for all nodes.
For each node, define what to do in the presence of a NaN: use the 'true' (if the attribute value is 1) or 'false' (if the attribute value is 0) branch based on the value in this array.<br>This attribute may be left undefined and the defalt value is false (0) for all nodes.
For example, the following tensor shapes are supported (with broadcast=1):
For internal use.
For map type num_values MUST be 2
for node: 
For ort_value with index: 
For previous (depreciated) non-spatial cases, implementors are suggested
forgot to update the version range in DomainToVersionRange 
Format() == SparseFormat::kBlockSparse
Format() == SparseFormat::kCoo
Format() == SparseFormat::kCsrc
Format() == SparseFormat::kUndefined
format_data_.size() == 1U
format_data_.size() == 2U
FormatMessageA
FormatMessageW
forward
Found '.' not part of an ellipsis in input: 
Found '.' not part of an ellipsis in the output subscript provided
Found a '.' not part of an ellipsis in input: 
Found a '.' not part of an ellipsis in the output subscript provided
found duplicated provider 
Found kernel for Op with name (
Found session/run/environment configuration in the model file to be used while running the model
found_in_outer_scope_location_map
Four modes: round_prefer_floor (default, as known as round half down), round_prefer_ceil (as known as round half up), floor, ceil. Only used by nearest interpolation. It indicates how to get "nearest" pixel in input tensor from x_original, so this attribute is valid only if "mode" is "nearest".
foward
FPE8fxI
FPH+FHH
FPH9FHH
frame != nullptr
FreeDimensionOverrideTransformer
FreeLibrary
FreeLibrary failed with error 
func info for node: 
function
Function
Function body initialization failed for Function '
Function body initialization failed for node '
function not supported
Fused
fused 
fused Add and Gelu
fused Add-Dropout-(Add) for 
Fused an attention node for GPT.
Fused an attention node.
Fused Attention subgraphs 
fused Conv 
fused EmbedLayerNorm subgraphs 
fused Gelu subgraphs 
fused Gemm 
Fused Gemm with Sum
Fused Gemm with Transpose
fused GPT2Gelu subgraphs 
fused LayerNorm subgraphs 
fused Matmul and Add 
Fused MatMul and Scale
fused MatMul and Transpose 
fused op (
Fused reshape node: 
fused SkipLayerNorm subgraphs 
fused_
fused_activation
fused_activation_domain
fused_activation_since_version
fused_alpha
fused_beta
fused_function_subgraph
fused_gamma
fused_ratio
FusedActivation
FusedAdd
FusedAddTensor
FusedBatchNormalization
FusedConv
FusedConvTranspose
FusedGemm
FusedInstanceNormalization
FusedMatMul
FusedMeanVarianceNormalization
FusedNode's nodeArgList does not contain one of the nodeArg
FusedSum
FuseReluClip
FuseReluClip_
fusion_style == IExecutionProvider::FusionStyle::Function
FXD9nPt
FXE9nPt
FXH+FPH
FXI+FPH
G 9B H
G E9p
G H+G
G I;G(t
G Jc,
G L+G
G L9w0
G(9G,td
g(D+g0D
g(fE9n
G(H+G H
G@!GDH
G@]\>
G@D8uPt
G@H;GHt
G@H+G8H
G@H9G8u
G`I9GX
G0H9G(
G0HcH
G0LcG
G4#92
G8H;G@t
G8H+G0H
G8I+G0H
G8LcG H
Gamma
gamma
gamma is expected to have 1 dimension, got 
gamma is expected to have 1 dimensions, got 
gamma is expected to have size of 
Gamma scale must be a scalar or 1D tensor of size 1
Gamma should be of shape (hidden_size). 
gamma should have 2 dimension, dimension size known, and same hidden size as word_embedding.
Gamma zero point must be a scalar or 1D tensor of size 1
gamma_quant
gamma_scale
gamma_zero_point
gates
Gather
gather axis value not expected
gather indices not matched.
gather input 1 value is not expected
Gather node in path 2 is not linked to another subgraph.
Gather Tind type not supported in this build.
GatherElements
GatherElements op: Cannot operate on scalar input
GatherElements op: Data type of input 'data' should match the data type of the output
GatherElements op: 'indices' shape should have values within bounds of 'data' shape. Invalid value in indices shape is: 
GatherElements op: Rank of input 'data' needs to be equal to rank of input 'indices'
GatherElements op: Value in indices must be within bounds [
GatherND
GatherNDBase PrepareForCompute: Input count mismatch
Gaussian Error Linear Unit.
Gelu approximation
GeluApproximation
GeluFusion
Gemm bias is not constant
Gemm bias is not constant initializer
Gemm bias shape is not expected
Gemm bias shape not expected
Gemm does not have 3 inputs
Gemm weight is not constant initializer
Gemm weight shape is not expected
GEMM: Dimension mismatch, W: 
Gemm: Invalid bias shape for broadcast
Gemm@
gemm_input_edge.src_arg_index < 2
GemmActivationFusion
GemmSumFusion
GemmTransposeFusion
GENERAL ERROR
generated at runtime
generic
GenuD
GenuH
Georgian
GetCPInfo
GetCurrentProcess
GetCurrentProcessId
GetCurrentProcessorNumber
GetCurrentThread
GetCurrentThreadId
GetEnvironmentVariableA
GetFileAttributesA
GetFileAttributesW
GetFileSizeEx
GetFileSizeEx 
GetFinalPathNameByHandle() failed: 
GetFinalPathNameByHandleW
GetFullPathNameW
GetFusedActivationAttr(info, activation_).IsOK()
GetLastError
GetLocaleInfoEx
GetLogicalProcessorInformation
GetModuleFileNameA
GetModuleFileNameW
GetModuleHandleExW
GetModuleHandleW
GetNativeSystemInfo
GetProcAddress
GetProcessHeap
GetProvider
GetSessionGetInputDevice
GetStringTypeW
GetSystemInfo
GetSystemTimeAsFileTime
GetSystemTimePreciseAsFileTime
GfE98s
gfffffffH
gfffffffH+
gfffffffI
GHH+G@I
GHI+G@H
Given `data` tensor of rank r >= 1, and `indices` tensor of rank q >= 1, gather
Given model could not be parsed while creating inference session. Error message: 
GivenTensorFill
Glagolitic
global
global_bias
global_weight
GlobalAveragePool
GlobalLpPool
GlobalMaxPool
Got invalid dimensions for input: 
Got nullptr for sequence input.
Got nullptr from GetKernel for node: 
Got weights of size: 
Gothic
Gp9Fpt
GPH+GHH
GpH+GhH
GPH9GHtnH
GPH9GHtPH
GPT2Gelu
GradientTensor
-grams
Grantha
GRAPH
Graph
graph
Graph attribute inferencing failed: 
Graph attribute inferencing returned type information for 
Graph attribute value was null. Invalid ORT format model.
Graph ctor should have created NodeArg for initializer. Missing:
Graph has 
Graph in 'body' attribute of Loop should have 
Graph initializer names must appear after the actual inputs: 
Graph is null. Invalid ORT format model.
Graph must be in single static assignment (SSA) form, however '
Graph state to be loaded into must be empty.
Graph to run if condition is false. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the then_branch.
Graph to run if condition is true. Has N outputs: values you wish to be live-out to the enclosing scope. The number of outputs must match the number of outputs in the else_branch.
Graph transformers must be registered before the session is initialized.
graph.RemoveNode(gemm_node.Index())
graph.RemoveNode(sum_node.Index())
graph_->GetNode(idx) != nullptr
graph_index
graph_inputs_excluding_initializers_.empty() && graph_inputs_including_initializers_.empty() && value_info_.empty() && graph_outputs_.empty()
graph_optimization_level
graph_optimization_level is not valid
graph_optimization_level option in the model file must be an integer
graph_proto != nullptr
graph_proto cannot be null
graph_proto_ is not in sync with name_to_initial_tensor_.
GraphProto attribute inferencing is not enabled in this InferenceContextImpl instance.
GRAPHS
graphs
GraphTransformerHelpers::RegisterGraphTransformers
Greater
GreaterOrEqual
Greek
Grid batch size 
grid_dims[0] == N
grid_dims[3] == 2
GridSample
group
group count is <= 0
GroupCount
GrowStack() failed: 
GRU operator does not support double yet
GRUUnit
GRUUnit computes the activations of a standard GRU,
gsl::narrow_cast<int64_t>(input_axes_.size()) == num_scan_inputs_
gsl::narrow_cast<int64_t>(input_shape.Size()) == size
gsl::narrow_cast<int64_t>(output_axes_.size()) == num_scan_outputs
gsl::narrow_cast<int64_t>(tensor_shape.NumDimensions()) >= slice_dimension
gsl::narrow_cast<int64_t>(X_shape.NumDimensions()) >= axis
Gujarati
Gunjala_Gondi
Gurmukhi
GxH+GpH
GXH+GPHcK
GZ4hz
h != kInvalidChunkHandle
h < chunks_.size()
H 9{(u
H A9H A
H D9c(t8H
H H+H
H H99
H H99u
H Hc@
h j<l
H L9!
H L9)
H L91
H SVWH
H SWH
H UATAUAVAWH
h UAVAWH
h VWATAVAWH
h VWAVH
H WATAUAVAWH
h WAVAWH
H!;H!{
H!\$(L
H!\$@f
H!\$0D
H!\$0H
H!\$0H!\$@L
H!\$0L
H!\$PH;U
H!|$0H
H!|$0L
H!A@H
H!D$ L
H!D$0H
H!D$0H!D$@H
H!D$0L
H!D$HL
H!D$P
H!D$PH
H!D$pL
H!E(H
H!E7H
H!E'9
H!E'M
H!EpD
H!H H
H!L$`H
H!L$HE
H!t$ H
H!T$(H
H!T$0D
H!T$0E3
H!t$0H
H!T$0H
H!t$0I
H!t$0L
H!T$83
H!T$8H
H!t$PH
H"DJBA
H#N0H
H#NHH
H#r0H
H(A;I
H(A9I
H(D9o 
H(Db:HD
h(j"l"n"p"r
h(jFb>l
h(XhRhTbj
H,A;I
H,A9I
H,J2HfL,N<LLN4PTRTLJTTV
h.t:h
H;\$ 
H;\$ t*
H;\$(t
H;\$0
H;\$0rMH;]
H;\$8tgH
H;\$H
H;\$Ht'
H;\$ht$
H;\$Hu
H;\$P
H;\$pt
H;\$xD
H;\$XL
H;\$xt
H;\$xt/H;
H;]'|
H;]g}tIc
H;]gL
H;]h|
H;_8u
H;_p|)H
H;{ H
H;{(|
H;{(}UI
H;{h|
H;{Hv
H;|$ 
H;|$ t$L;
H;|$@
H;|$@t'A
H;|$0
H;|$8H
H;|$H
H;|$p
H;|$X
H;|$xr=H
H;|80u
H;} t
H;}0|
H;~ H
H;~0u
H;5g'p
H;A(s
H;A8u
H;AHu
H;APu
H;APu^
H;B }bH
H;B r
H;C r
H;C rWH
H;C(t
H;C`t
H;C8|
H;C8t/M
H;C8t:I
H;C8t4I
H;C8t7M
H;C8u
H;Cht
H;Cpt
H;CXt
H;Cxt=@8|$ t
H;D$@
H;D$`
H;D$0u
H;D$8
H;D$8u
H;D$ht
H;D$hu
H;D$P
H;D$pr4M
H;D$x
H;D$X
H;D$xH
H;E'|
H;E0|
H;Eh|
H;EhuQI
H;Eo}nL
H;Epu]L
H;EpuQI
H;Ew}nL
H;ExuQI
H;F tDL
H;F@|
H;Fxu
H;G@|
H;G0rP
H;G8u
H;Gxt
H;GxtBH
H;Gxu
H;H s
H;H@s
H;H8t=H
H;H8t9H
H;K r
H;L$(~
H;L$(tC
H;L$@
H;L$@|
H;L$@u
H;L$0
H;L$0~
H;L$h
H;L$H~
H;L$p
H;L$pt\H
H;L$X
H;M't
H;P }iH
H;P8v
H;PHsaH
H;Q }=I
H;Q }>I
H;Q }CM+
H;Q }iH
H;q sxH
H;Q tfL9
H;q(swA
H;QhH
H;r }aH
H;s`r
H;s8u
H;S8v
H;t$ u
H;t$@
H;T$@H
H;T$0|
H;t$8
H;t$8H
H;T$H
H;t$h
H;T$H
H;T$H|
H;t$P
H;T$xu
H;u u
H;UhI
H;UhM
H;UPt
H;w |
H;W H
H;W I
H;w8r
H;W8v,H
H;X0u
H;XXs
H;xXu5
H;y |
H;Y r
H;y r
H;YhH
h^d8bx
H_^[]
h_^[]
h_^][
H_^][
H{;%':
H+\$XH
H+] H
H+A8H;
H+C8H
H+C8H;
H+C8I;
H+D$(H
H+D$0H
H+D$8H
H+D$8J
H+D$PL;
H+D$xH
H+ExH
H+F8H
H+F8H;
H+F8I;
H+L$ xFH
H+L$(H
H+L$(x<H
H+NHH
H+Q H
H+t$(I
H+t$PH
H+V0H
H+W`H
H+WHH
H0;N 
H0;N$
H0H;H8t@H
H0H;H8t<H
H0HcP(L
h6`@.B,
H9:t+
H9\$ t
H9\$ t$H
H9\$0
H9\$H
H9\$ht8
H9\$Hv`H
H9]`t7
H9]pt53
H9^ tGA
H9^(H
H9_(L
H9_xH
H9{`H
H9{8~&H
H9{8~{D
H9{8~zH
H9{h~(H
H9{Ht
H9|$`
H9|$0u
H9|$h
H9|$p
H9|$p~AO
H9|$Pu^A
H9}hu
H9}Pt.
H9}Pt]
H9}PtS
H9}Ptv
H9>tW
H90uJL
H91t:H
H91tUH
H93t{H
H98|XH
H98~.L
H98tgH
H98uJH
H99~RD
H99t0H9y0H
H9A s
H9CHt
H9D$ t.H;
H9D$ t-H;
H9D$(u
H9D$8t%
H9D$8t0
H9D$p
H9D$pt$3
H9FPu
H9G uM
H9GpH
H9Gpv!H
H9Gxt?H
H9K@H
H9KHH
H9l$pH
H9l$pu
H9l$xu
H9L$XwmD
H9Mwu H
H9n(H
H9n8H
H9oHsI
H9p(H
H9P0H
H9p0H
H9P0L
H9q }
H9q8v H
'H9q8v!H
H9s@H
H9S@H
H9s`v?3
H9s0H
H9T$H
H9t$h
H9T$H
H9t$puiH
H9t$puJH
H9T$PwfH
H9t$XvaL
H9u`t;
H9uhu
H9uPu9K
H9uXt:
H9w H
H9WhH
H9x }
H9X s
H9x s
H9X s
H9X0H
H9Y u`
H9Y0H
H9y0L
H9Y0t
H9z0H
HA^_^[
hA^_^[
hA_A^_^[]
hA_A^_^][
HA_A^_^][
hA_A^_^][
hA_A^A]A\_^[]
hA_A^A]A\_^][
HA_A^A]A\_^][
hA_A^A]A\_^][
HA_A^A]A\_^][
hA_A^A]A\_^][
HA_A^A]A\_^][
hA_A^A]A\_^][
HA_A^A]A\_^][
hA_A^A]A\_^][
HA_A^A]A\_^][
half_pixel
Hangul
Hanifi_Rohingya
Hanunoo
Hardmax
Hardmax inputs N, D and N * D must be < 
hardsigmoid
HardSigmoid
HardSwish
has output size 
has_key_padding_mask
has_layer_state
has_starts && has_ends && attr_starts_.size() == attr_ends_.size()
HasDataType(dense_proto)
HasExclusiveProduct
HasExclusiveSum
Hatran
Having memory pattern enabled is not supported while using the DML Execution Provider. 
Hc@ H
Hc@(H;
Hc@@I
Hc@8H
Hc@hH
Hc[@A
Hc\$ H
Hc\$PH
Hc]@H
Hc^ H
Hc^8H
Hc^PH
Hc_$H
Hc|$<H
Hc|$4
Hc|$4H
Hc} H
HcA,H
HcA0H
HcA8H
HcAhH
HcB(H
HcB8H
HcB8H;
HcBhH
HcBPH
HcC(I;
HcC,H
HcC@H
HcC0HcK,H+
HcCxH;
HcD$ H
HcD$ L
HcD$$H
HcD$(H
HcD$`H
HcD$0
HcD$8H
HcD$dH
HcD$PH
HcD$pH
HcD$TH
HcD$XI;
HcE H
HcE_H
HcE_L
HcEgH
HcEOH
HcEwH
HcEXH
HcF I
HcF L
HcF(H
HcF@H
HcF8H
HcF8H;
HcFhH
HcFhH;
HcFPH
HcFpI
HcFXH
HcG H
HcG I
HcG$H
HcG$L
HcG(H;
HcG`I
HcG8H;
HcGhH;
HcGPH
HcGXH
HcH(H
HcH@H
HcH0H
Hci H
HcI H
HcJ(H
HcJ(I;
HcJ8H
HcJ8I;
HcJhH
HcJhI;
HcK H
HcK$H
HcK(;
HcK,H
HcK0H
HcK8;
HcKh;
HcL$ H
HcL$|;
HcL$8;
HcL$h;
HcL$p;
HcL$pH
HcM';
HcMPH
HcN H
HcN8;
HcNP;M
HcO ;
HcO H
HcO$H
HcO$L
HcO(H
HcO0HcW(L
Hco8H
HcOh;
HcOhA;
HcOhH
HcOPA;
HcP,H
HcP@H
HcP0I
HcPhH
HcQ H
HcQ,H
HcQ0H
Hcr8H
HcSh;
HcSP;
HcT$ H
HcT$ I
HcT$@H
HcT$0
HcT$0H
Hct$0H
HcT$0I
HcT$8H
Hct$8H
HcT$8H
HcT$8I
HcT$DH
HcT$xH
HcUhH
HcUP;
HcV ;
HcV8;
HcVh;
HcVp;
HcVP;
HcVX;
HcW ;
HcW$H
HcW$L
HcW(H
HcW8;
HcWP;
Hcy H
Hcy0M
HeapAlloc
HeapFree
Hebrew
height_scale
helper.HaveTwoTensorInputs()
hHcr8H
HhHcT
HHJ2H L@Ne
HiD$ %y
hidden
Hidden layer sizes of Q, K, V paths in Attention
hidden_prev
hidden_size
hidden_size != num_heads * head_size
hidden_size should be divisiable by num_heads.
hidden_size should be divisiable by num_heads:
HiddenInitTensor
hipMalloc
Hiragana
HjFvJfL(N"P,R*T"VxX
HkL$PXH
HnJbP
host unreachable
However, the number of key is 
HPH;K
HPH;N
hPH;n
HPH;N
hPH;n
HPH;O
HPH9i
HpL6N
hResult
https://arxiv.org/abs/1502.03167. Depending on the mode it is being run,
https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html
HUSVH
HUSVWATAUAVAWH
HUSVWATAUAVH
HUSVWATAUH
HUSVWAVATH
HUSVWAVAUATH
HUSVWAWAVAUATH
HUSVWAWH
HUSVWH
HvJ8N
HvL6NtR6T
HXI9IX
HzNzTA
i < input_shape.NumDimensions()
i < tensors_.size()
I D9i(
I L9AP
I#M0I
I#u0H
I#u0L
I.e. the output shape should be [C][0] or [N][C][0] if input shape was [N][C].
I;@(u]I
I;@8t.L
I;@8t/H
I;@8t/L
I;@8t3L
I;@8t7H
I;@8tCH
I;@8t-L
I;@8u
I;@8u]I
I;^(H
I;A8}
I;A8u
I;Bxt
I;C8t
I;D$xu
I;F0u
I;FHu
I;G`u
I;G8u
I;GXt
I;H8t5L
I;H8t-M
I;H8u
I;I8u
I;J8u
I;L$@r
I;L$0t
I;L$0v
I;N t8H
I;OXt
I;p |
I;Pht}L
I;Pp|
I;pp|
I;Pp|
I;Q |
I;Q(unL;
I;QHs
I;RPt
I;SHt
I;T$8v
I;V(t
I;X(u
I;X8t3H
I;X8t4H
I;X8t5H
I;Xp|
I;Y8|
i^kO6
I_`|B
I_>gE
I|:0G0
I+<$H
I+4$H
I+C0H
I+CHH
I+D$0H
I+F8H;
I+VHH
I0G1-0+
i4CZd
I5Dn^
i7~P+
I9\$ 
I9~(I
I9~0I
I9~xt
I9~xtZH
I9>rkH
I9>t]H
I90w>I
I98~1L
I9BhI
I9EXt}H
I9h0~3H
I9Jhs
I9Khs
I9L$@v
I9NXt
I9wpt
I9Y8~
I9ZXI
Iba|H
IbbeHQ
IbR=@
IbR=P
Ic@8H
Ic@PH
Ic\$ 
Ic\$ !T$`L
Ic\$(
Ic^P3
IcD$hL
IcD$PH
IcE H
IcE L
IcE8H
IcEhL
IcEPH
IcF H
IcF8H
IcFhH
IcFPH
IcG H
IcG L
IcG8H
IcGhH
IcGPH
IcH8H;
IcH8I
IcMP;
IcN$H
IcN8;
IcNPA;M
IcP(H
IcT$ H
IcU8H
IcUP;
IcUX;
IcV ;
IcV8;
IcV8H
IcVh;
IcVP;
Icw H
IcWh;
id >= 0 && static_cast<size_t>(id) < ort_value_info_.size()
Identifier expected but not found.
identifier removed
Identity
IdentityTo
ideruVH
IExecutionProvider constructor must be called with true for use_metadef_id_creator
IExecutionProvider::Compile with fused Node and dll path is not implemented by 
IExecutionProvider::Compile with fused Node is not implemented by 
IExecutionProvider::Compile with FusedNodeAndGraph is not implemented by 
If `axes` are omitted, they are set to `[0, ..., ndim-1]`.
If 0, normalize the mean only.  Default is 1.
If 1, mean and variance are computed across channels. Default is 0.
If align_corners=1, the extrema (-1 and 1) are considered as referring to the center points of the input's corner pixels. If align_corners=0, they are instead considered as referring to the corner points of the input's corner pixels, making the sampling more resolution agnostic.
if coordinate_transformation_mode is "align_corners", <br/>
if coordinate_transformation_mode is "asymmetric", <br/>
if coordinate_transformation_mode is "half_pixel", <br/>
if coordinate_transformation_mode is "pytorch_half_pixel", <br/>
if coordinate_transformation_mode is "tf_crop_and_resize", <br/>
if coordinate_transformation_mode is "tf_half_pixel_for_nn", <br/>
If keepdims equal 0, then the resulting tensor have the reduced dimension pruned.
If necessary the right-hand-side argument will be broadcasted to match the
If node has 
'If' node has 
If scale is not provided, crop the borders as provided.
If set to 1 will perform the sums in reverse direction.
If set to 1 will return exclusive sum in which the top element is not included. In other terms, if set to 1, the j-th output element would be the sum of the first (j-1) elements. Otherwise, it would be the sum of the first j elements.
If set to 1, the weight of sampling locations outside the tensor will be set to 0 and the weight will be renormalized so that their sum is 1.0. The default value is 0.
If set to nonzero, run spatial batch normalization in test mode, default is 0.
If set to true then it indicates dropout is being used for training. It is an optional value hence unless specified explicitly, it is false. If it is false, ratio is ignored and the operation mimics inference mode where nothing will be dropped from the input data and if mask is requested as output it will contain all ones.
If set to true, it indicates BatchNormalization is being used for training, and outputs 1, 2, 3, and 4 would be populated.
If set, defines the broadcast dimensions.
If set, defines the broadcast dimensions. See doc for details.
If shape was concrete we shouldn't be using a custom allocator
If the tokenizer receives empty input of [0] then the output is [0] if empty input
If the value of map_form is 'SPARSE,' this attribute indicates the total length of the output tensor.
If tokenizer removes the entire content of [C]-input, it will produce [[]].
If true and category is not present, will return all zeros; if false and a category if not found, the operator will fail.
If true, check only for Inf, -Inf.
If true, check only for NaN.
If true, compute the mean and variance across all spatial elements If false, compute the mean and variance across per feature.Default is 1.
If true, compute the mean and variance across per activation. If false, compute the mean and variance across per feature over each mini-batch.
If value is 1, output type is uint32_t, else int32_t. Default value is 1.
ig;<j
iG_t_
ignore_index
Ignoring unsupported session option in ORT config: 
IH;\$8t9H
ii0xWVY
illegal byte sequence
illegal input path:
ilogb
ilogbf
ImageScaler
Imperial_Aramaic
impl_->max_gram_length_ >= impl_->min_gram_length_
impl_->max_skip_count_ >= 0
impl_->min_gram_length_ > 0
impl_->weighting_criteria_ != kNone
impl_->weights_.size() == impl_->ngram_indexes_.size()
implementation such as CuDNN.
imputed_value_floats
imputed_value_int64s
imputed_values_float_.empty() ^ imputed_values_int64_.empty()
Imputer
in a sequence-length aware fashion.
in initializers. 
in onnx/defs/schema.h).
in the inclusive range [
in[idx]->IsTensor()
inappropriate io control operation
IncludePadding
Incompatible dimensions
Incompatible dimensions for matrix multiplication
Incompatible matrix dimensions for matMul
Inconsistent shape in loop output for output. 
Incorrect arena extend strategy.
Incorrect or missing attribute value for starts and ends
Incorrect or missing input value for starts and ends
index < data_.size()
index >= 0 && static_cast<size_t>(index) < inputs.size()
index >= 0 && static_cast<size_t>(index) < outputs.size()
index is out of bounds
index out of range
Index out of range
Index size: 
Index tensor shape should be same as that of the input data tensor to unpool.
IndexDimensions
IndexedSubGraph contains values not present in the Graph
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [0, R], where R is the rank of the input tensor. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
Indicate up to which input dimensions (exclusive) should be flattened to the outer dimension of the output. The value for axis must be in the range [-r, r], where r is the rank of the input tensor. Negative value means counting dimensions from the back. When axis = 0, the shape of the output tensor is (1, (d_0 X d_1 ... d_n), where the shape of the input tensor is (d_0, d_1, ... d_n). 
Indicates the transform to apply to the regression output vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates the transform to apply to the score. <br> One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates the transform to apply to the score. <br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT.'
Indicates the transform to apply to the scores vector.<br>One of 'NONE,' 'SOFTMAX,' 'LOGISTIC,' 'SOFTMAX_ZERO,' or 'PROBIT'
Indicates whether to do OvR or multinomial (0=OvR is the default).
Indicates whether to only output as many values as are in the input (dense), or position the input based on using the key of the map as the index of the output (sparse).<br>One of 'DENSE', 'SPARSE'.
Indices
indices
Indices and updates must have the same rank
Indices dim=
indices element out of data bounds, idx=
Indices must have the same rank as Input. Indices rank=
Indices shape must have dim[0] == 2
indices tensor data type not supported
indices tensor must has rank larger than 0
Indices tensor must have rank >= 1
Indices type is not supported.
Indices vs updates dimensions differs at position=
indices_shape[1] > 0 && static_cast<size_t>(indices_shape[1]) == dims.size()
IndicesDimensionCount
IndicesTensor
ineIu
InferenceSession is null. Invalid ORT format model.
Inferred elem type differs from existing elem type: (
Inferred shape and existing shape differ in dimension 
Inferred shape and existing shape differ in rank: (
InfinityMode
info == nullptr
info.GetAttr("alpha", &alpha_).IsOK()
info.GetAttr("beta", &beta_).IsOK()
info.GetAttr("blocksize", &blocksize_).IsOK()
info.GetAttr("direction", &direction).IsOK()
info.GetAttr("direction", &direction_).IsOK()
info.GetAttr("hidden_size", &hidden_size_).IsOK()
info.GetAttr("hidden_size", &int64_value).IsOK() && int64_value > 0
info.GetAttr("keepdims", &keepdims).IsOK()
info.GetAttr("linear_before_reset", &int64_value).IsOK()
info.GetAttr("num_heads", &num_heads).IsOK() && num_heads > 0
info.GetAttr("scale", &scale_).IsOK()
info.GetAttr("storage_order", &storage_order).IsOK()
info.GetAttr<float>("alpha", &alpha_).IsOK()
info.GetAttr<float>("beta", &beta_).IsOK()
info.GetAttr<float>("high", &high_).IsOK()
info.GetAttr<float>("low", &low_).IsOK()
info.GetAttr<float>("mean", &mean_).IsOK()
info.GetAttr<float>("scale", &scale_).IsOK()
info.GetAttr<float>("spatial_scale", &spatial_scale_).IsOK()
info.GetAttr<int64_t>("across_channels", &across_channels_).IsOK()
info.GetAttr<int64_t>("axis", &axis_).IsOK()
info.GetAttr<int64_t>("batch_axis", &batch_axis).IsOK()
info.GetAttr<int64_t>("channels", &channels_).IsOK()
info.GetAttr<int64_t>("channels_last", &channels_last_).IsOK()
info.GetAttr<int64_t>("count_include_pad", &temp).IsOK()
info.GetAttr<int64_t>("default_int64", &default_int_).IsOK()
info.GetAttr<int64_t>("dtype", &dtype).IsOK()
info.GetAttr<int64_t>("max_map", &max_map_).IsOK()
info.GetAttr<int64_t>("max_ngram_size", &max_ngram_size_).IsOK()
info.GetAttr<int64_t>("min_ngram_size", &min_ngram_size_).IsOK()
info.GetAttr<int64_t>("ngram_size", &ngram_size_).IsOK()
info.GetAttr<int64_t>("normalize_variance", &normalize_variance_).IsOK()
info.GetAttr<int64_t>("num_scan_inputs", &num_scan_inputs_).IsOK()
info.GetAttr<int64_t>("p", &p_).IsOK()
info.GetAttr<int64_t>("sample_size", &num_samples_).IsOK()
info.GetAttr<int64_t>("size", &size).IsOK()
info.GetAttr<int64_t>("targets", &num_targets_).IsOK()
info.GetAttr<int64_t>("time_axis", &time_axis).IsOK()
info.GetAttr<int64_t>("transA", &temp).IsOK()
info.GetAttr<int64_t>("transB", &temp).IsOK()
info.GetAttr<int64_t>("upper", &temp).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("body", &proto).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("else_branch", &proto).IsOK()
info.GetAttr<ONNX_NAMESPACE::GraphProto>("then_branch", &proto).IsOK()
info.GetAttr<std::string>("auto_pad", &auto_padding).IsOK()
info.GetAttr<std::string>("cast_to", &attr).IsOK()
info.GetAttr<std::string>("coordinate_transformation_mode", &transformation_mode).IsOK()
info.GetAttr<std::string>("default_string", &default_string_).IsOK()
info.GetAttr<std::string>("equation", &equation_).IsOK()
info.GetAttr<std::string>("map_form", &attr).IsOK()
info.GetAttr<std::string>("metric", &metric).IsOK()
info.GetAttr<std::string>("mode", &mode).IsOK()
info.GetAttr<std::string>("norm", &norm).IsOK()
info.GetAttrs("activations", activations_).IsOK()
info.GetAttrs("axes", axes_).IsOK()
info.GetAttrs(std::is_same<AttrType, std::string>::value ? "string_vocabulary" : "int64_vocabulary", vocabulary_).IsOK()
info.GetAttrs<float>("bias", bias_).IsOK()
info.GetAttrs<float>("coefficients", coefficients_).IsOK()
info.GetAttrs<float>("kernel_params", kernel_params).IsOK()
info.GetAttrs<float>("rho", rho_).IsOK()
info.GetAttrs<float>("scales", scales_).IsOK()
info.GetAttrs<int64_t>("cats_int64s", int_categories).IsOK()
info.GetAttrs<int64_t>("kernel_shape", kernel_shape).IsOK()
info.GetAttrs<int64_t>("kernel_shape", kernel_shape_).IsOK()
info.GetAttrs<int64_t>("pooled_shape", pooled_shape).IsOK()
info.GetAttrs<int64_t>("scales", scales_).IsOK()
info.GetAttrs<int64_t>("shape", shape).IsOK()
info.GetAttrs<std::string>("cats_strings", string_categories).IsOK()
info.GetAttrs<std::string>("classes_strings", string_classes).IsOK()
info.GetAttrs<std::string>("classlabels_strings", classlabels_strings_).IsOK() || info.GetAttrs<int64_t>("classlabels_ints", classlabels_ints_).IsOK()
info.GetAttrs<TKey>(_key_field_name, keys).IsOK()
info.GetAttrs<TValue>(_value_field_name, values).IsOK()
info_ == nullptr
Inherited
initial_c
initial_chunk_size_bytes
initial_growth_chunk_size_bytes
initial_h
initial_state_and_scan_inputs
InitializeCriticalSectionAndSpinCount
InitializeCriticalSectionEx
Initialized tensor with unexpected type: 
Initializer 
Initializer tensor is missing. Invalid ORT format model.
Initializer with same name exists. Name:
initializer_node_arg != nullptr
InitializeSListHead
InitializeSRWLock
Initializing session.
InitOnceBeginInitialize
InitOnceComplete
Inner and Outer indices must either be both zero or non-zero
inner_num == src.Values().Shape().Size()
Input
input
Input 
input != nullptr
Input 0 and 1 shall have same shape
Input 0 and 7 (mask) shall have same shape
Input 0 is expected to have 1 or more dimensions, got 
Input 1 dimension 0 should have same length as dimension 2 of input 0
Input 1 dimension 0 should have same length as the last dimension of input 0
Input 1 dimension 1 should be 3 times of hidden dimension
Input 1 is expected to have 1 dimensions, got 
Input and output types can be of any tensor type.
Input and target dimension value mismatch.
input and zero_point pair is expected to have be same type.
input and zero_point pair is expected to have same type.
input array doesn't equal tensor size
input array is too short
Input axes has incorrect length
Input axes has invalid data
Input axis is invalid: 
Input B must have shape {
Input 'bias' dimension 0 should have same length as dimension 1 of input 'weights'
Input 'bias' is expected to have 1 dimension, got 
Input can be of any tensor type.
Input cannot be split evenly on selected axis. Input shape=
Input channels C is not equal to kernel channels * group.
Input channels is not divisible by group.
Input contains invalid utf8 chars
input count mismatch
input count mismatch, expected 1 input - the tensor to be processed
input count mismatch, expected 2 inputs - the tensor to be processed and a tensor containing k value
Input count of Tile OP mismatch, the first one is empty
Input count of Tile OP mismatch, the second one is empty
Input data tensor from the previous layer.
Input data tensor from the previous operator; 4-D feature map of shape (N, C, H, W), where N is the batch size, C is the number of channels, and H and W are the height and the width of the data.
Input data to be scaled
Input data type does not match the expected data type
Input data type does not match the expected data type. Current data type is 
Input data type is not int32 or int64
Input data with index: 
Input 'depth' must be a scalar or rank 1 tensor.
Input 'depth' must have exactly one element.
Input dim is zero but required output dim is non-zero. 
Input dimension cannot be less than 3.
Input dimensions are either [C] or [N][C] allowed
Input dimensions are either[C > 0] or [1][C > 0] allowed
input edges
Input element type of 
Input 'extra_add_qk' dimension 0 should be same as batch_size, got 
Input 'extra_add_qk' dimension 1 should be same as number of heads, got 
Input 'extra_add_qk' dimension 2 should be same as sequence_length, got 
Input 'extra_add_qk' dimension 3 should be same as sequence_length, got 
Input 'extra_add_qk' is expected to have 4 dimensions, got 
Input features_per_batch[
Input id is not valid. 
input index out of range
input index: 
Input initial_c must have shape {
Input initial_h must have shape {
Input 'input' is expected to have 3 dimensions, got 
Input is ether string UTF-8 or int32/int64
input is expected to have 3 dimensions, got 
Input is expected to have dim value in all dimensions.
Input is expected to have four dimensions corresponding to [N,C,H,W]
Input is expected to have four dimensions corresponding to [N,C,H,W], got 
Input is not of one of the supported map types.
Input is not of one of the supported sequence types.
Input is not of type sequence or map.
Input 'mask_index' is expected to have 1, 2, 3 or 4 dimensions, got 
Input must be an optional-type value containing an element with type information.
Input must be of COO format
Input must be of CSR format
'input' must have rank >= 2
input name cannot be empty
Input of int64 must have output of string 
Input of reshape_before_gemm is not the input of subgraph
Input of string must have output of int64
Input of tensor(int64) must have output of tensor(string)
Input of tensor(string) must have output of tensor(int64)
Input offset, 4-D tensor of shape (N, H_out, W_out, 2), where H_out and W_out are the height and width of grid and output, Grid specifies the sampling pixel locations normalized by the input spatial dimensions. Therefore, it should have most values in the range of [-1, 1]. If grid has values outside the range of [-1, 1], the corresponding outputs will be handled as defined by padding_mode.
Input P must have shape {
Input 'past' is expected to have 5 dimension, got 
Input R must have shape {
Input rank for starts and ends should be the same: (
Input rank must be >= 2.
Input scale is not float for input def @
Input scale is not float for quantized input @
input scale must be a scalar or 1D tensor of size 1
Input 'scales' must have float element type.
Input Sequence and Tensor are expected to have the same elem type. Sequence=
Input Sequence and Tensor are expected to have type info. Current type is null.
Input sequence_lens must have shape {
Input shape dimensions mismatch:
Input shape had more than 2 dimension. Dims=
Input shape is unknown or not 2D, or data type unknown
Input shape must have either [C] or [1,C] dimensions where C > 0
Input shape must have either [C] or [B,C] dimensions with B > 0.
Input shape needs to be at least a single dimension.
input shape: 
Input 'sizes' must have int64 element type.
Input 'split' can not be empty.
Input steps has incorrect length
Input string contains invalid utf8 chars
Input string contains invalid utf8 chars: 
input tensor
Input tensor
Input tensor A. The shape of A should be (M, K) if transA is 0, or (K, M) if transA is non-zero.
input tensor and indices tensor must has rank larger than 0. 
Input tensor B. The shape of B should be (K, N) if transB is 0, or (N, K) if transB is non-zero.
Input tensor C. The shape of C should be unidirectional broadcastable to (M, N).
Input tensor can be of arbitrary type.
Input tensor has no dimensions
Input tensor must be 2-dimensional
Input tensor must be 4-dimensional
Input tensor must have at least 2 dimensions
Input tensor must have atleast 2 dimensions
Input tensor must have rank 1 or 2
Input tensor must have rank 2
Input tensor of rank 2 or higher.
Input tensor of shape [N,C,H,W]
Input tensor should have a rank of at least 2
Input tensor to Unique op should be 1D
Input tensor X must have atleast 2 dimensions.
Input tensor.
Input tensor. Every matrix in the batch must be invertible.
Input tensors of wrong rank (0).
Input tensors to check.
Input to 'Range' op should be scalars (Tensor with only one element and shape empty)
Input to set must exist.
Input type for input at index 
Input type for input at index 0 is null. Type info is expected.
Input type is not float tensor but keys_floats is set
Input type is not int64 tensor but keys_int64s is set
Input type is not string tensor but key_strings is set
Input type is null. Input must have Type information.
Input type is null. Type information is expected for the input.
Input type was null
Input 'values' must be rank 1 tensor.
Input 'values' must have exactly two elements.
Input W must have shape {
Input was expected to have either tensor, sequence, or optional type. Got 
Input was expected to have optional type. Got 
Input was expected to have sequence type. Got 
Input was expected to have tensor or sparse tensor type. Got 
Input 'weights' is expected to have 2 dimensions, got 
Input with name: 
Input X must have 3 dimensions only. Actual:
Input x_scale must be a scalar or 1D tensor of size 1
input x_zero_point must be a scalar or 1D tensor of size 1 if given
input y_scale must be a scalar or 1D tensor of size 1
input y_zero_point must be a scalar or 1D tensor of size 1 if given
input zero point must be a scalar or 1D tensor of size 1.
Input/Output is a string tensor
Input: 
input_0
input_1
input_1.DataType() == input_2.DataType()
input_arg->Type() != nullptr
input_as_shape
input_copy_needed != DeviceCopyCheck::Unknown && output_copy_needed != DeviceCopyCheck::Unknown
input_count >= 0 && static_cast<size_t>(input_count) == input_dimensions_.size()
input_count >= 1
input_count_x3 >= 6 && input_count_x3 % 3 == 0
input_def_count >= 8 && (input_def_count - 2) % 3 == 0
input_dims.size() >= 2
input_dims[rank - 2] == input_dims[rank - 1]
input_forget
input_gather_element
input_gather_element_transform
input_ids
input_ids and position_ids shall have same shape
Input_ids and segment id should have the same shape. 
input_ids is expected to have 2 dimensions, got 
input_ids shall be 2 dimensions
input_ids_dims.size() == 2
input_indices.size() == expected_values.size() && input_indices.size() > 0
input_mean
input_node.InputDefs().size() == 2 && scale_and_index->second < 2
input_num_bytes % 4 == 0
input_offset >= 0 && output_offset >= 0
input_ptr
input_rank == permutation.size()
input_rank == reference_rank
input_scale
input_sequence
input_shape.Size() > 0 || input_shape[0] == 0
input_shape.Size() > 0 || N == 0
input_shape[i] == 1
input_shape_1_override.size() == 3 && input_shape_2_override.size() == 3
input_shape_1_override[0] == input_shape_2_override[0]
input_shape_1_override[2] == input_shape_2_override[1]
input_size < std::numeric_limits<std::ptrdiff_t>::max()
input_tensor != nullptr && indices_tensor != nullptr
input_tensor_ptr != nullptr
input_var
'input_var'.
input_zero_point
input->Exists()
InputBroadcaster can only start at span boundary!
InputCount
inputCount >= 1
InputDimensionCount
inputdimensions
inputdimensions attribute must be provided
InputFirstMomentTensor
InputGradientTensor
InputParametersTensor
InputPixelOffset
InputPixelOffsets
Inputs
inputs
Inputs 0 shall be 3 dimensions
Inputs 4 shall be 5 dimensions
inputs are expected to have tensor type and output type should not be null.
inputs are expected to have tensor type.
inputs by their magnitude, rather than gates inputs by their sign as in ReLUs.
Inputs have ellipses in them but the provided output subscript does not contain an ellipsis
Input's height (
Inputs 'mask_index' with 1D data shall have length of batch_size or 2 * batch_size
Inputs 'mask_index' with 2D data shall have shape batch_size x (past_sequence_length + sequence_length)
Inputs 'mask_index' with 3D data shall have shape batch_size x sequence_length x (past_sequence_length + sequence_length)
Inputs 'mask_index' with 4D data shall have is_unidirectional_ set to false
Inputs 'mask_index' with 4D data shall have shape batch_size x 1 x max_sequence_length x max_sequence_length)
Inputs 'past' dimension 0 shall have length of 2
Inputs 'past' dimension 1 shall have same length as dimension 0 of input 0
Inputs 'past' dimension 2 shall have length of 
Inputs 'past' dimension 2 shall have length of num_heads
Input's shape must be 4-D
Input's shape should be 1D or 2D
Input's width (
InputScaleTensor
InputSecondMomentTensor
InputStateTensor
InputTensor
InputTensors
InputWindowOffsets
InputWindowSizes
InputWindowStrides
InputZeroPointTensor
Inscriptional_Pahlavi
Inscriptional_Parthian
Insert and concatenate on a new axis or not, default 0 means do not insert new axis.
InsertCastTransformer works on the assumption that `dtype` attribute holds an integer.
inserted
InsertedCast_
InstanceNormalization
Insufficient dimensions to slice on 
int16
int1u
int32
int32_data
int3u
int64
Int64 tensor
int64_data
int64_vocabulary
int6u
int8u
Integer indicate the format of the box data. The default is 0. 0 - the box data is supplied as [y1, x1, y2, x2] where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute. Mostly used for TF models. 1 - the box data is supplied as [x_center, y_center, width, height]. Mostly used for Pytorch models.
Integer overflow
Integer representing the embedding vector size for each char.If not provide, use the char embedding size of embedding vector.
Integer representing the embedding vector size for each word.If not provide, use the fileter size of conv weight
Integer value expected, but not found.
inter_op_num_threads
inter_op_num_threads option in the model file must be an integer
intercepts
InterlockedFlushSList
internal error
Internal error in BatchNormalizationMulFusion. BatchNormalization_B_tensor_proto is NULL
Internal error. The preallocated buffer is too small. Requires 
InternalName
InternalTestingExecutionProvider
inter-op
-inter-op
InterpolationMode
interrupted
intra_op_num_threads
intra_op_num_threads option in the model file must be an integer
intra-op
-intra-op
inv_std_var
Invalid activation function of 
Invalid allocation kind: 
invalid allocator.
Invalid arg_num of 
invalid argument
Invalid argument for depth; it's not a scalar.
Invalid argument for values; either it's rank is more than 1 or it has more than 2 elements
Invalid argument: input has empty dimensions.
Invalid argument: X input has empty dimensions.
Invalid assumption of output element size
Invalid attribute perm {
Invalid axes attribute, axes attribute (if present) should have the same size as starts/ends attributes
Invalid batch_axis of 
Invalid bias shape
invalid BOM; must be 0xEF 0xBB 0xBF if given
Invalid CAST_TO value of 
invalid channel count
invalid character class
invalid character class range
invalid comment; expecting '/' or '*' after '/'
invalid comment; missing closing '*/'
Invalid data type 
Invalid data type for GRU operator of 
Invalid data type for LSTM operator of 
Invalid data type for split tensor 
Invalid data type of 
Invalid DataTypeImpl TypeProto definition
Invalid destination node arg slot specified when adding edge.
Invalid destination node arg slot specified when removing edge.
Invalid dim0_offset of 
Invalid dimension of 
Invalid dimension value: 
Invalid 'direction' argument of '
Invalid direction value of '
Invalid dtype of 
Invalid 'end'. Value is larger than 'start'.
Invalid entries in sequence_lens. Max sequence length was 
invalid escape sequence
Invalid ExecutionOrder
invalid expand shape
Invalid fd was supplied: 
Invalid Feed Input Name:
Invalid free dimension override.
Invalid GRU hidden gate activation function: 
Invalid GRU reset gate activation function: 
invalid hash bucket count
invalid index 
invalid index found, index = 
Invalid index requested for map type.
Invalid index: 
invalid indice found, indice = 
Invalid input B: 
Invalid input B: 0th dimension != 
Invalid input B: number of dimensions is not 1: 
Invalid input B: NumDimensions() != 
Invalid input data: number of dimensions is less than 3: 
Invalid input index for node 
Invalid input mean: 
Invalid input mean: 0th dimension != 
Invalid input mean: NumDimensions() != 
Invalid input scale: 
Invalid input scale: 0th dimension != 
Invalid input scale: number of dimensions is not 1: 
Invalid input scale: NumDimensions() != 
Invalid input shape. Only N can be zero. Got:
Invalid input shape: 
Invalid input type of value: 
Invalid input type:
Invalid input var: 
Invalid input var: 0th dimension != 
Invalid input var: NumDimensions() != 
Invalid key found: 
invalid literal
invalid location range
Invalid LSTM merge activation function of 
invalid map<K, T> key
Invalid 'mode' attribute value
Invalid mode of value 
Invalid model. Node input '
invalid named capture group
Invalid node indexes specified when adding edge.
Invalid node indexes specified when removing edge.
Invalid normalize value of 
Invalid number of outputs for BN training
invalid number; expected '+', '-', or digit after exponent
invalid number; expected digit after '-'
invalid number; expected digit after '.'
invalid number; expected digit after exponent sign
Invalid ORT format model.
Invalid Output Name:
Invalid PACK_MAP value of 
Invalid 'pads' attribute value
invalid perl operator
Invalid position of 0
Invalid position of 0.
Invalid program_counter entries at index 
Invalid rank for 
Invalid rank for input: 
Invalid RE2: 
invalid repetition size
Invalid roi input index.
Invalid run log severity level. Not a valid onnxruntime::logging::Severity value: 
invalid scales dimension
invalid scales value
Invalid scan input:
invalid seek
Invalid sequence index (
Invalid sequence length: 
Invalid session log severity level. Not a valid onnxruntime::logging::Severity value: 
Invalid shape value: 
Invalid source node arg slot specified when adding edge.
Invalid source node arg slot specified when removing edge.
Invalid SparseTensor indices. INT16 indices must be in the raw data of indices tensor
Invalid SparseTensor indices. INT8 indices must be in the raw data of indices tensor
Invalid SparseTensor indices. Should be rank 0 or 1. Got:
Invalid SparseTensor indices. Should one of the following types: int8, int16, int32 or int64
Invalid 'start'. Value is smaller than previous 'end'.
Invalid start/ending offset [
invalid stod argument
invalid stof argument
invalid stol argument
invalid stoll argument
invalid stoull argument
invalid string position
invalid string: '\u' must be followed by 4 hex digits
invalid string: control character U+0000 (NUL) must be escaped to \u0000
invalid string: control character U+0001 (SOH) must be escaped to \u0001
invalid string: control character U+0002 (STX) must be escaped to \u0002
invalid string: control character U+0003 (ETX) must be escaped to \u0003
invalid string: control character U+0004 (EOT) must be escaped to \u0004
invalid string: control character U+0005 (ENQ) must be escaped to \u0005
invalid string: control character U+0006 (ACK) must be escaped to \u0006
invalid string: control character U+0007 (BEL) must be escaped to \u0007
invalid string: control character U+0008 (BS) must be escaped to \u0008 or \b
invalid string: control character U+0009 (HT) must be escaped to \u0009 or \t
invalid string: control character U+000A (LF) must be escaped to \u000A or \n
invalid string: control character U+000B (VT) must be escaped to \u000B
invalid string: control character U+000C (FF) must be escaped to \u000C or \f
invalid string: control character U+000D (CR) must be escaped to \u000D or \r
invalid string: control character U+000E (SO) must be escaped to \u000E
invalid string: control character U+000F (SI) must be escaped to \u000F
invalid string: control character U+0010 (DLE) must be escaped to \u0010
invalid string: control character U+0011 (DC1) must be escaped to \u0011
invalid string: control character U+0012 (DC2) must be escaped to \u0012
invalid string: control character U+0013 (DC3) must be escaped to \u0013
invalid string: control character U+0014 (DC4) must be escaped to \u0014
invalid string: control character U+0015 (NAK) must be escaped to \u0015
invalid string: control character U+0016 (SYN) must be escaped to \u0016
invalid string: control character U+0017 (ETB) must be escaped to \u0017
invalid string: control character U+0018 (CAN) must be escaped to \u0018
invalid string: control character U+0019 (EM) must be escaped to \u0019
invalid string: control character U+001A (SUB) must be escaped to \u001A
invalid string: control character U+001B (ESC) must be escaped to \u001B
invalid string: control character U+001C (FS) must be escaped to \u001C
invalid string: control character U+001D (GS) must be escaped to \u001D
invalid string: control character U+001E (RS) must be escaped to \u001E
invalid string: control character U+001F (US) must be escaped to \u001F
invalid string: forbidden character after backslash
invalid string: ill-formed UTF-8 byte
invalid string: missing closing quote
invalid string: surrogate U+D800..U+DBFF must be followed by U+DC00..U+DFFF
invalid string: surrogate U+DC00..U+DFFF must follow U+D800..U+DBFF
Invalid Target shape product of 0
Invalid Target shape product of 0. Product cannot be 0 in combination with -1
Invalid tensor data type 
Invalid tensor shape slice argument.
Invalid TensorProto
Invalid time_axis of 
Invalid type
invalid unordered_map<K, T> key
Invalid usage. Input 1 is a shape with no data.
invalid UTF-8
Invalid value for attribute axis
Invalid value for attribute k
Invalid value in scan_input_axes for input 
Invalid value in scan_output_axes for output 
Invalid value in 'split' attribute. All values must be > 0
Invalid value in 'split' input. All values must be >= 0
Invalid value of attribute 'axis'. Accepted range=[
Invalid value of attribute 'axis'. Rank=
Invalid value(
Invalid value/s in sequence_lens. All values must be > 0 and < seq_length. seq_length=
Invalid values in '
invalid vector subscript
Invalid Y argument: index is out of range: Y[
Invalid Y argument: num_indices = 0
INVALID_ARGUMENT
INVALID_GRAPH
invalid_iterator
INVALID_PROTOBUF
Inverse
inverse_indices
InvStdDev
InvStdDev = Reshape (InvStdDev2D, ReducedShape)
InvStdDev2D = Reciprocal (StdDev)
io error
ios_base::badbit set
ios_base::eofbit set
ios_base::failbit set
iostream
iostream stream error
iou_threshold
iou_threshold must be in range [0, 1].
IpD;I`
Irfft
irVersion
is a directory
is applied to the data tensor elementwise.
is applied to the tensor elementwise.
'is defined.
is not supported.
is_case_sensitive
is_concrete_shape_
is_model_proto_parsed
is_spatial_
is_test
IsAllFinite
IsBQuantParamSupported(b_offset->Shape(), b ? b->Shape() : b_shape_)
IsBQuantParamSupported(b_scale->Shape(), b ? b->Shape() : b_shape_)
IsBQuantParamSupported(b_zero_point->Shape(), b ? b->Shape() : b_shape_)
IsBQuantParamSupported(b_zp_tensor->Shape(), b_tensor ? b_tensor->Shape() : b_shape_)
IsDebuggerPresent
IsInf
isinf_only
ISink must be provided.
IsNaN
isnan_only
IsOptionalSeqTensor(type)
IsOptionalTensor(type)
IsProcessorFeaturePresent
isRedist
IsSameDataType(tensor)
IsScalarOr1ElementVector(a_offset)
IsScalarOr1ElementVector(a_scale)
IsScalarOr1ElementVector(a_zero_point)
IsScalarOr1ElementVector(a_zero_point_tensor)
IsScalarOr1ElementVector(a_zp)
IsScalarOr1ElementVector(k)
IsScalarOr1ElementVector(tensor_a_scale)
IsScalarOr1ElementVector(tensor_b_scale)
IsScalarOr1ElementVector(tensor_c_scale)
IsScalarOr1ElementVector(tensor_x_scale)
IsScalarOr1ElementVector(tensor_x_zero_point)
IsScalarOr1ElementVector(tensor_y_scale)
IsScalarOr1ElementVector(tensor_y_zero_point)
IsScalarOr1ElementVector(W_Zero_Point)
IsScalarOr1ElementVector(X_scale)
IsScalarOr1ElementVector(X_Zero_Point)
IsScalarOr1ElementVector(X_zero_point)
IsScalarOr1ElementVector(y_offset)
IsScalarOr1ElementVector(y_scale)
IsScalarOr1ElementVector(Y_scale)
IsScalarOr1ElementVector(Y_zero_point)
IsSparseTensor()
IsTensor()
IsTensorSequence()
IsValidQuantParam(W_scale, M)
IsValidQuantParam(W_zero_point, M)
it->i < (int64_t)predictions.size()
iteration_num_ < sequence_len_
iterator does not fit current value
iterator out of range
itr != node_args.end()
It's an extension of Gelu. It takes the sum of input A and bias input B as the input of Gelu activation. 
IZfD;
j .",
J 9y(
J Hcy H
j l"j$f&l(n*n,n.p0n2l4f6h8f:f<P>2
J V$V(`,
J$0 B$
J%t#_
J&L0N*P"^z`H^L\
J(BH<n>NL
j(fXdfvvx(z8|
J.H@<
J>f;O
j8L;u
Javanese
JD9H(tKH
jdgqm
jkpFE'
JLkmk
job_.size() = 
jOBh9G
j-R,H
Json stored in the `ort_config` key cannot be parsed. Error message: 
JY]Gv
k and v are not from same Split node
k argument [
K HcC
K HcC,H
K input must be a one-dimensional tensor of size 1.
K input must be of type int64.
k root is not layer norm
k should be a 1-D or 0-D tensor.
K SUVWAUAVAWH
k tensor should be a 1D tensor of size 1
k VWAVH
K(9H(u
K,9H,u
K?[2\1
k_matmul and k_add shape not matched
k_reshape const not matched
k_temp > 0
k_transpose has not perm attribute
k_transpose perm attribute not matched
K}UeW
K0D;0
K0H9KHu
K0HcQ
K4UG'
Kaithi
Kannada
Katakana
Kayah_Li
KbbeHQ
KBc~Vo
Keep the reduced dimension or not, default 1 mean keep reduced dimension.
Keep the split dimension or not. Default 1, which means we keep split dimension. If input 'split' is specified, this attribute is ignored.
keepdims
Kernel
kernel != nullptr
Kernel create info hashes are null. Invalid ORT format model.
Kernel create info is null. Invalid ORT format model.
Kernel create info node indices are null. Invalid ORT format model.
kernel def can't be NULL
Kernel not found
kernel_info != nullptr
kernel_params
kernel_shape
kernel_shape is not compatible with W shape.
kernel_shape num_dims is not compatible with W num_dims.
kernel_shape num_dims is not compatible with X num_dims.
kernel_shape[dim] > 0
kernel_shape_[dim] > 0
kernel_type
kernel32.dll
KERNEL32.DLL
kernelbase.dll
key '
key and value cache dimensions value shall not be null
key and value cache shall be 4 dimensions
Key and value tensors have unequal number of elements.
Key type is not supported yet.
key_cache
key_padding_mask
key_type
keys_floats
keys_int64s
keys_strings
Kharoshthi
kHcK(H
Khitan_Small_Script
KHL9C`u&
Khmer
Khojki
Khudawadi
KJSpMi
kkW4+w
KLNAp
known by the checker.
KpD;K`|xA
KPI;O
kRegexpCapture cap() == 0
kSpz{
ktJE;c
kv_weight
L 6$M
L!|$(L!
L!|$hH
L!|$XH
L!}@I
L!B 3
L!D$ E3
L!d$(L!d$@D
L!l$P
L!m@I
L!t$ H
L!t$0H
L!t$pH
L"Dh>L@
L#b0M
L#q0L
L#q0M
L#r0M
L#V0H
L#z0M
L$ @8y
l$ A*
L$ E2
L$ E3
l$ E3
L$ E3
l$ E3
L$ E3
l$ E3
L$ E3
L$ fA
L$ fE#
l$ H!|$(
L$ H;
L$ H+
L$ H3
L$ I;
l$ I+
l$ Ic
l$ Ic}
L$ L;
L$ L;L$ u
l$ L;O
L$ L+
l$ M;
L$ SUVWAVAWH
L$ SUVWH
L$ SWH
L$ UVWATAUAVAWH
l$ VATAUAVAWH
l$ VAVAWH
l$ VWATAUAVAWH
l$ VWATAUAVH
l$ VWATAVAW
l$ VWATAVAWH
l$ VWATAVAWL
l$ VWAUAVAWH
l$ VWAVAWH
l$ VWAVH
l$ VWAVI
l$ VWAVL
l$ VWL
l$ WATAUAVAWH
l$ WH
l$$D9m
L$(;|$ ~HLcD$ 
L$(9J(
L$(A9}
L$(E3
L$(fH
L$(H!D$8H
L$(H;
l$(H;
L$(H;
L$(H;W
l$(H+l$ H
L$(H3
L$(H91u
L$(I!C
L$(I;
L$(I+
L$(L;
l$(L;O
L$(L9[`L
l$(M+
L$,L;
L$@;|
L$@@8x
L$@`L
l$@A_A^_^
L$@D;
L$@D;o
L$@E3
L$@H;
l$@H;
L$@H;
L$@H+L$8H
L$@H3
L$@H9
L$@H9A }
L$@Hc
l$@Hk
l$@I;
L$@I;
l$@I;
L$@I;
l$@I;
L$@I;
L$@I+
L$@Ic
L$@L+
l$@L9I 
l$@L9m
l$@M;
L$@Mch(E3
l$`;G 
L$`;M
l$`9_8
L$`D9v
L$`E3
L$`H!D$pH
L$`H;
L$`H3
L$`I;
L$`L;
L$`LcG
l$`M;
L$`M;
l$`M9Y@
L$|L;
l$0@8}
L$0@8q
l$0@8u
l$0_^
L$09Q |
L$0D;E
l$0D8
L$0D8P8
L$0D9A |
L$0E2
L$0E3
l$0E3
L$0E3
l$0E3
L$0E3
L$0fD
L$0H;
l$0H;
L$0H;
L$0H;L$8u
L$0H;L$hu
L$0H;W
L$0H+
L$0H3
L$0H9
L$0H90H
L$0H9Q }
L$0Hc
L$0I;
l$0I+
l$0I+l$(H
L$0L;
l$0L;O
l$0L9
L$0M;
l$0M9o
L$4L;
l$8A^_^
l$8A^A]_^
L$8D;
l$8D;l$@
L$8E3
l$8E3
L$8E3
l$8E3
L$8E3
l$8E3
L$8E3
l$8E3
L$8E3
l$8H;
L$8H;
l$8H;
L$8H;
l$8H;
L$8H;
l$8H;
l$8H+
L$8H+
l$8H+
L$8H+
l$8H+
L$8H+
L$8H+L$0H
L$8H3
L$8H9A }
l$8I+
L$8L;
L$8tBH
L$d@H
L$DE3
l$GL;
L$h;M
L$h@8
L$h8Y
l$HA;
l$HA_A^A]_^
L$HE3
L$hE3
L$HE3
L$hE3
L$HE3
l$HfA
L$hH!D$x
L$HH;
L$hH;
L$HH;
L$hH;
L$HH;
l$HH;|$@
L$hH;L$pt
L$HH;L$Xt)
L$HH+
L$hH+
l$hH+
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH3
L$HH3
L$hH9
L$hHc
L$HHc
L$hHc
l$HI;
l$hI;
L$HIc
l$HIc
l$HL;l$Pt
l$HL9l$0
l$hL9y 
L$HM;
l$huDM
l$huEM
l$huFM
l$huRM
L$'I;
L$lA99
L$p+M
l$p9n 
l$PA_A^A]A\_^
L$PD;G
L$PE3
l$PE3
L$PE3
l$PE3
L$pE3
L$PE3
l$pfD
L$pH!
L$pH!E
L$PH;
L$pH;
L$PH;
L$pH;
L$PH;
L$pH;
L$PH;
l$PH;
L$pH;
L$PH;
L$pH;A
L$PH;L$pt,
L$pH+
L$PH+
L$pH+
L$PH+
L$pH+
L$PH+
L$pH+
L$PH+L$HH
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
L$pH3
L$PH3
l$PH9
l$pHc
L$pHc
l$pHc
L$pI;
L$PI;
l$PI+
L$PIc
L$PL!D$PH
l$PL;
L$pL;
L$PL+
L$pM;
l$PM;
l$pM;Q`s7I
l$pM+
L$u>xG
L$X9O 
L$xE3
L$XE3
L$xE3
L$XE3
l$XE3
L$XE3
L$XH!D$hH
l$xH!t$PH!t$X
L$XH;
L$xH;
l$xH;
L$xH;A
L$XH+
L$xH+
L$XH+
L$xH+
L$XH+L$PH
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$XH3
L$xH3
L$xH9
L$XH9
L$xH9
L$XH9
L$XI;
l$XI9}
L$XIc
l$XL;
l$XL;}
l$xL+
l$XL9
l$xM+
L$xM9K
l$xu]M
l$xu^M
l$xu`M
l$xuaM
l$xujM
l$xumM
l$xunM
l$xupM
l$xuUM
L((H9J
L)l$ I
l*Zd!d2
l,n2lNpJtTvXpDxTz
l,nFl
L;@(u
L;[h|
L;|$ 
L;|$(
L;|$@t
L;|$P
L;|$pL
L;|$ps
L;|$X
L;A }<M
L;A H
L;A r
L;A(tCD
L;b }
L;B s
L;D$(|
L;D$(uYH
L;d$@t
L;D$`u
L;D$0|
L;d$8L
L;d$8t'
L;D$8uJH
L;d$h
L;D$H|
L;d$P
L;D$P
L;d$pI
L;D$PuLH
L;E(|
L;E8t
L;E8t I
L;Fp|)H
L;H(u
L;I r_I
L;J r
L;J(t
L;L$(A
L;L$(t
L;l$h
L;L$H|
L;l$P
L;L$P|
L;l$Pu
L;L$PurM
L;L$X
L;MhI
L;o |
L;o }gH
L;P(u
L;R s
L;R(u
L;sp| H
L;t$(u
L;t$0t
L;t$8D
L;t$H
L;T$H
L;t$P
L;t$X
L;W8r
L;wHt>M+
L;wHu
L;y r
L;Z r
L;Z(u
l?4?~?
l?4?~?4?~?4?~?4?~?
L@P(R
L\XXL
L_"_k
L+,$H
L+|$8
L+|$pI
L+~ L
L+<0x
L+CxH+
L+D$PI
L+d$xJ
L+ExI
L+F0I
L+IHL
L+QxH+
L+t$(I
L+t$@I
L+t$HB
L+T$HH
L+t$HO
L+t$PL
L>2?~>
L>2?~>2?~>2?~>2?~>
L0B~.
L0N(P0R4T
L0Vj(lN5
L0X(Z0\(^0`,b0d*f!
L0Xj"]
l5]m3
L9 spH
L9 t.H
L9)~oE
L9:u{I
L9;|1L9{
L9@ s
L9[h~eH
L9[h~iH
L9` }
L9`0H
L9{8L
L9{HL
L9|$@
L9|$@t6
L9|$8t>
L9|$h
L9|$ht]
L9|$ht8
L9|$x
L9|$xu
L9}pt?
L9}xt5
L90u"H
L95gJg
L97uJH
L98uSH
L9A s
L9A t
L9A(L
L9a0H
L9aHs
L9aht<H
L9c`L
L9C0H
L9CXL
L9D$(
L9d$@
L9d$@t>
L9d$@t4
L9d$`
L9d$P
L9d$pu
L9d$X
L9E/u
L9ept:
L9eptg
L9epu:H
L9g(ufH
L9g8u
L9H }
L9H s
L9h0H
L9I0H
L9j(H
L9j0H
L9kHu
L9KXL
L9l$8u
L9l$Xu@H
L9m@u
L9nHs
L9o(v\I
L9O@t
L9o0H
L9P }
L9p s
L9P0H
L9Q s
L9Q0H
L9r0H
L9s8t?I
L9sht
L9SPL
L9t$0t>
L9t$htX
L9T$X
L9u`u
L9u0u
L9uPu
L9u't:
L9u't7
L9uwu
L9x s
L9X s
L9X0H
L9x0H
L9X0L
L9y8E
Label encoder has only one input.
Label encoder has only one output.
LabelEncoder
labels
lambd
largest
largest <= 1
last >= first
Last dimension of `indices` input tensor in GatherND op must not be larger than the rank of `data` tensor
Last dimension of beta and input does not match
Last dimension of bias and input does not match
Last dimension of gamma and input does not match
Last dimension of grid: 
last dimension of indices must not be larger and rank of data tensor
last dimension of indices must not be larger than rank of input tensor
last_loop_red_size > 0
last_loop_size > 0
last_outputs[j + 1].IsTensor()
Latin
layer_norm_out
layernorm_out
LayerNormalization
LayerNormFusion
layout
layout_ == 0
Lc@(H
Lc`,M
Lc{(J
Lc{8I
Lc{8J
Lc{8K
Lc{hJ
Lc}(M
Lc}XM
Lc8E3
LcA H
LcA$H
LcA<E3
LcC0A
Lcd$(H
Lcd$tE
LcEPHcUHHcM@L
LcepI
LcF(I
LcF8I
LcFhI
LcG$H
LcG(I
LcG`H
LcG0A
LcG8I
LcGhI
lCKR1
Lcl$(H
Lcl$0H
Lcl$x
LCMapStringEx
LcMwI
LcO@I
LcOXI
LcQ,H
Lcr(J
Lcr8J
Lcr8K
LcrhJ
LcT$(I
LcT$@I
LcT$0H
LcV(LcF$A
Lcx H
lda >= K && ldb >= K && ldc >= N
LeakyRelu
leakyrelu
LearningRate
LeaveCriticalSection
left operand cannot broadcast on dim 
Left shape: 
left.NumDimensions() == 2 || left.NumDimensions() == 1
left.Shape().Size() == left_shape_override.Size()
left_dim == right_dim
left_num_dims and right_num_dims must be >= 1
left_rank == right_rank
legacy optimization attribute.
LegalCopyright
len <= op_schema.inputs().size()
len >= 0 && static_cast<uint64_t>(len) < std::numeric_limits<size_t>::max()
length
length > buffer.size()
length of each output
length of each output. Values should be >= 0.
Length of permutation must match the rank of the input to be permutated
length overflow
lengths allocation failed
Lepcha
LessOrEqual
Level
Limbu
limit
limit in Range operator should be scalar like tensor, yet got shape:
linear
LINEAR
Linear
'Linear' mode only support:
Linear_A
Linear_B
linear_before_reset
LinearBeforeReset
LinearClassifier
LinearRegressor
list count 
List of 3 elements containing gamma, coef0, and degree, in that order. Zero if unused for the kernel.
List of categories, ints.<br>One and only one of the 'cats_*' attributes must be defined.
List of categories, strings.<br>One and only one of the 'cats_*' attributes must be defined.
list of floats. This attribute stores the weight of each n-gram in pool. The i-th element in weights is the weight of the i-th n-gram in pool. Its length equals to the size of ngram_indexes. By default, weights is an all-one tensor.This attribute is used when mode is "IDF" or "TFIDF" to scale the associated word counts.
List of int64 n-grams learned from the training set. Either this or pool_strings attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
list of int64s (type: AttributeProto::INTS). This list is parallel to the specified 'pool_*' attribute. The i-th element in ngram_indexes indicate the coordinate of the i-th n-gram in the output tensor.
List of integers indicate the padding element count at the beginning and end of each axis, for 2D it is the number of pixel. `paddings` rank should be double of the input's rank. `paddings` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
List of integers indicating the dimensions to be inserted. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(expanded).
List of integers indicating the dimensions to squeeze. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
List of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D it is the number of pixels. `pads` rank should be double of the input's rank. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
List of non-negative integers, indicate the dimensions to be inserted
List of non-negative integers, indicate the dimensions to squeeze.
List of stop words. If not set, no word would be removed from X.
List of strings n-grams learned from the training set. Either this or pool_int64s attributes must be present but not both. It's an 1-D tensor starting with the collections of all 1-grams and ending with the collections of n-grams. The i-th element in pool stores the n-gram that should be mapped to coordinate ngram_indexes[i] in the output vector.
List of tensors for 
list too long
lj(lN
load external data into raw data for tensor: 
Load model 
Load model from 
loadedFrom
loading_ort_format && serialized_session_state != nullptr
LoadLibrary failed with error 
LoadLibraryExA
LoadLibraryExW
LoadLibraryW
LoadNodeArgsFromOrtFormat: Node [
loatu
Local\SM0:%d:%d:%hs
locale
LocalFree
LocalSize
localtime_s(&local_tm, &in_time_t) == 0
location
location dimensions do not match shape size
log_prob
LogHr
LOGISTIC
LOGISTICL9
LogSoftmax
LogStart must pair with LogEnd
Long tensor containing the indices to extract from embedding matrix.
LongformerAttention
Loop 'body' subgraph outputs should all be tensors but output 
Loop 'body' subgraph outputs should all be tensors or sequences but output 
Loop 'body' subgraph outputs should all be tensors or sequences or optionals, but output 
Loop 'body' subgraph scan outputs should all be tensors but output 
Loop had zero iterations and the shape of subgraph output 
'Loop' input 'cond' should be a scalar tensor. Got shape of 
'Loop' input 'M' should be a scalar tensor. Got shape of 
'Loop' node has 
Loop subgraph input 0 has unknown shape: 
Loop subgraph input 1 has unknown shape: 
loss_N1dd
loss_NCdd
loss_Ndd
loss_sum
loss_unweighted
LOWER
Lower boundary of the output values.
LpNormalization
LpPool
lR:KWX
lrt(v6x
LSTM operator does not support double yet
LSvw-
lv'SG
Lycian
Lydian
LZH8F
M A+M0+
M H!E03
M H!E0H
M H1E
M#^0M
M#B0M
M#C0I
M#u0H
M#u0M
M#x0M
M(A+M0A
M(H!E8H
M(L9 
M(L9 u8H
M/H+M'H
M;A M
M;A(u
M;B |
M;H I
M;K r
M;l$0v
M;Q(t
M;Q8|
M;w(t
M;Xp| I
M;YpsvH
M;Z(t
M@H!EPH
m@I#u0H
M_ == 1 && N_ == 1 was false
M_ >= 0 && K_ > 0 && N_ >= 0
M`H!Ep
M`H!EpI
M`H;Mhs
M+,$L
M+<$I
-M+1+
M0@8x
M09L8
M0D!e8H
M0D!m8H
M0H+M(H
M0K0I
M7H!EGE3
m8D9a 
M8H+M0H
M9 t0H
M9&jp[
M9,$I
M9~Hs
M94$t
M94$t2I
M94$u
M9aXM
M9b`M
M9e(I
M9f`t
M9fpt
M9g0I
M9H s
M9H s,I
M9iPM
M9o H
M9o u}L
M9o uzL
M9P0I
M9Q@M
M9q0I
M9Q8~iI
M9Q8~tI
M9t$(t
M9uht
Mahajani
Main Graph instance should have populated all subgraphs when being resolved.
Makasar
Malayalam
Malformed repeat 
Mandaic
Manichaean
Map is missing type entry for its value
map(int64, double)
map(int64, float)
map(int64, string)
map(string, double)
map(string, float)
map(string, int64)
map/set too long
map_form
map_form_ != PACK_MAP::SPARSE || max_map_ > 0
map_formH
map_type
MapFileIntoMemory is not implemented on Windows.
Marchen
Masaram_Gondi
Mask data type is not int32 or int64 or float32
Mask is neither unidirectional nor all ones
Mask shape is unknown or not 2D, or data type unknown
mask_index
mask_index_out
Mask_Int32
mask_mul const input not matched
mask_sub const input not matched
mask_unsqueeze_1 axes not matched. Expect: 1
mask_unsqueeze_2 axes not matched. Expect: 2
MaskCastH
Match contains invalid utf8 chars: 
Matched 
MatchInputMaskSubgraph returns false
MatchPastSubgraph returns false
MatchUnidirMaskSubgraph returns NULL
MatMul
MatMul dimension mismatch
MatMul_With_Transpose
MatMulAddFusion
MatMulInteger
MatmulInteger : B zero point is not valid
MatmulInteger : b zero point is not valid
MatmulInteger : input1 A_scale must be a scalar or 1D tensor of size 1
MatmulInteger : input1 A_zero_point must be a scalar or 1D tensor of size 1 if given
MatmulInteger : input1 B_scale must be a scalar or 1D tensor of size 1
MatmulInteger : input1 B_zero_point must be a scalar or 1D tensor of size 1 if given
MatmulInteger : input1 C_scale must be a scalar or 1D tensor of size 1
MatmulInteger : input1 C_zero_point must be a scalar or 1D tensor of size 1 if given
MatmulInteger : input1 zero point must be a scalar or 1D tensor of size 1
MatMulInteger16
MatMulIntegerToFloat
MatMulIntegerToFloat : input a zero point must be a scalar or 1D tensor of size 1. Per-Channel is not supported yet.
MatMulIntegerToFloatFusion
MatMulScaleFusion
MatmulTransposeFusion
Matrix dimensions are not equal. Square matrix is expected
Matrix multiply results
Matrix multiply results from A * B
Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html
Matrix product that behaves like numpy.matmul: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.matmul.html.
max should be a scalar.
max_dead_bytes_per_chunk
max_gram_length
max_gram_length must be inbounds of ngram_counts: 
max_map
max_map must be > 0 if map_form is SPARSE
max_mem
max_ngram_size
max_ngram_size_ > 0
max_ngram_size_ >= min_ngram_size_
max_output_boxes_per_class
max_skip_count
max_skip_count is required
max_skip_count must be non-negative: 
max->Shape().IsScalar()
Maximum n-gram length. If this value is 3, 3-grams will be used to generate the output.
Maximum number of events reached, could not record profile event.
Maximum number of items (integers/strings) to be skipped when constructing an n-gram from X. If max_skip_count=1, min_gram_length=2, max_gram_length=3, this operator may generate 2-grams with skip_count=0 and skip_count=1, and 3-grams with skip_count=0 and skip_count=1
Maximum value, above which element is replaced by max
MaximumSamplesPerOutput
MaxPool
MaxpoolWithMask
MaxRoiPool
MaxUnpool
MaxUnpool op must have either two or three inputs.
MBCBV
mbL(^*
McF8M
McFpH
Mcn8K
McUPL
ME9gX
Mean = Reshape (Mean2D, ReducedShape)
mean@
Mean2D = ReduceMean <axes = [1]> (XU)
meanD
MeanOfSquare = ReduceMean <axes = [1]> (Square)
MeanTensor
MeanVarianceNormalization
Medefaidrin
Meetei_Mayek
Mem pattern should be disabled when using DML execution provider.
mem_steps <= max_memory_steps_ && mem_steps > 0
Memcpy
MemcpyFromHost
MemcpyToHost
MemcpyTransformer
Memory pattern planner is not enabled on this execution framework.
memory.enable_memory_arena_shrinkage
memory_seq_lens
Mende_Kikakui
Meroitic_Cursive
Meroitic_Hieroglyphs
message size
metadef_id_generator_
Method IncrementIndexAndComputeOffset assumes this value is strictly positive.
metric
MGD;}
MGHcG
MhH!Ex
MHH!EXH
MhH!ExH
MHH;Mht
MhH;Mpt1H;
MHL;MPt0H
mHL;U`
-mhU?
Microsoft
Microsoft America Operations1&0$
Microsoft Corporation
Microsoft Corporation1
Microsoft Corporation1%0#
Microsoft Corporation1&0$
Microsoft Corporation1.0,
Microsoft Corporation1200
Microsoft Time-Stamp PCA 2010
Microsoft Time-Stamp PCA 20100
Microsoft Time-Stamp Service
Microsoft Time-Stamp Service0
Microsoft Windows0
Microsoft.ML.ONNXRuntime
MIGraphXExecutionProvider
min should be a scalar.
min_ <= max_
min_gram_length
min_gram_length >= max_gram_length required: 
min_gram_length is required
min_gram_length must be inbounds of ngram_counts: 
min_ngram_size
min_ngram_size_ > 0
min->Shape().IsScalar()
mincharnum
mincharnum is too big for char level tokenezation
mincharnum_ > 0
Minimum n-gram length. If this value is 2 and max_gram_length is 3, output may contain counts of 2-grams and 3-grams.
Minimum number of characters allowed in the output. For example, if mincharnum is 2, tokens such as "A" and "B" would be ignored
Minimum value, under which element is replaced by min
MinimumSamplesPerOutput
MinMaxDataType
Mismatch between expected shape and shape from first output
Mismatch between Graph and IndexedSubGraph. Input not found:
Mismatch between Graph and IndexedSubGraph. Node not found: 
Mismatch between Graph and IndexedSubGraph. Output not found:
Mismatch between input data and B: size of B != input channel count 
Mismatch between input data and scale: size of scale != input channel count 
Mismatch between number of source and target dimensions. Source=
Mismatch between number of splits (
Mismatch between source and target type. Source=
Mismatch between the sum of 'split' (
Mismatched attribute type in '
Mismatched data types between input and output Tensors. 
Mismatched sparse tensor element type:
Mismatched tensor element type for output 
Mismatched tensor element type:
Mismatched type for output 
Mismatched type:
missing )
missing ]
Missing case in Compiler: 
Missing dimensions for initializer. Invalid ORT format model.
Missing dims for sparse initializer: 
Missing 'equation' attribute
Missing indicies for sparse initializer: 
Missing Input: 
Missing model IR version.
Missing Model. Invalid ORT format model.
Missing name for SparseTensor initializer. Invalid ORT format model.
Missing opset in the model. All ModelProtos MUST have at least one entry that specifies which version of the ONNX OperatorSet is being imported.
Missing or invalid starts and ends attribute
Missing raw data for initializer. Invalid ORT format model.
Missing session state for subgraph. Node:'
Missing string data for initializer. Invalid ORT format model.
Missing values for sparse initializer. Invalid ORT format model.
Missing/Invalid 'axes' attribute value
Missing/Invalid 'axis' attribute value
Misuse of LoopStateVariable. Attempt to move beyond end of sequence
ml_type != nullptr
mL+1I
MLDataType for: 
mlvalue.Fence() == nullptr
mode "
mode attribute is 
mode is required
mode: 
mode_str == "bilinear" || mode_str == "nearest" || mode_str == "bicubic"
Model file not found!
model format error!
model format error! Missing 'location'
model format error! Need a key for the external data info
model format error! Need a value for the external data info
Model must have opset imports. Invalid ORT format model.
Model was not loaded
Model was not loaded.
MODEL_LOADED
model_loading_array
model_loading_from_saved_proto
model_loading_proto
model_loading_uri
model_path must not be empty. Ensure that a path is provided when the model is created or loaded.
model_run
modelDomain
modelGraphName
modelMetaData
modelProducerName
modelProducerVersion
ModelProto corresponding to the model to be loaded has already been parsed. Invoke Load().
ModelProto corresponding to the model to be loaded has not been parsed yet. This API should be called in conjunction with a ctor that takes a model abstraction.
ModelProto does not have a graph.
ModelProto needs to be parsed to check for ORT config within it
momentum
momentumH
Mongolian
More work items than threads
Move it out of graph inputs if there is no need to override it, 
MP8A }
MpH;M
MpH+MhH
MPI;MP
MPI9~h
MpL9}
Msg:[%ws] 
mul_B_tensor_proto
mul_inputs.size() == 2
MulInteger
Multani
multi_class
MultiByteToWideChar
Multinomial
Multiple entries for operator is not supported. OpType=
Multiple errors were found.
multiplication
Multiplicative spatial scale factor to translate ROI coordinates from their input scale to the scale used when pooling.
Multiplicative spatial scale factor to translate ROI coordinates from their input spatial scale to the scale used when pooling, i.e., spatial scale of the input feature map X relative to the input image. E.g.; default is 1.0f. 
MurmurHash3
Must be a scalar or 1D tensor or size 1.
must be overloaded.
Must contain BlockSparse format. Got: 
Must contain Coo format. Got: 
Must contain Csr format. Contains: 
Must have 1 or more inputs
Must have a single dimension
Must have a single dimension of 1
Must have a valid data type
Must have a valid input shape.
Must have the same shape
Must have the same size. Got src_size: 
Must have valid 'axis' attribute
Must provide classlabels_strings or classlabels_int64s but not both.
Must provide imputed_values_float_ or imputed_values_int64_ but not both.
Must use Function based fusion when exporting compiled nodes to dll.
mutually equal shape is specified by the argument "axis", and if it is not set,
mwtMH
MXD;J
MXH!Eh
MxH+MpH
MXH9u
MXI;u
MxL+MpI
Myanmar
N ^"b B
n <= num_threads_+1
n >= 0
n >= 0 && static_cast<size_t>(n) < ort_value_info_.size()
n >= 0 && static_cast<size_t>(n) < plan_.allocation_plan.size()
n 4J>L
N 9H uaA
N A+N0+
N H+N
N HcF
n".$,
N"PZNX@u
n&Mvu
n(.*,
n(@8~)
n(@8~)u~H
n(^:~
N(LTFhHVP
n(p6rjt(vNx0|x~x
n(pFh:r
N(RTD
N*<0~<.>,
N,E8n4I
n?&w`
n_supports
n_targets
n_targets_or_classes > 0
N`J8H
N|Mb%
N0HcF(L
N0I;N8t8H
N0L0J
N8H+N0H
Nabataean
name:
name: 
Nandinagari
naxes > 0
NchwcTransformer
N-dimensional dense matrix B
N-dimensional matrix A
N-dimensional matrix B
nearest
NEAREST
nearest_mode
nearest_mode:[
Negative index values are not permitted. First entry in map has index value of 
Negative ngram_indexes values are not allowed
Negative values are not allowed in a shape specification
NegativeLogLikelihoodLoss
Nested parallelism not supported
network down
network reset
network unreachable
New shape
new_axis
new_axis must be either 0 or 1
new_axisH
new_gemm_input_defs.size() == 3
new_gemm_output_defs.size() == 1
new_key_cache
new_num_elts == old_num_elts
New_Tai_Lue
new_value_cache
n-gram counts out of bounds for 
ngram_counts
ngram_indexes
ngram_indexes must be non-empty with no negative values
ngram_size
ngram_size_ > 0
NGramRepeatBlock
NHH;NPu
Nhttp://www.microsoft.com/pkiops/crl/Microsoft%20Time-Stamp%20PCA%202010(1).crl0l
NhwcMaxPool
NhwcTransformer
nj(lNnBp&rBt
njob_ = 
nlj2h8fv
NnapiExecutionProvider
No allocator for this device has been registered for sharing.
no argument for repetition operator
No attribute with name:'
No attribute with name: 
No attribute with this name is defined.
no buffer space
no child process
no error
No Graph instance was found for attribute 
No graph was found in the protobuf.
No kernel shape is set.
no link
no lock available
No matching 'start' entry.
no message
no message available
No NodeArg found for name 
No Op registered for 
No opset import for domain '
No opset registered for domain 
no protocol option
No provider specified.
No ranges in char class
No requested allocator available
no space on device
no stream resources
no such device
no such device or address
no such file or directory
no such process
NO_MODEL
NO_SUCHFILE
Node 
Node (
Node [
Node id for each node. Ids may restart at zero for each tree, but it not required to.
Node id for each node. Node ids must restart at zero for each tree and increase sequentially.
node id that this weight is for.
Node index is out of range
Node index value is too large to save to ORT format model: 
Node is missing. Invalid ORT format model.
Node must only have one used output
Node placements
Node:
Node::LoadEdgesFromOrtFormat, edge is missing for 
Node::LoadFromOrtFormat, input_arg_counts is missing
node_arg
node_arg_ != nullptr
node_arg_name cannot be null
node_idx <= NodesToOptimizeIndices::kEmptyNodeIndex
node_in_parent_graph->InputDefs().size() == function_body_graph.GetInputsIncludingInitializers().size()
node_in_parent_graph->OutputDefs().size() == function_body_graph.GetOutputs().size()
node_index < nodes_.size()
node_index_info and ort_value_idx_map are out of sync and cannot be used
node_index_info_
node_index_info_.GetMaxMLValueIdx() == ort_value_idx_map.MaxIdx()
node_offsets_index < node_offsets_size_
node->GetOutputEdgesCount() == 0
nodearg
NodeArg is missing. Invalid ORT format model.
NodeArg Name is missing. Invalid ORT format model.
NodeEdge is missing. Invalid ORT format model.
NodeProto (name: 
Nodes in a graph must be topologically sorted, however input '
nodes_.size() < static_cast<unsigned int>(std::numeric_limits<int>::max())
nodes_falsenodeids
nodes_falsenodeids.size() == nodes_featureids.size()
nodes_falsenodeids.size() == nodes_modes.size()
nodes_falsenodeids.size() == nodes_nodeids.size()
nodes_falsenodeids.size() == nodes_treeids.size()
nodes_falsenodeids.size() == nodes_truenodeids.size()
nodes_falsenodeids.size() == nodes_values.size()
nodes_featureids
nodes_hitrates
nodes_missing_value_tracks_true
nodes_modes
nodes_nodeids
nodes_treeids
nodes_truenodeids
nodes_values
Non concat axis dimensions must match: Axis 
Non per-tensor quantization is not supported now.
non_tensor_base != nullptr
NONED
noneD
NONED
noneD
NONED
Non-empty ngram_counts is required
Non-empty ngram_indexes is required
non-empty pool_int64s is required if pool_strings not provided
NonMaxSuppression
NonZero
Non-zero status code returned while running 
noop_with_empty_axes
NoopElimination
normalize_variance
normalized
Normalized = Div (Deviation, StdDev)
NormalizedT = Cast (Normalized)
Normalizer
NormalizeVariance
not a directory
not a socket
not a stream
Not able to find appropriate IDataTransfer to copy sparse data
Not all dimensions to be reduced have been reduced in the candidate output. Candidate output dims: 
not connected
Not eliminating output 
Not enough elements in dilations. Expected: 
Not enough elements in kernel shape. Expected: 
Not enough elements in pads. Expected: 
Not enough elements in strides. Expected: 
not enough memory
not enough space: expected 
Not expecting an allocator set
not implemented
Not implemented
not support normalize yet.
not supported
Not supported
Not supported with filtered graph.
NOT_IMPLEMENTED
NOT_SET
Notations:
Note that 'input_mean' and 'input_var' are expected to be the estimated
Notice that ReduceVar refers to the population variance, and it equals to
NOTSET
NotWhereFusion
NPH+NHH
NPH9NHt
nQ0mzk
NQDgX
Nr2t\xNz<|(~N
NrJt6!
nt16u
nt32u
nt64u
ntelA
nteltd
Null batch_indices_ptr
Null crop_size_ptr
Null entry in dimensions. Invalid ORT format model.
Null entry in metadata_props. Invalid ORT format model.
Null floats attribute. Invalid ORT format model.
Null graph attribute. Invalid ORT format model.
Null input ptr
Null input X ptr
Null ints attribute. Invalid ORT format model.
null literal
Null map type info. Invalid ORT format model.
Null rois_ptr
Null sequence type info. Invalid ORT format model.
NULL state in RunStateOnByte
Null string attribute. Invalid ORT format model.
Null string in strings attribute. Invalid ORT format model.
Null strings attribute. Invalid ORT format model.
Null tensor attribute. Invalid ORT format model.
Null tensor in tensors attribute. Invalid ORT format model.
Null tensor type info. Invalid ORT format model.
Null tensors attribute. Invalid ORT format model.
Null type info for 
Null value type info in fbs::MapType. Invalid ORT format model.
Null value type info in fbs::SequenceType. Invalid ORT format model.
nullH
nullptr != func_meta_def
nullptr != p.output_tensor
nullptr != tensor_type_base
nullptr != type_proto
nullptr == p_data
num_axes > 0
num_broadcasted_indices < num_of_ellipsis_dims_
num_categories_ > 0
num_classes is < 1
num_dims_with_pad - 1 != num_output_dims
num_dims_with_pad - 2 != num_output_dims
num_dims_with_pad != num_output_dims
num_entries == int_categories.size()
num_explicit_inputs == static_cast<size_t>(target_input_idx)
num_features == feature_count_
num_heads
num_inputs >= 1
num_keys == num_values
num_samples is < 1
num_scan_inputs
num_subgraph_outputs - 1 == num_outputs
num_subgraph_outputs == static_cast<size_t>(num_outputs)
num_variadic_inputs == num_subgraph_inputs
number
number literal
Number of attention heads
Number of dimensions for batch indices should be exactly 1
Number of dimensions for crop size should be exactly 1
Number of dimensions for rois should be exactly 
number of elements in this dimension), it represents `n`. For slicing to the
Number of elements of attribute 'scales' must be same as rank of input 'X'
Number of elements of input 'scales' must be same as rank of input 'X'
Number of elements of input 'sizes' must be same as rank of input 'X'
Number of entries in '
Number of entries in 'scan_input_axes' was 
Number of entries in 'scan_output_axes' was 
number of groups input channels and output channels are divided into.
number of groups input channels and output channels are divided into. default is 1.
Number of input tensors does not match the operands in the equation.
Number of inputs (
Number of items must compose whole 
Number of neurons in the hidden layer
Number of neurons in the hidden layer.
Number of sampling points in the interpolation grid used to compute the output value of each pooled output bin. If > 0, then exactly sampling_ratio x sampling_ratio grid points are used. If == 0, then an adaptive number of grid points are used (computed as ceil(roi_width / output_width), and likewise for height). Default is 0.
Number of scan input axes specified (
Number of scan output axes specified (
Number of subscripts in the input equation does not match number of input tensors
Number of times to sample.
Number of top elements to retrieve
Number of values should be at least 1.
number overflow parsing '
NumCapturesWalker::ShortVisit called
NumReducedAxes = Neg (Axis1D)
NumReducedAxes = Sub (Rank, Axis1D)
NupharExecutionProvider
Nushu
NXH;i
Nyiakeng_Puachue_Hmong
O 9K t
o D9g
O L+O
o"bq=H
O(+O0
O(A+O0A
O(H;O0t
O(H+O H
o@fA9v
O@t'H
o\$PH
O-]xy
o_~wm
O`H+OXH
o|$0J
O01&[
O0H+O(H
O0M0K
o8H;]0t
O8Hc\$PH
object
object key
object separator
oD$ D
oD$ f
oD$0f
of [N, 0] then [N, 0].
offset
Offset
offset % span_size_ == 0
offset + size <= size_t(span.size())
offset < 0
offset >= 0 && static_cast<size_t>(offset) < node_values_size_
Offsets
offsets buffer is not equal to tensor size
Ogham
OHE8n@t"H
OhH;Wxt
OHH+O@M
OhL;G
oL$0f
Ol_Chiki
Old_Hungarian
Old_Italic
Old_North_Arabian
Old_Permic
Old_Persian
Old_Sogdian
Old_South_Arabian
Old_Turkic
OLEAUT32.dll
One (or two if bidirectional) activation function for input gate. The activation function must be one of the activation functions specified above. Optional: Default `Tanh` if not specified.
One and only one of the attributes 'value', 'value_*' or 'sparse_value' must be specified for a Constant node.
One and only one of the 'cats_*' attributes must be defined
One falsenode is pointing either to itself, either to another tree.
One float, indicates the value to be filled, default is 0
One float, indicates the value to be filled.
One of 'MAX,' 'L1,' 'L2'
One of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
One sided attention windows length W, or half of total window length
one_class
OneHot
OneHot node must have three inputs.
OneHotEncoder
onesided
Only 1 batch dimension is allowed for MatMul
Only 4-D tensor is supported
Only bool
Only CPU allocators can be shared between multiple sessions for now.
Only CPU devices are supported for now.
Only one instance of LoggingManager created with InstanceType::Default can exist at any point in time.
Only one node should produce an output. Existing entry for 
Only one of keys_*'s can be set in label encoder.
Only one of scales or sizes must be provided as input.
Only one of the attributes 'value' or 'sparse_value' must be specified for a Constant node.
Only one of values_*'s can be set in label encoder.
Only one thread was configured for parallel execution. Hence will use sequential execution.
Only ONNX MLDataType can be registered
Only Optional type OrtValues containing Tensors and Sequence Tensors are acceptable
Only supports `int32_t` or `int64_t` inputs for split
Only supports `int32_t` or `int64_t` inputs for starts/ends/axes/steps
Only tensors are supported for external outputs for now.
Only tensors, tensor sequence, optional tensor, and optional tensor sequence types are supported
Only works on matrices with two dimensions.
ONNX Runtime
ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 
ONNX Runtime only *guarantees* support for models stamped with opset version 7 or above for opset domain 'ai.onnx'. Please upgrade your model to opset 7 or higher. For now, this opset 
ONNX Schema 
onnx.AttributeProto
onnx.FunctionProto
onnx.GraphProto
onnx.ModelProto
onnx.NodeProto
onnx.OperatorSetIdProto
onnx.SparseTensorProto
onnx.StringStringEntryProto
onnx.TensorAnnotation
onnx.TensorProto
onnx.TensorProto.Segment
onnx.TensorShapeProto
onnx.TensorShapeProto.Dimension
onnx.TrainingInfoProto
onnx.TypeProto
onnx.TypeProto.Map
onnx.TypeProto.Opaque
onnx.TypeProto.Optional
onnx.TypeProto.Sequence
onnx.TypeProto.SparseTensor
onnx.TypeProto.Tensor
onnx.ValueInfoProto
ONNX_NAMESPACE::TensorProto::DataType_IsValid(dtype_) && dtype_ != ONNX_NAMESPACE::TensorProto::UNDEFINED
ONNX_NAMESPACE::TensorProto::DataType_IsValid(output_dtype_) && output_dtype_ != ONNX_NAMESPACE::TensorProto::UNDEFINED
ONNX_NAMESPACE::TensorProto::DataType_IsValid(t_proto.data_type())
onnxruntime
onnxruntime.dll
onnxruntime.pdb
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashes
onnxruntime::`anonymous-namespace'::AssignNodesToEpsFromHashesImpl
onnxruntime::`anonymous-namespace'::Cast::Cast
onnxruntime::`anonymous-namespace'::CastToString
onnxruntime::`anonymous-namespace'::ConstantOfShape::Compute
onnxruntime::`anonymous-namespace'::CopyData
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<__int64>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<double>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<float>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<int>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<struct onnxruntime::BFloat16>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<struct onnxruntime::MLFloat16>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<unsigned __int64>::operator ()
onnxruntime::`anonymous-namespace'::ExtractScalarAsFloatDispatchTarget<unsigned int>::operator ()
onnxruntime::`anonymous-namespace'::GetClipConstantMinMax::<lambda_2c3e38ae2de27c60397226fcef4474a0>::operator ()
onnxruntime::`anonymous-namespace'::GetCurrentTimeString
onnxruntime::`anonymous-namespace'::GetInputNodeMerges
onnxruntime::`anonymous-namespace'::GetIntermediateMLFloat16ToFloatTensor
onnxruntime::`anonymous-namespace'::GetOutputNodeMerges
onnxruntime::`anonymous-namespace'::GetRatioOrDefault
onnxruntime::`anonymous-namespace'::GetScalarConstantInitializer
onnxruntime::`anonymous-namespace'::GetScaleFromNode
onnxruntime::`anonymous-namespace'::MoveInputOutputImpl
onnxruntime::`anonymous-namespace'::ParsePathRoot
onnxruntime::`anonymous-namespace'::PartitionOrtFormatModel
onnxruntime::`anonymous-namespace'::TraverseFormalParametersWithTypeProto
onnxruntime::`anonymous-namespace'::VerifyEachNodeIsAssignedToAnEp
onnxruntime::`anonymous-namespace'::WindowsEnv::DeleteFolder
onnxruntime::`anonymous-namespace'::WindowsEnv::FormatLibraryFileName
onnxruntime::`anonymous-namespace'::WindowsEnv::GetCanonicalPath
onnxruntime::`anonymous-namespace'::WindowsEnv::GetNumCpuCores
onnxruntime::`anonymous-namespace'::WindowsEnv::ReadFileIntoBuffer
onnxruntime::`anonymous-namespace'::WindowsThread::WindowsThread
onnxruntime::AccumulateAllNestedSubgraphsInfo
onnxruntime::AllocateSparseTensor
onnxruntime::AllocatorManager::InsertAllocator
onnxruntime::AllocPlanPerValue::ProgramCounter::AddEnd
onnxruntime::AllocPlanPerValue::ProgramCounter::AddStart
onnxruntime::ApiGraph::CopyValueInfo
onnxruntime::ApiGraph::GetValueInfo
onnxruntime::ApiGraph::ReshapeInitializer
onnxruntime::ApiGraph::TransposeInitializer
onnxruntime::ApiTensor::Data
onnxruntime::ApiTensor::NumElements
onnxruntime::ApiValueInfo::PermuteDims
onnxruntime::AttentionFusion::ApplyImpl
onnxruntime::AttentionFusion::FuseSubGraph
onnxruntime::AttentionFusionHelper::CheckDistilBertReshapeShape
onnxruntime::AttentionFusionHelper::CheckNodesInPathK
onnxruntime::AttentionFusionHelper::CheckNodesInPathQ
onnxruntime::AttentionFusionHelper::CheckNodesInPathV
onnxruntime::AttentionFusionHelper::CheckSliceParameters
onnxruntime::AttentionFusionHelper::FuseGptAttention
onnxruntime::AttentionFusionHelper::MatchGemmSubgraph
onnxruntime::AttentionFusionHelper::MatchInputMaskSubgraph
onnxruntime::AttentionFusionHelper::MatchPastSubgraph
onnxruntime::AttentionFusionHelper::MatchUnidirMaskSubgraph
onnxruntime::AttentionFusionHelper::ValidateGemmInitializer
onnxruntime::AttentionFusionHelper::ValidateUnidirMask
onnxruntime::BatchNorm<double>::BatchNorm
onnxruntime::BatchNorm<double>::Compute
onnxruntime::BatchNorm<float>::BatchNorm
onnxruntime::BatchNorm<float>::Compute
onnxruntime::BFCArena::AllocateRawInternal
onnxruntime::BFCArena::AllocationRegion::AllocationRegion
onnxruntime::BFCArena::AllocationRegion::IndexFor
onnxruntime::BFCArena::BFCArena
onnxruntime::BFCArena::ChunkFromHandle
onnxruntime::BFCArena::DeallocateRawInternal
onnxruntime::BFCArena::Extend
onnxruntime::BFCArena::Extend::<lambda_1064b317e773adcb1310893e56d55e4e>::operator ()
onnxruntime::BFCArena::FindChunkPtr
onnxruntime::BFCArena::FreeAndMaybeCoalesce
onnxruntime::BFCArena::InsertFreeChunkIntoBin
onnxruntime::BFCArena::Merge
onnxruntime::BFCArena::RegionManager::RegionFor
onnxruntime::BFCArena::RegionManager::RemoveAllocationRegion
onnxruntime::BFCArena::RemoveFreeChunkFromBin
onnxruntime::BFCArena::RemoveFreeChunkIterFromBin
onnxruntime::BFCArena::Reserve
onnxruntime::BFCArena::Shrink
onnxruntime::BFCArena::SplitChunk
onnxruntime::BiasDropoutFusion::ApplyImpl
onnxruntime::BiasGeluFusion::ApplyImpl
onnxruntime::BiasSoftmaxFusion::ApplyImpl
onnxruntime::BitShift<unsigned __int64>::BitShift
onnxruntime::BitShift<unsigned __int64>::Compute::<lambda_2dfbb49707127c93d1d3311367fcbf5e>::operator ()
onnxruntime::BitShift<unsigned char>::BitShift
onnxruntime::BitShift<unsigned char>::Compute::<lambda_1bac9798e02ce2daa410e33c40a170ad>::operator ()
onnxruntime::BitShift<unsigned int>::BitShift
onnxruntime::BitShift<unsigned int>::Compute::<lambda_ede6396af27e2bad4c061429d30c1587>::operator ()
onnxruntime::Broadcaster::Broadcaster
onnxruntime::BroadcastIterator::Append
onnxruntime::BroadcastIterator::Init
onnxruntime::BroadcastLooper
onnxruntime::CheckInput
onnxruntime::Clip::ComputeImpl<__int64>::operator ()
onnxruntime::Clip::ComputeImpl<double>::operator ()
onnxruntime::Clip::ComputeImpl<float>::operator ()
onnxruntime::Clip::ComputeImpl<signed char>::operator ()
onnxruntime::Clip::ComputeImpl<unsigned __int64>::operator ()
onnxruntime::Clip::ComputeImpl<unsigned char>::operator ()
onnxruntime::clip_internal::Clip_6Base<float>::Clip_6Base
onnxruntime::common::Status::Status
onnxruntime::CommonSubexpressionElimination::ApplyImpl
onnxruntime::Compress::Compute
onnxruntime::ComputePadAndOutputShape
onnxruntime::ConcatBase::ComputeImpl
onnxruntime::ConcatBase::ConcatBase
onnxruntime::ConcatBase::PrepareForCompute
onnxruntime::ConcatFromSequence::Compute
onnxruntime::concurrency::CreateThreadPoolHelper
onnxruntime::concurrency::ThreadPool::ParallelFor
onnxruntime::concurrency::ThreadPool::ParallelSection::ParallelSection
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEnd
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::LogEndAndStart
onnxruntime::concurrency::ThreadPoolProfiler::MainThreadStat::Reset
onnxruntime::concurrency::ThreadPoolProfiler::Stop
onnxruntime::concurrency::ThreadPoolTempl<class onnxruntime::Env>::RunInParallel
onnxruntime::concurrency::ThreadPoolTempl<class onnxruntime::Env>::RunInParallelSection
onnxruntime::ConfigOptions::AddConfigEntry
onnxruntime::ConstantFolding::ApplyImpl
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::ConstantOfShapeBase
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::PrepareCompute
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::SetValue
onnxruntime::ConstantOfShapeBase<struct onnxruntime::TypeList<__int64,struct onnxruntime::MLFloat16,float,double,signed char,short,int,unsigned char,unsigned short,unsigned int,unsigned __int64,bool> >::SetValueFromTensorProto
onnxruntime::ConstPointerContainer<class std::vector<class onnxruntime::NodeArg *,class std::allocator<class onnxruntime::NodeArg *> > >::at
onnxruntime::contrib::`anonymous-namespace'::QLinearImpl
onnxruntime::contrib::`anonymous-namespace'::SparseToDenseCoo<__int64>::operator ()
onnxruntime::contrib::`anonymous-namespace'::SparseToDenseCoo<double>::operator ()
onnxruntime::contrib::`anonymous-namespace'::SparseToDenseCoo<float>::operator ()
onnxruntime::contrib::`anonymous-namespace'::SparseToDenseCoo<int>::operator ()
onnxruntime::contrib::`anonymous-namespace'::SparseToDenseCoo<unsigned __int64>::operator ()
onnxruntime::contrib::`anonymous-namespace'::SparseToDenseCoo<unsigned int>::operator ()
onnxruntime::contrib::Affine<float>::Affine
onnxruntime::contrib::Attention<float>::Compute
onnxruntime::contrib::AttentionBase::AttentionBase
onnxruntime::contrib::AttentionBase::GetPresent
onnxruntime::contrib::AttentionCPUBase::ApplyAttention
onnxruntime::contrib::BahdanauAttention<float>::BahdanauAttention
onnxruntime::contrib::BahdanauAttention<float>::PrepareMemory
onnxruntime::contrib::BiasGelu<float,0>::Compute
onnxruntime::contrib::BiasGelu<float,1>::Compute
onnxruntime::contrib::BifurcationDetector::BifurcationDetector
onnxruntime::contrib::BifurcationDetector::Compute
onnxruntime::contrib::CDist<double>::CDist
onnxruntime::contrib::CDist<float>::CDist
onnxruntime::contrib::Crop<float>::Compute
onnxruntime::contrib::CropAndResize<float>::CropAndResize
onnxruntime::contrib::DeepCpuAttnLstmOp::Compute
onnxruntime::contrib::DeepCpuAttnLstmOp::ComputeImpl
onnxruntime::contrib::DeepCpuAttnLstmOp::DeepCpuAttnLstmOp
onnxruntime::contrib::DeepCpuAttnLstmOp::ValidateInputs
onnxruntime::contrib::DynamicQuantizeLSTM::PrePack
onnxruntime::contrib::DynamicQuantizeMatMul::Compute
onnxruntime::contrib::EmbedLayerNorm<float>::Compute
onnxruntime::contrib::EmbedLayerNormBase::EmbedLayerNormBase
onnxruntime::contrib::ExpandDims::Compute
onnxruntime::contrib::FusedConvFloat::FusedConvFloat
onnxruntime::contrib::FusedGemm<float>::FusedGemm
onnxruntime::contrib::GridSample<float>::Compute
onnxruntime::contrib::GridSample<float>::GridSample
onnxruntime::contrib::ImageScaler<float>::ImageScaler
onnxruntime::contrib::LayerNorm<double,0>::Compute
onnxruntime::contrib::LayerNorm<double,0>::LayerNorm
onnxruntime::contrib::LayerNorm<double,1>::Compute
onnxruntime::contrib::LayerNorm<double,1>::LayerNorm
onnxruntime::contrib::LayerNorm<float,0>::Compute
onnxruntime::contrib::LayerNorm<float,0>::LayerNorm
onnxruntime::contrib::LayerNorm<float,1>::Compute
onnxruntime::contrib::LayerNorm<float,1>::LayerNorm
onnxruntime::contrib::MatMulInteger16<short,short,int>::Compute
onnxruntime::contrib::MatMulIntegerToFloat::Compute
onnxruntime::contrib::MatMulIntegerToFloatBase::ComputeCommon
onnxruntime::contrib::MaxpoolWithMask::Compute
onnxruntime::contrib::MurmurHash3::Compute
onnxruntime::contrib::NchwcConv::Compute
onnxruntime::contrib::NchwcConv::NchwcConv
onnxruntime::contrib::NchwcPoolBase::NchwcPool
onnxruntime::contrib::NchwcPoolBase::NchwcPoolBase
onnxruntime::contrib::NchwcUpsample::Compute
onnxruntime::contrib::NchwcUpsample::NchwcUpsample
onnxruntime::contrib::NGramRepeatBlock::Compute
onnxruntime::contrib::NGramRepeatBlock::Compute::<lambda_7f7ecb7c96871d43cc6d400ce6170f09>::operator ()
onnxruntime::contrib::NGramRepeatBlock::NGramRepeatBlock
onnxruntime::contrib::NhwcMaxPool::Compute
onnxruntime::contrib::QAttention<float>::Compute
onnxruntime::contrib::QEmbedLayerNorm<float>::Compute
onnxruntime::contrib::QGemm::CheckInputs
onnxruntime::contrib::QGemm::Compute
onnxruntime::contrib::QLinearAveragePool::Compute
onnxruntime::contrib::QlinearBuildLookupTable
onnxruntime::contrib::QLinearConcat::Compute
onnxruntime::contrib::QLinearConcat::QLinearConcat
onnxruntime::contrib::QLinearGlobalAveragePool::Compute
onnxruntime::contrib::RegisterContribSchemas::<lambda_273270d63d2edeeb9cb50e9432a42c00>::operator ()
onnxruntime::contrib::RegisterCpuContribKernels
onnxruntime::contrib::RegisterNchwcKernels
onnxruntime::contrib::RegisterQuantizationKernels
onnxruntime::contrib::ReorderInput::Compute
onnxruntime::contrib::ReorderInput::ReorderInput
onnxruntime::contrib::ReorderOutput::Compute
onnxruntime::contrib::ReorderOutput::ReorderOutput
onnxruntime::contrib::Scale<float>::Scale
onnxruntime::contrib::SkipLayerNorm<double>::SkipLayerNorm
onnxruntime::contrib::SkipLayerNorm<float>::SkipLayerNorm
onnxruntime::contrib::SparseToDenseMatMul::Compute
onnxruntime::contrib::Tokenizer::Tokenizer
onnxruntime::contrib::WordConvEmbedding::Compute
onnxruntime::Conv<float>::Compute
onnxruntime::ConvActivationFusion::ApplyImpl
onnxruntime::ConvAddFusion::Apply
onnxruntime::ConvAttributes::ConvAttributes
onnxruntime::ConvAttributes::InferOutputShape
onnxruntime::ConvBNFusion::Apply
onnxruntime::ConvertMaskToInt32
onnxruntime::ConvInteger::Compute
onnxruntime::ConvMulFusion::Apply
onnxruntime::ConvTranspose<float>::DoConvTranspose
onnxruntime::ConvTransposeAttributes::ComputePadsAndOutputShape
onnxruntime::ConvTransposeAttributes::ComputeTransposePadAndOutputShape
onnxruntime::ConvTransposeAttributes::PrepareForCompute
onnxruntime::core_impl::<lambda_57cfefc55869a6904acbae1315b5b1ba>::operator ()
onnxruntime::core_impl::<lambda_cc28a3a6e50de277c1640406cde367e7>::operator ()
onnxruntime::core_impl::<lambda_d225b397643c22bd72de44da053cd583>::operator ()
onnxruntime::core_impl::<lambda_ff722d1aa0e133d0aa24feb7c90fe947>::operator ()
onnxruntime::CPUDataTransfer::CopyTensor
onnxruntime::CPUExecutionProvider::GetKernelRegistry
onnxruntime::CreateAllocator
onnxruntime::CreateCopyAndAppendCpuTensor
onnxruntime::CreateCustomRegistry
onnxruntime::CreateReplacementNode
onnxruntime::CreateSchema
onnxruntime::CumSum<__int64>::Compute
onnxruntime::CumSum<double>::Compute
onnxruntime::CumSum<float>::Compute
onnxruntime::CumSum<int>::Compute
onnxruntime::CustomOpKernel::CustomOpKernel
onnxruntime::data_types_internal::DataTypeRegistry::RegisterDataType
onnxruntime::data_types_internal::IsCompatible
onnxruntime::data_types_internal::MapTypeHelper::Set
onnxruntime::data_types_internal::OptionalTypeHelper::Set
onnxruntime::data_types_internal::SequenceTypeHelper::Set
onnxruntime::DataTransferManager::CopySparseTensors
onnxruntime::DataTransferManager::CopyTensors
onnxruntime::DataTypeImpl::GetType<T>() == type_
onnxruntime::DeepCpuGruOp::Compute
onnxruntime::DeepCpuGruOp::ComputeImpl
onnxruntime::DeepCpuGruOp::DeepCpuGruOp
onnxruntime::DeepCpuLstmOp::Compute
onnxruntime::DeepCpuLstmOp::PrePack
onnxruntime::DepthToSpace::Compute
onnxruntime::DepthToSpace::DepthToSpace
onnxruntime::DequantizeLinear<int>::Compute
onnxruntime::Det<float>::Compute
onnxruntime::DispatchStridedCopy
onnxruntime::DoTransposeEltWise
onnxruntime::DoTransposeImpl
onnxruntime::Dropout<double,double>::Compute
onnxruntime::Dropout<double,float>::Compute
onnxruntime::Dropout<float,double>::Compute
onnxruntime::Dropout<float,float>::Compute
onnxruntime::DynamicQuantizeLinear<unsigned char>::Compute
onnxruntime::DynamicQuantizeMatMulFusion::ApplyImpl
onnxruntime::Einsum::DeviceCompute
onnxruntime::Einsum::Einsum
onnxruntime::EinsumComputePreprocessor::PostProcessBroadcastedDims
onnxruntime::EinsumComputePreprocessor::Run
onnxruntime::EinsumOp::DeviceHelpers::CpuDeviceHelpers::DataCopy
onnxruntime::EinsumOp::DeviceHelpers::CpuDeviceHelpers::Diagonal
onnxruntime::EinsumOp::DeviceHelpers::CpuDeviceHelpers::DiagonalInnermostDims
onnxruntime::EinsumOp::IsTransposeRequired
onnxruntime::EinsumOp::MatMul
onnxruntime::EinsumOp::Transpose
onnxruntime::EinsumTypedComputeProcessor<__int64>::FinalizeOutput
onnxruntime::EinsumTypedComputeProcessor<__int64>::PairwiseOperandProcess
onnxruntime::EinsumTypedComputeProcessor<double>::FinalizeOutput
onnxruntime::EinsumTypedComputeProcessor<double>::PairwiseOperandProcess
onnxruntime::EinsumTypedComputeProcessor<float>::FinalizeOutput
onnxruntime::EinsumTypedComputeProcessor<float>::PairwiseOperandProcess
onnxruntime::EinsumTypedComputeProcessor<int>::FinalizeOutput
onnxruntime::EinsumTypedComputeProcessor<int>::PairwiseOperandProcess
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<__int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<__int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<short> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<short> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<signed char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<signed char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned __int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned __int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned short> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Abs<unsigned short> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Ceil<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Ceil<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Celu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Celu<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Elu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Elu<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Exp<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Floor<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Floor<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::HardSigmoid<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::HardSigmoid<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::LeakyRelu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::LeakyRelu<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Log<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Log<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Log<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Log<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<__int64> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<__int64> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<int> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<signed char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Neg<signed char> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::ParametricSoftplus<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::ParametricSoftplus<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Reciprocal<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<int> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Relu<signed char> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::ScaledTanh<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::ScaledTanh<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Selu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Selu<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sigmoid<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Softplus<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Softsign<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<double> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Sqrt<float> >::ElementWiseKernel
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<double> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::Tanh<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::ThresholdedRelu<float> >::Compute
onnxruntime::ElementWiseKernel<struct onnxruntime::functors::ThresholdedRelu<float> >::ElementWiseKernel
onnxruntime::EmbedLayerNormFusion::ApplyImpl
onnxruntime::ExecutionFrame::{ctor}::<lambda_892836f21345417272512adea8711b39>::operator ()
onnxruntime::ExecutionFrame::AllocateAsPerAllocationPlan
onnxruntime::ExecutionFrame::AllocateMLValueTensorPreAllocateBuffer
onnxruntime::ExecutionFrame::AllocateMLValueTensorSelfOwnBufferHelper
onnxruntime::ExecutionFrame::AllocateReusedOrtValueIfNotAllocatedHelper
onnxruntime::ExecutionFrame::ExecutionFrame
onnxruntime::ExecutionFrame::GetAllocationPlan
onnxruntime::ExecutionFrame::ReleaseMLValueImpl
onnxruntime::ExecutionFrame::TraceAllocate
onnxruntime::ExecutionFrame::TraceFree
onnxruntime::ExecutionFrame::VerifyOutputSizes
onnxruntime::ExecutionProviders::Add
onnxruntime::ExLibLoader::{dtor}::<lambda_c97304e2ece92b7381e847cbdb64609e>::operator ()
onnxruntime::ExLibLoader::~ExLibLoader
onnxruntime::ExLibLoader::LoadExternalLib
onnxruntime::Expand_8<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::Compute::<lambda_c61de806568fb8e84995e9be0077f048>::operator ()
onnxruntime::ExpandBroadcastLooper
onnxruntime::FastGeluFusion::ApplyImpl
onnxruntime::fbs::utils::LoadAttributeOrtFormat
onnxruntime::fbs::utils::LoadInitializerOrtFormat
onnxruntime::fbs::utils::LoadMapTypeOrtFormat
onnxruntime::fbs::utils::LoadOpsetImportOrtFormat
onnxruntime::fbs::utils::LoadSequenceTypeOrtFormat
onnxruntime::fbs::utils::LoadSparseInitializerOrtFormat
onnxruntime::fbs::utils::LoadTensorDimensionOrtFormat
onnxruntime::fbs::utils::LoadTensorShapeOrtFormat
onnxruntime::fbs::utils::LoadTensorTypeAndShapeOrtFormat
onnxruntime::fbs::utils::LoadTypeInfoOrtFormat
onnxruntime::fbs::utils::LoadValueInfoOrtFormat
onnxruntime::fbs::utils::SaveAttributeOrtFormat
onnxruntime::fbs::utils::SaveInitializerOrtFormat
onnxruntime::fbs::utils::SaveMapTypeOrtFormat
onnxruntime::fbs::utils::SaveSequenceTypeOrtFormat
onnxruntime::fbs::utils::SaveSparseInitializerOrtFormat
onnxruntime::fbs::utils::SaveTensorTypeAndShapeOrtFormat
onnxruntime::fbs::utils::SaveTypeInfoOrtFormat
onnxruntime::fbs::utils::SaveValueInfoOrtFormat
onnxruntime::FeedsFetchesInfo::FeedsFetchesInfo
onnxruntime::FeedsFetchesInfo::MapNamesToMLValueIdxs
onnxruntime::FeedsFetchesManager::SetDeviceCopyChecks
onnxruntime::FinalizeSessionOptions
onnxruntime::Flatten::Compute
onnxruntime::Flatten::Flatten
onnxruntime::FreeDimensionOverrideTransformer::ApplyImpl
onnxruntime::FreeDimensionOverrideTransformer::FreeDimensionOverrideTransformer
onnxruntime::FuncManager::GetFuncs
onnxruntime::FunctionImpl::FunctionImpl
onnxruntime::FunctionKernel::FunctionKernel
onnxruntime::functors::ElementWiseRangedTransform<float>::Create
onnxruntime::functors::HardSigmoid<float>::Init
onnxruntime::functors::ParametricSoftplus<float>::Init
onnxruntime::functors::ScaledTanh<float>::Init
onnxruntime::functors::Selu<float>::Init
onnxruntime::FuseReluClip::Apply
onnxruntime::FuseSubGraph
onnxruntime::FuseSubGraphDistilBert
onnxruntime::FuseSubGraphQK
onnxruntime::FuseSubGraphQKDistilBert
onnxruntime::FuseSubGraphQKImpl
onnxruntime::Gather::Compute
onnxruntime::GatherBase::GatherBase
onnxruntime::GatherElements::GatherElements
onnxruntime::GatherND::Compute
onnxruntime::GeluApproximation::ApplyImpl
onnxruntime::GeluFusion::ApplyImpl
onnxruntime::GemmActivationFusion::ApplyImpl
onnxruntime::GemmBase::GemmBase
onnxruntime::GemmBroadcastBias
onnxruntime::GemmHelper::GemmHelper
onnxruntime::GemmSumFusion::Apply
onnxruntime::GemmSumFusion::SatisfyCondition
onnxruntime::GetCpuPreferredNodes
onnxruntime::GetCpuPreferredNodes::<lambda_21ca116bba4007835cdddfee631b7f69>::operator ()
onnxruntime::GetKernelCreateInfo
onnxruntime::GetNodesToOptimizeIndices::<lambda_2b3ea6407275864e85e8d3a338349287>::operator ()
onnxruntime::GetScalarSplitInput
onnxruntime::GetSeqIdx
onnxruntime::GetSplitSizesInput
onnxruntime::GetSubGraphSessionStatesOrtFormat
onnxruntime::GetTransposePerms
onnxruntime::Graph::AddEdge
onnxruntime::Graph::AddInitializedTensor
onnxruntime::Graph::AllocateNode
onnxruntime::Graph::BuildConnections
onnxruntime::Graph::CleanUnusedInitializersAndNodeArgs
onnxruntime::Graph::CreateFusedSubGraphNode
onnxruntime::Graph::FinalizeFuseSubGraph
onnxruntime::Graph::ForThisAndAllSubgraphs
onnxruntime::Graph::Graph
onnxruntime::Graph::InferAndVerifySubgraphTypes
onnxruntime::Graph::InferAndVerifyTypeMatch
onnxruntime::Graph::InitFunctionBodyForNode
onnxruntime::Graph::InitializeStateFromModelFileGraphProto
onnxruntime::Graph::InitInputsInitializersOutputs
onnxruntime::Graph::InlineFunction
onnxruntime::Graph::KahnsTopologicalSort
onnxruntime::Graph::LoadFromOrtFormat
onnxruntime::Graph::LoadFromOrtFormat::<lambda_dbbdad314ea6c338685c73dc6e5d5371>::operator ()
onnxruntime::Graph::NodeAtIndexImpl
onnxruntime::Graph::PerformTypeAndShapeInferencing
onnxruntime::Graph::RemoveEdge
onnxruntime::Graph::RemoveInitializedTensor
onnxruntime::Graph::RemoveNode
onnxruntime::Graph::Resolve
onnxruntime::Graph::SaveToOrtFormat
onnxruntime::Graph::SetInputs
onnxruntime::Graph::SetOuterScopeNodeArgs
onnxruntime::Graph::ToGraphProto
onnxruntime::Graph::ToGraphProtoInternal
onnxruntime::Graph::VerifyNodeAndOpMatch
onnxruntime::graph_utils::AddInitializer
onnxruntime::graph_utils::AddNodeInput
onnxruntime::graph_utils::CanUpdateImplicitInputNameInSubgraphs
onnxruntime::graph_utils::FindPath
onnxruntime::graph_utils::GetIndexFromName
onnxruntime::graph_utils::GetNodeInputName
onnxruntime::graph_utils::GetNodeOutputName
onnxruntime::graph_utils::RemoveNode
onnxruntime::graph_utils::RemoveNodeWithSingleNodeInSingleUsedOutput
onnxruntime::graph_utils::ReplaceNodeInput
onnxruntime::graph_utils::UpdateImplicitInputNameInSubgraph
onnxruntime::GraphPartitioner::Partition
onnxruntime::GraphPartitioner::PartitionOnnxFormatModel
onnxruntime::GraphPartitioner::PartitionOrtFormatModel
onnxruntime::GraphTransformer::Apply
onnxruntime::GraphTransformer::Recurse
onnxruntime::GraphTransformerManager::ApplyTransformers
onnxruntime::GraphViewer::GetNodesInTopologicalOrder
onnxruntime::GraphViewer::GetRootNodes
onnxruntime::GraphViewer::GraphViewer
onnxruntime::HandleNegativeAxis
onnxruntime::Hardmax<float>::Compute
onnxruntime::IAllocator::CalcMemSizeForArrayWithAlignment::<lambda_c6b03386de95717d3eea3a793c94afde>::operator ()
onnxruntime::IDataTransfer::CopySparseTensors
onnxruntime::IDataTransfer::CopyTensors
onnxruntime::IdentityOp<0>::Compute
onnxruntime::IdentityOp<1>::Compute
onnxruntime::IExecutionFrame::GetMLValue
onnxruntime::IExecutionFrame::GetOrCreateNodeOutputMLValue
onnxruntime::IExecutionFrame::IExecutionFrame
onnxruntime::IExecutionFrame::Init
onnxruntime::IExecutionProvider::GenerateMetaDefId
onnxruntime::IExecutionProvider::InsertAllocator
onnxruntime::IExecutionProvider::TryInsertAllocator
onnxruntime::If::Compute
onnxruntime::If::Info::Info
onnxruntime::If::Init
onnxruntime::If::SetupSubgraphExecutionInfo
onnxruntime::IfImpl::Execute
onnxruntime::IfImpl::Initialize
onnxruntime::IncrementIndexAndComputeOffsetSetup
onnxruntime::inference_session_utils::JsonConfigParser::ParseOrtConfigJsonInModelProto
onnxruntime::inference_session_utils::JsonConfigParser::ParseOrtConfigJsonInModelProto::<lambda_f5703e30d66339144972d370855935b6>::operator ()
onnxruntime::inference_session_utils::JsonConfigParser::ParseSessionOptionsFromModelProto
onnxruntime::InferenceSession::{dtor}::<lambda_117bb6d1dfafcab7bc48c4431153f278>::operator ()
onnxruntime::InferenceSession::~InferenceSession
onnxruntime::InferenceSession::AddCustomOpDomains
onnxruntime::InferenceSession::AddPredefinedTransformers
onnxruntime::InferenceSession::ConstructorCommon
onnxruntime::InferenceSession::ConstructorCommon::<lambda_7cec36099d1ae29ef2b3cbe41ba5b9a0>::operator ()
onnxruntime::InferenceSession::CreateLoggerForRun
onnxruntime::InferenceSession::EndProfiling
onnxruntime::InferenceSession::GetModelInputs
onnxruntime::InferenceSession::GetModelMetadata
onnxruntime::InferenceSession::GetModelOutputs
onnxruntime::InferenceSession::GetOverridableInitializers
onnxruntime::InferenceSession::GetSessionState
onnxruntime::InferenceSession::InferenceSession
onnxruntime::InferenceSession::Initialize
onnxruntime::InferenceSession::Initialize::<lambda_4f6bc740749357f1ee569964a854a405>::operator ()
onnxruntime::InferenceSession::Initialize::<lambda_b4dbd8b7631db100bde145756917a967>::operator ()
onnxruntime::InferenceSession::InitLogger
onnxruntime::InferenceSession::Load
onnxruntime::InferenceSession::LoadOrtModel
onnxruntime::InferenceSession::LoadOrtModel::<lambda_564e08730d4bd4a97b43e8c38a06cf59>::operator ()
onnxruntime::InferenceSession::NewIOBinding
onnxruntime::InferenceSession::RegisterExecutionProvider
onnxruntime::InferenceSession::RegisterGraphTransformer
onnxruntime::InferenceSession::Run
onnxruntime::InferenceSession::SaveToOrtFormat
onnxruntime::InferenceSession::ShrinkMemoryArenas
onnxruntime::InferenceSession::TransformGraph
onnxruntime::InferenceSession::ValidateInputs
onnxruntime::Initializer::Initializer
onnxruntime::Initializer::ReadExternalRawData
onnxruntime::Initializer::ToProto
onnxruntime::InitNestedModelLocalFunction
onnxruntime::InlineNodes
onnxruntime::InputBroadcaster::AdvanceBy
onnxruntime::InsertCastTransformer::ApplyImpl
onnxruntime::InstanceNorm<float>::Compute
onnxruntime::InstanceNorm<float>::InstanceNorm
onnxruntime::IOBinding::BindInput
onnxruntime::IOBinding::SynchronizeInputs
onnxruntime::IOBinding::SynchronizeOutputs
onnxruntime::IOTypeConstraintHelper
onnxruntime::IsInf::IsInf
onnxruntime::KernelDefBuilder::VariadicAlias
onnxruntime::KernelRegistry::Register
onnxruntime::KernelRegistry::TryCreateKernel
onnxruntime::KernelUseSharedPrePackedBuffers
onnxruntime::LayerNormFusion::ApplyImpl
onnxruntime::LoadOrtModelBytes
onnxruntime::logging::LoggingManager::CreateDefaultLogger
onnxruntime::logging::LoggingManager::DefaultLogger
onnxruntime::logging::LoggingManager::LoggingManager
onnxruntime::Loop::Compute
onnxruntime::Loop::Info::Info
onnxruntime::Loop::Init
onnxruntime::Loop::SetupSubgraphExecutionInfo
onnxruntime::LoopDir
onnxruntime::LoopImpl::ConcatenateLoopOutput
onnxruntime::LoopImpl::Execute
onnxruntime::LoopImpl::Execute::<lambda_bd8174261d52a27a5d071d22ebdb87ce>::operator ()
onnxruntime::LoopImpl::Initialize
onnxruntime::LoopImpl::SaveOutputsAndUpdateFeeds
onnxruntime::LpNorm<double>::LpNorm
onnxruntime::LpNorm<float>::LpNorm
onnxruntime::LRN<float>::Compute
onnxruntime::LRN<float>::LRN
onnxruntime::LSTMBase::ComputeImpl
onnxruntime::LSTMBase::LSTMBase
onnxruntime::MatchInputToConcatSubgraph
onnxruntime::MatchPositionEmbeddingSubgraphsFromGather
onnxruntime::math::NextPosition
onnxruntime::MatMul<__int64>::Compute
onnxruntime::MatMul<double>::Compute
onnxruntime::MatMul<float>::Compute
onnxruntime::MatMul<int>::Compute
onnxruntime::MatMulAddFusion::ApplyImpl
onnxruntime::MatMulComputeHelper::Compute
onnxruntime::MatMulComputeHelper::Compute::<lambda_aebe3ddf278f554a396f06ee5c1fe5fb>::operator ()
onnxruntime::MatMulInteger::Compute
onnxruntime::MatMulIntegerToFloatFusion::ApplyImpl
onnxruntime::MatMulScaleFusion::ApplyImpl
onnxruntime::MatmulTransposeFusion::ApplyImpl
onnxruntime::Max_6<float>::Compute
onnxruntime::MaxPoolV8::ComputeImpl
onnxruntime::MaxUnpool::Compute
onnxruntime::MaxUnpool::MaxUnpool
onnxruntime::Mean_6<float>::Compute
onnxruntime::MeanVarianceNormalization_0<float>::MeanVarianceNormalization_0
onnxruntime::MemcpyTransformer::ApplyImpl
onnxruntime::MemPatternPlanner::TraceAllocation
onnxruntime::MergeIntoTarget::Run
onnxruntime::MergeShapeInfo
onnxruntime::Min_6<float>::Compute
onnxruntime::ml::batched_update_scores_inplace
onnxruntime::ml::CastInputToFloat
onnxruntime::ml::CastMap::CastMap
onnxruntime::ml::CastMap::ComputeImpl
onnxruntime::ml::CategoryMapper::CategoryMapper
onnxruntime::ml::detail::TreeAggregator<double,float>::FinalizeScores
onnxruntime::ml::detail::TreeAggregator<float,float>::FinalizeScores
onnxruntime::ml::detail::TreeAggregatorAverage<double,float>::FinalizeScores
onnxruntime::ml::detail::TreeAggregatorAverage<float,float>::FinalizeScores
onnxruntime::ml::detail::TreeAggregatorClassifier<__int64,float>::_set_score_binary
onnxruntime::ml::detail::TreeAggregatorClassifier<__int64,float>::FinalizeScores
onnxruntime::ml::detail::TreeAggregatorClassifier<double,float>::_set_score_binary
onnxruntime::ml::detail::TreeAggregatorClassifier<double,float>::FinalizeScores
onnxruntime::ml::detail::TreeAggregatorClassifier<float,float>::_set_score_binary
onnxruntime::ml::detail::TreeAggregatorClassifier<float,float>::FinalizeScores
onnxruntime::ml::detail::TreeAggregatorClassifier<int,float>::_set_score_binary
onnxruntime::ml::detail::TreeAggregatorClassifier<int,float>::FinalizeScores
onnxruntime::ml::detail::TreeAggregatorMax<double,float>::MergePrediction
onnxruntime::ml::detail::TreeAggregatorMax<float,float>::MergePrediction
onnxruntime::ml::detail::TreeAggregatorMin<double,float>::MergePrediction
onnxruntime::ml::detail::TreeAggregatorMin<float,float>::MergePrediction
onnxruntime::ml::detail::TreeAggregatorSum<__int64,float>::MergePrediction
onnxruntime::ml::detail::TreeAggregatorSum<__int64,float>::ProcessTreeNodePrediction
onnxruntime::ml::detail::TreeAggregatorSum<double,float>::MergePrediction
onnxruntime::ml::detail::TreeAggregatorSum<double,float>::ProcessTreeNodePrediction
onnxruntime::ml::detail::TreeAggregatorSum<float,float>::MergePrediction
onnxruntime::ml::detail::TreeAggregatorSum<float,float>::ProcessTreeNodePrediction
onnxruntime::ml::detail::TreeAggregatorSum<int,float>::MergePrediction
onnxruntime::ml::detail::TreeAggregatorSum<int,float>::ProcessTreeNodePrediction
onnxruntime::ml::detail::TreeEnsembleCommon<__int64,float>::TreeEnsembleCommon
onnxruntime::ml::detail::TreeEnsembleCommon<double,float>::compute
onnxruntime::ml::detail::TreeEnsembleCommon<double,float>::TreeEnsembleCommon
onnxruntime::ml::detail::TreeEnsembleCommon<float,float>::compute
onnxruntime::ml::detail::TreeEnsembleCommon<float,float>::TreeEnsembleCommon
onnxruntime::ml::detail::TreeEnsembleCommon<int,float>::TreeEnsembleCommon
onnxruntime::ml::detail::TreeEnsembleCommonClassifier<__int64,float>::compute
onnxruntime::ml::detail::TreeEnsembleCommonClassifier<double,float>::compute
onnxruntime::ml::detail::TreeEnsembleCommonClassifier<float,float>::compute
onnxruntime::ml::detail::TreeEnsembleCommonClassifier<int,float>::compute
onnxruntime::ml::DictVectorizerOp<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<__int64,double>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<__int64,float>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double>::DictVectorizerOp
onnxruntime::ml::DictVectorizerOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float>::DictVectorizerOp
onnxruntime::ml::FeatureVectorizer::Compute
onnxruntime::ml::FeatureVectorizer::FeatureVectorizer
onnxruntime::ml::ImputerOp::Compute
onnxruntime::ml::ImputerOp::ImputerOp
onnxruntime::ml::LabelEncoder::LabelEncoder
onnxruntime::ml::LabelEncoder_2<__int64,__int64>::LabelEncoder_2
onnxruntime::ml::LabelEncoder_2<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::LabelEncoder_2
onnxruntime::ml::LabelEncoder_2<__int64,float>::LabelEncoder_2
onnxruntime::ml::LabelEncoder_2<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::LabelEncoder_2
onnxruntime::ml::LabelEncoder_2<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float>::LabelEncoder_2
onnxruntime::ml::LabelEncoder_2<float,__int64>::LabelEncoder_2
onnxruntime::ml::LabelEncoder_2<float,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::LabelEncoder_2
onnxruntime::ml::LinearClassifier::ComputeImpl
onnxruntime::ml::LinearClassifier::LinearClassifier
onnxruntime::ml::LinearRegressor::LinearRegressor
onnxruntime::ml::MakeCast
onnxruntime::ml::MakeNormalize
onnxruntime::ml::MakePack
onnxruntime::ml::Normalizer::Normalizer
onnxruntime::ml::OneHotEncoderOp<__int64>::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<double>::OneHotEncoderOp
onnxruntime::ml::OneHotEncoderOp<float>::OneHotEncoderOp
onnxruntime::ml::RegisterOnnxMLOperatorKernels
onnxruntime::ml::ScalerOp<__int64>::ScalerOp
onnxruntime::ml::ScalerOp<double>::ScalerOp
onnxruntime::ml::ScalerOp<float>::ScalerOp
onnxruntime::ml::ScalerOp<int>::ScalerOp
onnxruntime::ml::SVMClassifier::Compute
onnxruntime::ml::SVMClassifier::SVMClassifier
onnxruntime::ml::SVMCommon::SVMCommon
onnxruntime::ml::SVMRegressor<float>::Compute
onnxruntime::ml::SVMRegressor<float>::SVMRegressor
onnxruntime::ml::ZipMapOp::ZipMapOp
onnxruntime::Mod::Mod
onnxruntime::mod_internal::CallModImpl<double,void>::operator ()
onnxruntime::mod_internal::CallModImpl<float,void>::operator ()
onnxruntime::mod_internal::CallModImpl<struct onnxruntime::MLFloat16,void>::operator ()
onnxruntime::Model::Load
onnxruntime::Model::LoadFromOrtFormat
onnxruntime::Model::Model
onnxruntime::Model::Save
onnxruntime::Model::SaveToOrtFormat
onnxruntime::model_load_utils::IsAllowReleasedONNXOpsetsOnlySet
onnxruntime::model_load_utils::ValidateOpsetForDomain
onnxruntime::MoveInputOutput
onnxruntime::Multinomial::Multinomial
onnxruntime::MultinomialCompute
onnxruntime::NchwcTransformer::ApplyImpl
onnxruntime::ngram_details::PopulateGrams
onnxruntime::NhwcTransformer::ApplyImpl
onnxruntime::Node::ForEachWithIndex
onnxruntime::Node::LoadEdgesFromOrtFormat
onnxruntime::Node::LoadEdgesFromOrtFormat::<lambda_25bf04bd2587261b1112d5d221d28912>::operator ()
onnxruntime::Node::LoadFromOrtFormat
onnxruntime::Node::LoadFromOrtFormat::<lambda_9d082e5b6e5038c4215b2f4bff108ed6>::operator ()
onnxruntime::Node::SaveToOrtFormat
onnxruntime::NodeArg::UpdateTypeAndShape
onnxruntime::NodeIndexInfo::GetMLValueIndex
onnxruntime::NodeIndexInfo::GetNodeOffset
onnxruntime::NodeIndexInfo::Init::<lambda_ca37d5ec199e35c30b080471c345d05e>::operator ()
onnxruntime::NodeIndexInfo::Init::<lambda_e256c24a178e1d4e49acb7fa7090a7cb>::operator ()
onnxruntime::NodesToOptimize::GetNode
onnxruntime::NodesToOptimizeIndicesBuilder::Build
onnxruntime::NonMaxSuppression::Compute
onnxruntime::NonMaxSuppressionBase::GetThresholdsFromInputs
onnxruntime::NonMaxSuppressionBase::NonMaxSuppressionBase
onnxruntime::NonMaxSuppressionBase::PrepareCompute
onnxruntime::NonTensorTypeBase::FromDataContainer
onnxruntime::NonTensorTypeBase::IsMapCompatible
onnxruntime::NonTensorTypeBase::IsSequenceCompatible
onnxruntime::NonTensorTypeBase::ToDataContainer
onnxruntime::NonZero<__int64>::Compute
onnxruntime::NonZero<bool>::Compute
onnxruntime::NonZero<float>::Compute
onnxruntime::NonZero<int>::Compute
onnxruntime::NonZero<unsigned char>::Compute
onnxruntime::OneHotOp<__int64,__int64,__int64>::Compute
onnxruntime::OneHotOp<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::Compute
onnxruntime::OneHotOp<__int64,float,__int64>::Compute
onnxruntime::OneHotOp<__int64,float,float>::Compute
onnxruntime::OneHotOp<__int64,float,int>::Compute
onnxruntime::OneHotOp<__int64,int,float>::Compute
onnxruntime::OneHotOp<float,__int64,__int64>::Compute
onnxruntime::OneHotOp<float,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64>::Compute
onnxruntime::OneHotOp<float,float,float>::Compute
onnxruntime::OneHotOp<int,float,float>::Compute
onnxruntime::OneHotOp<int,float,int>::Compute
onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSchemaInternal
onnxruntime::OnnxRuntimeOpSchemaRegistry::RegisterOpSet
onnxruntime::OpKernel::ComputeAsync
onnxruntime::OpKernelContext::GetOrCreateOutputMLValue
onnxruntime::OpKernelContext::Input
onnxruntime::OpKernelContext::NumVariadicInputs
onnxruntime::OpKernelContext::OpKernelContext
onnxruntime::OpKernelContext::Output
onnxruntime::OpKernelContext::OutputMLValue
onnxruntime::OpKernelContext::RequiredInput
onnxruntime::OpKernelContext::RequiredOutput
onnxruntime::OpKernelContextInternal::OpKernelContextInternal
onnxruntime::OpKernelInfo::GetMemoryInfo
onnxruntime::OpNodeProtoHelper<class onnxruntime::ProtoHelperNodeContext>::GetAttrs
onnxruntime::OpNodeProtoHelper<struct onnx::InferenceContext>::GetAttrs
onnxruntime::optimizer_utils::GenerateRewriteRules
onnxruntime::optimizer_utils::GenerateRuleBasedGraphTransformer
onnxruntime::optimizer_utils::GenerateTransformers
onnxruntime::optimizer_utils::GenerateTransformersForRuntimeOptimizations
onnxruntime::OptimizerExecutionFrame::Info::{ctor}::<lambda_11b6908471b85c842f67ae917be35bc8>::operator ()
onnxruntime::OptimizerExecutionFrame::Info::Info
onnxruntime::Optional::Compute
onnxruntime::Optional::Optional
onnxruntime::OptionalGetElement::Compute
onnxruntime::OptionalTypeBase::GetDeleteFunc
onnxruntime::OptionalTypeBase::GetElementType
onnxruntime::OptionalTypeBase::IsCompatible
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Create
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Iterator::Iterator
onnxruntime::OrtValueTensorSlicer<struct OrtValue const >::Iterator::operator *
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Create
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Iterator::Iterator
onnxruntime::OrtValueTensorSlicer<struct OrtValue>::Iterator::operator *
onnxruntime::OuterScopeNodeArgLocationAccumulator
onnxruntime::OuterScopeNodeArgLocationAccumulator::<lambda_10d9e40dd67492c4fb3c3f078abc9bd8>::operator ()
onnxruntime::OuterScopeNodeArgLocationAccumulator::<lambda_f8822893c953bd42037266e93f73744e>::operator ()
onnxruntime::OutputBroadcaster::OutputBroadcaster
onnxruntime::Pad::Compute
onnxruntime::PadBase::PadBase
onnxruntime::PadImpl
onnxruntime::PadInputWithDimValueOfZero
onnxruntime::PadValueFromFloat
onnxruntime::ParallelExecutor::Execute
onnxruntime::ParallelExecutor::RunNodeAsync
onnxruntime::PartitionOnnxFormatModelImpl
onnxruntime::PartitionOrtFormatModelImpl
onnxruntime::Path::Parse
onnxruntime::PlaceNode
onnxruntime::PlannerImpl::AllocPlan
onnxruntime::PlannerImpl::Buffer
onnxruntime::PlannerImpl::ComputeReusePlan
onnxruntime::PlannerImpl::ComputeUseCounts
onnxruntime::PlannerImpl::ComputeUseCounts::<lambda_f3e7e1c16a77783b35cd48a7c1464d44>::operator ()
onnxruntime::PlannerImpl::CreatePlan
onnxruntime::PlannerImpl::GenerateDeallocationPlan
onnxruntime::PlannerImpl::GeneratePlanForWeightsHelper
onnxruntime::PlannerImpl::GetElementSize
onnxruntime::PlannerImpl::GetLocationForNodeInput
onnxruntime::PlannerImpl::Index
onnxruntime::PlannerImpl::ProcessDef
onnxruntime::PlannerImpl::Reuse
onnxruntime::PlannerImpl::UseCount
onnxruntime::PlannerImpl::VerifyMemoryTimeSchedule
onnxruntime::Pool<float,class onnxruntime::LpPool>::Compute
onnxruntime::PoolAttributes::ComputeSizePadDilations
onnxruntime::PoolAttributes::InferOutputSize
onnxruntime::PoolAttributes::PoolAttributes
onnxruntime::PoolAttributes::SetOutputSize
onnxruntime::PoolBase::Compute
onnxruntime::PoolProcessContext::init
onnxruntime::PrePackedWeights::GetHash
onnxruntime::PrepackedWeightsContainer::GetOrCreateAllocator
onnxruntime::PrepareForQDQ
onnxruntime::profiling::Profiler::EndProfiling
onnxruntime::profiling::Profiler::EndTimeAndRecordEvent
onnxruntime::profiling::Profiler::Initialize
onnxruntime::profiling::Profiler::Start
onnxruntime::profiling::Profiler::StartProfiling
onnxruntime::PropagateInputOrtValueToFirstOutput
onnxruntime::ProviderLibrary::Get
onnxruntime::ProviderLibrary::Unload
onnxruntime::ProviderSharedLibrary::Ensure
onnxruntime::ProviderSharedLibrary::Unload
onnxruntime::QDQPropagationTransformer::ApplyImpl
onnxruntime::QDQS8ToU8Transformer::ApplyImpl
onnxruntime::QLinearConv::Compute
onnxruntime::QLinearConv::ComputeOffset
onnxruntime::QLinearConv::ComputeOutputScale
onnxruntime::QLinearConv::UseSharedPrePackedBuffers
onnxruntime::QLinearMatMul::Compute
onnxruntime::RandomNormal::RandomNormal
onnxruntime::RandomNormalLike::RandomNormalLike
onnxruntime::RandomUniform::RandomUniform
onnxruntime::RandomUniformLike::RandomUniformLike
onnxruntime::ReduceKernelBase<0>::ReduceKernelBase
onnxruntime::ReduceKernelBase<1>::ReduceKernelBase
onnxruntime::RegisterCPUKernels
onnxruntime::RegisterOnnxOperatorKernels
onnxruntime::ReleaseNodeMLValues
onnxruntime::RemoveDuplicateCastTransformer::ApplyImpl
onnxruntime::ReorderCastAndTranspose
onnxruntime::ReplaceWithNew::Run
onnxruntime::ReplaceWithNew::RunForSave
onnxruntime::Reshape::Compute
onnxruntime::Reshape_1::Reshape_1
onnxruntime::ReshapeFusion::ApplyImpl
onnxruntime::ReshapeFusion::Fuse_Subgraph
onnxruntime::ReshapeHelper::ReshapeHelper
onnxruntime::ResultsNoTransposePrepareForReduce::ValidateNotEmpty
onnxruntime::ReverseSequenceOp::Compute
onnxruntime::ReverseSequenceOp::ReverseSequenceOp
onnxruntime::rnn::detail::ComputeGemm
onnxruntime::rnn::detail::deepcpu::ActivationFuncByName
onnxruntime::rnn::detail::deepcpu::GruOutputGateFuncByName
onnxruntime::rnn::detail::deepcpu::GruResetGateFuncByName
onnxruntime::rnn::detail::deepcpu::LstmMergeGatesFuncByName
onnxruntime::rnn::detail::MakeDirection
onnxruntime::rnn::detail::NormalizeActivationArgumentAndGetAlphaBetaCount
onnxruntime::rnn::detail::SafeRawConstPointer
onnxruntime::rnn::detail::SafeRawPointer
onnxruntime::RNN<float>::Compute
onnxruntime::RNN<float>::RNN
onnxruntime::RoiAlignBase::RoiAlignBase
onnxruntime::RoiPool<float>::Compute
onnxruntime::RoiPool<float>::RoiPool
onnxruntime::RuleBasedGraphTransformer::ApplyImpl
onnxruntime::RuleBasedGraphTransformer::ApplyRulesOnNode
onnxruntime::SaveModel
onnxruntime::scan::detail::AllocateOutput
onnxruntime::scan::detail::CreateFeedsFetchesManager
onnxruntime::scan::detail::Info::Info
onnxruntime::scan::detail::IterateSequence
onnxruntime::scan::detail::IterateSequence::<lambda_e4de1e6d15c53abac777de14725b2d0a>::operator ()
onnxruntime::scan::detail::LoopStateVariable::Next
onnxruntime::scan::detail::OutputIterator::AllocateFinalBuffer
onnxruntime::scan::detail::OutputIterator::AllocateFinalOutput
onnxruntime::scan::detail::OutputIterator::GetOutput
onnxruntime::scan::detail::OutputIterator::Initialize
onnxruntime::scan::detail::OutputIterator::operator *
onnxruntime::scan::detail::OutputIterator::operator ++
onnxruntime::scan::detail::ReadDirections
onnxruntime::Scan<8>::Compute
onnxruntime::Scan<8>::Init
onnxruntime::Scan<8>::SetupSubgraphExecutionInfo
onnxruntime::Scan<9>::Compute
onnxruntime::Scan<9>::Init
onnxruntime::Scan<9>::SetupSubgraphExecutionInfo
onnxruntime::Scan8Impl::AllocateOutputTensors
onnxruntime::Scan8Impl::CreateLoopStateVariables
onnxruntime::Scan8Impl::Execute
onnxruntime::Scan8Impl::Initialize
onnxruntime::Scan8Impl::ValidateInput
onnxruntime::ScanImpl::AllocateOutputTensors
onnxruntime::ScanImpl::CreateLoopStateVariables
onnxruntime::ScanImpl::Execute
onnxruntime::ScanImpl::Initialize
onnxruntime::ScanImpl::SetupInputs
onnxruntime::ScanImpl::TransposeOutput
onnxruntime::ScanImpl::ValidateInput
onnxruntime::Scatter<struct onnxruntime::TypeList<float,double,__int64,unsigned __int64,int,unsigned int,short,unsigned short,signed char,unsigned char,struct onnxruntime::MLFloat16,struct onnxruntime::BFloat16,bool,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > >::Scatter
onnxruntime::ScatterND::Compute
onnxruntime::ScatterNDBase::PrepareForCompute
onnxruntime::SelectorActionTransformer::ApplyImpl
onnxruntime::SelectorActionTransformer::MatchAndProcess
onnxruntime::SelectorActionTransformer::SelectorActionTransformer
onnxruntime::SelectorsAndActions::RegisterSelectorAndAction
onnxruntime::SequenceConstruct::Compute
onnxruntime::SequenceEmpty::Compute
onnxruntime::SequenceErase::Compute
onnxruntime::SequenceInsert::Compute
onnxruntime::SequenceTensorTypeBase::GetElementType
onnxruntime::SequenceTensorTypeBase::IsCompatible
onnxruntime::SequentialExecutor::Execute
onnxruntime::session_state_utils::DeserializeTensorProto
onnxruntime::session_state_utils::SaveInitializedTensors
onnxruntime::session_state_utils::SaveInitializedTensors::<lambda_59a68c93b954c1615c2da7f82b7605e4>::operator ()
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping::<lambda_5f4d12f5625f87c7fb1ce2d7795c65fa>::operator ()
onnxruntime::session_state_utils::SaveInputOutputNamesToNodeMapping::<lambda_6f564a616944b22adda71fa903488618>::operator ()
onnxruntime::SessionState::AddOutputNameToNodeInfoMapping
onnxruntime::SessionState::AddSubgraphSessionState
onnxruntime::SessionState::CreateGraphInfo
onnxruntime::SessionState::CreateSubgraphSessionState
onnxruntime::SessionState::FinalizeSessionState
onnxruntime::SessionState::FinalizeSessionStateImpl
onnxruntime::SessionState::GetNodeIndexInfo
onnxruntime::SessionState::GetNodeKernelCreateInfo
onnxruntime::SessionState::LoadFromOrtFormat
onnxruntime::SessionState::LoadFromOrtFormat::<lambda_c5c5b355d2a2c88bd85d8931b713a2e0>::operator ()
onnxruntime::SessionState::PopulateKernelCreateInfo
onnxruntime::SessionState::PrepackConstantInitializedTensors::<lambda_61c6200b3fa909ae7eb7a3a40a81346e>::operator ()
onnxruntime::SessionState::SaveToOrtFormat
onnxruntime::SessionState::SetupAllocators
onnxruntime::SessionState::UpdateToBeExecutedNodes
onnxruntime::SetEnableProfiling
onnxruntime::SetExecutionMode
onnxruntime::SetGraphOptimizationLevel
onnxruntime::SetInterOpNumThreads
onnxruntime::SetIntraOpNumThreads
onnxruntime::Shrink::Shrink
onnxruntime::SimplifiedLayerNormFusion::ApplyImpl
onnxruntime::SliceBase::Compute
onnxruntime::SliceBase::FillVectorsFromInput
onnxruntime::SliceBase::PrepareForCompute
onnxruntime::SliceBase::SliceBase
onnxruntime::SliceImpl::<lambda_2f378bba7d73ec2c16a1e9a755eda4f7>::operator ()
onnxruntime::SliceImpl::<lambda_66f06e233b0a64f25a2f272d85a883a3>::operator ()
onnxruntime::SliceImpl::<lambda_93ca941f50a0a49b2b4c0ced3b0c592e>::operator ()
onnxruntime::SliceImpl::<lambda_bc7a68c171e484232baed5d83da3897a>::operator ()
onnxruntime::SliceImpl::<lambda_bcecb15eb8cf7fa8e3b34d315d7dea50>::operator ()
onnxruntime::SliceIteratorBase::CopyInnermostAxisNonSolitaryInnerStep
onnxruntime::SliceIteratorBase::Init
onnxruntime::SliceSkips::SliceSkips
onnxruntime::Softmax<double>::ComputeImplOpset13
onnxruntime::Softmax<float>::ComputeImplOpset13
onnxruntime::SpaceDepthBase::SpaceDepthBase
onnxruntime::SpaceToDepth::Compute
onnxruntime::sparse_utils::DenseTensorToSparseCoo
onnxruntime::sparse_utils::DenseTensorToSparseCsr
onnxruntime::sparse_utils::SparseCooToDenseTensor
onnxruntime::sparse_utils::SparseCsrToDenseTensor
onnxruntime::SparseTensor::AllocateBuffer
onnxruntime::SparseTensor::AsBlockSparse
onnxruntime::SparseTensor::AsCoo
onnxruntime::SparseTensor::AsCsr
onnxruntime::SparseTensor::Copy
onnxruntime::SparseTensor::GetCooIndexDims
onnxruntime::SparseTensor::GetSparseTensorFromOrtValue
onnxruntime::SparseTensor::MakeBlockSparseData
onnxruntime::SparseTensor::MakeBlockSparseStrings
onnxruntime::SparseTensor::MakeCooData
onnxruntime::SparseTensor::MakeCooStrings
onnxruntime::SparseTensor::MakeCsrData
onnxruntime::SparseTensor::MakeCsrStrings
onnxruntime::SparseTensor::UseBlockSparseIndices
onnxruntime::SparseTensor::UseCooIndices
onnxruntime::SparseTensor::UseCsrIndices
onnxruntime::SparseTensor::ValidateBlockSparseShapes
onnxruntime::SparseTensor::ValidateCsrIndices
onnxruntime::SparseTensorTypeBase::GetElementType
onnxruntime::SparseTensorTypeBase::IsCompatible
onnxruntime::Split::Compute
onnxruntime::Split::ComputeImpl
onnxruntime::SplitBase::SplitBase
onnxruntime::SplitToSequence::ComputeImpl
onnxruntime::Squeeze::Compute
onnxruntime::SqueezeBase::ComputeOutputShape
onnxruntime::StridedCopy
onnxruntime::StridedCopy::<lambda_11e4c67999de7fde8000f344864dbedb>::operator ()
onnxruntime::StridedCopy::<lambda_2db246e2ce365efa8cc2cf5d40338a67>::operator ()
onnxruntime::StridedCopy::<lambda_414b2f36cd6ead6cc1f643a6940e8f0c>::operator ()
onnxruntime::StridedCopy::<lambda_4b2e976425c8109a05bca3d80983d4bb>::operator ()
onnxruntime::StridedCopy::<lambda_4b6703e7c30870568a65367efbb3ac2f>::operator ()
onnxruntime::StridedCopy::<lambda_9162731c94ecaf479f99be17541de90c>::operator ()
onnxruntime::StridedCopy::<lambda_9a0964aea19bb920233e6fe5b8fa95e2>::operator ()
onnxruntime::StridedCopy::<lambda_b9d9aa3891683438224b1c5285b28a19>::operator ()
onnxruntime::StridedCopy::<lambda_c883cb8d41543031ae666c752948f20d>::operator ()
onnxruntime::StridedCopy::<lambda_ff1ccdcb7441249452b8640b2e9dfe31>::operator ()
onnxruntime::string_normalizer::Locale::Locale
onnxruntime::StringNormalizer::StringNormalizer
onnxruntime::StringToAutoPadType
onnxruntime::Sum_6<double>::Compute
onnxruntime::Sum_6<float>::Compute
onnxruntime::SwapAdjacentNodes
onnxruntime::SyncProviders
onnxruntime::Tensor::Data
onnxruntime::Tensor::DataAsSpan
onnxruntime::Tensor::DataRaw
onnxruntime::Tensor::Init
onnxruntime::Tensor::MutableData
onnxruntime::Tensor::MutableDataAsSpan
onnxruntime::Tensor::MutableDataRaw
onnxruntime::Tensor::Reshape
onnxruntime::Tensor::SizeInBytes
onnxruntime::Tensor::Tensor
onnxruntime::TensorAllocator::TensorAllocator
onnxruntime::TensorSeq::Add
onnxruntime::TensorSeq::Get
onnxruntime::TensorSeq::SetType
onnxruntime::TensorShape::SizeFromDimension
onnxruntime::TensorShape::SizeToDimension
onnxruntime::TensorShape::Slice
onnxruntime::TensorTypeBase::GetElementType
onnxruntime::TensorTypeBase::IsCompatible
onnxruntime::TfIdfVectorizer::TfIdfVectorizer
onnxruntime::Tile::Compute
onnxruntime::ToMBString
onnxruntime::TopkOpset10ConstructorCommon
onnxruntime::TopkOpset11ConstructorCommon
onnxruntime::TopkOpset9ConstructorCommon
onnxruntime::ToWideString
onnxruntime::TransformerMemcpyImpl::ProcessDefs
onnxruntime::TransformerMemcpyImpl::ProcessInitializers
onnxruntime::TransformerMemcpyImpl::ProcessInitializers::<lambda_e2d9c65f3423a9c8d6e3cd7ee2b26307>::operator ()
onnxruntime::Transpose::Compute
onnxruntime::TransposeBase::TransposeBase
onnxruntime::TransposeOptimizer::ApplyImpl
onnxruntime::Trilu::Compute
onnxruntime::Trilu::Trilu
onnxruntime::TypedDoTransposeEltWise
onnxruntime::Unsqueeze::Compute
onnxruntime::UnsqueezeBase::PrepareCompute
onnxruntime::UnsqueezeBase::UnsqueezeBase
onnxruntime::UnsqueezeElimination::Apply
onnxruntime::UntypedExpand
onnxruntime::UpdateConsumerCount
onnxruntime::UpdateSubgraphsWithinFunctionBody
onnxruntime::Upsample<float>::BaseCompute
onnxruntime::Upsample<float>::Compute
onnxruntime::Upsample<int>::BaseCompute
onnxruntime::Upsample<int>::Compute
onnxruntime::Upsample<unsigned char>::BaseCompute
onnxruntime::Upsample<unsigned char>::Compute
onnxruntime::UpsampleBase::ParseScalesData
onnxruntime::UpsampleBase::ParseScalesDataFromOutputSize
onnxruntime::UpsampleBase::ScalesValidation
onnxruntime::UpsampleBase::StringToCoordinateTransformationMode
onnxruntime::UpsampleBase::StringToNearestMode
onnxruntime::UpsampleBase::StringToUpsampleMode
onnxruntime::UpsampleBase::UpsampleBase
onnxruntime::UpsampleNearest
onnxruntime::utils::BatchOrCopyMLValue
onnxruntime::utils::CalculateStaticCopyInfoForFeed
onnxruntime::utils::CalculateStaticCopyInfoForFeeds
onnxruntime::utils::ConstantNodeProtoToTensorProto
onnxruntime::utils::ContainerChecker::ContainerChecker
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,__int64,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,__int64> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,double,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,double> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,__int64,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,__int64> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,double,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,double> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::vector<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > >,class std::allocator<class std::map<__int64,float,struct std::less<__int64>,class std::allocator<struct std::pair<__int64 const ,float> > > > > >::check
onnxruntime::utils::ContainerChecker::IsContainerOfType<class std::vector<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > >,class std::allocator<class std::map<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> >,float,struct std::less<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > >,class std::allocator<struct std::pair<class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const ,float> > > > > >::check
onnxruntime::utils::CopyInputsAcrossDevices
onnxruntime::utils::CopyOneInputAcrossDevices
onnxruntime::utils::CopyOutputsAcrossDevices
onnxruntime::utils::CopySparseData
onnxruntime::utils::DenseTensorToSparseTensorProto
onnxruntime::utils::detail::CopyLittleEndian
onnxruntime::utils::ExecuteGraph
onnxruntime::utils::ExecuteGraphImpl
onnxruntime::utils::FinalizeCopyInfoForFeeds
onnxruntime::utils::FinalizeCopyInfoForFetches
onnxruntime::utils::FindMemoryInfoForValue
onnxruntime::utils::GetElementTypeFromOptionalSeqTensor
onnxruntime::utils::GetElementTypeFromOptionalTensor
onnxruntime::utils::GetFileContent
onnxruntime::utils::GetMLDataType
onnxruntime::utils::GetShape
onnxruntime::utils::InitializeFeedFetchCopyInfo
onnxruntime::utils::mltype_dispatcher_internal::CallableDispatchableHelper::CheckCalledOnce
onnxruntime::utils::mltype_dispatcher_internal::UnsupportedTypeDefaultPolicy<class onnxruntime::common::Status>::operator ()
onnxruntime::utils::SparseTensorProtoToDenseTensorProto
onnxruntime::utils::TensorProtoToMLValue
onnxruntime::utils::TensorProtoToTensor
onnxruntime::utils::UnpackInitializerData
onnxruntime::utils::UnpackTensorWithExternalDataImpl
onnxruntime::ValidateCommonFastReduce
onnxruntime::ValidateFastReduceKR
onnxruntime::ValidateFastReduceKRK
onnxruntime::ValidateFastReduceRK
onnxruntime::ValidateKeepDims
onnxruntime::ValidateMustBeOverloaded
onnxruntime::ValidateNoTransposeReduce
onnxruntime::ViewerFunctionImpl::Body
onnxruntime::ViewerFunctionImpl::MutableBody
onnxruntime::WritableSliceIterator<__int64>::Init
onnxruntime::WritableSliceIterator<double>::Init
onnxruntime::WritableSliceIterator<float>::Init
onnxruntime::WritableSliceIterator<int>::Init
onnxruntime_profile_
onnxruntime_providers_cuda.dll
onnxruntime_providers_dnnl.dll
onnxruntime_providers_openvino.dll
onnxruntime_providers_rocm.dll
onnxruntime_providers_shared.dll
onnxruntime_providers_tensorrt.dll
ool)u
Op registered for 
Op with name (
op_kernel_info.GetAttr("axis", &axis_).IsOK()
op_kernel_info.GetAttr<float>("bias", &bias_temp).IsOK()
op_kernel_info.GetAttr<float>("epsilon", &epsilon_).IsOK()
op_kernel_info.GetAttr<float>("lambd", &lambd_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("axis", &axis_).IsOK()
op_kernel_info.GetAttr<int64_t>("axis", &axis_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("k", &k_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("largest", &largest_temp).IsOK()
op_kernel_info.GetAttr<int64_t>("p", &p_).IsOK()
op_kernel_info.GetAttr<int64_t>("sorted", &sorted_temp).IsOK()
op_type
opaque
Opaque type is not a non_tensor type!!!
opaque(
opaque_type
open file 
OpenSemaphoreW
OpenVINO_GPU
OpenVINOExecutionProvider
operation canceled
operation in progress
operation not permitted
operation not supported
operation would block
Operator '
OpKernel was null
opset id is null. Invalid ORT format model.
opset import domain is null. Invalid ORT format model.
opt_k_transpose perm attribute not matched
optimization.enable_gelu_approximation
optimization.save_runtime_optimizations
optimizer_utils::CheckOutputEdges(graph, up_node, 1)
Optional
optional
Optional is expected to have an output.
Optional is expected to have either an input or the type attribute set.
Optional op must have a TypeProto in the 'type' attribute if the attribute is present
Optional position subgraph nodes number of outputs unexpected.
Optional position subgraph nodes Where node is expected to be the parent of Reshape.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.
Optional scaling values used by some activation functions. The values are consumed in the order of activation functions, for example (f, g, h) in LSTM. Default values are the same as of corresponding ONNX operators.For example with LeakyRelu, the default alpha is 0.01.
Optional Type mismatch. Expected: 
optional(
optional(seq(tensor(bool)))
optional(seq(tensor(complex128)))
optional(seq(tensor(complex64)))
optional(seq(tensor(double)))
optional(seq(tensor(float)))
optional(seq(tensor(float16)))
optional(seq(tensor(int16)))
optional(seq(tensor(int32)))
optional(seq(tensor(int64)))
optional(seq(tensor(int8)))
optional(seq(tensor(string)))
optional(seq(tensor(uint16)))
optional(seq(tensor(uint32)))
optional(seq(tensor(uint64)))
optional(seq(tensor(uint8)))
optional(tensor(bool))
optional(tensor(complex128))
optional(tensor(complex64))
optional(tensor(double))
optional(tensor(float))
optional(tensor(float16))
optional(tensor(int16))
optional(tensor(int32))
optional(tensor(int64))
optional(tensor(int8))
optional(tensor(string))
optional(tensor(uint16))
optional(tensor(uint32))
optional(tensor(uint64))
optional(tensor(uint8))
optional_type
OptionalGetElement
OptionalGetElement must have an input element.
OptionalHasElement
OptionalHasElement is expected to have 1 input.
OptionalHasElement is expected to have 1 output.
or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.
Order
OriginalFilename
Oriya
ORT config json from the model: 
ORT model verification failed.
ORT optimization- Force fallback to CPU execution for node: 
ort_config
ORT_LOAD_CONFIG_FROM_MODEL
ort_value.Fence() == nullptr
ort_value.IsAllocated()
ort_value.IsTensor()
ort_value_idx >= 0 && static_cast<size_t>(ort_value_idx) < alloc_plan.size()
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < all_values_size_
ort_value_index >= 0 && static_cast<size_t>(ort_value_index) < alloc_plan.size()
ort_value_name_idx_map.MaxIdx() > -1
OrtApis::CreateOpaqueValue
OrtApis::FillSparseTensorBlockSparse
OrtApis::FillSparseTensorCoo
OrtApis::FillSparseTensorCsr
OrtApis::GetOpaqueValue
OrtApis::GetTensorTypeAndShape
OrtApis::UseBlockSparseIndices
OrtApis::UseCooIndices
OrtApis::UseCsrIndices
OrtCreateMapMLValue
OrtCreateValueImplMapHelper
OrtCreateValueImplSeqHelper
OrtEnv::Release
OrtGetApiBase
OrtGetWinMLAdapter
OrtMemoryInfo is null
OrtMemoryInfo:[
ORTMH
OrtProgrammingProjection
OrtSessionOptionsAppendExecutionProvider_CPU
OrtSessionOptionsAppendExecutionProvider_Cuda: Failed to load shared library
OrtSessionOptionsAppendExecutionProvider_DML
OrtSessionOptionsAppendExecutionProvider_Rocm: Failed to load shared library
OrtSessionOptionsAppendExecutionProviderEx_DML
OrtValue has not been allocated so can't be sliced.
OrtValue indexes should have been populated.
OrtValue is TensorSequence type but has no element Tensor DataType.
OrtValue shape verification failed. Current shape:
OrtValue should contain a Tensor or a Sparse Tensor
OrtValue::Get
OrtValue::GetMutable
Osage
Osmanya
oT$@f
other_error
other_sum_input != nullptr
oublu
out of index
Out of memory
out_of_range
Outer index count must be rows + 1 or zero. Got: 
Outer indices must be M + 1. Got: 
Outer scope node arg name '
Outer size must be M + 1
outer_num == (rows + 1)
outer_scope_node_arg != nullptr
outer_scope_node_args_consumed.empty()
OutOfBoundsInputValue
output
Output
Output 
output != nullptr
output == output_end
output and sum shape must match
Output buffer allocation failed
output buffer is too small. Use GetStringTensorDataLength.
Output case #1: Y, mean, var, saved_mean, saved_var (training mode)
Output case #1: Y, running_mean, running_var (training_mode=True)
Output case #2: Y (test mode)
Output case #2: Y (training_mode=False)
Output channels M is not divisible by group.
output count mismatch, expected 2 outputs to be present for TopK operator
Output data after scaling
Output data tensor.
Output edge count not expected for Add or MatMul in path v
Output edge count not expected for mask nodes
Output edge count not expected for nodes in gemm gather path
Output edge count not expected for nodes in gemm path
Output edge count not expected for nodes in past subgraph
Output edge count not expected for nodes in path 1 of position shape.
Output edge count not expected for nodes in path 1 of unidirectional mask
Output edge count not expected for nodes in path 2 of position shape.
Output edge count not expected for nodes in path v
Output edge count not expected for nodes in path1.
Output edge count not expected for Softmax
Output edge count not expected for squeeze_2/slices2/shape2 of unidirectional mask
Output edge count not expected for unsqueeze2 of unidirectional mask
Output edge count not expected for unsqueeze3 of unidirectional mask
output edges
output name cannot be empty
Output OrtValue has not been created for loop state variable output 
Output size mismatch.
Output subscript contains letters not seen in the inputs
Output subscript contains repeated letters
output tensor
Output tensor must have at least 2 dimensions
Output tensor of shape (M, N).
Output tensor of the same type and shape as the input tensor.
Output tensor of the same type as the input tensor. Shape of the output is * x M, where '*' is the shape of input indices, and 'M' is the embedding size.
Output type is determined by the specified 'values_*' attribute.
Output type must be int32 or int64
Output type not supported in this build: 
Output vector incorrectly sized: output_names.size(): 
Output vector pointer is NULL
Output was expected to have tensor type. Got 
output, dropout_mask = Dropout(data + bias, ratio) + residual, Intended to specialize the dropout pattern commonly found in transformer models.
output.SizeInBytes() == input.SizeInBytes()
Output:
output_dims.size() == dims.size()
output_dims[i] == 0
output_height
output_mlvalue
output_names_to_nodeinfo.empty()
output_node.OutputDefs().size() == 1
output_padding
output_ptr
output_sequence
output_shape
output_shape is smaller than minimum required. output_shape:
'output_shape' must be rank 1 tensor.
'output_shape' must have same number of elements as the shape of input tensor X.
output_size
output_width
OutputBiasGradientTensor
OutputCellSingleTensor
OutputCoordinatesTensor
OutputCount
OutputCountTensor
OutputDebugStringW
OutputFirstMomentTensor
OutputGradientTensor
OutputIndexTensor
OutputIndicesTensor
OutputMeanTensor
OutputPadding
OutputParametersTensor
OutputPixelOffset
OutputPixelOffsets
OutputROIGradientTensor
outputs
Outputs from Scan are not optional and should never be null.
outputs...
OutputScaleGradientTensor
OutputScaleTensor
OutputSecondMomentTensor
OutputSequenceTensor
OutputSingleTensor
OutputStateTensor
OutputTensor
OutputTensors
OutputValueTensor
OutputVarianceTensor
OutputZeroPointTensor
owner dead
OXI;OX
P .",
P \\P-
p AWH
P H+P
P Hc@
P I+P
P J"6
p L+p
p L9f
p M9f
p p t y 
p P6!
p UWATAVAWH
p UWATH
p UWAUAVAWH
p UWAVH
p UWAWH
p value of the Lp norm used to pool over the input data, default is 2.0.
p value of the Lp norm used to pool over the input data.
p WATAUAVAWH
p WAVAWH
p!\PI
p!Tme_
p"]Th
p"Rz-
p#UP:
p#Xr0
P%DBY
P&R,P T
P(H;P0t
p(l`hhlbx
P,XJZ
P.7JdY
p.first->second->id_ == 0
p.second
p:(-=8
p:_0#
P:p&W
p;TXi
P@I+P8H
p@PRg7
p@vDW7]
p[TVd?
p^&?^
p^]u]
p^|TY
p^r(plr(plr(plr"pN|"pXl
P^w~]
p_ == 1 || p_ == 2
p_fetches->size(): 
p_int < base_int + memory_size_
p_int >= base_int
p_kernel_def
p_ml_value
p_mlvalue
p_op_kernel
p_provider
p_type != nullptr
p</w1I
P>|TY
p>|TY
P08~|TY
P08N|TY
P0Hc@(H
p0Qt 
p0S|I&
P2c7l
p2S\S
P2v)c\
p2W<R.
P5Vfo*|
p6$E^
P6;w]
p6|TY
P6|TY
p6|TY
P6|TY
p6<?^
p7M}6p7M
p7YGJ
P8@HP^
p8@HPX`hp
P8@HPX`hpx
P8E8Q8t)I
p8H;]
p8V||
p9U4X
pA^^[
pA^_^
PA^_^
pA^_^
PA^_^
pA^_^[]
PA^_^[]
pA^_^[]
PA^_^[]
pA^_^[]
PA^_^[]
pA^_^[]
PA^_^[]
PA^_^][
pA^_^][
PA^_^][
pA^_^][
PA^_^][
pA^A\_^]
PA^A\_^]
pA__^[]
PA_A]A\_^
PA_A^_][
pA_A^_^[
PA_A^_^[
pA_A^_^[
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
PA_A^_^]
pA_A^_^]
pA_A^A\^[
PA_A^A\^[
PA_A^A\_^
pA_A^A\_^
PA_A^A\_^
pA_A^A\_^
pA_A^A\_^[]
PA_A^A\_^[]
pA_A^A\_^[]
PA_A^A\_^[]
pA_A^A\_^[]
PA_A^A\_^[]
pA_A^A\_^[]
PA_A^A\_^[]
pA_A^A\_^[]
PA_A^A\_^[]
PA_A^A\_^][
pA_A^A\_^][
PA_A^A\_^][
PA_A^A]_^][
PA_A^A]A\^
pA_A^A]A\_
PA_A^A]A\_^[
pA_A^A]A\_^[
PA_A^A]A\_^[
pA_A^A]A\_^[
PA_A^A]A\_^[
pA_A^A]A\_^[
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
PA_A^A]A\_^]
pA_A^A]A\_^]
Pad should be smaller than kernel.
pad_value
Padding for the beginning and ending along each axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute.
Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0. The value represent the number of pixels added to the beginning and end part of the corresponding axis. `pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`. This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaults to 0 along start and end of each spatial axis.
Padding for the beginning and ending along each spatial axis, it can take any value greater than or equal to 0.The value represent the number of pixels added to the beginning and end part of the corresponding axis.`pads` format should be as follow [x1_begin, x2_begin...x1_end, x2_end,...], where xi_begin the number ofpixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.This attribute cannot be used simultaneously with auto_pad attribute. If not present, the padding defaultsto 0 along start and end of each spatial axis.
padding_idx
padding_mode
padding_mode "
padding_mode_str == "zeros" || padding_mode_str == "border" || padding_mode_str == "reflection"
PaddingMode
paddings
PaddingValue
PaddingValueDataType
Pads has incorrect number of values
'pads' has wrong number of values
'pads' input must be a 1D (shape: [2 * input_rank]) tensor of type int64
'pads' input must be a 1D (shape: [2 * n_input_dims]) tensor of type int64
'pads' input must be a 1D (shape: [input_rank]) or 2D tensor (shape: [1, input_rank]) of type int64
Pads tensor should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]
Pads tensor should be an INT64 tensor
Pads tensor size should be equal to twice the input dimension count 
pads[dim] < kernel_shape[dim] && pads[dim + kernel_shape.size()] < kernel_shape[dim]
pads_[dim] < kernel_shape_[dim] && pads_[dim + kernel_shape_.size()] < kernel_shape_[dim]
pads_size == 2 * data_rank
pads_tensor.IsDataType<int64_t>()
pads_tensor_dims.size() == 1 || (pads_tensor_dims.size() == 2 && pads_tensor_dims[0] == 1)
Pahawh_Hmong
Palmyrene
Parallel execution mode does not support the CUDA Execution Provider. 
Parallel execution mode does not support the DML Execution Provider. 
Parallel mode
ParallelExecutor::Execute
parameter_size
ParametricSoftplus
ParametricSoftplus takes one input data (Tensor<T>) and produces one output data
parse
parse error
parse_error
ParseData type mismatch for tensor: 
parsing 
PartA_PrivTags
Pass 1 to enable broadcasting
Pass CheckNodesInPathK
Pass CheckNodesInPathQ
Pass CheckNodesInPathV
Pass MatchGemmSubgraph
Pass MatchInputMaskSubgraph
Pass MatchInputMaskSubgraphDistilBert
Pass MatchPastSubgraph
Pass MatchUnidirMaskSubgraph
Pass ValidateGemmInitializer
past_k_gather indices != 0
past_k_transpose perm attribute not matched
past_v_gather and past_k_gather does not have same past input
past_v_gather indices != 1
PathCchRemoveBackslash
PathCchRemoveFileSpec
pattern length 
pattern too large - compile failed
Pau_Cin_Hau
pcP>w
pcU>>
pCZTG?)
PeepholeTensor
Per-column quantization parameter of batched matrix should have same dimension as the matrix,and its size by K should be equal to the matrix's size.
Perform mean variance normalization.
Performs element-wise binary {name} on 8 bit data types (with Numpy-style broadcasting support).
perm.size() == gsl::narrow_cast<size_t>(shape_proto->dim_size())
perm: 
perm@
permD
permission denied
Permutation entry 
Permutation length 
pf|TY
pfzz(Q
pG Df
pG@Df
pG`Df
PH;w(r
Phags_Pa
Phoenician
Phttp://www.microsoft.com/pkiops/certs/Microsoft%20Time-Stamp%20PCA%202010(1).crt0
pHZR4
pi[Z[
pj[\x
Please fetch output tensor with specified shape.
Please register the allocator as OrtDeviceAllocator even if the provided allocator has arena logic built-in. OrtArenaAllocator is reserved for internal arena logic based allocators only.
pO6BN+2v#
points_.empty()
pool_attrs_.kernel_shape.size() == 2
pool_int64s
pool_strings
pool_strings must not be empty if specified
pooled_height_ > 0
pooled_shape
pooled_shape.size() == 2
pooled_width_ > 0
PooledSize
Popularity of each node, used for performance and may be omitted.
position
Position embedding data type shall be float or float16.
Position embedding scale must be a scalar or 1D tensor of size 1
Position embedding shape is not expected.
Position embedding shape not matched.
Position embedding zero point must be a scalar or 1D tensor of size 1
position_ >= 0 && position_ < sequence_length_
position_embedding
position_embedding is expected to have 2 dimensions, got 
position_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
position_embedding_quant
position_embedding_scale
position_embedding_zero_point
position_embeddings
position_ids
positive
positiveH
positiveI
post_transform
Pow takes input data (Tensor<T>) and exponent Tensor, and
pP[\=
pP^P[
PPH;V
PPI;S
pq^^|
pq_PT'
pqXrv
pred_tokens
pred_tokens_len == (src_tokens_len + 1 - prev_suffix_match_idx_data)
predictions.size() == (size_t)n_targets_or_classes_
predictions.size() == 2
predictions.size() == predictions2.size()
PrefixShape = Slice (XShape, Zero1D, Axis1D)
PRelu
prepacked_buffers[0].get() == nullptr
present
present_k_transpose perm attribute not matched
present_k_unsqueeze axes value not expected
present_v_unsqueeze axes value not expected
prev_suffix_match_idx
Previous entry was not terminated.
prob_a
prob_b
proba_.size() == probb_.size()
Processed_STD
ProcessInfo
Produces a slice of the input tensor along multiple axes. Similar to numpy:
produces one output data (Tensor<T>) where the function `f(x) = x^exponent`,
ProductName
ProductVersion
Profiler is disabled.
Profiler not started yet
program size 
projected_index.size() > 0
proto != nullptr
Protobuf parsing failed.
Protobuf serialization failed.
protocol error
protocol not supported
Provided allocator is null
provided axis. The resulting tensor has the same rank as the input if keepdims equal 1.
Provided OrtMemoryInfo is null
Provided type is not an optional sequence tensor
Provided type is not an optional tensor
provider
Provider 
Provider_SetHost
providerH
ProviderH9H
pRT8Y
Psalter_Pahlavi
pSV~0
pUqL?k
pVkwx
pWpDfD
PXL9WX
pXQtf
pytorch_half_pixel
pz^:7'
q _xY
Q +Q0
q and v are not from same Split node
Q D8R t/H
Q H+Q
Q L9APL
q P6!
q root should be layer normalization
q X>Y
q!\PI
q!_X;
q!P~'
q!UVt
q!YzX?A
q"]Th
q"Rz-
q"V>\?
q"Zzv6
q#Sz}
q#UP:
q#Xr0
Q(+Q0
q(Hci 3
q(Hci A
q)U^#
q*]p-
q:_0#
q:U>N
q:X6p
q;TXi
Q?nh+
q@PRg7
q[TVd?
q\Q17
q_matmul and q_add shape not matched
q_reshape const not matched
q_transpose perm attribute not matched
q_weight
q+Q<^
q+Rr`
Q0H;P
Q0H+Q(H
q0L+q(I
q0Qt 
q0R^G'
q0S|I&
q0SZ+6p
q0Y62
q1RX&
q2\Zi
q2W<R.
q3]x!7d
q8^pi
q8+q(M
Q8H+Q0H
q8V||
q9R43
q9U4X
qaPp|
QAttention
qaUvT
qb]rn
QbQ}X
Qbr}X
QbreH
qBTXM
qbVZd
qcP>w
qCPTn
qcU>>
qcVx:
qCZpO
qCZTG?)
qd7&[p
qdq_s8_to_u8_quant
qdq_s8_to_u8_zp_conversion
QDQPropagationTransformer
QDQS8ToU8Transformer
QDQSelectorActionTransformer
QEmbedLayerNormalization
qf^2j
QGemm
QGemm : scale of input a must be a scalar or 1D tensor of size 1
QGemm : scale of input b must be a scalar or 1D tensor of size 1 or N
QGemm : scale of y must be null or a scalar or 1D tensor of size 1
QGemm : zero point and scale of input b should have same shape size
QGemm : zero point of input a must be a scalar or 1D tensor of size 1
QGemm : zero point of input b must be a scalar or 1D tensor of size 1 or N
QGemm : zero point of y must be null or a scalar or 1D tensor of size 1
QHH+Q@H
qHZR4
qi[Z[
qIR|[
qj[\x
qJXX%
qk_div const not matched.
qkv_bias
qkv_hidden_sizes
qkv_hidden_sizes attribute should have 3 elements
qkv_hidden_sizes first element should be same as the second
qkv_hidden_sizes should have 3 elements
qkv_sizes doesn't match the wights dimension
qkv_weights
QLinear
QLinear Pooling unsupported pooling size!
QLinearAdd
QLinearAveragePool
QlinearBuildLookupTable : input X_scale must be a scalar or 1D tensor of size 1
QlinearBuildLookupTable : input X_zero_point must be a scalar or 1D tensor of size 1
QlinearBuildLookupTable : input Y_scale must be a scalar or 1D tensor of size 1
QlinearBuildLookupTable : input Y_zero_point must be a scalar or 1D tensor of size 1
QLinearConcat
QLinearConv
QLinearConv : filter scale shape invalid
QLinearConv : filter zero point shape invalid
QLinearConv : input scale must be a scalar or 1D tensor of size 1
QLinearConv : input zero point must be a scalar or 1D tensor of size 1
QLinearConv : result scale must be a scalar or 1D tensor of size 1
QLinearConv : result zero point must be a scalar or 1D tensor of size 1
QLinearConv : zero point of per-channel filter must be same
QLinearGlobalAveragePool
QLinearGlobalAveragePool parameter out of computation range!
QLinearLeakyRelu
QLinearMatMul
QLinearMatmul : input scale must be a scalar or 1D tensor of size 1
QLinearMatmul : input zero point must be a scalar or 1D tensor of size 1
QLinearMatmul : result scale must be a scalar or 1D tensor of size 1
QLinearMatmul : result zero point must be a scalar or 1D tensor of size 1
QLinearMatmul : weight scale must be a scalar, 1D tensor of size 1, or last to second dimension is 1
QLinearMatmul : weight zero point must be a scalar, 1D tensor of size 1, or last to second dimension is 1
QLinearMul
QLinearReduceMean
QLinearSigmoid
Qm0d5
qP[\=
qp^pE
QPH+QHH
qpU2D
qPZph?
qq]t5
qq^^|
qq_PT'
qqV|!
qqWp)
qQY:D7
qQZXU&8
qRP|I
qRT8Y
qRV>.
qS~C*
qSPV&
qSV~0
qsVZD
Quantized GEMM only support alpha equal to 1.0f and beta equal to 0.0f or 1.0f
QuantizeLinear
query
QueryPerformanceCounter
QueryPerformanceFrequency
qX\pG
qXQtf
qY]4r
qyQ|%
qyT~}
qYT6+
qZTXT
R D8RHu
R D8ZHu
r D9g(t
R!s4Z
R(Hx<f>
R,F": ^2
R:&<">,@nB
r;Ic8I
R^*/m
R_scale
R_zero_point
r`HcS$H
r{X]2
R|r(t6v~x(zT|6
R|Z'(
r<~@LB
R->Shape()[1] == 5
r3w1HcC(H
r5w,H
raB3G
RaiseException
RaiseFailFastException
RandomNormal
RandomNormalLike
RandomUniform
RandomUniformLike
Range
Rank = Size (XShape)
rank >= 2 && dim_1 != dim_2 && input_dims[dim_1] == input_dims[dim_2]
rank must be greater than axis
Rank of input 
Rank of input and output tensor should be same.
Rank of input to Normalized must be less than 2. Got 
Rank of the input must match number of subscript labels corresponding to the input
Ranks inferred (
Ranks of input data are different, cannot concatenate them. expected rank: 
Ranks of pair-wise operands must be equal. 
ratio
ratio input should have a single value.
ratio must be in the range [0, 1)
Ratio of Dropout must be a scalar.
ratio_tensor->Shape().Size() == 1
raw_data
rbb}H
RbN@L*J*H*
rbp4@
RbQ}X
RE2: invalid startpos, endpos pair. [
RE2: unexpected op: 
read only file system
ReadExternalRawData() failed: 
ReadFile
ReadFile 
Reading the provided model for the ORT config
Real memory steps 
Received invalid value for allow_spinning. Valid values are 0 or 1
Received invalid value for arena extend strategy. Valid values can be either 0, 1 or -1.
Received invalid value of arena_extend_strategy 
Received negative size from stat call
Received null OrtThreadingOptions
Received nullptr for custom registry
Received nullptr for exec provider
Received nullptr for graph transformer
Received nullptr for name.
Received nullptr for OrtValue.
Received OrtValue is not a tensor. Only tensors are supported.
Reciprocal
RecurrenceTensor
Recurrent
Redmond1
reduced
reduced_scale
reduced_zero_point
ReducedShape = Concat <axis = 0> (PrefixShape, SuffixShape)
ReduceL1
ReduceL2
ReduceLogSum
ReduceLogSumExp
ReduceMax
ReduceMean
ReduceMin
ReduceProd
ReduceSum
ReduceSumInteger
ReduceSumSquare
reduction
Reduction on all axes, output size should be 1.
ReductionFunction
reflect
reflection
Regexp not destroyed.
RegisterCustomOps
RegisterCustomOpsLibrary: Entry point RegisterCustomOps not found in library
RegisterCustomOpsLibrary: Failed to load library
Rejang
Release_State_
ReleaseMutex
ReleaseSemaphore
ReleaseSRWLockExclusive
ReleaseSRWLockShared
relu@
ReluQuantRewrite
RemoveDirectory() failed - path: 
RemoveDirectoryW
RemoveDuplicateCastTransformer
Removing initializer '
Removing NodeArg '
reorder
ReorderInput
ReorderOutput
'repeat' input tensor must be 1 dimensional
'repeat' input tensor must have the same length as the 'input' tensor
Repeats
repeats
'Repeats' input has incorrect number of values. The number of values in 'repeats' must be equal to the number of input dimensions.
'Repeats' input must be 1D tensor of type int64
RepeatsCount
RepetitionWalker::ShortVisit called
replaced_value_float
replaced_value_int64
representative.output_index != kInvalidOutputIndex
Requested attribute: 
requested_shape[i] >= -1
Required attribute '
Required attribute axis is missing
Required input at index 
Required min_gram_length must be positive: 
Required output at index 
reserved_chunks_.find(ptr) == reserved_chunks_.end()
Reserving memory in BFCArena for 
ResetEvent
Reshape
reshape
reshape initializer value is not expected
reshaped
ReshapeFusion
residual
Resize
Resize operator
Resize: input shape needs to be at least a single dimension
Resize: input tensor's dimension does not match the scales.
Resize: input tensor's rank does not match the output tensor's rank.
Resize: input/output value is nullptr
Resize: input/output value's dimension mismatch
Resize: size of roi array should be 2 * N where N is the rank of input tensor X.
Resize: unexpected mode
Resolve subgraph failed:
resource deadlock would occur
resource unavailable try again
result
Result buffer is not large enough
result out of range
Result, has same shape and type as input
Result, has same type as input, with H and W dimensions reduced.
ReturnHr
reused != reused_for
reverse
ReverseSequence
Rfd2f
r-H;Q
RhTVV
RIGHT
right operand cannot broadcast on dim 
Right shape: 
right.NumDimensions() == 2
right.Shape().Size() == right_shape_override.Size()
rJ]cr
rjp=1
RknpuExecutionProvider
rLH9r
rlwjH
RNN op: Invalid activation attribute - 
ROCMExecutionProvider
ROI pool output shape (height, width).
RoI pooled output, 4-D tensor of shape (num_rois, C, crop_height, crop_width). The r-th batch element Y[r-1] is a pooled feature map corresponding to the r-th RoI X[r-1].
roi_batch_id < batch_size
roi_batch_id >= 0
roi_input_idx_ > 0
RoiAlign
RoIs (Regions of Interest) to pool over; rois is 2-D input of shape (num_rois, 4) given as [[y1, x1, y2, x2], ...]. The RoIs' coordinates are normalized in the coordinate system of the input image. Each coordinate set has a 1:1 correspondence with the 'batch_indices' input.
rois input tensor has wrong dimension
RoIs tensor must have 2 dimensions
ROITensor
RoOriginateLanguageException
Round
round_prefer_ceil
round_prefer_floor
RoundingMode
Rp^6`9
rPttLx
RTcJff
RtlCaptureContext
RtlLookupFunctionEntry
RtlPcToFileHeader
RtlUnwindEx
RtlVirtualUnwind
run_options.run_log_severity_level >= 0 && run_options.run_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
Runic
Running with tag: 
running_mean
running_mean = input_mean * momentum + current_mean * (1 - momentum)
running_var
running_var = input_var * momentum + current_var * (1 - momentum)
RunStateOnByteUnlocked failed after Reset
RunStateOnByteUnlocked failed after ResetCache
RUNTIME_EXCEPTION
RuntimeError
RuntimePerf
runtimeVersion
s AVH
s D+s0D
s D9s8~!H
S H;S(H
S H;S(t
S H;S(t@
S H;S(t\H
S H;S(tH
S H+S
s H+s
S H+S
s HcK
's number of inputs is different from function body graph's number of input.
's number of outputs is different from function body graph's number of outputs.
s WATAUAVAWH
s WAVAWH
s!f9r
s"f9r
s#fD9z
s$fD9q
s%f9i
s&f9j
s(+s0
S(H;S0t
S(H;S0tFD
S(H;S0tH
s(HcD$
s)f9j
s)f9r
s*f9i
s*f9r
s*f9Y
s@D;m
S@H;SHt
s@Hck83
s@Hck8I
s~H;_
s+fD9y
s+fD9z
s0I9M
S6=7p
s8D9sP~!H
S8H;S@~
S8H;S@L
S8H;S@t
S8H;S@t@
S8H;S@tH
SafeIntExceptionHandler<class onnxruntime::OnnxRuntimeException>::SafeIntOnDivZero
SafeIntExceptionHandler<class onnxruntime::OnnxRuntimeException>::SafeIntOnOverflow
Samaritan
SAME_LOWER
SAME_LOWH9
SAME_UPPER
SAME_UPPH9
Sample echo operator.
sample_size
SampleOp
Sampling ratio should be >=0, but it was 
sampling_ratio
sampling_ratio_ >= 0
Saurashtra
SaveAttributeOrtFormat: Unsupported attribute type: 
Saved inverse standard deviation used during training to speed up gradient computation.
Saved inverse standard variance used during training to speed up gradient computation.
Saved mean used during training to speed up gradient computation
saved_mean
saved_var
SaveMLValueNameIndexMapping
SaveValueInfoOrtFormat: value_info_proto for 
Saving initialized tensors.
Saving runtime optimizations is not enabled in this build.
Sbad variant access
sbetu9
sBfD9z
SbreH
Scalar multiplier for input tensor C, the default value is 1.0.
Scalar multiplier for input tensor C.
Scalar multiplier for the product of input tensors A * B, the default value is 1.0.
Scalar multiplier for the product of input tensors A * B.
Scalar multiplier for the product of the input tensors.
Scale
scale
scale > 0
scale >= 1
Scale and bias the input image. Bias values are stored in
Scale and Zero-point must be a scalar
scale must be 1D tensor with size 
'Scale' must contain exactly 2 values - (height, width)
Scale size: (
Scale takes one input data (Tensor<float>) and produces one output data
Scale tensor.
Scale value should be greater than 0.
Scale value should be greater than or equal to 1.
scale.Shape().NumDimensions() == 1 && scale.Shape()[0] == broadcast_dim
scale_.size() == offset_.size()
scale_grad_by_freq
Scale2D = Flatten <axis = 0> (Scale)
ScaleBias
ScaleCount
Scaled = Mul (NormalizedT, Scale2D)
scaledtanh
ScaledTanh
Scaler
scales
Scales
scales size should be greater than 0.
scales.size() == 2 || (scales.size() == 4 && scales[0] == 1 && scales[1] == 1)
scales.size() == 2 || (scales.size() == 4 && scales[0] == 1 && scales[1] == 1) || (scales.size() == 4 && scales[0] == 1 && scales[3] == 1) || scales.size() == 3 || (scales.size() == 5 && scales[0] == 1 && scales[1] == 1)
scales_.size() == 4
scales_[0] == 1 && scales_[1] == 1 && scales_[2] >= 1 && scales_[3] >= 1
scales_size > 0
ScaleSize
ScaleTensor
Scaling parameter.
Scaling value
Scan 'body' subgraph outputs should all be tensors but output 
Scan input 
Scan inputs have inconsistent batch size. Previous value was 
Scan inputs have inconsistent sequence lengths. Previous value was 
scan_input_axes
scan_input_directions
scan_output_axes
scan_output_directions
Scan<8> spec does not support transpose of output. This should never be called.
Scatter
ScatterElements
ScatterND
Schema error: 
schemaVersion
score_threshold
scores
scores must be a 3D tensor.
Scores output is incorrect size. Expected:
scores.size() == static_cast<size_t>(expected_num_scores)
scores_dims.size() == 2
scores_dims[0] == batch_size
scores_out
scores_output_data.length() >= scores_output_size
scores_tensor
sD9g(
SearchBitState inconsistency
SearchDFA inconsistency
SearchNFA inconsistency
SearchOnePass inconsistency
Second dimension for rois should be exactly 
Second input does not have rank 2
Second input of Gather in path 1 of position shape should be a constant with value 0.
Second input of Gather in path 2 of position shape should be a constant with value 1.
Second input of Gather should be a constant with value 1. 
Second input tensor has wrong dimension
Second set of probability coefficients. This array must be same size as prob_a.<br>If these are provided then output Z are probability estimates, otherwise they are raw scores.
Second, multiply by this.<br>Can be length of features in an [N,F] tensor or length 1, in which case it applies to all features, regardless of dimension count.<br>Must be same length as 'offset'
Seed for the hashing algorithm, unsigned 32-bit integer, default to 0.
seed@
Segment embedding scale must be a scalar or 1D tensor of size 1
Segment embedding zero point must be a scalar or 1D tensor of size 1
Segment id is not valid. 
segment_embedding
segment_embedding is expected to have 2 dimensions, got 
segment_embedding should have 2 dimensions, dimension size known, and same hidden size as word_embedding.
segment_embedding_scale
segment_embedding_zero_point
segment_ids
segment_ids input shall be 2 dimensions
select_last_index
selected_indices
selectors_and_actions_map_.find(name) == selectors_and_actions_map_.cend()
Selu@
separators
separators must not be empty
seq(map(int64, float))
seq(map(string, float))
seq(tensor(bfloat16))
seq(tensor(bool))
seq(tensor(complex128))
seq(tensor(complex64))
seq(tensor(double))
seq(tensor(float))
seq(tensor(float16))
seq(tensor(int16))
seq(tensor(int32))
seq(tensor(int64))
seq(tensor(int8))
seq(tensor(string))
seq(tensor(uint16))
seq(tensor(uint32))
seq(tensor(uint64))
seq(tensor(uint8))
seq_lengths
Sequence
Sequence is missing type entry for its element
Sequence of (Tensor, Scale, ZeroPoint) tuples. The type is sequence of (T8, TF, T8).
sequence_lens
sequence_lens length of 
'sequence_lens' must have rank of 1
sequence_lens shape must be {batch_size}. Got:
sequence_type
SequenceAt
SequenceConstruct
SequenceConstruct is expected to have at least 1 input.
SequenceEmpty
SequenceErase
SequenceInsert
SequenceLength
SequenceLengthsTensor
Sequences must have tensors of the same data type. There was at least one tensor in the input that was different.
Sequential execution should be enabled when using DML execution provider.
Sequential mode
SequentialExecutor::Execute
Serialization error. Graph attribute was serialized without Graph instance
Serialization of fused function body is not currently supported, 
Serialized version info is null. Invalid ORT format model.
Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.
Session
session-
Session has already been initialized.
Session must be initialized to create session state.
Session not initialized.
Session successfully initialized.
Session was not initialized
session.disable_prepacking
session.disable_quant_qdq
session.inter_op.allow_spinning
session.intra_op.allow_spinning
session.load_model_format
session.save_model_format
session.set_denormal_as_zero
session.use_device_allocator_for_initializers
session.use_env_allocators
session.use_ort_model_bytes_directly
session_env.EnvCreatedWithGlobalThreadPools()
session_initialization
session_logger != nullptr
session_options
session_options_.session_log_severity_level >= 0 && session_options_.session_log_severity_level <= static_cast<int>(logging::Severity::kFATAL)
session_state
session_state_ != nullptr
SessionCreation
SessionCreationStart
sessionId
SessionOptionsAppendExecutionProvider_OpenVINO: Failed to load shared library
SessionOptionsAppendExecutionProvider_Tensorrt: Failed to load shared library
SessionState for subgraphs is null. Invalid ORT format model.
SessionState is null. Invalid ORT format model.
SessionState should have saved the KernelCreateInfo prior to this running. NodeIndex:
SetEvent
SetFilePointerEx
SetFilePointerEx 
SetGraphAndCreateKernels must be called prior to GetExecutionInfo.
SetLastError
SetThreadAffinityMask
SetThreadDescription
setting data_type field (tensor name: 
Setting enable_profiling to 
Setting execution_mode to 
Setting graph_optimization_level to ORT_DISABLE_ALL
Setting graph_optimization_level to ORT_ENABLE_ALL
Setting graph_optimization_level to ORT_ENABLE_BASIC
Setting graph_optimization_level to ORT_ENABLE_EXTENDED
Setting inter_op_num_threads to 
Setting intra_op_num_threads to 
SetUnhandledExceptionFilter
SetupSubgraphExecutionInfo should only be called once for each subgraph.
sfoTs
sGJ]Wp
shape
Shape
shape && sp_tensor.DenseShape() == *shape
shape && tensor.Shape() == *shape
shape as a contiguous subset of the first tensor's shape. The starting of the
Shape inference error(s): 
'shape' input must be 1D tensor of type INT64
Shape input must be a one-dimensional tensor.
shape is invalid
Shape mismatch attempting to re-use buffer. 
Shape must be 1 dimensional as it's tensor data of a shape
shape of layer norm bias tensor not expected
shape of left-hand-side argument. When broadcasting is specified, the second
shape.Size() must >=0
shape_.Size() == new_shape.Size()
shape_data_tensor.Shape().GetDims().size() == 1
shape_size == out.length()
Shape3D
shapeTensor->Shape().NumDimensions() == 1
Sharada
Shavian
Should be unreachable if CanRemoveNodeAndMergeEdges is in sync with the logic here.
should never happen
Should not have entry in kernel create info with nullptr for kernel_def
Shouldn't be possible to have NodeArgs that haven't been handled already.
Shrink
Siddham
sigmoid
Sigmoid
signal_ndim
SignWriting
SimplifiedLayerNormalization
SimplifiedLayerNormFusion
Simplify case not handled: 
SimplifyWalker::ShortVisit called
Single dimension value must be greater than 0
single_node_compute_func should have 1 elements
Sinhala
size != 0 && (input_shape.Size() % size) == 0
size >= 0
size is different
Size mismatch for kernel create info node indexes and hashes. Invalid ORT format model.
Size mismatch validating subgraph inputs. Got 
Size mismatch: feed_names has 
size overflow
size_ % 2 == 1
size_ == size
size_ > 0
size_t(impl_->max_gram_length_) <= impl_->ngram_counts_.size()
size_t(impl_->min_gram_length_) <= impl_->ngram_counts_.size()
sizeof(uint32_t) == output_element_bytes
Sizes
sizes
sizes != nullptr && sizes->Shape().Size() != 0
sizes == nullptr
skip is expected to have same shape as input
SkipLayerNormalization
SkipLayerNormFusion
Sleep
SleepConditionVariableCS
SleepConditionVariableSRW
Slice
Slice does not have enough number of inputs
Slice ends is less than INT_MAX
Slice op must have either three, four or five inputs.
Slice parameter is not expected. Input index:
slice the input `data` tensor. If a negative value is passed for any of the
Sliced data tensor.
slices of `data` into an output tensor of rank q - 1 + r - indices[-1].
Slices uses `axes`, `starts` and `ends` inputs to specify the start and end
slope
SlopeTensor
snprintf() failed with return value: 
snprintf_result > 0
snprintf_result > 0 && gsl::narrow_cast<size_t>(snprintf_result) == buffer_span.size() - 1
So disabling it for this session since it uses the DML Execution Provider.
So making the execution mode sequential for this session since it uses the CUDA Execution Provider.
So making the execution mode sequential for this session since it uses the DML Execution Provider.
SOFTMAX
Softmax
Softmax attribute axis is expected to be 3
softmax_axis
SOFTMAX_H9
SOFTMAX_ZERO
SoftmaxCPU inputs N, D and N * D must be < 
SoftmaxCrossEntropyLoss
Softplus
softplus
softplusH
Softsign
softsign
softsignH
Sogdian
Some nodes are not included in the topological sort, graph have a cycle.
Sora_Sompeng
sorted
source and destination buffer size mismatch
Source and target must both be tensors
source optional type missing element type.
source sequence type missing element type.
Soyombo
SpaceDepth ops require a 4-D input. Provided rank: 
SpaceToDepth
SpaceToDepth requires input height to be a multiple of block_size
SpaceToDepth requires input width to be a multiple of block_size
SPARSE
Sparse format must not be set. Already contains format: 
Sparse indices int32 data size does not match expected
Sparse indices int64 data size does not match expected
Sparse Indices raw data size does not match expected.
Sparse initializer must have a name. This model is invalid
Sparse Initializer tensor is missing. Invalid ORT format model.
Sparse tensor (
Sparse Tensor does not contain sparse data
Sparse tensor indices (
Sparse tensor initializers must have a non-empty name
sparse tensor type 
Sparse tensor values (
SPARSE_TENSOR
sparse_tensor
sparse_tensor(
sparse_tensor(double)
sparse_tensor(float)
sparse_tensor(int32)
sparse_tensor(int64)
sparse_tensor(uint32)
sparse_tensor(uint64)
sparse_tensor_names_ not in sync with name_to_initial_tensor_
sparse_tensor_names_.count(tensor_name) == 0
sparse_tensor_proto
sparse_tensor_type
SPARSE_TENSORS
sparse_tensors
sparse_value
SparseTensor Allocation failed for size: 
SparseToDenseMatMul
spatial
Spatial
spatial_scale
spatial_scale_ > 0
SpatialScale
SpatialScaleX
SpatialScaleY
sPD9sh~!H
specific_subgraph_kernel_create_info_map != subgraphs_kernel_create_info_maps_.end()
Specified axis to insert a dimension
Specified device is not supported.
Specified domain and type names combination does not refer to a registered opaque type
Specified provider is not supported.
Specifies a target value that is ignored and does not contribute to the input gradient. It's an optional value.
Specify batchs of sequence words to embedding
Specify bias of conv
Specify embedding vector of char
Specify if the RNN is forward, reverse, or bidirectional. Must be one of forward (default), reverse, or bidirectional.
Specify weights of conv
SPH;SXt
SpH;Sxt
spHckh3
spHckhI
Split
split
Split operator does not support 
Split should be > 0
split_scalar > 0
split_size_sum (
split_tensor->Shape().NumDimensions() == 1
SplitToSequence
SplitToSequence operator does not support 
sqeuclidean
Square = Mul (XU, XU)
SquareOfMean = Mul (Mean2D, Mean2D)
Squeeze
squeeze_mask
squeezed
Src and Dst must be of the same type
src and dst must have same shape and not be rank 0.
src and dst types must match
src.SizeInBytes() == dst.SizeInBytes()
src_tokens
src_tokens_len >= prev_suffix_match_idx_data
Stack not empty.
Stacktrace:
start
Start CheckNodesInPathK
Start CheckNodesInPathQ
Start CheckNodesInPathV
Start FuseGptAttention
start in Range operator should be scalar like tensor, yet got shape:
Start MatchGemmSubgraph
Start MatchInputMaskSubgraph
Start MatchInputMaskSubgraphDistilBert
Start MatchPastSubgraph
Start MatchUnidirMaskSubgraph
start or end indices, it represent number of elements before the end of that
Start ValidateGemmInitializer
start_offset % span_size == 0 && real_end % span_size == 0
start_offset >= 0 && real_end >= 0 && start_offset <= real_end && real_end <= len
Starting indices of corresponding axis in `axes`
StartPadding
startpos: 
starts
Starts and axes shape mismatch
Starts and ends shape mismatch
Starts and steps shape mismatch
Starts must be a 1-D array
starts.size()=
starts_.empty() || start > ends_.back()
starts_.size() == ends_.size()
starts_.size() == ends_.size() + 1
stash_type
state (NxD), and the sequence lengths (N), computes the GRU
state not recoverable
StateSaver failed to restore state.
static_cast<int>(activation_func_names.size()) == num_directions_ * 3
static_cast<size_t>(index) < nodes_.size() && ((node = nodes_[index]) != nullptr || !required)
static_cast<size_t>(num_subgraph_inputs) == subgraph_inputs.size()
static_kv
statistics in inference mode (training_mode=False, default),
status.IsOK()
status.IsOK() && !impl_->ngram_counts_.empty()
status.IsOK() && !impl_->ngram_indexes_.empty()
status.IsOK() && !input_dimensions_.empty()
status.IsOK() && !pool_int64s.empty()
std::all_of(impl_->ngram_indexes_.cbegin(), impl_->ngram_indexes_.cend(), [](int64_t i) { return i >= 0; })
std::all_of(output_edges.cbegin(), output_edges.cend(), [&src_idx](const GraphEdge& edge) { return edge.src_arg_index == src_idx; })
std::all_of(split_sizes.cbegin(), split_sizes.cend(), [](int64_t value) { return value >= 0; })
std::all_of(split_sizes_.cbegin(), split_sizes_.cend(), [](int64_t value) { return value >= 0; })
std::count_if(subgraph_node.InputEdgesBegin(), subgraph_node.InputEdgesEnd(), [input_slot_index](const Node::EdgeEnd& entry) { return entry.GetDstArgIndex() == input_slot_index; }) == 0
std::exception: %hs
StdDev = Sqrt (VarPlusEpsilon)
Steepness
'step' cannot be 0
'step' cannot be 0 for Slice
'step' value cannot be 0
steps
steps.size()=
stod argument out of range
stof argument out of range
stol argument out of range
stoll argument out of range
Stopword contains invalid utf8 chars
stopwords
storage_order
stoull argument out of range
strcmp
strcspn
stream timeout
Stride along each axis.
Stride along each spatial axis.
Stride along each spatial axis. If not present, the stride defaults is 1 along each spatial axis.
Stride along each spatial axis. If not present, the stride defaults to 1 along each axis.
Stride along each spatial axis. If not present, the stride defaults to 1 along each spatial axis.
strides
Strides
strides.size() == kernel_shape.size()
strides_.size() == kernel_shape_.size()
STRING
string
string buffer allocation failed
STRING data (tensor name: 
string enum that cases output to be lowercased/uppercases/unchanged. Valid values are "LOWER", "UPPER", "NONE". Default is "NONE"
string literal
string tensor can not have raw data
string tensor can not use pre-allocated buffer
string tensor is not supported for copying between allocators
string too long
String value expected, but not found.
string_data
string_vocabulary
StringFileInfo
StringNormalizer
STRINGS
strings
Strings can only reside in CPU memory
Strings to tokenize
strncmp
strnlen
subgraph
Subgraph
Subgraph in 'body' produces 
Subgraph input missing type.
Subgraph must have the shape set for all outputs but 
Subgraph SessionState entry for 
Subgraph SessionState for 
Subgraph SessionState was not found for '
Subgraph SessionState was not found for 'body' attribute.
subgraphs_kernel_create_info_maps.find(local_subgraph_kernel_create_info_map_key) == subgraphs_kernel_create_info_maps.end()
success
SUCCESS
suffix matching is assumed. 1-dim expansion doesn't work yet.
suffix_match_idx
SuffixShape = ConstantOfShape (NumReducedAxes)
Sum of split values not equal to 'input' dim size on 'axis'. 'axis' dim size=
sum(sqrd(x_i - x_avg)) / N
sum_node.GetOutputEdgesCount() == 0
sum_output_edge.src_arg_index == 0
Sundanese
Support 2-D matrices only
Support padding modes for outside grid values: `zeros`(default), `border`, `reflection`. zeros: use 0 for out-of-bound grid locations, border: use border values for out-of-bound grid locations, reflection: use values at locations reflected by the border for out-of-bound grid locations.
Support vector coefficients.
support_vectors
Supported modes: `constant`(default), `reflect`, `edge`
SUVWATAUAVAWH
SUVWATAVAWH
SUVWAVAWH
SUVWAVH
SUVWH
SVATAVAWH
SVAVH
SVMClassifier
SVMRegressor
SVWATAUAVAWH
SVWATAUAWH
SVWAVAWH
SVWAVH
SwapAdjacentNodes
SXH;S`
sXHckPA
sxHckpA
sXHckPI
Syloti_Nagri
syntax error 
Syriac
system
system error number 
SystemError
T 4"2$4&T*4,2
t 8X8t
t E9N
t M;Q(t
t t$0&l*
t!A9}
t"@8=
t"D9`
t"L;J(t
t"L;O
t"M;Q(t
t#E9L$(
t#HcQ
t$ A^
t$ E3
T$ E3
t$ E3
T$ E3
t$ E3
T$ E3
t$ E3
T$ E3
t$ E3
t$ E9pxu-M
t$ fI
T$ H;
t$ H;K
T$ H;Qp
t$ H;W
t$ H+
T$ H+
t$ H+
t$ I;
t$ I;W
t$ I+
T$ I+
T$ I+T$
T$ L!l$(I
T$ L!l$0I
T$ L;
t$ L;
T$ L;
t$ L;
t$ L;O
t$ L+
T$ L+
T$ L91H
T$ M;
t$ M;
T$ M+
t$ UATAVH
t$ UAVAWH
t$ UH
t$ UWATAUAVH
t$ UWATAUAWH
t$ UWATAVAWH
t$ UWAUAVAWH
t$ UWAVH
t$ UWAWH
t$ WATAUAVAWH
t$ WAVA
t$ WAVAWH
t$ WH
T$$A;
T$$fD
T$$Hc
T$(D8P
T$(E3
t$(H;
T$(H;
t$(H;
t$(H;S
T$(H+
t$(I;
T$(L;
t$(M+
t$@@8q t]
t$@A_A^A]A\_
t$@D8a
T$@E3
t$@E3
T$@E3
t$@H;
T$@H;
T$@H+
t$@H+
t$@H9
t$@I;
T$@I;
t$@I;
t$@I+
T$@I+
t$@L!
T$@L;
t$`!T$
t$`@8p t4H
T$`A9r
t$`D8p t4H
T$`E3
t$`E3
T$`E3
t$`E3
T$`E3
t$`fD
T$`H;
T$`H;T$h
T$`H;T$ht
T$`H+
t$`H+
T$`H+
T$`I;
t$`I+
t$`L;
t$`L+
T$`L9\$Xt
t$`M;
t$`t%H
T$0@8j
t$0|0I
t$09s(
t$0A^_
t$0A9
T$0D9m
T$0E3
t$0E3
T$0E3
t$0E3
T$0f9w
t$0fD
T$0H;
t$0H+
T$0H+
t$0H+
T$0H+
t$0H+
T$0H+
t$0H+
T$0H+
t$0H+
T$0H+
t$0H+
T$0H+
t$0H+
t$0H9
T$0Hc
t$0Hc
T$0Hc
t$0I#
T$0I;
t$0I;
T$0I;
t$0I;
T$0I+
t$0Ic
T$0Ic
t$0L#
T$0L;
t$0L;
t$0L+
t$0L9t$pt
t$0M;
t$4D;
T$4Hc
t$8@8q
T$89T$@
t$8A_A^A\_
t$8D8hH
t$8E3
T$8E3
t$8E3
T$8H!|$8
T$8H;
t$8H;\$0t
T$8H+
T$8H+T$0H
t$8Hc
t$8Hi
t$8I;
T$8I+
t$8I+
t$8L;
t$8L9t$ht
T$8M;
T$DfD
T$h!D$xH
T$HA9>
T$HD+
T$hE3
T$HE3
t$HE3
T$HE3
t$HE3
T$HE3
t$HH#
T$HH;
t$HH;
T$HH;
T$hH;
t$hH;
T$HH;
t$hH;
T$hH;
T$HH;
T$HH;AHtfH
T$HH;APtfH
T$hH;s s
T$hH;T$pt
t$HH;u
t$HH;U8t
T$hH+
T$HH+
T$hH+
T$HH+
T$hH+
T$HH+
T$HH+T$@H
t$hHcD$ H
t$hHcD$0K
T$HI;
T$hI;
T$HI;
t$hI;
T$HI;
T$hI;
T$HI;
t$HI;
t$HLc
T$hM;
t$hM;
t$hM;Q`s<I
t$HMc
t$p!t$tE3
T$p+U
T$PE;
T$PE3
T$pE3
T$PE3
t$pE3
T$PE3
t$PE3
t$pE3
T$PE3
t$pE3
T$pE3
t$PE3
T$pE3
t$pE3
t$PE3
T$pE3
T$PE3
T$pE3
t$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
T$PH;
T$pH;
t$PH;]
T$PH;T$Xt
T$pH;T$xt
T$PH;T$Xt
t$PH;U
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+
T$pH+
T$PH+T$HH
t$pH9
t$PHc
T$pHc
T$pI;
T$PI;
T$pI;
T$PI;
t$PI+
T$PL;
t$pL+
T$pL9\$ht
t$pL9Q(
T$PM;
t$PM;
T$PM;
t$PM+
t$pM9Y@
t$pO;,
T$qfD9H6u
t$x;n 
t$X@8p
t$x@8p
t$X@8p
T$XA;V |
T$XA;V8|
t$XD8p
t$XD9P
T$XE3
t$XE3
T$xE3
T$Xf!T$xI
t$XfA
t$xfD
T$XH;
t$XH;
T$xH;
T$XH;
t$XH;]
T$xH+
T$XH+
T$xH+
T$XH+
T$XH+T$PH
t$xH+t$pH
T$XH+T$PH
t$XHc
T$xHcE
T$xHcM
t$XI;
T$xI;
T$XI;
T$xI;
t$XI;
T$xL+
t$XM;
t$xu|M
t$xuoM
T%#hF
t%A9|$
t%A9X H
t%ba|H
t%LcF
t&A88t
t&HcSpH;
t&I;Q(t
t&L"8 -
t&L9+u
t(@,4Il
t(H93
t(HcP
t(p`hhlbv
t)D8}`t#I
t)HcSPH
t)IcV
t*ba|H
t*HcA
t*HcS@H
t*HcS`H
t*HcSPH
t*I;B(t
t,D8=
t.;y@s)H
t.HcS
t.HcS(H
t.HcSPH
t.HcSxH
t:fA9(t4H
t:H9}h
t:H9uh
T;8H+
t;8J8t6H
t;9)u
t?D8}
t@33{@
T@9}N
t@HcS
t[Hc_$
t\fD;
t\fD;*s
t]fE; s
t^H9]
t_fD;
t_proto_p->dims()[0] == 1
t_proto_p->dims_size() == 1
t{9W(
t|HcP0H
t}A9v(
t+fE9>u
t+L9 
T<4>2
t=I;S(t.
T=VGN
T=wHN
t>L9)u
t>M;w(t/I
t0H;=
t0H;E
t1ba|H
t1H;=;
t2HcT$0H
t2HcT$HH
t39]'u.H
t4E88t/H
T5qGN
t6HcT$8H
t6M;w(t+I
t6M;Z(t+
t7HcD$8H
t8ba|H
t9A;p
t9HcM8H
Tagalog
Tagbanwa
tAHcP
Tai_Le
Tai_Tham
Tai_Viet
Takri
Tamil
Tangut
tanh@
tanhA
tanhD
target
target optional type missing element type.
Target rank must be 1 less than the input rank.
target sequence type missing element type.
Target shape may not have multiple -1 dimensions
Target shape may not have multiple -1 dimensions.
target_class_ids.size() == target_class_nodeids.size()
target_class_ids.size() == target_class_treeids.size()
target_ids
target_node != NodesToOptimizeIndices::kEmptyNodeIndex
target_nodeids
target_treeids
target_type
target_weights
targets
tbfD;
tbHcC
TbP6LV2
tcba|H
tcfD;
tdH;\$XH
tDH;U
tDH9q
tdHcL$0
tdK94
tdLcBXH
teH9Khu
tEHcR
Telugu
TempSpace allocator not found
TENSOR
tensor
Tensor after padding.
tensor can either be of element size 1 (including a scalar tensor and any
tensor can't contain negative dims
Tensor does not have external data to read from.
Tensor element type mismatch. 
tensor failed memory size calculation
Tensor initializers must have a non-empty name
Tensor is expected to contain one of the primitive data types. Got: 
Tensor must always contain primitive types. Found: 
tensor of bool, which should be a scalar.
Tensor of data to extract slices from.
tensor of int64, which should be a scalar.
Tensor of integers indicating the number of padding elements to add or remove (if negative) at the beginning and end of each axis. For 2D input tensor, it is the number of pixels. `pads` should be a 1D tensor of shape [2 * input_rank] or a 2D tensor of shape [1, 2 * input_rank]. `pads` format (1D example) should be as follow [x1_begin, x2_begin,...,x1_end, x2_end,...], where xi_begin is the number of pixels added at the beginning of axis `i` and xi_end, the number of pixels added at the end of axis `i`.
Tensor of rank q >= 1.
Tensor of rank q-1+r-indices[-1].
Tensor of rank r >= 1.
Tensor proto with external data for value attribute is not supported.
tensor rank too small
Tensor sequence must contain only primitive types
Tensor shape cannot contain any negative value
Tensor size (
Tensor size mismatch
tensor size overflow
tensor type 
Tensor type mismatch.
Tensor type mismatch. 
Tensor types should have been handled already
tensor with rank equal to or smaller than the first tensor), or having its
Tensor with shape information must be 1 dimensional.
tensor(
tensor(bfloat16)
tensor(bI
tensor(bool)
tensor(complex128)
tensor(complex64)
tensor(complext128)
tensor(complext64)
tensor(dL9
tensor(double)
tensor(fL9
tensor(float)
tensor(float16)
tensor(iI
tensor(int16)
tensor(int32)
tensor(int64)
tensor(int8)
tensor(string)
tensor(string) expected as input
tensor(uI
tensor(uint16)
tensor(uint32)
tensor(uint64)
tensor(uint8)
tensor_a_zero_point == nullptr || IsScalarOr1ElementVector(tensor_a_zero_point)
tensor_b_zero_point == nullptr || IsScalarOr1ElementVector(tensor_b_zero_point)
tensor_c_zero_point == nullptr || IsScalarOr1ElementVector(tensor_c_zero_point)
tensor_type
tensor_x_scale->IsDataType<float>()
tensor_x_zero_point == nullptr || IsScalarOr1ElementVector(tensor_x_zero_point)
tensor_x_zero_point->GetElementType() == tensor_y_zero_point->GetElementType()
tensor_y_zero_point == nullptr || IsScalarOr1ElementVector(tensor_y_zero_point)
TensorProto ( tensor name: 
TensorProto (tensor name: 
TensorProto external data size mismatch. 
TensorProto external data size mismatch. Computed size: 
TensorProto type 
TensorProtoToMLValue() must take a pre-allocated MemBuffer!
TensorProtoToTensor() tensor shape mismatch!
TensorRT execution provider is not enabled in this build.
TensorrtExecutionProvider
tensors
TENSORS
TensorSeq: tensor to be added has a different data type.
ter!u13
TerminateProcess
text file busy
text size: 
tf_crop_and_resize
tf_half_pixel_for_nn
tffE;
TFIDF
TfIdfVectorizer
tFL9oHs
tgfE;
Thaana
Thales TSS ESN:3E7A-E359-A25D1%0#
than the operator set version 
t'HcG<
t'HcS
t'HcW
The Alpha value in Celu formula which control the shape of the unit. The default value is 1.0.
The axis along which same quantization parameters are applied. It's optional.If it's not specified, it means per-tensor quantization and input 'x_scale' and 'x_zero_point' must be scalars.If it's specified, it means per 'axis' quantization and input 'x_scale' and 'x_zero_point' must be 1-D tensors.
The axis in which to compute the arg indices.
The axis in which to compute the arg indices. Accepted range is [-r, r-1] where r = rank(data).
The axis on which to apply normalization, -1 mean last axis.
The bias (or mask) as Tensor.
The bias input data that is a 1D tensor.
The bias input, a vector with the same shape as last dim of data OR same shape with data
The bias value added to output. Default is 0.
The broadcasted dimensions of the inputs are incompatible
The coefficient 'a' used in cubic interpolation. Two common choice are -0.5 (in some cases of TensorFlow) and -0.75 (in PyTorch). Check out Equation (4) in https://ieeexplore.ieee.org/document/1163711 for the details. This attribute is valid only if "mode" is "cubic".
The computation of ReduceMean and ReduceVar uses float to avoid overflow for float16 inputs.
The coordinate of each dimension is transformed individually. Let's describe a case using axis x as an example.
The data type for the elements of the output tensor. Default is TensorProto::FLOAT.
The data type for the elements of the output tensor. If not specified, default is TensorProto::FLOAT.
The data type for the elements of the output tensor. if not specified, we will use the data type of the input tensor.
The data type to which the elements of the input tensor are cast. Strictly must be one of the types from DataType enum in TensorProto
The dimension with value zero exceeds the dimension size of the input tensor.
The distance metric to use. If a string, the distance function can be "braycurtis", "canberra", "chebyshev", "cityblock", "correlation", "cosine", "dice", "euclidean", "hamming", "jaccard", "jensenshannon", "kulsinski", "mahalanobis", "matching", "minkowski", "rogerstanimoto", "russellrao", "seuclidean", "sokalmichener", "sokalsneath", "sqeuclidean", "wminkowski", "yule".
The embedding matrix of size N x M. 'N' is equal to the maximum possible index + 1, and 'M' is equal to the embedding size
The environment variable contained the value: 
The epsilon value to use to avoid division by zero, default is 1e-5f.
The epsilon value to use to avoid division by zero.
the expected transformation of a stochastic regularizer which randomly applies
The exponent.
The filled tensor
The first input of CDist kernel has wrong shape: 
The first input of Range should be a constant with value 0.
The first normalization dimension: normalization will be performed along dimensions axis : rank(inputs).
The fused convolution operator schema is the same as Conv besides it includes an attribute
The FusedGemm operator schema is the same as Gemm besides it includes attributes
The given version [%u] is not supported, only version 1 to %u is supported in this build.
The graph run each iteration. It has 2+N inputs: (iteration_num, condition, loop carried dependencies...). It has 1+N+K outputs: (condition, loop carried dependencies..., scan_outputs...). Each scan_output is created by concatenating the value of the specified output value at the end of each iteration of the loop. It is an error if the dimensions or data type of these scan_outputs change across loop iterations.
The graph run each iteration. It has N+M inputs: (loop state variables..., scan_input_elts...). It has N+K outputs: (loop state variables..., scan_output_elts...). Each scan_output is created by concatenating the value of the specified scan_output_elt value at the end of each iteration of the loop. It is an error if the dimensions of these values change across loop iterations.
The id of the tree that each node is in.
The id of the tree that this node is in.
the identity or zero map to a neuron's input. The GELU nonlinearity weights
The index of the class list that each weight is for.
The index of the target that each weight is for
The inner-most 2 dimensions must have the same size (mat_w:
The innermost dims should have the same dim value to parse the diagonal elements
The input data as Tensor.
The input is not evenly splittable
The input must be a map from strings or integers to either strings or a numeric type. The key and value types cannot be the same.
The input must be a tensor of a numeric type or string. The output will be of the same tensor type.
The input must be a tensor of a numeric type, and of of shape [N,C] or [C]. In the latter case, it will be treated as [1,C]
The input must be a tensor of a numeric type, either [C] or [N,C].
The input must be a tensor of a numeric type.
The input must be a tensor of a numeric type. The output will be of the same tensor type.
The input must be a tensor of strings or integers, either [N,C] or [C].
The input must be an integer map to either string or float.
The input tensor cannot be reshaped to the requested shape. Input shape:
The input type is a tensor of any shape.
The input type must be a tensor of a numeric type, either [C] or [N,C].
The input type must be a tensor of a numeric type, either [N,C] or [C]. The output type will be of the same tensor type and shape.
The input type must be a tensor of a numeric type.
The input type must be a tensor of integers or strings, of any shape.
The integers of the map. This sequence must be the same length as the 'cats_strings' sequence.
The kernel corresponding to the node 
The kernel type, one of 'LINEAR,' 'POLY,' 'RBF,' 'SIGMOID'.
The keys when using int keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The keys when using string keys.<br>One and only one of the 'classlabels_*' attributes must be defined.
The lambd value for the Shrink formulation. Default is 0.5.
The maximum NGram size for suffix matching.
The mean of the normal distribution.
The minimum NGram size for suffix matching.
The model contains a 16-bit input (
The model has input '
The Model Proto has already been checked for the ORT config json.
The Model Proto hasn't been checked for the ORT config json.
The most inner dimension in boxes must have 4 data.
The new GRU hidden state calculated by this op.
The NGram size.
The node id of each weight
The node is not placed on any Execution Provider. 
The node kind, that is, the comparison to make at the node. There is no comparison to make at a leaf node.<br>One of 'BRANCH_LEQ', 'BRANCH_LT', 'BRANCH_GTE', 'BRANCH_GT', 'BRANCH_EQ', 'BRANCH_NEQ', 'LEAF'
The normal input data.
The number of batch dimensions. The gather of indexing starts from dimension of data[batch_dims:]
The number of channels to sum over
The number of graph input cannot be smaller than the number of node input
The number of support vectors.
The only subscript labels allowed are lower-cased letters (a-z) and upper-cased letters (A-Z)
The only supported values for the environment variable 
The op type of a node cannot be empty
The order of the normalization, only 1 or 2 are supported.
The ORT format model version [
the ort_value must contain a constructed sparse tensor
the ort_value must contain a constructed tensor
the ort_value must contain a constructed tensor or sparse tensor
The output is a 1-D tensor of string, float, or integer.
The output is a tensor of strings or integers. Its shape will be the same as the input shape.
The output mask of dropout.
The output scalar. Its value is true if all input tensors are finite. Otherwise, the output value would be false.
The output type will be a tensor of strings or integers, and will have the same shape as the input.
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used.
The output type will be a tensor of strings or integers, depending on which of the the classlabels_* attributes is used. Its size will match the bactch size of the input.
The output will be a sequence of string or integer maps to float.
The output will be a tensor of strings or integers.
The output will be a tensor of the value type of the input map. It's shape will be [1,C], where C is the length of the input dictionary.
The output.
The outputs are updated as follows when training_mode=True:
The override dims are not compatible with given tensor's shape. 
The pads attribute cannot be used simultaneously with auto_pad attribute
The parent of shape nodes are expected to be input_ids.
The parent of two shape nodes are expected to be input_ids.
The pooling method. Two modes are supported: 'avg' and 'max'. Default is 'avg'.
The pooling method. Two modes are supported: 'bilinear' and 'nearest'. Default is 'bilinear'.
The preallocated buffer is too small. Requires 
The previous GRU hidden state.
The rank of input tensor must be >= axis
The rank of the input must match permutation size for Transpose
The ratio of random dropout
The ratio of random dropout, with value in [0, 1). If this input was not set, or if it was set to 0, the output would be a simple copy of the input. If it's non-zero, output will be a random dropout of input, which is typically the case during training.
The registered allocator for device-id 
The residual input, must have the same shape as data
the same ordering as the image pixel format.
The scale along height dimension. It takes value greater than or equal to 1.
The scale along width dimension. It takes value greater than or equal to 1.
The scale array along each dimension. It takes value greater than or equal to 1. The number of elements of 'scales' should be the same as the rank of input 'X'.
The scale to apply.
The scaled hyperbolic tangent values of the input tensor computed element-wise
The second input of CDist kernel has wrong shape: 
The sequence output for the hidden is optional if 0. Default 0.
The session already has a PrePackedWeightsContainer instance
The shape format of inputs X, initial_h and outputs Y, Y_h. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = [batch_size, num_directions, hidden_size].
The shape format of inputs X, initial_h, initial_c and outputs Y, Y_h, Y_c. If 0, the following shapes are expected: X.shape = [seq_length, batch_size, input_size], Y.shape = [seq_length, num_directions, batch_size, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [num_directions, batch_size, hidden_size]. If 1, the following shapes are expected: X.shape = [batch_size, seq_length, input_size], Y.shape = [batch_size, seq_length, num_directions, hidden_size], initial_h.shape = Y_h.shape = initial_c.shape = Y_c.shape = [batch_size, num_directions, hidden_size].
The shape of filled tensor
The shape of the convolution kernel. If not present, should be inferred from input W.
The shape of the convolution kernel. If not present, should be inferred from input 'w'.
The shape of the output can be explicitly set which will cause pads values to be auto generated. If output_shape is specified pads values are ignored. See doc for details for equations to generate pads
The shape of the output tensor.
The size of each input in the input list
The size of the kernel along each axis.
The standard deviation of the normal distribution.
The starting indexes of 1-grams, 2-grams, and so on in pool. It is useful when determining the boundary between two consecutive collections of n-grams. For example, if ngram_counts is [0, 17, 36], the first index (zero-based) of 1-gram/2-gram/3-gram in pool are 0/17/36. This format is essentially identical to CSR (or CSC) sparse matrix format, and we choose to use this due to its popularity.
The storage order of the tensor. 0 is row major, and 1 is column major.
The string used to pad output tensors when the tokens extracted doesn't match the maximum number of tokens found. If start/end markers are needed, padding will appear outside the markers.
The strings of the map. This sequence must be the same length as the 'cats_int64s' sequence
The subgraph in 'body' requires 
the tensor elementwise.
the tensor to be tiled using Tile OP must be atleast 1 dimensional
The third input of Range should be a constant with value 1.
The timestep for this operation.
The total number of regression targets, 1 if not defined.
The total number of targets.
The type of tensor: 
The type of the output tensor is integer.
The underlying implementation is MurmurHash3_x86_32 generating low latency 32bits hash suitable for implementing lookup tables, Bloom filters, count min sketch or feature hashing.
The value for the elements of the output tensor in sparse format.
The value for the elements of the output tensor.
The value for the sole element for the scalar, float32, output tensor.
The value for the sole element for the scalar, int64, output tensor.
The value for the sole element for the scalar, UTF-8 string, output tensor.
The values for the elements for the 1D, float32, output tensor.
The values for the elements for the 1D, int64, output tensor.
The values for the elements for the 1D, UTF-8 string, output tensor.
The weight for each target
The weight for the class in class_id.
The weighting criteria. It can be one of "TF" (term frequency), "IDF" (inverse document frequency), and "TFIDF" (the combination of TF and IDF)
The WordConvEmbedding takes in a batch of sequence words and embed each word to a vector.
The zero-padding added to one side of the output. This is also called adjs/adjustment in some frameworks.
tHE9>u
then optionally start the crop offset by the left/top border amounts.
then_branch
then_branch and else_branch produce different number of outputs. 
then_feeds_fetches_manager_ && else_feeds_fetches_manager_
There are five required inputs 'X', 'scale', 'B', 'input_mean' and
There are multiple cases for the number of outputs, which we list below:
there are multiple cases for the number of outputs, which we list below:
There is no location for this node arg in the outer scope location map
There must be one (and only one) dynamic typed input to the custom op. Its type info at runtime will be used to infer the type info of this dynamic typed output which is required for the success of the model loading step. More than one dynamic typed inputs are currently not supported as differing types at runtime means the output type cannot be inferred without which model loading cannot proceed.
There was a problem acquiring temporary memory allocator in Einsum op
There's no data transfer registered for copying tensors from 
thH9s
tHH9Y
this API does not support strings
This API supports Tensors or SparseTensors
This attribute describes how to transform the coordinate in the resized tensor to the coordinate in the original tensor. <br/>
This instance should not be empty
This is an invalid model. At top level graph without matching NodeArg that subgraph consumes. Name=
This is an invalid model. Error: Duplicate definition of name (
This is an invalid model. Error: the graph is not acyclic.
This is an invalid model. Error: two nodes with same node name (
This is an invalid model. Failed to find NodeArg in all parent graphs. Name=
This is an invalid model. Graph output (
This is an invalid model. In Node, 
This is an invalid model. Model input (
This is an invalid model. Node (
This is an invalid model. Tensor does not have type information.
This is an invalid model. The sum of input arg count is not equal to size of input defs in node (
This is an invalid model. Type Error: Type '
This may prevent some of the graph optimizations, like const folding. 
This method does not expect allocator to be set
This method should follow a call to constructor that supplies the allocator
This number of op outputs should be 1 when Training_mode = False, but it is not.
This number of op outputs should be 3 when Training_mode = True, but it is not.
This operator applies convolution to word from left to right with window equal to conv_window_size and stride to 1.Take word 'example' for example, with conv_window_size equal to 2, conv is applied to [ex],[xa], [am], [mp]...If not provide, use the first dimension of conv kernal shape.
This operator has **optional** inputs/outputs. See [the doc](IR.md) for more details about the representation of optional arguments. An empty string may be used in the place of an actual argument's name to indicate a missing argument. Trailing optional arguments (those not followed by an argument that is present) may also be simply omitted.
This operator supports **multidirectional (i.e., Numpy-style) broadcasting**; for more details please check [the doc](Broadcasting.md).
This optimizer does not support external data for unidirectional mask right now
This session already contains a loaded model.
This session has already been initialized.
This session will use the allocator registered with the environment.
this tensor already has populated sparse_indices
This transformer is already registered 
This ZeroCopyOutputStream doesn't support aliasing. Reaching here usually means a ZeroCopyOutputStream implementation bug.
this->base_values_.size() == predictions.size()
thisProto->value_case() == TypeProto::ValueCase::kMapType
thisProto->value_case() == TypeProto::ValueCase::kOptionalType
thisProto->value_case() == TypeProto::ValueCase::kSequenceType
thisProto->value_case() == TypeProto::ValueCase::kSparseTensorType
thisProto->value_case() == TypeProto::ValueCase::kTensorType
tHL+d$(L+
ThP,N8L
thread_scheduling_stats
Three interpolation modes: bilinear (default), nearest and bicubic.
Three interpolation modes: nearest (default), linear and cubic. The "linear" mode includes linear interpolation for 1D tensor and N-linear interpolation for N-D tensor (for example, bilinear interpolation for 2D tensor). The "cubic" mode includes cubic interpolation for 1D tensor and N-cubic interpolation for N-D tensor (for example, bicubic interpolation for 2D tensor).
Three modes: `constant`(default) - pads with a given constant value, `reflect` - pads with the reflection of the vector mirrored on the first and last values of the vector along each axis, `edge` - pads with the edge values of array
Three modes: constant(default), reflect, edge
threshold
Threshold
Threshold value
thresholdedrelu
ThresholdedRelu
Thresholds to do the splitting on for each node.
t'I;B(t
Tibetan
tID8G&tIA
Tifinagh
Tile doesn't have an implementation yet for the type: 
Tile doesn't support string type yet
tiles
time_axis
time_axis < 2
time_axis and batch_axis must have different values but both are 
timed out
tionProvH
tionProvH9H
tionProvH9P
Tirhuta
tJba|H
tjH9_
tKba|H
tKL+t$ L+
t'L;O
t-Lck
tLD8h8tFH
tLH+\$8H+
TlP0X
tmI;O
tmp_cats_int64s.empty() || tmp_cats_strings.empty()
TNMiM
tNxQH
to flatten the input shape to (N x C * D1 * D2 * ... * Dn) before a BatchNormalization Op.
to flatten the input shape to (N x C*D1*D2 ..*Dn) before a BatchNormalization Op.
to.custom_join_thread_fn
TO_FLOAT
TO_FLOATH
TO_INT64
TO_STRING
token_id < vocab_size
tokenexp
Tokenized strings
Tokenizer
tokens
tOL9oHs
too many files open
too many files open in system
too many links
too many symbolic link levels
TorchEmbedding
Total allocated bytes: 
Total fused Attention node count: 
Total fused reshape node count: 
Total Gelu Approximation (FastGelu) node count: 
totalRunDuration
totalRuns
tPD+v
tQL9P uK
tr@8=
TraceAllocation for ort_value_idx=
TraceFree for ort_value_idx=
trailing \
Training mode only supports spatial BN
training_mode
training_mode of Dropout must be a scalar.
TrainingStepTensor
transA
TransA
transB
TransB
transform_targets
transformation_mode_ == TransformationMode::ASYMMETRIC
Translation
Transpose
Transpose not implemented for empty tensors.
Transpose of element size not supported in this build. Size=
transpose_node.InputDefs().size() == 1
transposed
TransposeMatMul
TransposeOptimizer
Tree id for each node.
TreeEnsembleClassifier
TreeEnsembleRegressor
tRHcK(H
tRHcO(H
tried creating tensor with negative value in shape
tried Filling sparse tensor with negative value in block sparse indices shape
tried Filling sparse tensor with negative value in values shape
tried to allocate 0 bytes
Tried to allocate without valid type information, ort_value index=
Trilu
tRLcY
true literal
trueH
TryAcquireSRWLockExclusive
Trying to allocate memory for unused optional inputs/outputs
Trying to get a SparseTensor, but got: 
Trying to get a Tensor, but got: 
Trying to get a TensorSeq, but got: 
Trying to register schema with name 
Trying to use OptionalGetElement on an optional type OrtValue which contains no data
tSHcK(H
tSMMG
tTH;>v
ttH9k
tTHc_$
tTI9]Hs
tTL9P uN
TtVHTe
TtX6Zx^6`
tUba|H
tUI9]Hs
twIcF
tWIcJ
Two interpolation modes: nearest (default), and linear (including bilinear, trilinear, etc)
Two interpolation modes: nearest(default), bilinear
two paths share the same shape
ty9_(
tYHcs
type == dtype_
type case mismatch. existing=
type case unsupported for symbolic shape inference. inferred=
type case unsupported. existing=
Type Error: Data in initializer '
Type Error: Shape of initializer 
Type Error: Type (
Type Error: Type parameter (
type field and data field mismatch in attribute 
Type mismatch. Current=
type must be number, but is 
Type of Mean and InvStdDev tensors.
Type of reduction to apply to loss: none, sum, mean (default). 'none': the output is the loss for each sample. 'sum': the output will be summed. 'mean': the sum of the output will be divided by the sum of applied weights.
Type of reduction to apply to loss: none, sum, mean(default). 'none': no reduction will be applied, 'sum': the output will be summed. 'mean': the sum of the output will be divided by the number of elements in the output.
Type of reduction to apply: none (default), add, mul. 'none': no reduction applied. 'add':  reduction using the addition operation. 'mul': reduction using the multiplication operation.
Type of the element in the optional output
type used for stash mean/inv_std_var
Type:
type: 
type_error
type_id_counter == 1
type_proto
type_proto is not of type map!
type_proto is not of type sequence!
type_protos
TypeAndShapeInferenceFunction implementation incomplete: this line should never be reached.
TypeProto must have shape for this to run
tzA9v(
tzHcH0H
U A+U0A
U H+U
u HcA<H
U I+U
u!bA-@
u"L;!
u%A:^
u%A8p
u%HcK(
u%LcC
u(!D$(H
U(A+U0A
u(bA-@
u(D9u,u
U(H;U0t
U(v&L
u)A8p
u*D8o
u*fD9o
u.H;Y r(H
u:I;t$
U?H;UGs H
U@L;}hA
u'[d2;
u\8D$<t
u]@83
u^A;p0t
U`H;Uht
u{9_(
u{9W(
u|D9g(
u}D9g(
u~9_(
u<!T$@
u=L9|$`u6L;d$hu/I
u>A9P(t}H
u>D!D$ 
u>Hc/H
u0A;H
u0D8o
U0H;U8t
u0HcU
u0Mcn
U0S0Q
u1</w
u18Ptu,H
u2H;U
u4f9O
u4H;Q
u4I9}(
u5I!K
u88_0t
u8D9J
U8I+U0H
U'9P@
u'A;H
ua@83
uA9C(
UATAUAVAWH
UATAUH
UATAVH
UATAWH
UAUAWH
UAVAWH
u'D9J
uDD!u
udM9(t
uE!D$x
ue_HhW
uFL;B r@I
uFM9fHu@E8a
uG!D$t
Ugaritic
ugH;M
uhD9}
uhH;M
UHH;UPt
UhH;Upt
UHH;UPt
uHL;B rBI
uIIc@
uiK94
uILc7M
uint16
uint32
uint64
uint64_data
uint8
uJF94
ujL;s rdH;
uKA9P(t:H
uLC94
uLL!t$HH
u'McT
Unable to convert strings tensor to a sparse tensor that is not on CPU
Unable to convert strings tensor to a sparse tensor that not on CPU
Unable to find a data transfer for copying from device type: 
Unable to find compiled kernel hash for node '
Unable to find node 
Unable to get an allocator
Unable to serialize model as it contains compiled nodes. Please disable any execution providers which generate compiled nodes.
Unable to shrink arena: 
Unable to write the provided PrePackedWeights instance into the container
Unactivated gate outputs from forget, update, and output gates, pre-activation.
UNDEFINED
Undefined tensor type!
unexpected 
unexpected )
Unexpected attribute type.
Unexpected CAST_TO value of 
Unexpected data type for Clip input of 
Unexpected data type for Clip 'min' input of 
Unexpected element size of 
unexpected error
unexpected failure
Unexpected input data type. Actual: (
Unexpected literal type.
Unexpected mode of 
Unexpected mode:
Unexpected NORMALIZE value of 
Unexpected op in Regexp::Equal: 
Unexpected opcode in IsMatch: 
Unexpected opcode in short circuit: 
Unexpected opcode: 
Unexpected re_anchor value: 
Unexpected special state in RunStateOnByte
Unexpected type.
Unexpected value for 'add_second_class' of 
unhandled 
Unhandled 
unhandled opcode: 
Unhandled type: %d
UnhandledExceptionFilter
unidir mask is not constant
unidir mask shape not expected
unidirectional
unimplemented activation: 
Unique
unk__
unknown
Unknown aggregation function in TreeEnsemble.
Unknown AutoPadType String
Unknown Category and zeros = 0.
Unknown encoding 
unknown error
Unknown error during EndProfiling()
Unknown exception
Unknown exception in Load()
Unknown exception was caught by catch-all handler.
unknown kernel type
unknown round: 
Unknown tensor type of 
unknown token
unknown_dim == -1
UnknownEvent
Unloading DSO 
unnamed_thread_pool
unordered_map/set too long
UnpackTensor: the pre-allocate size does not match the size in proto
UnpackTensor: the pre-allocated size does not match the raw data size, expected 
Unrecognized attribute: 
Unrecognized data_type (tensor name: 
Unrecognized type value case (value_info name: 
Unsqueeze
unsqueeze_after_gather axes value not expected
UnsqueezeElimination
UnsqueezeElimination cannot remove node 
UnsqueezeElimination_
Unsuported type proto value case.
Unsupported attribute value type of 
Unsupported AutoPad Type.
Unsupported convolution size.
Unsupported data type of 
Unsupported data type: 
unsupported data type: 
Unsupported device allocator in the context of pre-packed weights caching: 
Unsupported device id in the memory arena shrink list: 
Unsupported device specified in the memory arena shrink list: 
Unsupported 'dtype' in QLinear Pooling:
Unsupported 'dtype' value: 
Unsupported element size: 
Unsupported execution_mode value in ORT config: 
Unsupported graph_optimization_level value in ORT config: 
Unsupported indices_format passed
Unsupported input data type of 
Unsupported input element type of 
Unsupported input type
Unsupported input type in DepthToSpace op: 
Unsupported input type in SpaceToDepth op: 
Unsupported level
Unsupported mode '
Unsupported model IR version: 
Unsupported non-raw-data data type!
Unsupported optimization level: 
Unsupported OrtValue type to copy between device.
Unsupported OrtValue type.
Unsupported output datatype with size: 
Unsupported output type of 
Unsupported pooling size : 
Unsupported pooling size.
Unsupported Source/Target type=
Unsupported sparse tensor data type of 
Unsupported tensor type of 
Unsupported transformation mode '
Unsupported type
Unsupported type:
Unsupported type: 
Unsupported value attribute datatype with size: 
Unsupported value attribute datatype: 
Unsupported value for enable_profiling option: 
Unsupported value for inter_op_num_threads: 
Unsupported value for intra_op_num_threads: 
Unsupported version '
Unsupported X type: 
Unsupported Y type: 
unused
up_node should be parent of down_node and NodeArg slots of the edge between up_node and down_node should be (0, 0).
up_node should have only one Edge that points to down_node and its output is not graph output
updates
updates shape: 
updates tensor should have shape equal to indices.shape[:-1] + data.shape[indices.shape[-1]:]. 
UpdatesTensor
uPfD;"s
UPH+UHH
UpH9E
upL;}xA
upper
UPPER
Upper boundary of the output values.
Upsample
Upsample operator
Upsample: input shape needs to be at least a single dimension.
Upsample: input tensor's dimension does not match the scales.
Upsample: input/output value is nullptr
Upsample: input/output value's dimension mismatch
Upsample: unexpected mode
uQD9H uKH
uRD8m
uRIcF$H
us(={
uS;r0t
Use GetStringTensor*() API to retrieve strings
Use MakeBlockSparseStrings
Use MakeCooStrings
Use MakeCsrStrings
use_approximation
use_past
UseClipThreshold
usefp16
Using an input in multiple nodes on different devices is not supported currently. Input:
Using cached version of pre-packed weight for constant initializer: 
Using global/env threadpools since use_per_session_threads_ is false
Using transpose optimized pattern
Using user supplied initializer with name (
USVWATAUAVAWH
USVWATAUAVH
USVWATAVAWH
USVWAUAVAWH
USVWAVAWH
USVWAVH
USVWH
ut9{(
UTCReplace_AppSessionGuid
utils::HasDataType(t_proto)
utils::HasElemType(thisProto->optional_type())
utils::HasElemType(thisProto->sequence_type())
utils::HasElemType(thisProto->sparse_tensor_type())
utils::HasElemType(thisProto->tensor_type())
utils::HasKeyType(thisProto->map_type())
utils::HasName(sparse_tensor)
utils::IsPrimitiveDataType<T>(dtype_)
uu9_(
uUI;Q
UUUUUUU
UVATAVAWH
UVAUAVAWH
UVAVH
uVH9Y
UVWATAUAVAW
UVWATAUAVAWH
UVWATAVH
UVWATAWH
UVWAUAVH
UVWAVAWH
UvZH+
UWATAUAVH
UWATAUAWH
UWATAVAWH
UWATH
UWAUAVAWH
UWAUH
UWAVH
UWAWH
UxH+UpH
UXI;U`t/H
uy9_(
uyD9o(
uz9z(t7H
v >= 0 && static_cast<uint64_t>(v) <= std::numeric_limits<size_t>::max()
V A+V0A
V H;V(t
V H+V
V HcF
V I+V
v!yQR
v&.(,
V&X,V ZM
V(+V0
V(A+V0A
V(H+V H
V(L;2
v(xFpBz
v:fD;
V@H+V8H
v_final_and_scan_outputs
v_initial
v_reshape initializer value is not expected
V`H;Vht
v0I;Q
V8I+V0H
valid
VALID
ValidateUnidirMask returns false for mask_slice
Validating no unexpected access using an invalid node_index. Got:
Value
value
value at X[t][n] >= seqLengths[n].
Value expected but not found.
Value of alpha
Value of alpha default to 0.2
Value of alpha.
Value of attribute 
Value of beta
Value of beta default to 0.5
Value of beta.
value of k must not be negative
Value tensor should be a 1D tensor of size 1 with the same type as that of the input tensor
value too large
Value type is not supported yet: 
Value used for extrapolation, when applicable. Default is 0.0f. 
Value(s) to change to
Value(s) to change to.
value_cache
value_float
value_floats
value_info
value_int
value_ints
value_proto != nullptr
value_string
value_strings
value_tensor->DataType() == data_type && value_tensor->Shape().Size() == 1
value_type
value_type != nullptr
ValueDataType
ValueDelta
values
Values
Values greater than this are mapped to 1, others to 0.
values in 'axes' are beyond the bounds of the computed output shape
values is 
values of data_type '
Values size 
values.size() == static_cast<size_t>(attr->floats_size())
values.size() == static_cast<size_t>(attr->ints_size())
values_count == index_size
values_floats
values_int64s
values_strings
ValueStart
ValuesTensor
Var = Sub (MeanOfSquare, SquareOfMean)
VarFileInfo
VarianceH
VarianceTensor
VarPlusEpsilon = Add (Var, Epsilon)
VATAUAVAWH
VAVAWH
VbbeH
vb'vb'v
VBzc/
vd<[u)
vD9w(
vector too long
vector<bool> too long
vectors_per_class
vgV/m
VhH;Vpt
vHhH=V
via some custom implementation such as CuDNN.
Violation of the requirment that all input tensors must have the same data type.
VirtualAlloc
VirtualFree
VirtualProtect
VirtualQuery
VitisAIEH9
VitisAIExecutionProvider
VIWEF
Vn|M}j
VnZf\.^6`\b d<f
vOdYk
VpH;Vxt
VPI;Q
VPI;VXt
VPX4Z2
VRj(fC
VrtEO
VS_VERSION_INFO
vSs"Qq~
VUUUA
VUUUUUUUH
vvZtN
VWATAUAVAWH
VWATAUAVAWL
VWATAUAVH
VWATAUAWH
VWATAVAWH
VWAUAVAWH
VWAUAVH
VWAUH
VWAVH
VWAWH
VXH;V`t
VXH+VPH
w A+w0A
w A8p t.I
W H;W(t
W I+W
w IcG
W(+W0
W(A+W0A
w(A+w0A
W(A+W0A
w(A+w0A
W(A+W0A
W(H;W0t
W(H9h u@H
W(Hc\$PH
W,ROV
W/#w7dl?
W@8o`
W@H;WHt
W@H+W8H
w_^[]
w_scale
W_scale
w_zero_point
W_zero_point
W_zero_point_data[i] == W_zero_point_value
w{dx:
w|tTA
W>}H*
W5#H3
W6:y#
w6nh?
W8H;W@t
wA\A]A^_^[]
WaitForSingleObject
WaitForSingleObjectEx
WaitRevoke
WakeAllConditionVariable
WakeConditionVariable
Walk NULL
Wancho
Warang_Citi
WARNING
Warning: Checker does not support models with experimental ops: 
Warning: Shape inference does not support
Warning: Unsupported operator 
'was added but does not exist. 
Washington1
WATAUAVAWD
WATAUAVAWH
WATAVAWH
WATAVH
WAUAVH
WAVAWH
wcsnlen
We do not expect duplicate registration of types for: 
We do not support type [
We don't expect custom allocators for non-tensor types, so a shape is mandatory here.
weight
weight and zero_point pair is expected to have same type.
Weight point must be constant
Weight rank must be 1.
Weight zero point must be zero
weight_gather
weight_gather_sum
weight_gather_temp
weight_gather_temp_1
weight_scale
weight_zero_point
weights
Weights of the intercepts, if used.
Weights of the model(s).
weights.quant_para_
weights_to_be_filled_in.buffers_.size() > 0
WeightTensor
wet-A+
When computing the output of the hidden gate, apply the linear transformation before multiplying by the output of the reset gate.
When coordinate_transformation_mode is "tf_crop_and_resize" and x_original is outside the range [0, length_original - 1], this value is used as the corresponding output value. Default is 0.0f.
When the session is not configured to use per session threadpools, the env must be created with the the CreateEnvWithGlobalThreadPools API.
When training_mode=False, extra outputs are invalid.
When training_mode=False:
Where
where const not matched.
where N is the population size (this formula does not use sample size N - 1).
where:
Whether A should be transposed
Whether A should be transposed on the last two dimensions before doing multiplication
Whether B should be transposed
Whether B should be transposed on the last two dimensions before doing multiplication
Whether C should be broadcasted
Whether every token can only attend to previous tokens. Default value is 0.
Whether include pad pixels when calculating values for the edges. Default is 0, doesn't count include pad.
Whether the operator should behave like fmod (default=0 meaning it will do integer mods); Set this to 1 to force fmod treatment
Whether to return the elements in sorted order.
Whether to return the top-K largest or smallest elements.
Whether to select the last index or the first index if the {name} appears in multiple indices, default is False (first index).
Whether to use ceil or floor (default) to compute the output shape.
WhH;Wpt
WHH;WPt
Which axis to concat on
Which axis to concat on.  Default value is 1.
Which axis to concat on. A negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(inputs)..
Which axis to concat on. Accepted range in `[-r, r - 1]`, where `r` is the rank of input tensors. When `new_axis` is 1, accepted range is `[-r - 1, r]`. 
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
Which axis to gather on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1]
Which axis to scatter on. Negative value means counting dimensions from the back. Accepted range is [-r, r-1] where r = rank(data).
Which axis to split on
Which axis to split on. 
Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1] where r = rank(input).
Which axis to split on. A negative value means counting dimensions from the back. Accepted range is [-rank, rank-1].
which does not equal the specified override of 
while parsing 
WideCharToMultiByte
width_scale
WilError_03
window
Windows.Foundation.Collections.IIterator`1<Windows.Foundation.Collections.IKeyValuePair`2<String, UInt32>>
Windows.Foundation.Collections.IKeyValuePair`2<String, UInt32>
Windows.Foundation.Collections.IMap`2<String, UInt32>
Windows::AI::MachineLearning::Adapter::SessionRegisterCustomRegistry
WindowSize
WinmlRuleTransformer
with a fixed dimension size 
with activation 
wjH9Q
Word embedding scale must be a scalar or 1D tensor of size 1
Word embedding shape not expected.
Word embedding zero point must be a scalar or 1D tensor of size 1
word_embedding
word_embedding and position_embedding shall have same dimension 1
word_embedding and segment_embedding shall have same dimension 1
word_embedding is expected to have 2 dimensions, got 
word_embedding should have 2 dimensions and dimension size is known.
word_embedding_quant
word_embedding_scale
word_embedding_zero_point
WordConvEmbedding
Works on NHWC layout or not? Default not.
wouKL
wPI;u
Writing profiler data to file 
Wrong input type encountered for zero point input def @
Wrong input type encountered for zero point of quantized input @
Wrong op_type name for running propagation: 
wrong protocol type
wstr != wconv_error
wTH;J
X != nullptr
X and mask should have the same shape
x ATAUAVAWH
x ATAVAW
x ATAVAWH
x ATAVAWL
x AUAVAWH
x AVAWH
x AVAWI
x AVAWL
x AVAWLc
x AVH
x AVL
x AVM
x AWH
X dims is empty.
X H+X
X H9{
X I+X
X input is required!
x L+x
X L9{
X L9c
X L9s
X num_dims does not match W num_dims.
x UATAUAVAWH
x UATAUH
x UATAVH
x UATAWH
x UAUAVH
x UAVAWH
X UVWATAUAVAWH
X UVWAVAWH
X UVWH
X":$"
X">$"
X%zn3
x&;CP}!L
x&L;_(} M
x&L;O(} M
X(B\<p>NZ
x(D$@
x(L$0
x(T$ 
X(T\RM
X(T~Rvl6n
X(T6Rm
x(thpDt
x(tNp`tD
x(wEq
x)T$`H
X?f|wID
X@D8cDt
X_^[]
x_^[]
X_alpha
X_bias = Add (X, bias)
X_bias = Identity (X)
X_Exp
X_greater
X_Log
X_LogSM
X_LogSM_NCD
X_NCD
X_NDC
x_original = (x_resized + 0.5) / scale - 0.5, <br/>
x_original = (x_resized + 0.5) / scale, <br/>
x_original = length_resized > 1 ? (x_resized + 0.5) / scale - 0.5 : 0, <br/>
x_original = length_resized > 1 ? start_x * (length_original - 1) + x_resized * (end_x - start_x) * (length_original - 1) / (length_resized - 1) : 0.5 * (start_x + end_x) * (length_original - 1).
x_original = x_resized * (length_original - 1) / (length_resized - 1), <br/>
x_original = x_resized / scale, <br/>
x_ptr != nullptr
X_random
X_randomH
X_rank == 4
X_ReduceMax
X_ReduceSum
x_scale
X_scale
X_shape
X_shape.NumDimensions() == 4
X_shape.size() == 4
X_squared
X_Sub
X_variance
X_zero_point
x_zero_point
x_zero_point must be null or 1D tensor with size 
x_zero_point must be null or a scalar or 1D tensor or size 1.
X->Shape().GetDims().size() == output_dims.size()
X->Shape().NumDimensions() == 4
x0Hc@(L
x0L!e
X0V0T
X2D = Flatten (X)
x4z2t8v(|
X59;N
X5Z<N
x6H;A8}0H;
x9KCg
XA_A^_^][
xA_A^A]A\_^[]
XA_A^A]A\_^[]
xA_A^A]A\_^[]
xA_A^A]A\_^][
XA_A^A]A\_^][
xA_A^A]A\_^][
XA_A^A]A\_^][
xA_A^A]A\_^][
xAwOw
X-device copy of strings not supported
xecutionH9H
xH;A u
xH;F8tU
xhHc/A
xI;N u
xI;N8u
Xk2e=
XL$0f
XNNTd
xnt2r8p
Xsb|]
XShape = Shape (X)
xSu$W
xtshn8
XU = Cast (X2D)
xxG'iL
Y = (X - current_mean) / sqrt(current_var + epsilon) * scale + B
Y = (X - input_mean) / sqrt(input_var + epsilon) * scale + B
Y = Reshape (Biased, XShape)
Y = softmax(scores + bias)) with simple broadcast on bias. Intended to specialize softmax(scores + additive_mask) commonly found in transformer models.
Y A8X t/I
y H!E
y H+y
y(+y0A
y(H;]
Y*Se1&
Y,!F,1#
Y\$LH
y_scale
Y_scale
y_scale == nullptr || IsScalarOr1ElementVector(y_scale)
y_zero_point
Y_zero_point
y_zp == nullptr || IsScalarOr1ElementVector(y_zp)
y<#r.H
Y2}>D
Y5a;N
y8H+y0H
Yd$HH
YD$PH
YE9gp
yet this opset 
Yezidi
YhH;Yp
ywR9DQ
yx-!T
yxI;]
yxxxxxxxH+
z 1Y"B
z 9s(u
z".$,
z#u!I
z%u#3
z&u$3
z(.*,
z(|6~l
z(H;]
z(u&3
Z(X|RpTf\
z)u'3
z*u(3
Z,\2ZJ^JbTdP^JfVh\^JbZdP^JfZhT^JbTd\^(`*j ^
Z.\6^p` b6dnf h6jvl n`p6t
z+u)H
z>u<H
z1u/I;
z1u/L;
z2u0L;
z3u1I;
z4u2I;
z5u3I;
z8u6E3
Zanabazar_Square
zAu?H
zCuAI
zdaInB
zero_point == nullptr || std::all_of(zero_point, zero_point + x_zero_point->Shape().Size(), [](int32_t zp) { return zp == 0; })
zero_point_ptr == nullptr || (zero_point_ptr->Shape().NumDimensions() == 1 && zero_point_ptr->Shape()[0] == broadcast_dim)
zero_point_ptr == nullptr || IsScalarOr1ElementVector(zero_point_ptr)
Zero1D = Constant()
ZeroPointTensor
zeros
zFuDA
zGuEH
ZH>/t
ZipMap
Zipmap does not support empty dim count
Zipmap only supports 1D or 2D input tensors
zIuGI
ZN^N`
ZnV2T8R
zoU L
z-u+H
ZvD:\a\_work\1\s\engine\lotus\onnxruntime\core\providers\dml\DmlExecutionProvider\src\CommandQueue.cpp
zvutH
